{"completion":{"completedItemIds":["pn1623","pn1626","pn1628","pn2150","pn2153","pn2029","pn1710","pn626","pn2159","pn444","pn2157","pn464","pn601","pn602","pn1099","pn1092","pn1095","pn1097","pn264","pn263","pn116","pn111","pn113","pn119","pn118","pn965","pn286","pn967","pn288","pn761","pn1161","pn1362","pn1360","pn847","pn845","pn1942","pn1949","pn2447","pn2442","pn2441","pn2449","pn2140","pn1896","pn2020","pn2022","pn2031","pn2027","pn1763","pn1760","pn1421","pn1423","pn1425","pn1426","pn1428","pn1399","pn1398","pn614","pn1081","pn279","pn271","pn272","pn276","pn104","pn297","pn292","pn1171","pn1179","pn1375","pn1377","pn1372","pn621","pn2522","pn2525","pn1954","pn1958","pn2454","pn2451","pn1883","pn1881","pn2041","pn2046","pn2048","pn1773","pn1776","pn1414","pn1417","pn1410","pn1413","pn2193","pn590","pn1569","pn443","pn139","pn138","pn916","pn1188","pn1186","pn1182","pn1183","pn1341","pn1343","pn1347","pn1969","pn2463","pn2464","pn2293","pn2294","pn589","pn583","pn581","pn586","pn1579","pn455","pn121","pn122","pn906","pn905","pn1199","pn1190","pn1193","pn1192","pn639","pn1354","pn1351","pn838","pn2128","pn1978","pn1009","pn1976","pn169","pn2472","pn532","pn1750","pn1756","pn1758","pn1992","pn2266","pn1503","pn2084","pn337","pn330","pn150","pn155","pn1745","pn1325","pn1742","pn806","pn802","pn1036","pn1034","pn1032","pn1987","pn1982","pn1983","pn1667","pn2401","pn2406","pn2317","pn2074","pn2274","pn2277","pn2276","pn1513","pn1514","pn1517","pn1518","pn2095","pn2094","pn2096","pn2090","pn495","pn490","pn320","pn1200","pn1203","pn924","pn142","pn147","pn1330","pn1333","pn1337","pn1336","pn810","pn1020","pn796","pn2417","pn1682","pn1684","pn2303","pn2242","pn2244","pn1549","to108","to105","to104","to107","to106","to101","to103","to102","pn1525","pn1521","pn319","pn313","pn1238","pn799","pn1236","pn1237","pn558","pn730","pn555","pn951","pn950","pn734","pn736","pn1014","pn1015","pn2424","pn2420","pn1646","pn1834","pn2330","pn426","pn1586","pn1642","pn1587","to122","to127","pn1783","to118","pn1651","to117","to114","to112","to113","to110","pn1227","pn1225","pn1222","pn785","pn787","pn549","pn547","pn541","pn941","pn763","pn1316","pn164","pn166","pn1007","pn2432","pn1821","pn1820","pn2328","pn2327","pn1796","pn2220","pn2226","pn2227","pn2225","to129","to128","to123","pn2134","to120","pn1558","pn1635","pn1252","pn1257","pn1255","pn1490","pn576","pn751","pn750","pn208","pn205","pn683","pn687","pn686","pn371","pn372","pn757","pn756","pn755","pn977","pn198","pn975","pn999","pn1103","pn1818","pn1811","pn1814","pn1817","pn2358","pn2235","to134","to135","to136","to137","to131","to132","to133","pn1704","pn1670","pn1675","pn1709","pn1241","pn1242","pn1482","pn1485","pn1488","pn219","pn216","pn692","pn691","pn361","pn366","pn189","pn186","pn180","pn983","pn988","pn1110","pn1071","pn191","pn190","pn1806","pn1800","pn1904","pn2343","pn1901","pn2208","pn2200","pn2202","pn2203","pn2119","pn2112","pn2115","pn2117","pn1275","pn514","pn1475","pn1472","pn1473","pn1470","pn1471","pn739","pn228","pn223","pn222","pn737","pn224","pn428","pn425","pn794","pn641","pn643","pn648","pn791","pn1055","pn1057","pn1296","pn1295","pn1293","pn1290","pn1298","pn2268","pn1120","pn1123","pn775","pn1872","pn896","pn2372","pn897","to126","pn2216","pn2214","pn2105","pn2103","pn183","pn1617","pn1727","pn1724","pn1722","pn1269","pn1268","pn1262","pn1264","pn505","pn1460","pn1583","pn728","pn438","pn345","pn657","pn654","pn653","pn650","pn1046","pn235","pn233","pn239","pn1865","pn1867","pn2368","pn966","pn2560","pn171","pn1918","pn1915","pn1916","pn1911","to111","pn2175","pn2054","pn1736","pn1732","pn2005","pn2003","pn2001","pn1452","pn534","pn1454","pn400","pn405","pn404","pn664","pn887","pn884","pn883","pn395","pn399","pn241","pn714","pn245","pn248","pn718","pn435","pn2483","pn2487","pn2488","pn2489","pn866","pn862","pn2284","pn1859","pn1850","pn340","pn2399","pn2129","pn2394","pn343","pn431","pn1923","pn2160","pn1632","pn2168","pn1700","pn1707","pn2016","pn2011","pn2010","pn1447","pn1446","pn1442","pn1448","pn529","pn521","pn525","pn526","pn493","pn419","pn1281","pn898","pn677","pn671","pn672","pn673","pn389","pn385","pn386","pn701","pn250","pn704","pn255","pn2490","pn876","pn758","pn420","pn1845","pn2380","pn1936","pn1932","pn1282"],"incompletedItemIds":[]},"sessionMaking":true,"hierarchyLastUpdated":-1,"users":{},"sessions":{"HCI4D: Lost and Found in Translation":{"label":"HCI4D: Lost and Found in Translation","members":["pn1623","pn1414","pn1203","pn216","pn223"],"numMembers":5,"lastTimeUpdated":0},"Games: Exergame Design":{"label":"Games: Exergame Design","members":["pn1626","pn1183","pn122","pn1709"],"numMembers":4,"lastTimeUpdated":0},"UIST: Small Devices":{"label":"UIST: Small Devices","members":["pn1628","pn142","pn1007","pn372","pn1488"],"numMembers":5,"lastTimeUpdated":0},"UIST: Shape-Changers":{"label":"UIST: Shape-Changers","members":["pn2150","pn2041","pn1186","pn313","pn385"],"numMembers":5,"lastTimeUpdated":0},"Health: Stress":{"label":"Health: Stress","members":["pn2153","pn1188","pn1514","pn490"],"numMembers":4,"lastTimeUpdated":0},"Making: 3D printing":{"label":"Making: 3D printing","members":["pn2029","pn297","pn1034","pn1911"],"numMembers":4,"lastTimeUpdated":0},"Social: Social Media Applied":{"label":"Social: Social Media Applied","members":["pn1710","pn2159","pn1763","pn1806"],"numMembers":4,"lastTimeUpdated":0},"Methods and Models: The Eyes Have It":{"label":"Methods and Models: The Eyes Have It","members":["pn626","pn1982","pn951","pn405","pn718"],"numMembers":5,"lastTimeUpdated":0},"Health: Network of care":{"label":"Health: Network of care","members":["pn444","pn1896","pn2074","to111"],"numMembers":4,"lastTimeUpdated":0},"UIST: novel keyboards":{"label":"UIST: novel keyboards","members":["pn2157","pn2454","pn138","pn428"],"numMembers":4,"lastTimeUpdated":0},"Touch: Touch-me Mobile Interaction":{"label":"Touch: Touch-me Mobile Interaction","members":["pn464","pn425","pn1865","pn525"],"numMembers":4,"lastTimeUpdated":0},"People: Kinecting People":{"label":"People: Kinecting People","members":["pn601","pn1099","pn111","pn139","pn420"],"numMembers":5,"lastTimeUpdated":0},"HCI4D: Shopping and Economy":{"label":"HCI4D: Shopping and Economy","members":["pn602","pn2193","pn1032","pn2276"],"numMembers":4,"lastTimeUpdated":0},"Touch: Touch":{"label":"Touch: Touch","members":["pn1092","pn756","pn988","pn2372"],"numMembers":4,"lastTimeUpdated":0},"Viz: Visual Aesthetics":{"label":"Viz: Visual Aesthetics","members":["pn1095","pn555","pn701","pn2490"],"numMembers":4,"lastTimeUpdated":0},"Security: Passwords":{"label":"Security: Passwords","members":["pn1097","pn1399","pn2090","pn2227","pn757"],"numMembers":5,"lastTimeUpdated":0},"UIST: Pointing":{"label":"UIST: Pointing","members":["pn264","pn2449","pn2432","pn755"],"numMembers":4,"lastTimeUpdated":0},"CSCW: Crowdsourcing":{"label":"CSCW: Crowdsourcing","members":["pn263","pn150","pn1103","to137"],"numMembers":4,"lastTimeUpdated":0},"Information in Use":{"label":"Information in Use","members":["pn116","pn1760","pn1413","to129","pn431"],"numMembers":5,"lastTimeUpdated":0},"Touch: Multitouchy Feely":{"label":"Touch: Multitouchy Feely","members":["pn113","pn426","pn2117","pn896","pn343"],"numMembers":5,"lastTimeUpdated":0},"HCI4D: Finances":{"label":"HCI4D: Finances","members":["pn119","pn2134","pn186","pn671"],"numMembers":4,"lastTimeUpdated":0},"Design: Research through Design":{"label":"Design: Research through Design","members":["pn118","pn2220","pn1442","pn758"],"numMembers":4,"lastTimeUpdated":0},"UIST: On the surface":{"label":"UIST: On the surface","members":["pn965","pn1756","pn1225","pn1727","pn1936"],"numMembers":5,"lastTimeUpdated":0},"HCI4D: Emergency Response":{"label":"HCI4D: Emergency Response","members":["pn286","pn1014","pn1454","pn1281"],"numMembers":4,"lastTimeUpdated":0},"Making: how things don't work":{"label":"Making: how things don't work","members":["pn967","pn1682","pn643","pn2011"],"numMembers":4,"lastTimeUpdated":0},"Displays: Head-Worn Displays (UIST)":{"label":"Displays: Head-Worn Displays (UIST)","members":["pn288","pn589","pn736","pn222"],"numMembers":4,"lastTimeUpdated":0},"Health: Persuade Me":{"label":"Health: Persuade Me","members":["pn761","pn121","pn2317","pn2274"],"numMembers":4,"lastTimeUpdated":0},"CSCW: interactions in the crowd":{"label":"CSCW: interactions in the crowd","members":["pn1161","pn810","to107","pn526"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Learning and Education":{"label":"HCI4D: Learning and Education","members":["pn1362","pn1182","pn1817","pn2200"],"numMembers":4,"lastTimeUpdated":0},"UBI: Audio Interaction":{"label":"UBI: Audio Interaction","members":["pn1360","pn276","pn1193","pn1586"],"numMembers":4,"lastTimeUpdated":0},"UIST: Gesture-based interaction":{"label":"UIST: Gesture-based interaction","members":["pn847","pn1425","pn549","pn2216"],"numMembers":4,"lastTimeUpdated":0},"Viz: Studying Visualization":{"label":"Viz: Studying Visualization","members":["pn845","pn2027","pn1015","pn1783","to128","to126"],"numMembers":6,"lastTimeUpdated":0},"Games: Fun N Play":{"label":"Games: Fun N Play","members":["pn1942","pn2084","pn1987","pn791"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Sustainability and Everyday Practices":{"label":"HCI4D: Sustainability and Everyday Practices","members":["pn1949","to104","to117","to133"],"numMembers":4,"lastTimeUpdated":0},"Systems: Development Tools":{"label":"Systems: Development Tools","members":["pn2447","pn271","pn2103","pn664"],"numMembers":4,"lastTimeUpdated":0},"Viz: Visual System Design":{"label":"Viz: Visual System Design","members":["pn2442","pn1337","pn1316","pn966"],"numMembers":4,"lastTimeUpdated":0},"Systems: Tutorials":{"label":"Systems: Tutorials","members":["pn2441","pn1020","pn224","pn884"],"numMembers":4,"lastTimeUpdated":0},"Design: Critical Design":{"label":"Design: Critical Design","members":["pn2140","pn581","pn1667","pn999"],"numMembers":4,"lastTimeUpdated":0},"Health: Health and Everyday Life":{"label":"Health: Health and Everyday Life","members":["pn2020","pn1377","pn639","pn686","pn2284"],"numMembers":5,"lastTimeUpdated":0},"UIST: Gesture Entry":{"label":"UIST: Gesture Entry","members":["pn2022","pn1651","pn1473","pn898"],"numMembers":4,"lastTimeUpdated":0},"Art: Narratives and Storytelling":{"label":"Art: Narratives and Storytelling","members":["pn2031","pn443","to102","pn1820"],"numMembers":4,"lastTimeUpdated":0},"CSCW: Crowds and Creativity":{"label":"CSCW: Crowds and Creativity","members":["pn1421","pn1503","pn2235","pn2343","pn2208"],"numMembers":5,"lastTimeUpdated":0},"3D: 3D modeling":{"label":"3D: 3D modeling","members":["pn1423","pn330","pn1513","pn147","pn1262"],"numMembers":5,"lastTimeUpdated":0},"UBI: Activity Recognition":{"label":"UBI: Activity Recognition","members":["pn1426","pn1237","to134","pn1055","pn876"],"numMembers":5,"lastTimeUpdated":0},"Making: Hacking":{"label":"Making: Hacking","members":["pn1428","pn1081","pn2327","pn1904","pn529"],"numMembers":5,"lastTimeUpdated":0},"Systems: Machines Interactively Learning":{"label":"Systems: Machines Interactively Learning","members":["pn1398","pn1485","pn650","pn171"],"numMembers":4,"lastTimeUpdated":0},"Art: Image and Animation Authoring":{"label":"Art: Image and Animation Authoring","members":["pn614","pn2451","pn1992","pn228"],"numMembers":4,"lastTimeUpdated":0},"Displays: Interactive Whitebaords and Public Displays":{"label":"Displays: Interactive Whitebaords and Public Displays","members":["pn279","to105","pn166","pn1269"],"numMembers":4,"lastTimeUpdated":0},"Methods and Models: User Model 2":{"label":"Methods and Models: User Model 2","members":["pn272","pn2119","pn2105","pn1916","pn2394"],"numMembers":5,"lastTimeUpdated":0},"Systems: Multi-Device User Interfaces":{"label":"Systems: Multi-Device User Interfaces","members":["pn104","pn1200","pn1336","pn205"],"numMembers":4,"lastTimeUpdated":0},"Methods and Models: new HCI paradigms":{"label":"Methods and Models: new HCI paradigms","members":["pn292","pn1417","pn838","pn164"],"numMembers":4,"lastTimeUpdated":0},"Health: HCI for Rehabilitation":{"label":"Health: HCI for Rehabilitation","members":["pn1171","pn1736","pn2003","pn2487"],"numMembers":4,"lastTimeUpdated":0},"Systems: Presentations":{"label":"Systems: Presentations","members":["pn1179","pn1773","pn2303","pn1587"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Multilingual Communication":{"label":"HCI4D: Multilingual Communication","members":["pn1375","pn1347","pn1354","pn1867","pn248"],"numMembers":5,"lastTimeUpdated":0},"Displays: Novel Mobile Displays (UIST)":{"label":"Displays: Novel Mobile Displays (UIST)","members":["pn1372","pn654","pn2168","pn672"],"numMembers":4,"lastTimeUpdated":0},"Transportation: Transportation and Wayfinding":{"label":"Transportation: Transportation and Wayfinding","members":["pn621","pn2420","pn1796","pn2203","pn1850","pn250"],"numMembers":6,"lastTimeUpdated":0},"UBI: Smart Homes":{"label":"UBI: Smart Homes","members":["pn2522","pn1192","pn155","pn2244"],"numMembers":4,"lastTimeUpdated":0},"Security: Privacy":{"label":"Security: Privacy","members":["pn2525","pn1776","pn2463","pn2112"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: City Communities":{"label":"HCI4D: City Communities","members":["pn1954","pn2401","pn558","to112"],"numMembers":4,"lastTimeUpdated":0},"Social: Connecting over Video":{"label":"Social: Connecting over Video","members":["pn1958","pn1199","pn532","pn1333","pn883"],"numMembers":5,"lastTimeUpdated":0},"Displays: Displays (UIST)":{"label":"Displays: Displays (UIST)","members":["pn1883","pn1983","pn1222","pn389"],"numMembers":4,"lastTimeUpdated":0},"CSCW: Document and Intertextuality":{"label":"CSCW: Document and Intertextuality","members":["pn1881","pn2225","pn514","pn340"],"numMembers":4,"lastTimeUpdated":0},"Games: Games":{"label":"Games: Games","members":["pn2046","pn1518","pn799","pn683","pn1901"],"numMembers":5,"lastTimeUpdated":0},"Design: Design Theory":{"label":"Design: Design Theory","members":["pn2048","pn1642","pn1268","pn2129"],"numMembers":4,"lastTimeUpdated":0},"Social: Online Communities":{"label":"Social: Online Communities","members":["pn1410","pn1341","pn2095","pn1918"],"numMembers":4,"lastTimeUpdated":0},"People: Personal Information":{"label":"People: Personal Information","members":["pn590","pn2094","pn785","pn255","pn2380"],"numMembers":5,"lastTimeUpdated":0},"Art: Museum Experience":{"label":"Art: Museum Experience","members":["pn1569","pn1704","pn395","pn1632"],"numMembers":4,"lastTimeUpdated":0},"3D: The third dimension":{"label":"3D: The third dimension","members":["pn916","pn1758","pn734","pn977"],"numMembers":4,"lastTimeUpdated":0},"Social: Do Ask Do Tell":{"label":"Social: Do Ask Do Tell","members":["pn1343","pn1236","pn1255","pn1490","pn691"],"numMembers":5,"lastTimeUpdated":0},"Transportation: Driving Me Mental":{"label":"Transportation: Driving Me Mental","members":["pn1969","to131","pn648","pn233"],"numMembers":4,"lastTimeUpdated":0},"UIST: Text Entry and Evaluation":{"label":"UIST: Text Entry and Evaluation","members":["pn2464","to118","to135","pn404","pn1700"],"numMembers":5,"lastTimeUpdated":0},"Health: HealthyCHI":{"label":"Health: HealthyCHI","members":["pn2293","pn1475","pn887","pn677"],"numMembers":4,"lastTimeUpdated":0},"CSCW: Coordination & Collaboration":{"label":"CSCW: Coordination & Collaboration","members":["pn2294","pn2424","pn1470","pn1123"],"numMembers":4,"lastTimeUpdated":0},"Methods and Models: User Model 1":{"label":"Methods and Models: User Model 1","members":["pn583","pn750","pn1057","pn1293","pn2560"],"numMembers":5,"lastTimeUpdated":0},"Human-Robot Interaction":{"label":"Human-Robot Interaction","members":["pn586","pn1227","pn1252","pn2358","pn1722"],"numMembers":5,"lastTimeUpdated":0},"Art: Performance 2":{"label":"Art: Performance 2","members":["pn1579","pn547","pn541","pn1452","pn534"],"numMembers":5,"lastTimeUpdated":0},"Web: Web":{"label":"Web: Web","members":["pn455","to120","pn1670","pn1071"],"numMembers":4,"lastTimeUpdated":0},"Health: Older Adults":{"label":"Health: Older Adults","members":["pn906","to113","pn2016","pn704"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: CHI for Social Development":{"label":"HCI4D: CHI for Social Development","members":["pn905","pn1978","pn1325","pn2226"],"numMembers":4,"lastTimeUpdated":0},"Social: Computer Mediated Romance":{"label":"Social: Computer Mediated Romance","members":["pn1190","pn1238","pn941","pn2054"],"numMembers":4,"lastTimeUpdated":0},"CSCW: Interruptions and Distractions":{"label":"CSCW: Interruptions and Distractions","members":["pn1351","pn806","pn641","pn1282"],"numMembers":4,"lastTimeUpdated":0},"Systems: Desktop Search and History":{"label":"Systems: Desktop Search and History","members":["pn2128","pn361","pn239","pn400"],"numMembers":4,"lastTimeUpdated":0},"Health: Social Media and Health":{"label":"Health: Social Media and Health","members":["pn1009","pn802","pn1036","pn1814"],"numMembers":4,"lastTimeUpdated":0},"Security: Security":{"label":"Security: Security","members":["pn1976","pn1811","pn191","pn1724","pn2005"],"numMembers":5,"lastTimeUpdated":0},"HCI4D: doing the right thing - ethics":{"label":"HCI4D: doing the right thing - ethics","members":["pn169","pn399","pn2489","pn2160"],"numMembers":4,"lastTimeUpdated":0},"Games: Education Games":{"label":"Games: Education Games","members":["pn2472","pn1750","pn2330","pn1120"],"numMembers":4,"lastTimeUpdated":0},"People: constant connectivity":{"label":"People: constant connectivity","members":["pn2266","pn219","pn180","pn345"],"numMembers":4,"lastTimeUpdated":0},"Viz: Novel Visual Elements":{"label":"Viz: Novel Visual Elements","members":["pn337","pn2242","pn1472","pn1447"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Engage & Educate Children":{"label":"HCI4D: Engage & Educate Children","members":["pn1745","pn2406","pn950","pn2328"],"numMembers":4,"lastTimeUpdated":0},"People: Location Location Location":{"label":"People: Location Location Location","members":["pn1742","pn1675","pn1110","pn897"],"numMembers":4,"lastTimeUpdated":0},"Games: Exergames":{"label":"Games: Exergames","members":["pn2277","pn1521","pn737","pn775"],"numMembers":4,"lastTimeUpdated":0},"Design: Participatory Design":{"label":"Design: Participatory Design","members":["pn1517","pn2368","pn866","pn2399"],"numMembers":4,"lastTimeUpdated":0},"Systems: GUIs":{"label":"Systems: GUIs","members":["pn2096","pn198","pn189","pn435"],"numMembers":4,"lastTimeUpdated":0},"UIST: Motion and Haptics":{"label":"UIST: Motion and Haptics","members":["pn495","pn730","pn438","pn235","pn521"],"numMembers":5,"lastTimeUpdated":0},"UIST: sensible sensory":{"label":"UIST: sensible sensory","members":["pn320","pn319","pn728","pn419"],"numMembers":4,"lastTimeUpdated":0},"Social: Lonely, Sad and Awful":{"label":"Social: Lonely, Sad and Awful","members":["pn924","pn1242","pn1296","pn653","pn2488"],"numMembers":5,"lastTimeUpdated":0},"HCI4D: PolitiCHI":{"label":"HCI4D: PolitiCHI","members":["pn1330","pn763","pn657","pn1915"],"numMembers":4,"lastTimeUpdated":0},"Navigating Video":{"label":"Navigating Video","members":["pn796","pn1558","pn692","pn2268","pn1872"],"numMembers":5,"lastTimeUpdated":0},"Web: Photo sharing":{"label":"Web: Photo sharing","members":["pn2417","pn1525","pn1241","pn1295"],"numMembers":4,"lastTimeUpdated":0},"Health: Exergaming for healthcare":{"label":"Health: Exergaming for healthcare","members":["pn1684","pn2115","pn1290","pn1845"],"numMembers":4,"lastTimeUpdated":0},"Social: Connecting through Social Media":{"label":"Social: Connecting through Social Media","members":["pn1549","pn687","pn190","pn2483"],"numMembers":4,"lastTimeUpdated":0},"People: Emotions and Mobiles":{"label":"People: Emotions and Mobiles","members":["to108","pn1257","pn1818","pn2175"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Sustainability Perspectives":{"label":"HCI4D: Sustainability Perspectives","members":["to106","to127","to110","to136"],"numMembers":4,"lastTimeUpdated":0},"Health: Quantified Self":{"label":"Health: Quantified Self","members":["to101","pn2214","pn1446","pn493"],"numMembers":4,"lastTimeUpdated":0},"Methods and Models: Turn to the Wild":{"label":"Methods and Models: Turn to the Wild","members":["to103","to122","to123","to132"],"numMembers":4,"lastTimeUpdated":0},"Social: Social News":{"label":"Social: Social News","members":["pn1646","pn576","pn1460","pn862"],"numMembers":4,"lastTimeUpdated":0},"Art: Performance":{"label":"Art: Performance","members":["pn1834","pn2202","pn1275","pn1932"],"numMembers":4,"lastTimeUpdated":0},"UIST: Tangibles":{"label":"UIST: Tangibles","members":["to114","pn371","pn794","pn241","pn2010"],"numMembers":5,"lastTimeUpdated":0},"Health: Interfaces for Care and Support":{"label":"Health: Interfaces for Care and Support","members":["pn787","pn1821","pn1298","pn1859"],"numMembers":4,"lastTimeUpdated":0},"UIST: Force Input":{"label":"UIST: Force Input","members":["pn1635","pn1583","pn1046","pn386"],"numMembers":4,"lastTimeUpdated":0},"HCI4D: Family 2.0":{"label":"HCI4D: Family 2.0","members":["pn751","pn1800","pn1617","pn1732"],"numMembers":4,"lastTimeUpdated":0},"Health: Accessibility":{"label":"Health: Accessibility","members":["pn208","pn1482","pn739","pn2001","pn714"],"numMembers":5,"lastTimeUpdated":0},"Health: Older Adults 2":{"label":"Health: Older Adults 2","members":["pn975","pn1264","pn245","pn1923"],"numMembers":4,"lastTimeUpdated":0},"UIST: Read My Mind: Passive BCI":{"label":"UIST: Read My Mind: Passive BCI","members":["pn366","pn1471","pn183","pn673"],"numMembers":4,"lastTimeUpdated":0},"UBI: Battery Life":{"label":"UBI: Battery Life","members":["pn983","pn505","pn1707","pn1448"],"numMembers":4,"lastTimeUpdated":0}},"hierarchy":{},"items":{"pn1623":{"lastUpdateTime":1389285580072,"subcommitteeSplit":"A","labels":{"tools for learning":{"dislikes":[],"lastTimeUpdated":1386523299295,"checked":true,"likes":["moher@uic.edu","weibel@ucsd.edu"],"label":"tools for learning"},"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523455568,"label":"E-Learning and Education"},"second language learning":{"checked":false,"lastUpdateTime":1386523633644,"dislikes":[],"label":"second language learning","lastTimeUpdated":1386523260329,"likes":[]},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":["moher@uic.edu"],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188161}},"creationTime":1253,"content":{"authorList":["Geza Kovacs, Stanford University","Rob Miller, Massachusetts Institute of Technology"],"title":"Smart Subtitles for Vocabulary Learning","paperOrNote":"Paper","fullAbstract":"Language learners often use subtitled videos to help them learn. However, standard subtitles are suboptimal for vocabulary learning, as translations are nonliteral and made at the phrase level, making it hard to find connections between the subtitle text and the words in the video. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. Our user study shows that students studying Chinese learn more than twice as much vocabulary with Smart Subtitles than with dual Chinese-English subtitles, in the same amount of viewing time. Learners enjoyed viewing videos with Smart Subtitles just as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.","shortAbstract":"Language learners often use subtitled videos to help them learn. Howev","id":"pn1623"},"session":"HCI4D: Lost and Found in Translation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1623"},"pn1626":{"lastUpdateTime":1389221181945,"subcommitteeSplit":"B","labels":{"Exertion games":{"dislikes":[],"lastTimeUpdated":1386522974305,"checked":true,"likes":[],"label":"Exertion games"},"Entertainment":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522926952,"label":"Entertainment"},"dance/movement":{"dislikes":[],"lastTimeUpdated":1386522908677,"checked":true,"likes":["wendyju@stanford.edu","ztoups@nmsu.edu","aantle@sfu.ca"],"label":"dance/movement"},"games":{"dislikes":[],"lastTimeUpdated":1386522904014,"checked":true,"likes":["wendyju@stanford.edu","ztoups@nmsu.edu"],"label":"games"},"whole body interaction":{"dislikes":[],"lastTimeUpdated":1386522882260,"checked":true,"likes":["ztoups@nmsu.edu","aantle@sfu.ca"],"label":"whole body interaction"},"detecting movement":{"dislikes":[],"lastTimeUpdated":1386523002425,"checked":true,"likes":[],"label":"detecting movement"},"Laban":{"dislikes":[],"lastTimeUpdated":1386522988274,"checked":true,"likes":[],"label":"Laban"},"sensors":{"dislikes":[],"lastTimeUpdated":1386522992919,"checked":true,"likes":[],"label":"sensors"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755953}},"creationTime":1255,"content":{"authorList":["Jayden Garner, RMIT University ","Gavin Wood, Newcastle University","Sebastiaan Pijnappel, RMIT University","Martin Murer, University of Salzburg","Florian Mueller, RMIT University"],"title":"i-dentity: Innominate Movement Representation as Engaging Game Element","paperOrNote":"Paper","fullAbstract":"Movement-based digital games typically make it clear whose movement representation belongs to which player. In contrast, we argue that selectively concealing whose movement controls which representation can facilitate engaging play experiences. We call this innominate movement representation and explore this opportunity through our game i-dentity, where players have to guess who makes everyones controller light up based on his/her movements. Our work reveals five dimensions for the design of innominate movement representation: relationship between movement and representation; amount of sensors vs. representations; amount of players with representations; location of representation in relation to the body and technical attributes of movement representation. We also present five strategies for how innominate representation can be embedded into a play experience. With our work we hope to expand the range of digital movement games.","shortAbstract":"Movement-based digital games typically make it clear whose movement re","id":"pn1626"},"session":"Games: Exergame Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1626"},"pn1628":{"lastUpdateTime":1389222115080,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386525657180,"checked":true,"likes":["elm@purdue.edu","wolfgang@cse.yorku.ca","bulling@mpi-inf.mpg.de"],"label":"Touch Input"},"Smartwatches":{"dislikes":[],"lastTimeUpdated":1386539698774,"checked":true,"likes":[],"label":"Smartwatches"},"Touch Interaction":{"dislikes":[],"lastTimeUpdated":1386525654701,"checked":true,"likes":[],"label":"Touch Interaction"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644804}},"creationTime":1256,"content":{"authorList":["Da-Yuan Huang, National Taiwan University","Min-Lun Tsai, National Taiwan University","Ming-Chang Tsai, National Taiwan University","Liwei Chan, Academia Sinica","Mike Chen, National Taiwan University","Yi-Ping Hung, National Taiwan University"],"title":"Direct Mode Switching Using Different Areas On Users Finger Pads","paperOrNote":"Note","fullAbstract":"In this paper, we explore the direct mode switching technique for touch interaction using different areas on the finger pads. The proposed input technique determines the input mode using solely a single tapping, allowing mode-switching to be very efficient and requires minimal screen space (e.g., the space of tapping). To explore this novel approach, our studies answer the following two questions: (1) How precise can users target a position on their finger pads while performing touch interaction? (2) How to implant functions on the finger pads for direct mode switching without affecting existing touch interaction? Our study results provide the guidelines to the sizes and positions of function areas mapped to the finger pads. Overall, at most five modes can be mapped to the finger pad while preserving the region for normal touch. As a proof- of-concept, a finger-posture-aware watch system is built to predict the contact area located at the users finger pad. This prototype allows us to realize the design on the Calculator and the TextEditor applications, and to collect user feedbacks from an explorative study.","shortAbstract":"In this paper, we explore the direct mode switching technique for touc","id":"pn1628"},"session":"UIST: Small Devices","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1628"},"pn2150":{"lastUpdateTime":1389222102553,"subcommitteeSplit":"","labels":{"Funny":{"dislikes":[],"lastTimeUpdated":1386527531771,"checked":true,"likes":[],"label":"Funny"},"Tactile and Haptic UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531420135,"label":"Tactile and Haptic UIs"},"interactive furniture":{"dislikes":[],"lastTimeUpdated":1386529829377,"checked":true,"likes":[],"label":"interactive furniture"},"in the wild":{"dislikes":[],"lastTimeUpdated":1386527394253,"checked":true,"likes":[],"label":"in the wild"},"Ethnography":{"dislikes":[],"lastTimeUpdated":1386527473831,"checked":true,"likes":[],"label":"Ethnography"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["manfred.tscheligi@sbg.ac.at","marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531412802,"label":"User Studies"},"User Experience Design / Experience Design":{"dislikes":[],"lastTimeUpdated":1386526914466,"checked":true,"likes":["marcodesa@gmail.com"],"label":"User Experience Design / Experience Design"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165019}},"creationTime":1712,"content":{"authorList":["Majken Kirkegaard Rasmussen, Computer science, Aarhus University, ","Sofie Kinch, aarhus school of architecture","Erik Grnvall, Aarhus University","Marianne Graves Petersen, Aarhus University"],"title":"Causing Commotion with a Shape-changing Bench  - Experiencing Shape-Changing Interfaces in Use","paperOrNote":"Paper","fullAbstract":"In this paper we introduce coMotion, a shape-changing bench, which has been tested in the three different contexts: a concert hall foyer, an airport departure hall and a shopping mall. We have gathered insights from more than 120 people, with regard to how users have experienced and made sense of the shape changing capability. The paper applies McCarthy and Wrights six different sense making processes (anticipating, connecting, interpreting, reflecting, appropriating and recounting) as an instrument to analyse peoples experience with shape-changing furniture in the wild. The paper also introduces exploring as a seventh sense making process. Based on this analysis, the paper point out three relevant aspects when designing shape-changing artefacts for the wild, namely: 1) Affordance of shape-changing interfaces, 2) Transitions between background and foreground and 3) Interpreting physically dynamic objects.  ","shortAbstract":"In this paper we introduce coMotion, a shape-changing bench, which has","id":"pn2150"},"session":"UIST: Shape-Changers","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2150"},"pn2153":{"lastUpdateTime":1389222165018,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"College students":{"dislikes":[],"lastTimeUpdated":1386522591660,"checked":true,"likes":["l.ciolfi@shu.ac.uk"],"label":"College students"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Well-being":{"dislikes":[],"lastTimeUpdated":1386523043097,"checked":true,"likes":[],"label":"Well-being"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032723}},"creationTime":1715,"content":{"authorList":["Gloria Mark, University of California, Irvine","Yiran Wang, University of California, Irvine","Melissa Niiya, University of California, Irvine"],"title":"Stress and Multitasking in Everyday College Life: An Empirical Study of Online Activity","paperOrNote":"Paper","fullAbstract":"While HCI has focused on multitasking with information workers, we report on multitasking among Millennials--college students who grew up with digital media. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. Stress increased significantly with more daily time spent on computers and more window switching; both stress and computer usage rose throughout the day. Lower stress is associated with longer use of social media and Facebook. Night habits affect multitasking: late-nighters have longer computer use duration the following day; those ending the day earlier show less window switching the next day. We find that college students switch computer windows with double the frequency compared to studies of information workers. This is the first study to use logging and biosensors to measure stress and ICT use of college students in their real world environment. ","shortAbstract":"While HCI has focused on multitasking with information workers, we rep","id":"pn2153"},"session":"Health: Stress","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2153"},"pn2029":{"lastUpdateTime":1389236825484,"subcommitteeSplit":"","labels":{"3d printing":{"dislikes":[],"lastTimeUpdated":1386531946088,"checked":true,"likes":[],"label":"3d printing"},"Fabrication":{"dislikes":[],"lastTimeUpdated":1386532115467,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Fabrication"},"Prototyping":{"checked":true,"dislikes":[],"likes":["fanny@dgp.toronto.edu"],"lastUpdateTime":123456789,"label":"Prototyping"},"diy":{"checked":false,"lastUpdateTime":1386531598147,"dislikes":[],"label":"diy","lastTimeUpdated":1386531580140,"likes":[]},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["yangli@acm.org"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Rapid prototyping":{"dislikes":[],"lastTimeUpdated":1386531596526,"checked":true,"likes":[],"label":"Rapid prototyping"},"fabrication":{"dislikes":[],"lastTimeUpdated":1386531797184,"checked":true,"likes":[],"label":"fabrication"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840685}},"creationTime":1603,"content":{"authorList":["Scott Hudson, Carnegie Mellon University"],"title":"Printing Teddy Bears: A Technique for 3D Printing of Soft Interactive Objects","paperOrNote":"Paper","fullAbstract":"This paper considers the design, construction, and example use of a new type of 3D printer which fabricates three-dimensional objects from soft fibers (wool and wool blend yarn).  This printer allows the substantial advantages of additive manufacturing techniques (including rapid turn-around prototyping of physical objects and support for high levels of customization and configuration) to be employed with a new class of material.  This material is a form of loose felt formed when fibers from an incoming feed of yarn are entangled with the fibers in layers below it.  The resulting objects recreate the geometric forms specified in the solid models which specify them, but are soft and flexible  somewhat reminiscent in character to hand knitted materials.  This extends 3D printing from typically hard and precise forms into a new set of forms which embody a different aesthetic of soft and imprecise objects, and provides a new capability for researchers to explore the use of this class of materials in interactive devices. ","shortAbstract":"This paper considers the design, construction, and example use of a ne","id":"pn2029"},"session":"Making: 3D printing","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2029"},"pn1710":{"lastUpdateTime":1389222127656,"subcommitteeSplit":"B","labels":{"social computing":{"dislikes":[],"lastTimeUpdated":1386522882791,"checked":true,"likes":[],"label":"social computing"},"Research on Pinterest":{"dislikes":[],"lastTimeUpdated":1386522647544,"checked":true,"likes":[],"label":"Research on Pinterest"},"pinterest":{"dislikes":[],"lastTimeUpdated":1386522333955,"checked":true,"likes":[],"label":"pinterest"},"Research on Social Media Systems":{"dislikes":[],"lastTimeUpdated":1386522653496,"checked":true,"likes":[],"label":"Research on Social Media Systems"},"creativity":{"dislikes":[],"lastTimeUpdated":1386522337589,"checked":true,"likes":[],"label":"creativity"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu","wendyju@stanford.edu","reinecke@umich.edu"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Empirical Methods, Qualitative":{"dislikes":[],"lastTimeUpdated":1386523180762,"checked":true,"likes":["reinecke@umich.edu"],"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu","ztoups@nmsu.edu","fuzhiyong@tsinghua.edu.cn"],"lastUpdateTime":123456789,"label":"Ethnography"},"everyday creativity":{"dislikes":[],"lastTimeUpdated":1386522342375,"checked":true,"likes":[],"label":"everyday creativity"},"User Experience Design / Experience Design":{"dislikes":[],"lastTimeUpdated":1386523161983,"checked":true,"likes":["reinecke@umich.edu"],"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755921}},"creationTime":1329,"content":{"authorList":["Rhema Linder, Texas A&M University","Clair Snodgrass, Texas A&M University","Andruid Kerne, Interface Ecology Lab, Texas A&M University"],"title":"Everyday Ideation: All of My Ideas Are On Pinterest","paperOrNote":"Paper","fullAbstract":"Ideation, the process of exploring and generating ideas, is essential to professional and informal design. In everyday design, all people function as designers in that they gather and analyze data to understand context while iteratively personalizing and making things.   Everyday designers see artifacts and actions as creative resources for shaping the home in response to human needs. \\  \\ We analyze twenty interviews in which participants use Pinterest, a popular social curation platform, to find, collect, organize, and share ideas. We provide evidence that Pinterest users function as everyday designers who ideate though social curation. Thus, they engage in everyday ideation. For them, everyday ideation is a key source of practical and emotional value, as they seek to plan, motivate, and improve their lives.","shortAbstract":"Ideation, the process of exploring and generating ideas, is essential ","id":"pn1710"},"session":"Social: Social Media Applied","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1710"},"pn626":{"lastUpdateTime":1389591444890,"subcommitteeSplit":"A","labels":{"search":{"dislikes":[],"lastTimeUpdated":1386523952013,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"label":"search"},"information foraging":{"dislikes":[],"lastTimeUpdated":1386523987273,"checked":true,"likes":[],"label":"information foraging"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524839013,"label":"Empirical Methods, Quantitative"},"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523958460,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"label":"eye tracking"},"The Eyes Have It":{"dislikes":[],"lastTimeUpdated":1386526246076,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Eyes Have It"},"menus":{"dislikes":[],"lastTimeUpdated":1386523975544,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"label":"menus"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"interaction science":{"dislikes":[],"lastTimeUpdated":1386524247933,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"interaction science"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946743}},"creationTime":396,"content":{"authorList":["Duncan Brumby, University College London","Anna Cox, University College London","Jacqueline Chung, University College London"],"title":"How Does Knowing What You Are Looking For Change Visual Search Behavior?","paperOrNote":"Note","fullAbstract":"When searching a display, users sometimes know what the target is but sometimes do not. It has generally been assumed that for this latter case people must engage in a deeper semantic evaluation of items during the search process. This idea is central to Information Foraging theory. But do people actually spend longer assessing items when engaged in a semantically demanding search task? We investigate this by having participants locate target items in 16-item menus. Participants were either told exactly what to look for (known-item search) or they were told the category that the target belonged to (semantic search). Participants were faster and more accurate at known-item searches. Eye-movement data show that this was because participants were more likely to skip over items when performing known-item searches. Contrary to expectation, we found limited empirical evidence to support the idea that deeper semantic evaluations of items lead to longer gaze durations (this occurred only when items were arranged very close together). This finding is important because it reveals how people adopt different eye gaze strategies depending on the kind of search activity they are engaged in.","shortAbstract":"When searching a display, users sometimes know what the target is but ","id":"pn626"},"session":"Methods and Models: The Eyes Have It","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn626"},"pn2159":{"lastUpdateTime":1389222127656,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528905474,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Privacy":{"checked":true,"dislikes":[],"likes":["lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Privacy"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Facebook":{"dislikes":[],"lastTimeUpdated":1386522813899,"checked":true,"likes":["spdow@cs.cmu.edu"],"label":"Facebook"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032684}},"creationTime":1721,"content":{"authorList":["Pamela Wisniewski, The Pennsylvania State University","Heng Xu, The Pennsylvania State University","Yunan Chen, University of California, Irvine"],"title":"Understanding User Adaptation Strategies for the Launching of Facebook Timeline","paperOrNote":"Paper","fullAbstract":"This paper applies coping theory to understand user adaptation strategies to major interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively examine 1,149 user comments posted to the Facebooks official Timeline blog in order to get a large and unobtrusive sample of real Facebook users perceptions about the launch of Timeline. Our data suggests a high level of stress associated with the transition to the new interface introduced by Timeline. We also found evidence which suggests that increasing users perceptions of control over major interface changes may help facilitate user adaptation to these changes.","shortAbstract":"This paper applies coping theory to understand user adaptation strateg","id":"pn2159"},"session":"Social: Social Media Applied","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2159"},"pn444":{"lastUpdateTime":1388765600113,"subcommitteeSplit":"C","labels":{"Ludic engagement":{"checked":false,"lastUpdateTime":1386527587892,"dislikes":[],"label":"Ludic engagement","lastTimeUpdated":1386527410007,"likes":[]},"Older Adults":{"checked":false,"dislikes":[],"likes":["joanna@cs.ub.ca"],"lastUpdateTime":1386527166665,"label":"Older Adults"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"ludic engagement":{"dislikes":[],"lastTimeUpdated":1386527582751,"checked":true,"likes":[],"label":"ludic engagement"},"socialization":{"dislikes":[],"lastTimeUpdated":1386527110032,"checked":true,"likes":[],"label":"socialization"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386527123596,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527079173,"label":"Empirical Methods, Qualitative"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Virtual Worlds":{"dislikes":[],"lastTimeUpdated":1386526586323,"checked":true,"likes":[],"label":"Virtual Worlds","lastUpdateTime":1387553080478},"dementia":{"checked":true,"lastUpdateTime":1386527193808,"dislikes":[],"label":"dementia","lastTimeUpdated":1386526578780,"likes":[]},"connectedness":{"dislikes":[],"lastTimeUpdated":1386527487752,"checked":true,"likes":[],"label":"connectedness"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486635}},"creationTime":260,"content":{"authorList":["Panote Siriaraya, University of Kent","Chee Siang Ang, University of Kent"],"title":"Recreating Living Experiences from Past Memories through Virtual Worlds for People with Dementia","paperOrNote":"Paper","fullAbstract":"This paper describes a study aimed to understand the use of 3D virtual world (VW) technology to support life engagement for people with dementia in long-term care. Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising gestured-base interaction were developed. These prototypes were tested with older residents (80+) with dementia in care homes and their caregivers. Data collection was based on observations of how the residents and care staff interacted collaboratively with the VW. We discussed in depth the use of VWs in stimulating past memories and how this technology could help enhance their sense of self through various means. In addition, we highlighted key approaches in designing VWs to sustain attention, create ludic experiences and facilitate interaction for older people with dementia.","shortAbstract":"This paper describes a study aimed to understand the use of 3D virtual","id":"pn444"},"session":"Health: Network of care","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn444"},"pn2157":{"lastUpdateTime":1389221840890,"subcommitteeSplit":"","labels":{"Keyboards":{"dislikes":[],"lastTimeUpdated":1386531731623,"checked":true,"likes":["eve.hoggan@hiit.fi","olwal@mit.edu"],"label":"Keyboards"},"Gestural Interaction":{"dislikes":[],"lastTimeUpdated":1386532400947,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Gestural Interaction"},"Gesture Recognition":{"dislikes":[],"lastTimeUpdated":1386532412268,"checked":true,"likes":["david.kim@newcastle.ac.uk","olwal@mit.edu"],"label":"Gesture Recognition"},"Machine Learning":{"dislikes":[],"lastTimeUpdated":1386532195074,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Machine Learning"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386531758528,"checked":true,"likes":["hq@northwestern.edu"],"label":"Gestural interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386532452748,"checked":true,"likes":[],"label":"Text Entry"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840688}},"creationTime":1719,"content":{"authorList":["Haimo Zhang, National University of Singapore","Yang Li, Google Research"],"title":"GestKeyboard: Enabling Gesture-Based Interaction on Ordinary Physical Keyboard","paperOrNote":"Paper","fullAbstract":"Stroke gestures are intuitive and efficient but often require gesture-capable input hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique for gesturing over an ordinary, unmodified physical keyboardthat remains the major input modality for existing desktop and laptop computers. We discuss an exploratory study for understanding the design space of gesturing on a physical keyboard and our algorithms for detecting gestures in a modeless way without interfering with the keyboards major functionality such as text entry and shortcuts activation. We explored various features for detecting gestures and our experiment based on the data collected from 10 participants indicated it is feasible to reliably detect gestures from normal keyboard use, 95% detection accuracy within a maximum latency of 200ms.","shortAbstract":"Stroke gestures are intuitive and efficient but often require gesture-","id":"pn2157"},"session":"UIST: novel keyboards","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2157"},"pn464":{"lastUpdateTime":1388776475848,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Pen-based UIs":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","eve.hoggan@hiit.fi"],"lastUpdateTime":123456789,"label":"Pen-based UIs"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840629}},"creationTime":276,"content":{"authorList":["Albert Ng, ","Michelle Annett, University of Alberta","Paul Dietz, Microsoft Corporation","Anoop Gupta, Microsoft Corporation","Walter Bischof, Advanced Man-Machine Interface Lab, University of Alberta"],"title":"In the Blink of an Eye: Investigating Latency Perception during Stylus Interaction","paperOrNote":"Paper","fullAbstract":"Pen computing is continuing to become more popular, but is still unfortunately plagued by a number of problems, with device responsiveness, or latency, being in the forefront. Although there have been advances in digitizer technology over the last few years, commercial end-to-end latencies are unfortunately similar to those found with touchscreens, i.e., 65 - 120 milliseconds. This work reports on a prototype stylus-enabled device, the High Performance Stylus System (HPSS) that allows users to experience latencies as low as 1 millisecond while they are inking or dragging objects. \\  \\ To expand our understanding of latency during inking, psychophysical just-noticeable difference experiments were conducted using the HPSS. While participants performed dragging and scribbling tasks, they could distinguish very low levels of latency, between 1 and 2 milliseconds while dragging and between 5 and 38 milliseconds while scribbling. Supported by prior work, it thus appears that the perception of latency may be task dependent. Our experimentation has thus provided further motivation for the implementation of increased latency saving measures in both hardware and software.","shortAbstract":"Pen computing is continuing to become more popular, but is still unfor","id":"pn464"},"session":"Touch: Touch-me Mobile Interaction","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn464"},"pn601":{"lastUpdateTime":1389238054489,"subcommitteeSplit":"A","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386524679563,"checked":true,"likes":["eva@ehornecker.de"],"label":"gestures"},"Kinecting People":{"dislikes":[],"lastTimeUpdated":1386523837336,"checked":true,"likes":["sameer.patil@hiit.fi","mark.hancock@uwaterloo.ca","haochuan@cs.nthu.edu.tw","dabbish@cmu.edu"],"label":"Kinecting People"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525537476,"label":"Empirical Methods, Quantitative"},"Kinect":{"checked":true,"lastUpdateTime":1386533336415,"dislikes":[],"label":"Kinect","lastTimeUpdated":1386524242444,"likes":[]},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":["lorrie@acm.org"],"lastUpdateTime":1386526655458,"label":"Computer-Mediated Communication"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386524398815,"checked":true,"likes":[],"label":"Gestural interaction"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525604551,"label":"User Studies"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":1386526657573,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946633}},"creationTime":376,"content":{"authorList":["Hao-Chuan Wang, National Tsing Hua University","Chien-Tung Lai, National Tsing Hua University"],"title":"Kinect-taped Communication: Using Motion Sensing to Study Gesture Use and Similarity in Face-to-Face and Computer-Mediated Brainstorming","paperOrNote":"Paper","fullAbstract":"One key difference between face-to-face (F2F) communication and computer-mediated communication (CMC) is the availability of visual cues. It is often assumed that the reduction of visibility in audio and video conferencing may negatively impact the use of gesture to communicate, and thus negatively influence other outcomes. In this paper we Kinect-taped F2F and CMC communication in brainstorming groups by using motion sensors to record and analyze group members hand movements during communication. We investigate how different media influence gesture use and gestural similarity, and how the use of gesture associates with level of understanding and brainstorming performance. Implications to future research and design are discussed.","shortAbstract":"One key difference between face-to-face (F2F) communication and comput","id":"pn601"},"session":"People: Kinecting People","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn601"},"pn602":{"lastUpdateTime":1389284833413,"subcommitteeSplit":"","labels":{"community structures":{"dislikes":[],"lastTimeUpdated":1386528285388,"checked":true,"likes":[],"label":"community structures"},"crowd":{"checked":false,"lastUpdateTime":1386528277359,"dislikes":[],"label":"crowd","lastTimeUpdated":1386528235592,"likes":[]},"crowd innovation":{"dislikes":[],"lastTimeUpdated":1386527830848,"checked":true,"likes":[],"label":"crowd innovation"},"Prosociality":{"dislikes":[],"lastTimeUpdated":1386537700937,"checked":true,"likes":[],"label":"Prosociality"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"banking":{"checked":false,"lastUpdateTime":1386527811945,"dislikes":[],"label":"banking","lastTimeUpdated":1386527394130,"likes":[]},"alternative currency":{"dislikes":[],"lastTimeUpdated":1386528336492,"checked":true,"likes":[],"label":"alternative currency"},"Economics & HCI":{"dislikes":[],"lastTimeUpdated":1386537712968,"checked":true,"likes":[],"label":"Economics & HCI"},"HCI in Economic Life":{"dislikes":[],"lastTimeUpdated":1386537733912,"checked":true,"likes":[],"label":"HCI in Economic Life"},"Ethnography":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527312159,"label":"Ethnography"},"communities":{"dislikes":[],"lastTimeUpdated":1386537334783,"checked":true,"likes":["bellotti@parc.com"],"label":"communities"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527286904,"label":"User Studies"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386528271320,"checked":true,"likes":["wmoncur@dundee.ac.uk"],"label":"Crowd-Powered Systems"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386527637408,"label":"User Experience Design / Experience Design"},"Computer Supported Cooperative Work (CSCW)":{"dislikes":[],"lastTimeUpdated":1386528196226,"checked":true,"likes":["wmoncur@dundee.ac.uk"],"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165061}},"creationTime":377,"content":{"authorList":["Victoria Bellotti, Palo Alto Research Center","Sara Cambridge, UC Berkeley","Karen Hoy, Palo Alto Research Center Palo Alto","Patrick Shih, The Pennsylvania State University","Lisa Handalian, California College of the Arts","Kyungsik Han, The Pennsylvania State University","John Carroll, The Pennsylvania State University"],"title":"Dont Bank On IT if You Want to Help: Towards a New User Experience for Peer-to-Peer Service Exchange","paperOrNote":"Paper","fullAbstract":"Commercial peer-to-peer service systems, such as AirBnB, Lyft and TaskRabbit, are expanding rapidly, but their non- profit counterparts, although growing in number, are lagging behind. We have been studying the most prominent of these systems, timebanking, and have found problems with the very metaphor of banking itself, which are deterring participation and which we believe can be addressed through user experience design measures. Drawing on extensive fieldwork with multiple timebanking organizations, we explain the problems and how their impacts hold back timebanking and the value it can create. We propose possible user experience solutions that can overcome the problems to help timebanking catch up with its for-profit peers.","shortAbstract":"Commercial peer-to-peer service systems, such as AirBnB, Lyft and Task","id":"pn602"},"session":"HCI4D: Shopping and Economy","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn602"},"pn1099":{"lastUpdateTime":1389238054489,"subcommitteeSplit":"","labels":{"Performance Metrics":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528157102,"label":"Performance Metrics"},"Entertainment":{"checked":true,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Entertainment"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528159407,"label":"Empirical Methods, Quantitative"},"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528160846,"label":"Ubiquitous Computing / Smart Environments"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528150586,"label":"User-Centered Design / Human-Centered Design"},"Creativity Support Tools":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528166274,"label":"Creativity Support Tools"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528144455,"label":"User Interface Design"},"Performance":{"dislikes":[],"lastTimeUpdated":1386528186833,"checked":true,"likes":[],"label":"Performance"},"Home":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528142089,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk"],"lastUpdateTime":1386528140075,"label":"User Experience Design / Experience Design"},"Digital Arts":{"dislikes":[],"lastTimeUpdated":1386528176367,"checked":true,"likes":[],"label":"Digital Arts"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165081}},"creationTime":796,"content":{"authorList":["Chen Wang, Centrum Wiskunde&Informatica","Erik Geelhoed, Falmouth University","Pablo Cesar, Centrum voor Wiskunde&Informatica","Phil Stenton, Falmouth University"],"title":"Sensing a Live Audience","paperOrNote":"Note","fullAbstract":"Psychophysiological measurement has the potential to play an important role in audience research. Currently, such research is still in its infancy and it usually involves collecting data in the laboratory, where during each experimental session one individual watches a video recording of a performance. We extend the experimental paradigm by simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during a live performance. GSR data were synchronized with video footage of performers and audience. In conjunction with questionnaire data, this enabled us to identify a strongly correlated main group of participants, describe the nature of their theatre experience and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological engagement. The benefits of our approach are twofold. It provides a robust and accurate mechanism for assessing a performance. Moreover, our infrastructure can enable, in the future, real-time feedback from remote audiences for online performances. We are currently scaling up the system allowing for simultaneous GSR measurement of larger audiences.","shortAbstract":"Psychophysiological measurement has the potential to play an important","id":"pn1099"},"session":"People: Kinecting People","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1099"},"pn1092":{"lastUpdateTime":1388776467635,"subcommitteeSplit":"A","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525541583,"label":"Empirical Methods, Quantitative"},"Multitouchy Feely":{"dislikes":[],"lastTimeUpdated":1386526770298,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Multitouchy Feely"},"mid-air":{"dislikes":[],"lastTimeUpdated":1386524438102,"checked":true,"likes":[],"label":"mid-air"},"Touchy Feely":{"dislikes":[],"lastTimeUpdated":1386525469811,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Touchy Feely"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Touchy":{"dislikes":[],"lastTimeUpdated":1386525383193,"checked":true,"likes":["sameer.patil@hiit.fi","beverly_harrison@yahoo.com"],"label":"Touchy"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386524826556,"checked":true,"likes":["eva@ehornecker.de"],"label":"Multitouch"},"tabletop":{"dislikes":[],"lastTimeUpdated":1386524882769,"checked":true,"likes":["eva@ehornecker.de"],"label":"tabletop"},"interactive surfaces":{"dislikes":[],"lastTimeUpdated":1386524281561,"checked":true,"likes":["eva@ehornecker.de"],"label":"interactive surfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525630150,"label":"User Studies"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946650}},"creationTime":789,"content":{"authorList":["Chat Wacharamanotham, RWTH Aachen University","Kashyap Todi, RWTH Aachen University","Marty Pye, RWTH Aachen University","Jan Borchers, RWTH Aachen University"],"title":"Understanding Finger Input in Near-Surface Space","paperOrNote":"Paper","fullAbstract":"Using the space above desktop input devices adds a rich new input channel to desktop interaction. Dividing this volume into layers has been used e.g. to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table, and to access vertically stacked menus. However, designing these interactions is challenging, because the lack of haptic and direct visual feedback easily leads to input errors. The user's fingers need to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space. In this paper, we present the results of two user studies which inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume which users can reliably remain within. While accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into the layer. Based on the user's hand shape, we propose a technique that reliably distinguishes clicking from homing movements. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.","shortAbstract":"Using the space above desktop input devices adds a rich new input chan","id":"pn1092"},"session":"Touch: Touch","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1092"},"pn1095":{"lastUpdateTime":1388785673817,"subcommitteeSplit":"B","labels":{"Aesthetics":{"checked":true,"lastUpdateTime":1386523229111,"dislikes":[],"label":"Aesthetics","lastTimeUpdated":1386522409091,"likes":[]},"Installation":{"checked":false,"lastUpdateTime":1386523292508,"dislikes":[],"label":"Installation","lastTimeUpdated":1386523193212,"likes":[]},"Machine Aesthetics":{"checked":false,"lastUpdateTime":1386523294692,"dislikes":[],"label":"Machine Aesthetics","lastTimeUpdated":1386523063584,"likes":[]},"Art Installation":{"checked":false,"lastUpdateTime":1386523291048,"dislikes":[],"label":"Art Installation","lastTimeUpdated":1386523195882,"likes":[]},"music":{"checked":false,"lastUpdateTime":1386523350637,"dislikes":[],"label":"music","lastTimeUpdated":1386523320886,"likes":["wendyju@stanford.edu"]},"Art":{"checked":false,"lastUpdateTime":1386523289353,"dislikes":[],"label":"Art","lastTimeUpdated":1386523197866,"likes":[]},"Biometrics":{"checked":false,"lastUpdateTime":1386523300349,"dislikes":[],"label":"Biometrics","lastTimeUpdated":1386523073387,"likes":[]},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755910}},"creationTime":792,"content":{"authorList":["Vygandas Simbelis, KTH  Royal Institute of Technology","Anders Lundstrm, KTH  Royal Institute of Technology","Kristina Hook, KTH - Royal Institute of Technology","Jordi Solsona Belenguer, KTH  Royal Institute of Technology","Vincent Lewandowski, KTH - Royal Institute of Technology"],"title":"Metaphone: Machine Aesthetics Meets Interaction Design","paperOrNote":"Paper","fullAbstract":"Through our art project, Metaphone, we explored a particular form of aesthetics referred to in the arts tradition as machine aesthetics. The Metaphone machine captures bio-data from participants and creates a process of movement, painting and sound through interaction. The machine behaves in its own, machine-like, aesthetically evocative ways: a shaft on two large wheels swings around on the floor, carrying the colour paint that is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor data. At the same time a complex soundscape feeding off the participants data is generated. Six commentators were invited to interact with the machine. They reported a strangely relaxing atmosphere induced by the machine. What we find in our commentators descriptions is a machine aesthetics of the interaction, as it unfolds over time. Based on these experiences we discuss ways in which machine aesthetics could be of relevance to interaction design.","shortAbstract":"Through our art project, Metaphone, we explored a particular form of a","id":"pn1095"},"session":"Viz: Visual Aesthetics","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1095"},"pn1097":{"lastUpdateTime":1389238496089,"subcommitteeSplit":"","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528767913,"checked":true,"likes":["lorrie@acm.org","judy.kay@gmail.com"],"label":"usable privacy and security"},"Graphical Passwords":{"dislikes":[],"lastTimeUpdated":1386527942033,"checked":true,"likes":["lorrie@acm.org"],"label":"Graphical Passwords"},"Authentication":{"dislikes":[],"lastTimeUpdated":1386528755348,"checked":true,"likes":["lorrie@acm.org"],"label":"Authentication"},"Privacy":{"dislikes":[],"lastTimeUpdated":1386527214267,"checked":true,"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"label":"Privacy"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"authentication":{"dislikes":[],"lastTimeUpdated":1386528753001,"checked":true,"likes":[],"label":"authentication"},"User Authentication":{"dislikes":[],"lastTimeUpdated":1386527239803,"checked":true,"likes":[],"label":"User Authentication"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386528774510,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"graphical passwords":{"checked":false,"lastUpdateTime":1386527932296,"dislikes":[],"label":"graphical passwords","lastTimeUpdated":1386527924809,"likes":[]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165084}},"creationTime":794,"content":{"authorList":["Soumyadeb Chowdhury, university of Glasgow","Ron Poet, University of Glasgow","Lewis Mackenzie, University of Glasgow"],"title":"Passhint: Memorable and Secure Authentication","paperOrNote":"Paper","fullAbstract":"People find it difficult to remember multiple alphanumeric as well as graphical passwords. We propose a Passhint authentication system (PHAS), where the users have to choose four images and create hints for each one of them to form a password. During authentication, they have to recognize only the target images, which are displayed with their corresponding hints, among a collection of 15 decoy images, in a four step process. The results of a usability study with 40 subjects, who were required to create 1 Mikon, 1 doodle, 1 art and 1 object password and then attempt to recall them after a period of two weeks (without any practice sessions), demonstrated that the memorability of multiple passwords in PHAS is better than in existing Graphical authentication systems (GASs). Although the registration time is high, authentication time for successful attempts is either equivalent to or less than the time reported for existing GASs. A guessability study conducted with the same participants revealed that art passwords are the least guessable, followed by Mikon, doodle and objects. The results strongly suggest the use of art passwords in PHAS, which would offer usable as well as secure authentication. The preliminary results indicate that PHAS has solved the memorability problem with multiple passwords. We propose two new features that could enhance the security offered by PHAS, but the usability of these features needs to be tested before they could be adopted in practice. ","shortAbstract":"People find it difficult to remember multiple alphanumeric as well as ","id":"pn1097"},"session":"Security: Passwords","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1097"},"pn264":{"lastUpdateTime":1389222026624,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531979892,"checked":true,"likes":["yangli@acm.org"],"label":"Touch Input"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Performance Metrics"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Touch input":{"checked":false,"lastUpdateTime":1386532119045,"dislikes":[],"label":"Touch input","lastTimeUpdated":1386532115734,"likes":[]},"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386532142653,"checked":true,"likes":[],"label":"Target Acquisition"},"Pointing Techniques":{"dislikes":[],"lastTimeUpdated":1386532533528,"checked":true,"likes":[],"label":"Pointing Techniques"},"User Studies":{"dislikes":[],"lastTimeUpdated":1386532102728,"checked":true,"likes":[],"label":"User Studies"},"Target Acquistion":{"checked":false,"lastUpdateTime":1386532136450,"dislikes":[],"label":"Target Acquistion","lastTimeUpdated":1386532129405,"likes":[]},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840641}},"creationTime":122,"content":{"authorList":["Jrmie Gilliot, Inria","Gry Casiez, University of Lille","Nicolas Roussel, Inria"],"title":"Impact of Form Factors and Input Conditions on Absolute Indirect-Touch Pointing Tasks","paperOrNote":"Paper","fullAbstract":"Absolute indirect interaction maps the absolute position of a device's end-effector to the absolute position of a remote on-screen object. Despite its long-time use with graphics tablets and growing use in research prototypes, little is know on the influence of form factors and input conditions on pointing performance with such a mapping. The input and display can have different sizes and aspect ratios, for example. The on-screen targets can vary in size. Users can look solely at the display or at the input device as well. They can also hold the input device in certain cases, or let it rest on a table. This paper reports on two experiments designed to investigate the influence of all these factors on absolute indirect-touch pointing performance. We also provide design guidelines for interaction in these situations based on the observed impacting factors.","shortAbstract":"Absolute indirect interaction maps the absolute position of a device's","id":"pn264"},"session":"UIST: Pointing","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn264"},"pn263":{"lastUpdateTime":1389285494405,"subcommitteeSplit":"","labels":{"micro work tasks":{"dislikes":[],"lastTimeUpdated":1386522302151,"checked":true,"likes":[],"label":"micro work tasks"},"Smartphones":{"dislikes":[],"lastTimeUpdated":1386524130894,"checked":true,"likes":[],"label":"Smartphones"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386524033522,"checked":true,"likes":[],"label":"Handheld Devices and Mobile Computing"},"Mobile phone interaction":{"dislikes":[],"lastTimeUpdated":1386523737951,"checked":true,"likes":[],"label":"Mobile phone interaction"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521780024,"checked":true,"likes":["myriam.lewkowicz@utt.fr","gabriela.avram@gmail.com","jacovi@il.ibm.com"],"label":"crowdsourcing"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523500952,"label":"Social Computing and Social Navigation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556752}},"creationTime":121,"content":{"authorList":["Rajan Vaish, University of California","Keith Wyngarden, Stanford University","Brandon Cheung, Stanford University","Michael Bernstein, "],"title":"Twitch Crowdsourcing: Crowd Contributions in Short Bursts of Time","paperOrNote":"Paper","fullAbstract":"Success in crowdsourcing depends critically on motivating many individuals to contribute, but contributors often are discouraged by the non-trivial effort required to make meaningful contributions. To lower the threshold to participation, we present twitch crowdsourcing, quick crowd contributions that can be completed in one or two seconds. In spare moments, we habitually turn to mobile phones for work, messaging, and entertainment. Taking advantage of this habit, Twitch overrides the Android unlock screen and allows users to make micro-contributions toward crowdsourcing goals each time they unlock their phone. We perform a public field deployment of Twitch with 82 users. These users authored a census of local human activity, rated stock photos, and extracted structured data for Wikipedia pages via 11,240 unlock activities. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable speed or cognitive load costs compared to a standard slide-to-unlock gesture. ","shortAbstract":"Success in crowdsourcing depends critically on motivating many individ","id":"pn263"},"session":"CSCW: Crowdsourcing","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn263"},"pn116":{"lastUpdateTime":1387316165002,"subcommitteeSplit":"","labels":{"information overload":{"dislikes":[],"lastTimeUpdated":1386529080762,"checked":true,"likes":[],"label":"information overload"},"User Interface Design":{"checked":false,"lastUpdateTime":1386531939135,"dislikes":[],"label":"User Interface Design","lastTimeUpdated":1386527283085,"likes":["marcodesa@gmail.com"]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","e.karapanos@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165002}},"creationTime":12,"content":{"authorList":["Joshua Hailpern, Hewlett Packard","Bernardo A. Huberman, Hewlett Packard"],"title":"Odin: Contextual Document Opinions On The Go","paperOrNote":"Paper","fullAbstract":"Information overload is a systemic problem for knowledge workers in enterprise. For a long time, information was scarce and therefore valuable. While, the explosion of digital information has made information plentiful, time to read and process that content is now scarce. This problem is only exacerbated by our increased mobility, and the expectation to be on top of the continuous barrage of documents while on the go. Knowledge workers in enterprise need solutions that are designed with quick methods for finding what to read in a large collection of documents (e.g. financial reports, legal documents, news), and ways of presenting it within small visual real estate. Unlike reviews, document collections are long, more varied, and context is extremely important. In response, we present Odin, a mobile web-based window onto a users document corpus. Rather than performing corpus summarization, Odin users can quickly find opinions and documents that are Aligned or Divergent from the corpus consensus, or those that are the most Relevant given the overall corpus of opinions. Odin presents this information through a simple and intuitive mobile interface. To the authors knowledge, this is the first UI, algorithm, and system to allow mobile users to place documents and their opinions in context through alignment rather than raw word count or sentiment. Positive results from two evaluations are also presented.","shortAbstract":"Information overload is a systemic problem for knowledge workers in en","id":"pn116"},"session":"Information in Use","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn116"},"pn111":{"lastUpdateTime":1389238054489,"subcommitteeSplit":"","labels":{"head pose":{"checked":false,"lastUpdateTime":1386526121108,"dislikes":[],"label":"head pose","lastTimeUpdated":1386525593150,"likes":[]},"Context-Aware Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526117711,"label":"Context-Aware Computing"},"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526114850,"label":"Ubiquitous Computing / Smart Environments"},"Speech I/O":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Speech I/O"},"gaze":{"checked":false,"lastUpdateTime":1386526119073,"dislikes":[],"label":"gaze","lastTimeUpdated":1386525571268,"likes":[]},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","bickmore@ccs.neu.edu","aquigley@st-andrews.ac.uk"],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644746}},"creationTime":9,"content":{"authorList":["Soroush Vosoughi, Massachusetts Institute of Technology"],"title":"Improving Automatic Speech Recognition Through Head Pose Driven Visual Grounding","paperOrNote":"Note","fullAbstract":"In this paper, we present a multimodal speech recognition system for real world scene description tasks. Given a visual scene, the system dynamically biases its language model based on the content of the visual scene and visual attention of the speaker. Visual attention is used to focus on likely objects within the scene. Given a spoken description the system then uses the visually biased language model to process the speech. The system uses head pose as a proxy for the visual attention of the speaker. Readily available standard computer vision algorithms are used to recognize the objects in the scene and automatic real time head pose estimation is done using depth data captured via a Microsoft Kinect. The system was evaluated on multiple participants. Overall, incorporating visual information into the speech recognizer greatly improved speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies such as the Kinect allows systems with similar underlying principles to be used for many speech recognition tasks where there is visual information.","shortAbstract":"In this paper, we present a multimodal speech recognition system for r","id":"pn111"},"session":"People: Kinecting People","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn111"},"pn113":{"lastUpdateTime":1388776489997,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["mdixon@cs.washington.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Gesture-Based Interaction":{"dislikes":[],"lastTimeUpdated":1386531605701,"checked":true,"likes":[],"label":"Gesture-Based Interaction"},"Multi-touch":{"dislikes":[],"lastTimeUpdated":1386532252543,"checked":true,"likes":[],"label":"Multi-touch"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840716}},"creationTime":10,"content":{"authorList":["Julie Wagner, University of Munich","Eric Lecolinet, Telecom ParisTech","ted selker, Carnegie Mellon University - Silicon Valley"],"title":"Multi-finger Chords for Hand-held Tablets: Recognizable and Memorable","paperOrNote":"Paper","fullAbstract":"Despite the demonstrated benefits of multi-finger input, to- days gesture vocabularies offer a limited number of postures and gestures. Previous research designed several pos- ture sets, but does not address the limited human capacity of retaining them. We present a multi-finger chord vocabulary, introduce a novel approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy. A between-subjects experiment com- paring random to a categorized chord-command mapping found that users retained categorized mappings more accurate over one week than random ones. In response to the logical posture-language structure, people adapted to logical mem- orization strategies, such as exclusion, order, and category, to minimize the amount of information to retain. We conclude that structured chord-command mappings support learning, short-, and long-term retention of chord-command mappings.","shortAbstract":"Despite the demonstrated benefits of multi-finger input, to- days gest","id":"pn113"},"session":"Touch: Multitouchy Feely","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn113"},"pn119":{"lastUpdateTime":1389236966690,"subcommitteeSplit":"A","labels":{"HCI and personal finance":{"dislikes":[],"lastTimeUpdated":1386524625663,"checked":true,"likes":[],"label":"HCI and personal finance"},"money":{"dislikes":[],"lastTimeUpdated":1386525048598,"checked":true,"likes":[],"label":"money"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386538107387,"label":"Universal (or Disability)  Access"},"banking":{"dislikes":[],"lastTimeUpdated":1386525059226,"checked":true,"likes":[],"label":"banking"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524530826,"label":"Empirical Methods, Qualitative"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"HCI and finance":{"dislikes":[],"lastTimeUpdated":1386524230470,"checked":true,"likes":["dabbish@cmu.edu","Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"label":"HCI and finance"},"Show Me the Money":{"dislikes":[],"lastTimeUpdated":1386527547910,"checked":true,"likes":["lorrie@acm.org"],"label":"Show Me the Money"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525634401,"label":"User Studies"},"low income":{"dislikes":[],"lastTimeUpdated":1386525161703,"checked":true,"likes":["lorrie@acm.org","Brumby@cs.ucl.ac.uk","sameer.patil@hiit.fi"],"label":"low income"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946669}},"creationTime":15,"content":{"authorList":["John Vines, Newcastle University","Paul Dunphy, Newcastle University","Andrew Monk, University of York"],"title":"Pay or Delay: The Role of Technology When Managing a Low Income","paperOrNote":"Paper","fullAbstract":"This paper reports on a qualitative study of 38 low-income individuals living in the Anon region of England. The participants' experiences of money, banking and the role digital technology plays in their financial practices were identified through semi-structured interviews in peoples homes and group workshops. A grounded theory analysis of these data characterises how technology both helped and hindered participants to keep close control of their finances. These findings suggest design opportunities for future digital banking technologies that extend the already sophisticated practices of individuals managing a low income, focusing on: delaying, prioritising, planning, watching, and hiding monetary transactions.","shortAbstract":"This paper reports on a qualitative study of 38 low-income individuals","id":"pn119"},"session":"HCI4D: Finances","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn119"},"pn118":{"lastUpdateTime":1389238884539,"subcommitteeSplit":"A","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386535690551,"label":"Older Adults"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Theater":{"checked":true,"lastUpdateTime":1386535776774,"dislikes":[],"label":"Theater","lastTimeUpdated":1386523131375,"likes":[]},"New Design Methods":{"dislikes":[],"lastTimeUpdated":1386523628573,"checked":true,"likes":["scott.davidoff@jpl.nasa.gov"],"label":"New Design Methods"},"Design Fiction":{"checked":false,"lastUpdateTime":1386528411938,"dislikes":[],"label":"Design Fiction","lastTimeUpdated":1386523228409,"likes":[]},"dialogue":{"dislikes":[],"lastTimeUpdated":1386523231109,"checked":true,"likes":[],"label":"dialogue"},"Performance":{"dislikes":[],"lastTimeUpdated":1386523119273,"checked":true,"likes":[],"label":"Performance"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"design fiction":{"dislikes":[],"lastTimeUpdated":1386528409175,"checked":true,"likes":[],"label":"design fiction"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711793}},"creationTime":14,"content":{"authorList":["John Vines, Newcastle University","Tess Denman-Cleaver, Newcastle University","Paul Dunphy, Newcastle University","Peter Wright, Newcastle University","Patrick Olivier, Newcastle University"],"title":"Experience Design Theatre: Exploring the Role of Live Theatre in Scaffolding Design Dialogues","paperOrNote":"Paper","fullAbstract":"Theatre has been used in HCI as a tool for engaging participants in design processes. To date, however, the specific benefits of using live theatre over other communicative mediums, especially in projects involving multiple and diverse stakeholder groups, remains underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach to undertaking experience-centered design with multiple parties in the early stage of a design project. EDT was motivated by a need to involve several, diverse groups of people in the design of a digitally coordinated care service - NetCarers. We used live theatre as a way to engage small groups of participants in focused discussions around the design of NetCarers, to qualify their contributions in a refined performance, and to communicate their concerns and aspirations to domain experts. We highlight key benefits to using live theatre in experience-centered design work, and offer insights for researchers undertaking similar work in the future.","shortAbstract":"Theatre has been used in HCI as a tool for engaging participants in de","id":"pn118"},"session":"Design: Research through Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn118"},"pn965":{"lastUpdateTime":1389221950963,"subcommitteeSplit":"","labels":{"Body":{"checked":false,"lastUpdateTime":1386531601032,"dislikes":[],"label":"Body","lastTimeUpdated":1386527242414,"likes":[]},"muscles":{"checked":false,"lastUpdateTime":1386531598637,"dislikes":[],"label":"muscles","lastTimeUpdated":1386527278088,"likes":[]},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386531580131,"checked":true,"likes":["judy.kay@gmail.com"],"label":"Gestural interaction"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531654738,"label":"Usability Testing and Evaluation"},"gestures":{"checked":false,"lastUpdateTime":1386531591630,"dislikes":[],"label":"gestures","lastTimeUpdated":1386529181571,"likes":[]},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531674062,"label":"User Interface Design"},"Gestural Interaction":{"checked":false,"lastUpdateTime":1386531589406,"dislikes":[],"label":"Gestural Interaction","lastTimeUpdated":1386531563823,"likes":[]},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386531729060,"label":"Input and Interaction Technologies"},"Gesture":{"checked":false,"lastUpdateTime":1386531514746,"dislikes":[],"label":"Gesture","lastTimeUpdated":1386528799258,"likes":["marcodesa@gmail.com","judy.kay@gmail.com"]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165033}},"creationTime":683,"content":{"authorList":["Juan David Hincapi-Ramos, University of Manitoba","Xiang Guo, University of Manitoba","Pourang Irani, University of Manitoba"],"title":"Consumed Endurance: A Metric to Quantify Arm Fatigue of Mid-Air Interactions","paperOrNote":"Paper","fullAbstract":"Mid-air interactions are prone to fatigue and lead to a feeling \\ of heaviness in the upper limbs, a condition casually termed \\ as the gorilla-arm effect. Designers have often associated \\ limitations of their mid-air interactions with arm fatigue, but \\ do not possess a quantitative method to assess and therefore \\ mitigate it. In this paper we propose a novel metric, \\ Consumed Endurance (CE), derived from the biomechanical \\ structure of the upper arm and aimed at characterizing the \\ gorilla-arm effect. We present a method to capture CE in a \\ non-intrusive manner using an off-the-shelf camera-based \\ skeleton tracking system, and demonstrate that CE correlates \\ strongly with the Borg CR10 scale of perceived exertion. We \\ show how designers can use CE as a complementary metric \\ for evaluating existing and designing novel mid-air \\ interactions, including tasks with repetitive input such as \\ mid-air text-entry. Finally, we propose a series of guidelines \\ for the design of fatigue-efficient mid-air interfaces.","shortAbstract":"Mid-air interactions are prone to fatigue and lead to a feeling \\ of h","id":"pn965"},"session":"UIST: On the surface","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn965"},"pn286":{"lastUpdateTime":1389590959349,"subcommitteeSplit":"","labels":{"Smartphones":{"dislikes":[],"lastTimeUpdated":1386523539197,"checked":true,"likes":[],"label":"Smartphones"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"smart city":{"dislikes":[],"lastTimeUpdated":1386523480595,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk","emailaddress"],"label":"smart city"},"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"MESH Networking":{"dislikes":[],"lastTimeUpdated":1386521716894,"checked":true,"likes":[],"label":"MESH Networking"},"Emergency Response":{"dislikes":[],"lastTimeUpdated":1386521720206,"checked":true,"likes":["myriam.lewkowicz@utt.fr","gabriela.avram@gmail.com","teevan@gmail.com","emailaddress"],"label":"Emergency Response"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556732}},"creationTime":139,"content":{"authorList":["Amro Al-Akkad, Fraunhofer Institute for Applied Information Technology (FIT)","Leonardo Ramirez, Fraunhofer Headquarters","Alexander Boden, Fraunhofer Institute for Applied Information Technology (FIT)"],"title":"Help Beacons: Design and Evaluation of an Ad-Hoc Lightweight S.O.S. System for Smartphones","paperOrNote":"Paper","fullAbstract":"We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates ad-hoc communication between first responders and victims in emergency situations in the face of disruptions of existing network infrastructure. Our approach leverages established protocols and standards in unforeseen ways to provide a platform supporting the creation of short-lived communication links. The system comprises two mobile applications: one victim application that allows the broadcasting of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that allows first responders to discover and trace the people broadcasting the signals. The main difference of our system with other platforms enabling communication in crisis situations is, that our system is independent from existing network infrastructure and runs on off-the-shelf, commercially available smartphones. We describe the results of our evaluation process in the context of both a design evaluation during a real-world emergency response exercise as well as of two user workshops in preparation for an upcoming large-scale exercise.","shortAbstract":"We present the design and evaluation of a lightweight mobile S.O.S. sy","id":"pn286"},"session":"HCI4D: Emergency Response","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn286"},"pn967":{"lastUpdateTime":1389236845002,"subcommitteeSplit":"A","labels":{"Organizational Culture / Organizational Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Organizational Culture / Organizational Planning"},"making practices":{"dislikes":[],"lastTimeUpdated":1386523329893,"checked":true,"likes":[],"label":"making practices"},"stuff and things":{"dislikes":[],"lastTimeUpdated":1386522917718,"checked":true,"likes":[],"label":"stuff and things"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"Ethnography":{"checked":true,"dislikes":[],"likes":["e.v.d.hoven@tue.nl"],"lastUpdateTime":123456789,"label":"Ethnography"},"Maker":{"dislikes":[],"lastTimeUpdated":1386523030107,"checked":true,"likes":[],"label":"Maker"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711749}},"creationTime":685,"content":{"authorList":["Silvia Lindtner, University of California, Irvine","Garnet Hertz, University of California Irvine","Paul Dourish, University of California, Irvine"],"title":"Emerging Sites of HCI Innovation: Hackerspaces, Hardware Startups & Incubators","paperOrNote":"Paper","fullAbstract":"In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible, mobile and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY maker practice, we will provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we will show how DIY maker practice is illustrative of a broader return to and interest in physical materials. This has implications for recent HCI research that has begun investigating questions of materiality. Second, we shed light on how hackerspace and hardware incubators are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these bottom-up maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for a deep engagement with materials, tools and design methods.","shortAbstract":"In this paper, we discuss how a flourishing scene of DIY makers ","id":"pn967"},"session":"Making: how things don't work","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn967"},"pn288":{"lastUpdateTime":1389591757480,"subcommitteeSplit":"","labels":{"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"User Interface Design"},"camera tracking":{"dislikes":[],"lastTimeUpdated":1386526116106,"checked":true,"likes":[],"label":"camera tracking"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644724}},"creationTime":141,"content":{"authorList":["Andreas Mller, Technische Universitt Mnchen","Stefan Diewald, Technische Universitt Mnchen","Luis Roalter, Technische Universitt Mnchen","Tobias Stockinger, Universitt Passau","Marion Koelle, Universitt Passau","Patrick Lindemann, University of Passau","Matthias Kranz, University of Passau"],"title":"A Real-World Evaluation of User Interfaces for Visual Indoor Navigation","paperOrNote":"Paper","fullAbstract":"Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. \\ We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system motivates the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a real-world navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.","shortAbstract":"Mobile location recognition by capturing images of the environment (vi","id":"pn288"},"session":"Displays: Head-Worn Displays (UIST)","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn288"},"pn761":{"lastUpdateTime":1389285647205,"subcommitteeSplit":"A","labels":{"theory-driven design":{"dislikes":[],"lastTimeUpdated":1386523584859,"checked":true,"likes":[],"label":"theory-driven design"},"behavior change":{"dislikes":[],"lastTimeUpdated":1386523893913,"checked":true,"likes":[],"label":"behavior change"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["klasnja@umich.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526772817,"label":"Empirical Methods, Quantitative"},"persuasive":{"dislikes":[],"lastTimeUpdated":1386523580517,"checked":true,"likes":[],"label":"persuasive"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526683355,"label":"User-Centered Design / Human-Centered Design"},"Persuasive Design":{"dislikes":[],"lastTimeUpdated":1386523656517,"checked":true,"likes":[],"label":"Persuasive Design"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188187}},"creationTime":511,"content":{"authorList":["Anne Hsu, Queen Mary University of London","Jing Yang, Queen Mary, University of London","Yigit Han Yilmaz, Queen Mary, University of London","Md Sanaul Haque, Queen Mary, University of London","Cengiz Can, Queen Mary, University of London","Ann Blandford, University College London"],"title":"Applying Decision Theory To Persuasive Design: Psychological Rewards And Costs In Weight Management","paperOrNote":"Paper","fullAbstract":"A central challenge in weight management is the difficulty of overcoming desires for excessive and unhealthy food. However, studies show that when people are able to resist their desires for unhealthy choices, they experience pride and satisfaction. In order to alleviate the former and support the latter, we designed, implemented and tested a mobile application for improving snacking behavior. Our application delivers a food craving reduction intervention at the moment of need and allows users to track how often they successfully resisted cravings. Our craving reduction intervention is based on recent research that shows that food cravings can be reduced through imagery techniques. We conducted a week-long evaluation of our application, comparing the effectiveness of our application to a basic tracking application. We found that our imagery application significantly reduced both overall snacking and unhealthy snacking compared to a simple snack-tracking application. ","shortAbstract":"A central challenge in weight management is the difficulty of overcomi","id":"pn761"},"session":"Health: Persuade Me","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn761"},"pn1161":{"lastUpdateTime":1389285488228,"subcommitteeSplit":"A","labels":{"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386528377578,"checked":true,"likes":[],"label":"crowdsourcing"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Crowdsourcing":{"checked":false,"lastUpdateTime":1386528375950,"dislikes":[],"label":"Crowdsourcing","lastTimeUpdated":1386523847975,"likes":["kris.luyten@uhasselt.be"]},"Memory":{"dislikes":[],"lastTimeUpdated":1386524282572,"checked":true,"likes":[],"label":"Memory"},"Human Computation":{"dislikes":[],"lastTimeUpdated":1386524110804,"checked":true,"likes":[],"label":"Human Computation"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386523949323,"checked":true,"likes":["kris.luyten@uhasselt.be"],"label":"Crowd-Powered Systems"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081855}},"creationTime":851,"content":{"authorList":["Jeffrey Bigham, Carnegie Mellon University","Walter Lasecki, University of Rochester"],"title":"Crowd Storage: Storing Information on Existing Memories","paperOrNote":"Note","fullAbstract":"This paper introduces the concept of crowd storage, the idea that digital information can be stored and retrieved later from the memories of people in the crowd. Crowd storage may be useful when storing information in the memories of people is preferred over storing information in the cloud, when it is desirable for information to degrade inline with normal human memories, or possibly when used as a memory component in a human computation architecture. To explore and validate this idea, we created WeStore, a system that stores and then later retrieves digital images in the existing memories of crowd workers. WeStore does not store information directly, but rather connects information to existing memories elicited from individuals within the crowd, using details of the memories as keys to encrypt and then later decrypt the information that was stored. The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided. We demonstrate that crowd storage is feasible using an existing crowd marketplace (Amazon Mechanical Turk), explore a number of design considerations important for building systems that use crowd storage, and outline ideas for future research in this area.","shortAbstract":"This paper introduces the concept of crowd storage, the idea that digi","id":"pn1161"},"session":"CSCW: interactions in the crowd","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1161"},"pn1362":{"lastUpdateTime":1389286103691,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523446726,"label":"E-Learning and Education"},"MOOCs":{"dislikes":[],"lastTimeUpdated":1386523269443,"checked":true,"likes":[],"label":"MOOCs"},"Video Content / Communications":{"checked":false,"lastUpdateTime":1386526438865,"dislikes":[],"label":"Video Content / Communications","lastTimeUpdated":1386523866330,"likes":["mentis@umbc.edu"]},"design for learning":{"checked":false,"lastUpdateTime":1386539842365,"dislikes":[],"label":"design for learning","lastTimeUpdated":1386526419654,"likes":[]},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526316646,"label":"User Interface Design"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526343469,"label":"Computer-Mediated Communication"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526319851,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526325016,"label":"User Experience Design / Experience Design"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188226}},"creationTime":1029,"content":{"authorList":["Ren Kizilcec, Stanford University","Kathryn Papadopoulos, Stanford University","Lalida Sritanyaratana, Stanford University"],"title":"Showing Face in Video Instruction: Effects on Information Retention, Visual Attention, and Affect","paperOrNote":"Paper","fullAbstract":"The amount of online educational content is rapidly increasing, particularly in the form of video lectures. The goal is to design video instruction to facilitate an experience that maximizes learning and satisfaction, while keeping down production costs. A widely used but understudied design element in video instruction is the overlay of a small video of the instructor over lecture slides. We conducted an experiment (N=22) using eye-tracking and recall knowledge tests to investigate how adding the instructor's face to video instruction affects information retention, visual attention, and affect. Participants prefer instruction with the face and perceive it as more educational. However, it had no effect on short- and medium-term recall ability, even though participants spent about 41% of time looking at the face when present. Although it has no impact on information retention, video producers should weigh the cost of adding the face against the value of increased satisfaction.","shortAbstract":"The amount of online educational content is rapidly increasing, partic","id":"pn1362"},"session":"HCI4D: Learning and Education","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1362"},"pn1360":{"lastUpdateTime":1389590806489,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Interface Design":{"dislikes":[],"lastTimeUpdated":1386531615025,"checked":true,"likes":["rsodhi2@illinois.edu"],"label":"User Interface Design"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu","eve.hoggan@hiit.fi","olwal@mit.edu"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Visualization":{"dislikes":[],"lastTimeUpdated":1386531710653,"checked":true,"likes":["rsodhi2@illinois.edu"],"label":"Visualization"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840619}},"creationTime":1027,"content":{"authorList":["Alexander Adams, University of North Carolina at Charlotte","Berto Gonzalez, University of North Carolina at Charlotte","Celine Latulipe, University of North Carolina at Charlotte"],"title":"SonicExplorer: Fluid Exploration of Audio Parameters","paperOrNote":"Paper","fullAbstract":"In digital music production, the phrase ``in the box'' refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.","shortAbstract":"In digital music production, the phrase ``in the box'' refers to the i","id":"pn1360"},"session":"UBI: Audio Interaction","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1360"},"pn847":{"lastUpdateTime":1389221479624,"subcommitteeSplit":"","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386531551970,"checked":true,"likes":["hq@northwestern.edu"],"label":"gestures"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386530770373,"label":"Multimedia UIs"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386530744497,"label":"User-Centered Design / Human-Centered Design"},"Gesture":{"checked":false,"lastUpdateTime":1386531557918,"dislikes":[],"label":"Gesture","lastTimeUpdated":1386527974644,"likes":["judy.kay@gmail.com"]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165012}},"creationTime":579,"content":{"authorList":["Gustavo Rovelo Ruiz, Universitat Politcnica de Valncia","Davy Vanacken, Hasselt University - tUL - iMinds","Kris Luyten, Hasselt University - tUL - iMinds","Francisco Abad, Universitat Politcnica de Valncia","Emilio Camahort, Universitat Politcnica de Valncia"],"title":"Multi-Viewer Gesture-Based Interaction for Omni-Directional Video","paperOrNote":"Paper","fullAbstract":"Omni-directional video (ODV) offers viewers a 360 degree panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that 3D television is on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual usage and usage in collocated settings. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.","shortAbstract":"Omni-directional video (ODV) offers viewers a 360 degree panoramic rec","id":"pn847"},"session":"UIST: Gesture-based interaction","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn847"},"pn845":{"lastUpdateTime":1389107783778,"subcommitteeSplit":"C","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["kash@diku.dk","mtory@cs.uvic.ca","christopher.power@york.ac.uk"],"lastUpdateTime":123456789,"label":"Visualization"},"Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526181786,"label":"Visual Design"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386526169823,"checked":true,"likes":["mtory@cs.uvic.ca","joanna@cs.ub.ca"],"label":"Information Visualization"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526154075,"label":"User Studies"},"Graph Visualization":{"dislikes":[],"lastTimeUpdated":1386526191699,"checked":true,"likes":[],"label":"Graph Visualization"},"Navigation":{"checked":false,"lastUpdateTime":1386527463187,"dislikes":[],"label":"Navigation","lastTimeUpdated":1386527177705,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486612}},"creationTime":577,"content":{"authorList":["Basak Alper, University of California, Santa Barbara","Nathalie Henry Riche, Microsoft Research","Tobias Hollerer, University of California, Santa Barbara"],"title":"Structuring the Space: A Study on Enriching Node-Link Diagrams with Visual References","paperOrNote":"Paper","fullAbstract":"Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report  \\ mixed results regarding their utility. While some evidence showed that grid and  \\ other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture  \\ the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.","shortAbstract":"Exploring large visualizations that do not fit in the screen raises or","id":"pn845"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn845"},"pn1942":{"lastUpdateTime":1389221083200,"subcommitteeSplit":"B","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu","ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Visualization"},"User Studies":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"Game User Research":{"dislikes":[],"lastTimeUpdated":1386522680920,"checked":true,"likes":[],"label":"Game User Research"},"Entertainment":{"checked":false,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":1386522936080,"label":"Entertainment"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755955}},"creationTime":1530,"content":{"authorList":["Simone Kriglstein, Institute for Design and Assessment of Technology","Guenter Wallner, Institute of Art & Technology","Margit Pohl, Vienna University of Technology"],"title":"A User Study of Different Gameplay Visualizations","paperOrNote":"Paper","fullAbstract":"With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness and suitability. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data. ","shortAbstract":"With the rising interest in multiplayer gaming, gameplay statistics ha","id":"pn1942"},"session":"Games: Fun N Play","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1942"},"pn1949":{"lastUpdateTime":1389284883677,"subcommitteeSplit":"A","labels":{"Concept Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Concept Design"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523691676,"label":"Prototyping"},"Sustainability":{"dislikes":[],"lastTimeUpdated":1386523493087,"checked":true,"likes":[],"label":"Sustainability"},"eco-design":{"dislikes":[],"lastTimeUpdated":1386522717466,"checked":true,"likes":["ledantec@gatech.edu"],"label":"eco-design"},"reflection provocation":{"dislikes":[],"lastTimeUpdated":1386523231277,"checked":true,"likes":[],"label":"reflection provocation"},"performativity":{"dislikes":[],"lastTimeUpdated":1386523465399,"checked":true,"likes":[],"label":"performativity"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711766}},"creationTime":1536,"content":{"authorList":["Maria Normark, Sdertrn University","Jakob Tholander, Mobile Life, Stockholm University"],"title":"Performativity in Sustainable Interaction:  The Case of Seasonal Grocery Shopping in EcoFriends","paperOrNote":"Paper","fullAbstract":"The EcoFriends application was developed as an attempt to support grocery shopping adjusted to vegetables seasonality through a performative approach to interaction and interactive applications. The design aimed for critical reflection and inspiration among users, rather than achieving a certain kind of persuasion. It guided the practical design to be modelled on playfulness and challenging of ideas. It also allowed us to identify a number of critical issues regarding interactive technology and interaction design, related to aspects of knowledge and truth, trust, and responsibility. We argue that research addressing design for interactions about value-laden concepts such as sustainable action need find ways of supporting various knowledge discourses.","shortAbstract":"The EcoFriends application was developed as an attempt to support groc","id":"pn1949"},"session":"HCI4D: Sustainability and Everyday Practices","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1949"},"pn2447":{"lastUpdateTime":1389236450714,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"Debugging":{"dislikes":[],"lastTimeUpdated":1386524300958,"checked":true,"likes":[],"label":"Debugging"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["nebeling@inf.ethz.ch","kris.luyten@uhasselt.be","fabio.paterno@isti.cnr.it"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081863}},"creationTime":1960,"content":{"authorList":["Tom Lieber, Massachusetts Institute of Technology","Joel Brandt, Adobe Research","Rob Miller, Massachusetts Institute of Technology"],"title":"Addressing Misconceptions About Code with Always-On Programming Visualizations","paperOrNote":"Paper","fullAbstract":"We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.","shortAbstract":"We present Theseus, an IDE extension that visualizes run-time behavior","id":"pn2447"},"session":"Systems: Development Tools","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn2447"},"pn2442":{"lastUpdateTime":1388785654801,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"lastUpdateTime":1386526367711,"dislikes":[],"label":"Visualization","lastTimeUpdated":1386525657537,"likes":[]},"Visual System Design / Visual Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visual System Design / Visual Design"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525284518,"checked":true,"likes":["dan@microsoft.com","bulling@mpi-inf.mpg.de"],"label":"Information Visualization"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644778}},"creationTime":1958,"content":{"authorList":["Vidya Setlur, Tableau Software","Jock Mackinlay, Tableau Software"],"title":"Shaping Up Visualizations with Semantic Icon Encodings","paperOrNote":"Paper","fullAbstract":"Shape encoding can provide meaning semantics to categorical information in a visualization. Quite often, visualization tools neither provide shape libraries that are meaningful nor sufficient enough to handle larger cardinalities of data. The user is then forced to manually create or search for icons that can hinder the flow of visual analysis, leading to a suboptimal user experience. We propose a technique for automatically \\ generating semantically relevant shape encodings for a given visualization. The algorithm employs natural language processing in order to find relevant imagery from the \\ Internet. We evaluate our approach on Mechanical Turk by generating large libraries of shape icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created shapes, and particularly has higher user satisfaction for larger cardinalities of data.","shortAbstract":"Shape encoding can provide meaning semantics to categorical informatio","id":"pn2442"},"session":"Viz: Visual System Design","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn2442"},"pn2441":{"lastUpdateTime":1389236648218,"subcommitteeSplit":"","labels":{"Help":{"checked":false,"lastUpdateTime":1386532111620,"dislikes":[],"label":"Help","lastTimeUpdated":1386532108261,"likes":[]},"Apps":{"checked":false,"lastUpdateTime":1386532072334,"dislikes":[],"label":"Apps","lastTimeUpdated":1386532069253,"likes":[]},"End-user Programming":{"dislikes":[],"lastTimeUpdated":1386532484511,"checked":true,"likes":[],"label":"End-user Programming"},"tutorials":{"checked":false,"lastUpdateTime":1386532596436,"dislikes":[],"label":"tutorials","lastTimeUpdated":1386532514390,"likes":[]},"Computer vision":{"dislikes":[],"lastTimeUpdated":1386532404126,"checked":true,"likes":[],"label":"Computer vision"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Tutorials":{"dislikes":[],"lastTimeUpdated":1386532506936,"checked":true,"likes":[],"label":"Tutorials"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Programming by Demonstration":{"dislikes":[],"lastTimeUpdated":1386532577100,"checked":true,"likes":[],"label":"Programming by Demonstration"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"mobile apps":{"dislikes":[],"lastTimeUpdated":1386532583502,"checked":true,"likes":[],"label":"mobile apps"},"Handheld Devices and Mobile Computing":{"checked":false,"lastUpdateTime":1386532584854,"dislikes":[],"label":"Handheld Devices and Mobile Computing","lastTimeUpdated":1386532294312,"likes":[]},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840729}},"creationTime":1957,"content":{"authorList":["Cheng-Yao Wang, National Taiwan University","Wei-Chen Chu, National Taiwan University","Hou-Ren Chen, National Taiwan University","Mike Chen, National Taiwan University"],"title":"EverTutor: Automatically Creating Interactive Step-by-Step Tutorials on Smartphones","paperOrNote":"Paper","fullAbstract":"Smartphone users tend to search tutorials from the Internet when encountering problems in some scenarios, such as learning newly installed apps or advanced features. However, general static and video tutorials trouble users because of the frequent switch between tutorials and user contexts. We present EverTutor, a system that automatically generates interactive step-by-step tutorials on smartphone from user demonstrations. EverTutor records low-level touch events, distinguishes touchscreen gestures and extracts regional screenshot around event location to generate tutorials automatically. When a tutorial is browsed, the system not only uses vision-based techniques to locate the target interactive region and overlay the tutorial contextually, but also identifies the correctness of the users interaction and gives response. Besides, EverTutor automatically scroll or swipe to help users find the unseen interactive region. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, in which interactive tutorials were compared with static and video ones. Our results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials, and that interactive tutorial is the fastest in task completion time and 3 times faster the other types. 83% of the users chose interactive type as the preferred tutorial type and rated highest in easy to follow and easy to understand.","shortAbstract":"Smartphone users tend to search tutorials from the Internet when encou","id":"pn2441"},"session":"Systems: Tutorials","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2441"},"pn2449":{"lastUpdateTime":1389222026624,"subcommitteeSplit":"","labels":{"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386538594818,"checked":true,"likes":[],"label":"Target Acquisition"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Selection Techniques":{"dislikes":[],"lastTimeUpdated":1386532202438,"checked":true,"likes":[],"label":"Selection Techniques"},"Target Aquisition":{"checked":false,"lastUpdateTime":1386538599030,"dislikes":[],"label":"Target Aquisition","lastTimeUpdated":1386531728866,"likes":["yangli@acm.org","olwal@mit.edu"]},"input":{"dislikes":[],"lastTimeUpdated":1386531707124,"checked":true,"likes":["tomer@moscovich.net","eve.hoggan@hiit.fi"],"label":"input"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840702}},"creationTime":1962,"content":{"authorList":["Martez Mott, University of Washington","Jacob Wobbrock, University of Washington"],"title":"Beating the Bubble: Using Kinematic Triggering in the Bubble Lens for Acquiring Small, Dense Targets","paperOrNote":"Paper","fullAbstract":"We present the Bubble Lens, a new target acquisition technique that remedies the limitations of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense targetsprecisely those targets for which the Bubble Cursor degenerates to a point cursor. When targets are large and sparse, the Bubble Lens behaves like the default Bubble Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies nearby targets, making them larger in both visual and motor-space. Importantly, magnification is not governed by an explicit user-invoked mode-switch. Rather, magnification is activated through kinematic triggering, a technique that continuously examines an unfolding velocity profile to automatically trigger mode changes based on observed features. In a first study, we found the Bubble Cursor performed poorly when targets had an effective size smaller than 10 pixels. Using this threshold for the Bubble Lens in a second study, we found that the Bubble Lens significantly outperformed the Bubble Cursor, decreasing movement time by 10.2% and error rates by 34.3%, making the Bubble Lens quite possibly the fastest known pointing technique.","shortAbstract":"We present the Bubble Lens, a new target acquisition technique that re","id":"pn2449"},"session":"UIST: Pointing","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2449"},"pn2140":{"lastUpdateTime":1389236332031,"subcommitteeSplit":"B","labels":{"design in publics":{"dislikes":[],"lastTimeUpdated":1386522949421,"checked":true,"likes":[],"label":"design in publics"},"Science and Technology Studies":{"checked":true,"lastUpdateTime":1386523223457,"dislikes":[],"label":"Science and Technology Studies","lastTimeUpdated":1386522020668,"likes":[]},"design theory":{"dislikes":[],"lastTimeUpdated":1386531225117,"checked":true,"likes":[],"label":"design theory"},"Design Theory":{"checked":false,"lastUpdateTime":1386531227698,"dislikes":[],"label":"Design Theory","lastTimeUpdated":1386522324108,"likes":["bilge@cs.wisc.edu","stuart@tropic.org.uk","reinecke@umich.edu"]},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"critical design":{"dislikes":[],"lastTimeUpdated":1386521955868,"checked":true,"likes":["wendyju@stanford.edu","stuart@tropic.org.uk"],"label":"critical design"},"adversarial design":{"dislikes":[],"lastTimeUpdated":1386522442140,"checked":true,"likes":[],"label":"adversarial design"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["stuart@tropic.org.uk","reinecke@umich.edu","adf"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"contestational design":{"dislikes":[],"lastTimeUpdated":1386522409967,"checked":true,"likes":[],"label":"contestational design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755966}},"creationTime":1703,"content":{"authorList":["Carl DiSalvo, Georgia Institute of Technology","Jonathan Lukens, Georgia Institute of Technology","Thomas Lodato, Georgia Institute of Technology","Tom Jenkins, Georgia Institute of Technology","Tanyoung Kim, Georgia Institute of Technology"],"title":"Making Public Things: How HCI Design Can Express Matters of Concern","paperOrNote":"Paper","fullAbstract":"Science studies scholar Bruno Latour suggests that contemporary democracy is shifting from matters of fact to matters of concern. What is the role of HCI design in this endeavor? In this paper we draw from five design projects to explore the ways that design can work to express matters of concern, in effect, to communicate the factors and consequences of issues to broader publics.  In the process we consider the role of design in contributing to the formation of publics and reflect on what might an orientation toward public design in HCI. ","shortAbstract":"Science studies scholar Bruno Latour suggests that contemporary democr","id":"pn2140"},"session":"Design: Critical Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2140"},"pn1896":{"lastUpdateTime":1388765600113,"subcommitteeSplit":"","labels":{"Older Adults":{"checked":false,"lastUpdateTime":1386535824020,"dislikes":[],"label":"Older Adults","lastTimeUpdated":1386521748730,"likes":[]},"Caring for people":{"dislikes":[],"lastTimeUpdated":1386523128226,"checked":true,"likes":["emailaddress"],"label":"Caring for people"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Aging society":{"dislikes":[],"lastTimeUpdated":1386521491788,"checked":true,"likes":[],"label":"Aging society"},"Health Care":{"checked":true,"dislikes":[],"likes":["gabriela.avram@gmail.com","teevan@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk","emailaddress"],"lastUpdateTime":123456789,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523304394,"label":"Empirical Methods, Qualitative"},"network of care":{"dislikes":[],"lastTimeUpdated":1386523749606,"checked":true,"likes":[],"label":"network of care"},"dementia":{"dislikes":[],"lastTimeUpdated":1386535798306,"checked":true,"likes":[],"label":"dementia"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556792}},"creationTime":1488,"content":{"authorList":["Lin Wan, University of Siegen","Claudia Mller, University of Siegen","Volker Wulf, University of Siegen","David Randall, University of Siegen, Germany"],"title":"Addressing the Subtleties in Dementia Care: Pre-study & Evaluation of a GPS Monitoring System","paperOrNote":"Paper","fullAbstract":"In this work we present a user-centered development process for a GPS-based monitoring system to be used in dementia care. Our research covers a full design process including a qualitative-empirical pre-study, the prototyping process and the investigation of long-term appropriation processes of the stable prototypes in three different practice environments. The paper contributes to a more fine-grained understanding of the lines of conflicts in dementia care which impact on care practices in care environments. Specifically, we deal with the problem of wandering by persons suffering from dementia. We assess the practical and ideological issues surrounding care in different settings - the familial and the institutional - and report on the design of a GPS-based tracking system reflecting these considerations. What comes to the fore is the need for ICT to reflect complex organizational, ideological and practical issues that form part of a moral universe where sensitivity is crucial. ","shortAbstract":"In this work we present a user-centered development process for a GPS-","id":"pn1896"},"session":"Health: Network of care","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1896"},"pn2020":{"lastUpdateTime":1388766320872,"subcommitteeSplit":"A","labels":{"gaming":{"checked":false,"lastUpdateTime":1386523825246,"dislikes":[],"label":"gaming","lastTimeUpdated":1386523230820,"likes":["ian.r.oakley@gmail.com"]},"Tablet application":{"dislikes":[],"lastTimeUpdated":1386523146556,"checked":true,"likes":[],"label":"Tablet application"},"accessibility":{"checked":false,"lastUpdateTime":1386529198780,"dislikes":[],"label":"accessibility","lastTimeUpdated":1386522807468,"likes":[]},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522844158,"label":"Usability Testing and Evaluation"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"game":{"checked":true,"lastUpdateTime":1386523824017,"dislikes":[],"label":"game","lastTimeUpdated":1386522796792,"likes":["lennart.nacke@uoit.ca"]},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Children":{"dislikes":[],"lastTimeUpdated":1386523120861,"checked":true,"likes":[],"label":"Children"},"Accessibility":{"checked":false,"lastUpdateTime":1386536614620,"dislikes":[],"label":"Accessibility","lastTimeUpdated":1386529196683,"likes":[]},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711735}},"creationTime":1596,"content":{"authorList":["Linh Chi Nguyen, Interactive & Digital Media Institute, National University of Singapore","Ellen Yi-Luen Do, National University of Singapore","Audrey Chia, Singapore National Eyes Center","Yuan Wang, Interactive & Digital Media ","Henry Been-Lirn Duh, Interactive & Digital Media "],"title":"DoDo Game, a Color Vision Deficiency Screening Test for Young children","paperOrNote":"Note","fullAbstract":"This paper presents DoDos Catching Adventure, a new color vision deficient screening test for young children. Early detection of color blindness among children is useful for parents and teachers to better understand their child's needs, to overcome difficulties in learning, and life and career planning. Unfortunately, current color screening tests are not designed for young children, most requiring more advanced verbal or cognitive skills than children possess. DoDo game has taken a new approach by embedding game elements into a color vision screening test. A user study was conducted at XXX National Eyes Research Center on 28 children from 6-17 years old, identified fourteen of them as Red-Green deficient subjects as did by Ishihara screening test, showed that DoDo was adequately effective in identifying Red-Green color vision deficiency and is comparable to current gold standard colorblind Ishihara test. Furthermore, participants found the DoDo more enjoyable than the Ishihara and Farnsworth D15 tests.","shortAbstract":"This paper presents DoDos Catching Adventure, a new color vis","id":"pn2020"},"session":"Health: Health and Everyday Life","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2020"},"pn2022":{"lastUpdateTime":1389221449828,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Gestural Interaction":{"dislikes":[],"lastTimeUpdated":1386532288944,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Gestural Interaction"},"Pen-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen-based UIs"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Computer Vision":{"dislikes":[],"lastTimeUpdated":1386532313478,"checked":true,"likes":[],"label":"Computer Vision"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","david.kim@newcastle.ac.uk","olwal@mit.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386532304215,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Gestural interaction"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"3D Interaction":{"dislikes":[],"lastTimeUpdated":1386532325393,"checked":true,"likes":["david.kim@newcastle.ac.uk","olwal@mit.edu"],"label":"3D Interaction"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840549}},"creationTime":1597,"content":{"authorList":["David Kim, Microsoft Research","Shahram Izadi, Microsoft Research","Jakub Dostal, University of St Andrews","Cem Keskin, Microsoft Research","Christoph Rhemann, Microsoft Research","Matthias Niessner, Stanford University","Jamie Shotton, Microsoft Research","Christopher Zach, Microsoft Research","Sean Fanello, Istituto Italiano di Tecnologia","D. Alex Butler, Microsoft Research","Tim Large, Microsoft","Steven Bathiche, Microsoft","Vivek Pradeep, Microsoft"],"title":"FloodLight: 3D Silhouette Sensing for High-Precision Input On and Above Physical Surfaces","paperOrNote":"Paper","fullAbstract":"We present FloodLight, a new vision-based system that accurately senses the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. We use a simple, cheap, and easily reproducible setup, comprising two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retroreflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity (e.g. the users hand). A new low-computation stereo matching algorithm precisely estimates the 3D contours of interacting objects and surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using 3D contour points. We demonstrate extremely high precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above a surface. This allows a variety of interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retroreflective surface, including custom physical widgets fabricated by users. We compare our custom vision system with Kinect and Leap Motion, and conclude with limitations and future work.","shortAbstract":"We present FloodLight, a new vision-based system that accurately sense","id":"pn2022"},"session":"UIST: Gesture Entry","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2022"},"pn2031":{"lastUpdateTime":1389221814307,"subcommitteeSplit":"","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"BCI":{"dislikes":[],"lastTimeUpdated":1386532396980,"checked":true,"likes":[],"label":"BCI"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"passive BCI":{"dislikes":[],"lastTimeUpdated":1386531547998,"checked":true,"likes":[],"label":"passive BCI"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Children":{"checked":true,"dislikes":[],"likes":["eve.hoggan@hiit.fi"],"lastUpdateTime":123456789,"label":"Children"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840570}},"creationTime":1604,"content":{"authorList":["Jin Huang, Tsinghua University","Yuntao Wang, Tsinghua University","Yuhang Zhao, Tsinghua University","Siqi Liu, Tsinghua University","Chou Mo, Tsinghua University","Jie Liu, Tsinghua University","Yuanchun Shi, Tsinghua University"],"title":"FOCUS: Enhancing Childrens Engagement in Reading by Using Contextual BCI Training Sessions","paperOrNote":"Note","fullAbstract":"Reading is critical for deriving knowledge and for childrens personal growth. The reading achievement can be enhanced by increasing reading engagement. To enhance the childrens reading engagement, we designed a reading system - FOCUS with a combination of contextual brain-computer interface (BCI) training sessions. The BCI training sessions are activated when the system detects significant engagement drops and closed automatically when the engagement returns to a high level. An experimental evaluation of our system showed that FOCUS significantly improves childrens reading performance in reading engagement and comprehension. The score of the recall task increases by 40.9% and the accuracy rate of the quiz increases by 26.8%.","shortAbstract":"Reading is critical for deriving knowledge and for childrens person","id":"pn2031"},"session":"Art: Narratives and Storytelling","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2031"},"pn2027":{"lastUpdateTime":1389107972239,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Visualization"},"User Studies":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"User Studies"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"visual analytics":{"dislikes":[],"lastTimeUpdated":1386527990676,"checked":true,"likes":[],"label":"visual analytics"},"Datasets":{"dislikes":[],"lastTimeUpdated":1386527208141,"checked":true,"likes":[],"label":"Datasets"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165058}},"creationTime":1601,"content":{"authorList":["Maoyuan Sun, Virginia Tech","Lauren Bradel, Virginia Polytechnic Institute and State University","Chris North, Virginia Polytechnic Institute and State University","Naren Ramakrishnan, Virginia Tech"],"title":"The Role of Interactive Biclusters in Sensemaking","paperOrNote":"Note","fullAbstract":"Visual exploration of relationships within large, textual datasets is an important aid to users in sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and organizations), users can leverage their domain expertise and intuition to determine importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent collusion. Bixplorer is a visual analytics prototype that supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present the results of a study that analyze how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We find that biclusters play four principal roles in the analytical process: an effective starting point for analysis, a revealer for two levels of connections, an indicator for potentially important entities, and a useful label for clusters of spatially organized information. ","shortAbstract":"Visual exploration of relationships within large, textual datasets is ","id":"pn2027"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2027"},"pn1763":{"lastUpdateTime":1389222127656,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386521673624,"checked":true,"likes":[],"label":"social media"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522492571,"label":"Empirical Methods, Quantitative"},"Social data analysis":{"dislikes":[],"lastTimeUpdated":1386522341641,"checked":true,"likes":["myriam.lewkowicz@utt.fr"],"label":"Social data analysis"},"viral contagion":{"dislikes":[],"lastTimeUpdated":1386523299678,"checked":true,"likes":[],"label":"viral contagion"},"content popularity":{"dislikes":[],"lastTimeUpdated":1386523311253,"checked":true,"likes":[],"label":"content popularity"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523479982,"label":"Social Computing and Social Navigation"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522498178,"label":"User Studies"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556667}},"creationTime":1375,"content":{"authorList":["Flavio Figueiredo, Universidade Federal de Minas Gerais","Krishna Gummadi, Max Planck Institute of Software Systems","Fabrcio Benevenuto, Universidade Federal de Minas Gerais","Jussara Almeida, Universidade Federal de Minas Gerais"],"title":"What Drives Information Popularity in Social Media: Content or Dissemination?","paperOrNote":"Note","fullAbstract":"In this paper, we investigate what drives the popularity of information on social media platforms. Specifically, we focus on the YouTube video sharing site and seek to understand the extent to which a video's content by itself determines the video's popularity.  \\ Using mechanical turk as experimental platform, we asked users to evaluate pairs of videos, and compared users' relative perception of the videos' content against the videos' relative popularity as reported by YouTube. We found that users perception of content tends to be very subjective and that in a majority of our evaluations users could not reach consensus on which video had better content. Nevertheless, when users' reached consensus, the video with preferred content almost always achieved greater popularity on YouTube, highlighting the importance of content in driving popularity of information on social media. ","shortAbstract":"In this paper, we investigate what drives the popularity of informatio","id":"pn1763"},"session":"Social: Social Media Applied","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1763"},"pn1760":{"lastUpdateTime":1387830347931,"subcommitteeSplit":"B","labels":{"ontology development tools":{"dislikes":[],"lastTimeUpdated":1386523013931,"checked":true,"likes":[],"label":"ontology development tools"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Model-based design and evaluation":{"dislikes":[],"lastTimeUpdated":1386538607676,"checked":true,"likes":[],"label":"Model-based design and evaluation"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386522881528,"label":"Development Tools / Toolkits / Programming Environments"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032779}},"creationTime":1372,"content":{"authorList":["Markel Vigo, University of Manchester","Caroline Jay, University of Manchester","Robert Stevens, University of Manchester"],"title":"Design Insights for the Next Wave Ontology Authoring Tools","paperOrNote":"Note","fullAbstract":"Ontologies have been employed across scientific and business domains for some time, and the proliferation of linked data means the number and range of potential authors is set to increase significantly. Ontologies are complex artefacts, however: the authoring process requires not only knowledge of the application domain, but also skills in programming and description logics. To date, there has been no systematic attempt to understand the effectiveness of existing tools, or explore what users really require to build successful ontologies. Here we address this shortfall, presenting insights from an interview study with 15 ontology authors. We identify the problems reported by authors, and the workarounds they employ to solve them. We map the data to a set of design recommendations, which describe how tools can support ontology authoring going forward. A key challenge is dealing with information overload: improving the user's ability to navigate, populate and debug large ontologies will revolutionise the engineering process, and open ontology authoring up to a new generation of users","shortAbstract":"Ontologies have been employed across scientific and business domains f","id":"pn1760"},"session":"Information in Use","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1760"},"pn1421":{"lastUpdateTime":1389285480381,"subcommitteeSplit":"A","labels":{"Crowdsourcing":{"checked":false,"lastUpdateTime":1386528381186,"dislikes":[],"label":"Crowdsourcing","lastTimeUpdated":1386523865245,"likes":["nebeling@inf.ethz.ch"]},"E-Learning and Education":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["kris.luyten@uhasselt.be"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386528383699,"checked":true,"likes":[],"label":"crowdsourcing"},"Crowd-sourcing actions":{"dislikes":[],"lastTimeUpdated":1386523985786,"checked":true,"likes":[],"label":"Crowd-sourcing actions"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081867}},"creationTime":1084,"content":{"authorList":["Mira Dontcheva, Adobe Research","Robert Morris, MIT Media Lab","Joel Brandt, Adobe Research","Liz Gerber, Northwestern University"],"title":"Combining crowdsourcing and learning to improve engagement and performance","paperOrNote":"Paper","fullAbstract":"Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing in ways that benefit both the workers and the requesters. In a series of three studies over two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We motivated workers by employing game mechanics and highlighting the purpose of their work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system, workers gained new skills and produced high-quality edits, even if they had never used Photoshop before. \\ ","shortAbstract":"Crowdsourcing complex creative tasks remains difficult, in part becaus","id":"pn1421"},"session":"CSCW: Crowds and Creativity","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1421"},"pn1423":{"lastUpdateTime":1388776618754,"subcommitteeSplit":"C","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["bpbailey@illinois.edu"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526696336,"label":"Visual Design"},"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526697994,"label":"Multimedia UIs"},"Creativity Support Tools":{"checked":false,"dislikes":[],"likes":["kgajos@eecs.harvard.edu"],"lastUpdateTime":1386527169255,"label":"Creativity Support Tools"},"Animation":{"checked":false,"lastUpdateTime":1386526735239,"dislikes":[],"label":"Animation","lastTimeUpdated":1386526196252,"likes":[]},"Process Improvement":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526751613,"label":"Process Improvement"},"Systems":{"checked":false,"lastUpdateTime":1386527358815,"dislikes":[],"label":"Systems","lastTimeUpdated":1386526731667,"likes":["erinacarroll@gmail.com"]},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526750727,"label":"Interaction Design"},"User Studies":{"checked":false,"dislikes":[],"likes":["bpbailey@illinois.edu"],"lastUpdateTime":1386527206482,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526738365,"label":"User Experience Design / Experience Design"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486610}},"creationTime":1086,"content":{"authorList":["Ankit Gupta, University of Washington","Maneesh Agrawala, University of California, Berkeley","Brian Curless, University of Washington","Michael Cohen, Microsoft Research"],"title":"MotionMontage: A System to Annotate and Combine Motion Takes for 3D Animations","paperOrNote":"Paper","fullAbstract":"We present MotionMontage, a system for recording multiple motion takes of a rigid virtual object and compositing them together into a montage.  Our system incorporates a Kinect-based performance capture setup that allows animators to create 3D animations by tracking the motion of a rigid physical object and mapping it in realtime onto a virtual object.  The animator then temporally annotates the best parts of each take.  MotionMontage merges the annotated motions into a single composite montage using a combination of dynamic time warping and optimization of a Semi-Markov Conditional Random Field.  Our system also supports the creation of layered animations in which multiple objects are moving at the same time. To aid the animator in coordinating the motions of the objects we provide spatial markers which indicate the positions of previously recorded objects at user-specified points in time. We perform a user study to evaluate the perceived quality of the montages created with our system and find that viewers (including both the original animators and new viewers) generally prefer the animation montage to any individual take.  We also report on the qualitative experience of users working with our system to create multi-object \\ animations, including the utility of the spatial markers.","shortAbstract":"We present MotionMontage, a system for recording multiple motion takes","id":"pn1423"},"session":"3D: 3D modeling","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1423"},"pn1425":{"lastUpdateTime":1389221479624,"subcommitteeSplit":"A","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386524535163,"checked":true,"likes":["eva@ehornecker.de"],"label":"gestures"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525600943,"label":"User Studies"},"awareness":{"dislikes":[],"lastTimeUpdated":1386524559218,"checked":true,"likes":[],"label":"awareness"},"whole body interaction":{"dislikes":[],"lastTimeUpdated":1386524585492,"checked":true,"likes":["eva@ehornecker.de"],"label":"whole body interaction"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946664}},"creationTime":1088,"content":{"authorList":["Adrian Reetz, University of Saskatchewan","Carl Gutwin, University of Saskatchewan"],"title":"Making  Big Gestures: Effects of Gesture Size on Observability and Identification for Co-Located Group Awareness","paperOrNote":"Paper","fullAbstract":"Co-located work environments allow people to maintain awareness by observing others actions (called consequential communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (phone sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.","shortAbstract":"Co-located work environments allow people to maintain awareness by obs","id":"pn1425"},"session":"UIST: Gesture-based interaction","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1425"},"pn1426":{"lastUpdateTime":1389285111611,"subcommitteeSplit":"A","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Sleep interaction":{"dislikes":[],"lastTimeUpdated":1386523880648,"checked":true,"likes":[],"label":"Sleep interaction"},"Health sensing":{"dislikes":[],"lastTimeUpdated":1386524129820,"checked":true,"likes":[],"label":"Health sensing"},"Sensing":{"dislikes":[],"lastTimeUpdated":1386524171544,"checked":true,"likes":["roudauta@gmail.com"],"label":"Sensing"},"Context-Aware Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Context-Aware Computing"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081872}},"creationTime":1089,"content":{"authorList":["Jun-Ki Min, Carnegie Mellon University","Afsaneh Doryab, Carnegie Mellon University","Jason Wiese, Carnegie Mellon University","Shahriyar Amini, Carnegie Mellon University","John Zimmerman, Carnegie Mellon University","Jason Hong, Carnegie Mellon University"],"title":"Toss n Turn: Smartphone as Sleep and Sleep Quality Detector","paperOrNote":"Paper","fullAbstract":"The rapid adoption of smartphones along with peoples propensity to keep thee in their bedrooms at night presents an opportunity to use this device as a sleep detector. This ability is valuable for UbiComp systems in terms of user context, for personal informatics, and for healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual-user models performed better than generally trained models; to expect reasonably good prediction performance of the individual models, a user has to manually supply 3 days of training data for sleep detection and 3 weeks of training data for quality inference. Best-performing features included noise peaks and movement variations.","shortAbstract":"The rapid adoption of smartphones along with peoples propensity to ","id":"pn1426"},"session":"UBI: Activity Recognition","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1426"},"pn1428":{"lastUpdateTime":1389236836254,"subcommitteeSplit":"B","labels":{"hackerspace culture":{"dislikes":[],"lastTimeUpdated":1386522935681,"checked":true,"likes":[],"label":"hackerspace culture"},"make":{"dislikes":[],"lastTimeUpdated":1386522909473,"checked":true,"likes":[],"label":"make"},"making practices":{"dislikes":[],"lastTimeUpdated":1386523369629,"checked":true,"likes":[],"label":"making practices"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"diy":{"dislikes":[],"lastTimeUpdated":1386522126240,"checked":true,"likes":["ztoups@nmsu.edu","aantle@sfu.ca","silvia.lindtner@gmail.com","wendyju@stanford.edu"],"label":"diy"},"Ethnography":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Ethnography"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755984}},"creationTime":1091,"content":{"authorList":["Jeffrey Bardzell, Indiana University Bloomington","Shaowen Bardzell, Indiana University Bloomington","Austin Toombs, Indiana University Bloomington"],"title":"Now Thats Definitely a Proper Hack: Self-Made Tools in Hackerspaces","paperOrNote":"Note","fullAbstract":"Cultures of makingthat is, social practices of hacking, DIY, tinkering, repair, and craftcontinue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a year-long ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practicetool-makingwithin the hackerspace we studied.","shortAbstract":"Cultures of makingthat is, social practices of hacking, DIY, tinker","id":"pn1428"},"session":"Making: Hacking","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1428"},"pn1399":{"lastUpdateTime":1389238496089,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528703417,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Graphical Passwords":{"dislikes":[],"lastTimeUpdated":1386522023922,"checked":true,"likes":["lorrie@acm.org"],"label":"Graphical Passwords"},"Passwords":{"dislikes":[],"lastTimeUpdated":1386521723898,"checked":true,"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","rob.comber@ncl.ac.uk","lorrie@acm.org"],"label":"Passwords"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Authentication":{"dislikes":[],"lastTimeUpdated":1386521733655,"checked":true,"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","jonfroehlich@gmail.com","lorrie@acm.org"],"label":"Authentication"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386522072721,"checked":true,"likes":["jonfroehlich@gmail.com","lorrie@acm.org"],"label":"Usable Security"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Security":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de","jonfroehlich@gmail.com","a.sasse@cs.ucl.ac.uk","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Security"},"User Studies":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446317}},"creationTime":1063,"content":{"authorList":["Julie Thorpe, University of Ontario Institute of Technology","Muath Al-Badawi, University of Ontario Institute of Technology","Brent MacRae, University of Ontario Institute of Technology","Amirali Salehi-Abari, University of Toronto"],"title":"The Presentation Effect on Graphical Passwords","paperOrNote":"Note","fullAbstract":"We provide a simple yet powerful demonstration of how an \\ unobtrusive change to a graphical password interface can \\ modify the distribution of user chosen passwords, and thus \\ possibly the security it provides. The only change to the interface \\ is how the background image is presented to the user \\ in the password creation phase  we call the results of this \\ change the presentation effect. We demonstrate the presentation \\ effect by performing a comparative user study of two \\ groups using the same background image, where the image is \\ presented in one of two different ways prior to password creation. \\ Our results show a statistically different distribution of \\ users graphical passwords, with no observed usability consequences.","shortAbstract":"We provide a simple yet powerful demonstration of how an \\ unobtrusive","id":"pn1399"},"session":"Security: Passwords","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1399"},"pn1398":{"lastUpdateTime":1389221780441,"subcommitteeSplit":"A","labels":{"recommender systems":{"dislikes":[],"lastTimeUpdated":1386525415866,"checked":true,"likes":[],"label":"recommender systems"},"Agents and Intelligent Systems":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524650909,"label":"Agents and Intelligent Systems"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524652241,"label":"Empirical Methods, Quantitative"},"decision support system":{"dislikes":[],"lastTimeUpdated":1386524204064,"checked":true,"likes":[],"label":"decision support system"},"bias":{"checked":false,"lastUpdateTime":1386524661521,"dislikes":[],"label":"bias","lastTimeUpdated":1386524212686,"likes":[]},"customization":{"dislikes":[],"lastTimeUpdated":1386524209063,"checked":true,"likes":[],"label":"customization"},"Personalization":{"dislikes":[],"lastTimeUpdated":1386526046504,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Personalization"},"Semi-autonomous systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Semi-autonomous systems"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946696}},"creationTime":1062,"content":{"authorList":["Jacob Solomon, Michigan State University"],"title":"Customization Bias in Decision Support Systems","paperOrNote":"Paper","fullAbstract":"Many Decision Support Systems (DSS) afford customization of inputs or algorithms before generating recommendations to a decision maker. I demonstrate that the act of customizing a DSS can lead to biased decision making in an experiment where subjects use a DSS to make decisions in a fantasy baseball game. I show that users who mistakenly believe they have customized a DSS's recommendation algorithm are more likely to follow the recommendations regardless of their accuracy. I also show that this customization bias is the result of using a DSS to seek confirmatory information in a recommendation. ","shortAbstract":"Many Decision Support Systems (DSS) afford customization of inputs or ","id":"pn1398"},"session":"Systems: Machines Interactively Learning","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1398"},"pn614":{"lastUpdateTime":1389221625522,"subcommitteeSplit":"B","labels":{"arts":{"dislikes":[],"lastTimeUpdated":1386522694135,"checked":true,"likes":["stuart@tropic.org.uk"],"label":"arts"},"Design practice":{"dislikes":[],"lastTimeUpdated":1386523032330,"checked":true,"likes":[],"label":"Design practice"},"illustration":{"dislikes":[],"lastTimeUpdated":1386523037743,"checked":true,"likes":[],"label":"illustration"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu","stuart@tropic.org.uk","bilge@cs.wisc.edu","fuzhiyong@tsinghua.edu.cn"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Animation":{"dislikes":[],"lastTimeUpdated":1386522061608,"checked":true,"likes":[],"label":"Animation"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755898}},"creationTime":385,"content":{"authorList":["Makoto Nakajima, The University of Tokyo","Daisuke Sakamoto, The University of Tokyo","Takeo Igarashi, The University of Tokyo"],"title":"Offline Painted Media for Digital Animation Authoring","paperOrNote":"Paper","fullAbstract":"We present a system for integrating offline physical, painted media into digital authoring of Flash-style animations. Standardized digital authoring software tends to lack the individualism or atmosphere of physical media. We aim to advance the diversity of appearances in digital animation using offline physical media. First, a user makes a rough sketch of the visual elements and defines their movements using our digital authoring software with a sketch interface. Then these images are exported to printed pages, and the artist can paint using offline physical media. Finally, this work is scanned and imported back into the digital conte to composite an animation that combines the digital and physical media. We present an implementation of this system to demonstrate its workflow. We also discuss the advantages of using physical media in digital animations through user studies.","shortAbstract":"We present a system for integrating offline physical, painted media in","id":"pn614"},"session":"Art: Image and Animation Authoring","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn614"},"pn1081":{"lastUpdateTime":1389236836254,"subcommitteeSplit":"","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","bulling@mpi-inf.mpg.de","aquigley@st-andrews.ac.uk","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Prototyping"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525723949,"label":"Input and Interaction Technologies"},"Printed Electronics":{"dislikes":[],"lastTimeUpdated":1386526097934,"checked":true,"likes":[],"label":"Printed Electronics"},"fabrication":{"dislikes":[],"lastTimeUpdated":1386525356896,"checked":true,"likes":["dan@microsoft.com","sszhao@yahoo.com","bulling@mpi-inf.mpg.de","aquigley@st-andrews.ac.uk"],"label":"fabrication"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644741}},"creationTime":779,"content":{"authorList":["Steve Hodges, Microsoft Research","Nicolas Villar, Microsoft Research","Tushar Chugh, Microsoft Research","Nicholas Chen, Microsoft Research","Diana Nowacka, Newcastle University","Yoshihiro Kawahara, The University of Tokyo","Jie Qi, MIT Media Lab"],"title":"Sticker Circuits: A New Technique for Constructing Prototype Physical Interfaces","paperOrNote":"Note","fullAbstract":"We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call sticker circuits, involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides the necessary electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be inter-faced to a microcontroller or PC. In this paper we present three examples which illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found sticker circuits to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research prototyping, education and for hobbyists.","shortAbstract":"We present a novel approach to the construction of electronic prototyp","id":"pn1081"},"session":"Making: Hacking","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1081"},"pn279":{"lastUpdateTime":1389591992951,"subcommitteeSplit":"A","labels":{"design in publics":{"dislikes":[],"lastTimeUpdated":1386523672389,"checked":true,"likes":["lennart.nacke@uoit.ca"],"label":"design in publics"},"Remote Presence":{"dislikes":[],"lastTimeUpdated":1386522787974,"checked":true,"likes":[],"label":"Remote Presence"},"Remote Interaction":{"dislikes":[],"lastTimeUpdated":1386522792547,"checked":true,"likes":[],"label":"Remote Interaction"},"Video Chat":{"dislikes":[],"lastTimeUpdated":1386522783708,"checked":true,"likes":[],"label":"Video Chat"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"social triangulation":{"dislikes":[],"lastTimeUpdated":1386522866321,"checked":true,"likes":[],"label":"social triangulation"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Media Space":{"dislikes":[],"lastTimeUpdated":1386522767090,"checked":true,"likes":[],"label":"Media Space"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711777}},"creationTime":134,"content":{"authorList":["Jrg Mller, Alexander von Humboldt Institute for Internet and Society","Dieter Eberle, Telekom Innovation Laboratories, TU Berlin","Konrad Tollmar, KTH"],"title":"PlayPortal: A Field Study of a Public Display Mediaspace","paperOrNote":"Paper","fullAbstract":"We present PlayPortal, a public display Mediaspace.  \\ People passing by see their own contour mirrored on a public \\ display and can start to play with virtual objects. At the same time, they see \\ others playing at remote displays within the same virtual space. We \\ are interested whether people would use such a public display \\ Mediaspace, and if so, how and why. We evaluate \\ PlayPortal in a field study in six connected locations and find a remote Honeypot effect, i.e. people \\ interacting at one location attract people at other locations. The \\ conversion rate (percentage of by-passers starting to interact) rises \\ by +136% when people see others playing at remote locations.  \\ We also provide the first quantification of the real Honeypot effect (in our case it raised the conversion rate by +604% when people see others playing at the same location). We conclude that the integration of multiple public displays \\ into a media space is a promising direction for \\ public displays and can make them more valuable and interesting. \\ ","shortAbstract":"We present PlayPortal, a public display Mediaspace.  \\ People passing ","id":"pn279"},"session":"Displays: Interactive Whitebaords and Public Displays","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn279"},"pn271":{"lastUpdateTime":1389236450714,"subcommitteeSplit":"B","labels":{"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386523884284,"checked":true,"likes":[],"label":"Crowd-Powered Systems"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["nebeling@inf.ethz.ch","fabio.paterno@isti.cnr.it"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081874}},"creationTime":128,"content":{"authorList":["Ethan Fast, Stanford University","Michael Bernstein, ","Joel Brandt, Adobe"],"title":"Embedding Crowd-scale Programming Practice into the IDE","paperOrNote":"Paper","fullAbstract":"Emergent behaviors are uncodified across many domains such as programming and writing, but most interfaces require codified rules to guide how they support the user. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a data store that models programming knowledge by indexing over three million lines of high-quality Ruby code. Codex enables new data-driven interfaces for programming systems: statistical linting, which identifies code that is unlikely to occur in practice and may constitute a bug; pattern annotation, which automatically identifies common programming idioms and annotates them with metadata using expert crowdsourcing; and library generation, which constructs a living library: a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to find that Codex captures a broad swatch of programming practice, statistical linting detects problematic code snippets with a false positive rate of 2.5\\\\%, and pattern annotation produces a set of idioms that are generally useful and recomposable. Our work suggests that operationalizing practice-driven knowledge can enable a new class of software engineering applications. ","shortAbstract":"Emergent behaviors are uncodified across many domains such as programm","id":"pn271"},"session":"Systems: Development Tools","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn271"},"pn272":{"lastUpdateTime":1389591491705,"subcommitteeSplit":"A","labels":{"user modelling":{"checked":false,"lastUpdateTime":1386524576159,"dislikes":[],"label":"user modelling","lastTimeUpdated":1386524565594,"likes":[]},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":["lorrie@acm.org","Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Fitts's Law":{"dislikes":[],"lastTimeUpdated":1386524365471,"checked":true,"likes":[],"label":"Fitts's Law"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946746},"sorta fitz law":{"label":"sorta fitz law","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389105044181}},"creationTime":129,"content":{"authorList":["Antti Oulasvirta, Max Planck Institute for Informatics"],"title":"Automated Nonlinear Regression Modeling for HCI: A Million Paul Fittses Working on Your Data","paperOrNote":"Note","fullAbstract":"Predictive models in HCI, such as models of pointing performance, are often expressed as multivariate nonlinear regressions. This modeling approach is preferable, because it allows compact expression and theoretical scrutiny. However, existing tools in HCI and the common statistical packages support modeling with predefined nonlinear equations, but they do not help in the task of identifying novel nonlinear equations. We build on work on optimization methods and design a stochastic local search method that constructs equations iteratively. Importantly, the researcher can constrain search to desirable terms and operations and limit the maximum number of free parameters. A comparison of outputs to published baselines in HCI showed improvements in seven out of eleven cases. We conclude that the method can help researchers explore modeling problems.","shortAbstract":"Predictive models in HCI, such as models of pointing performance, are ","id":"pn272"},"session":"Methods and Models: User Model 2","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn272"},"pn276":{"lastUpdateTime":1389590796343,"subcommitteeSplit":"A","labels":{"Musical intefaces":{"checked":false,"lastUpdateTime":1386537505425,"dislikes":[],"label":"Musical intefaces","lastTimeUpdated":1386523975023,"likes":[]},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["jws@microsoft.com"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081881}},"creationTime":132,"content":{"authorList":["Jrg Mller, Alexander von Humboldt Institute for Internet and Society","Matthias Geier, Universitt Rostock","Christina Dicke, TU Berlin","Sascha Spors, Universitt Rostock"],"title":"The BoomRoom: Mid-air Direct Interaction with Virtual Sound Sources","paperOrNote":"Paper","fullAbstract":"In this paper we present a system that allows to touch, \\ grab and manipulate sounds in mid-air. \\ Further, arbitrary objects can seem to emit sound. \\ We use spatial sound reproduction for sound rendering and computer vision for tracking. Using our approach, sounds can be heard from anywhere in the room and always appear to originate from the same (possibly moving) position, regardless of the listener's position. \\ We demonstrate that direct touch interaction with sound is an interesting alternative to indirect interaction mediated through controllers or visual interfaces. \\ We show that sound localization is surprisingly accurate (14 cm), even in the presence of distractors. \\  We propose to leverage the ventriloquist effect to further increase localization accuracy. Finally, we demonstrate how affordances of real objects can create synergies of auditory and visual feedback. As an application of the system, we built a spatial music mixing room.","shortAbstract":"In this paper we present a system that allows to touch, \\ grab and man","id":"pn276"},"session":"UBI: Audio Interaction","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn276"},"pn104":{"lastUpdateTime":1389221773171,"subcommitteeSplit":"A","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["xiangcao@acm.org","krueger@dfki.de"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081850}},"creationTime":2,"content":{"authorList":["Olivier Chapuis, Univ Paris-Sud & CNRS","Stelios Frantzeskakis, University of Crete","Anastasia Bezerianos, Univ Paris Sud, CNRS & INRIA"],"title":"Smarties: An Input System for Wall Display Development","paperOrNote":"Paper","fullAbstract":"Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. On each touch mobile we find a set of cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of widgets associated to them are decided by the wall application, making the mobile interface customizable by the wall application they connect to. ","shortAbstract":"Wall-sized displays can support data visualization and collaboration, ","id":"pn104"},"session":"Systems: Multi-Device User Interfaces","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn104"},"pn297":{"lastUpdateTime":1389236825484,"subcommitteeSplit":"A","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"digital fabrication":{"dislikes":[],"lastTimeUpdated":1386524093202,"checked":true,"likes":["jws@microsoft.com","roudauta@gmail.com","nebeling@inf.ethz.ch","kris.luyten@uhasselt.be","xiangcao@acm.org"],"label":"digital fabrication"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081879}},"creationTime":145,"content":{"authorList":["Stefanie Mueller, Hasso Plattner Institute","Tobias Mohr, Hasso Plattner Institute","Kerstin Guenther, Hasso Plattner Institute","Johannes Frohnhofen, Hasso Plattner Institute","Patrick Baudisch, Hasso Plattner Institute"],"title":"faBrickation: Fast 3D printing of Functional Objects by Integrating Construction Kit Building Blocks","paperOrNote":"Paper","fullAbstract":"We present a new approach to rapid prototyping of functional objects, such as the body of a head-mounted display. The key idea is to save 3D printing time by automatically substituting sub-volumes with standard building blocks  in our case Lego bricks. When making the body for a head-mounted display, for example, getting the optical path right is paramount. Users thus mark the lens mounts as high-resolution to indicate that these should later be 3D printed. faBrickator then 3D-prints these parts. It also generates instructions that show users how to create everything else from Lego bricks. If users iterate on the design later, faBrickator offers even greater benefit as it allows re-printing only the elements that changed. We validated our system at the example of three 3D models of functional objects. On average, our system fabricates objects 2.44 times faster than traditional 3d printing while requiring only 11.6 minutes of manual assembly. ","shortAbstract":"We present a new approach to rapid prototyping of functional objects, ","id":"pn297"},"session":"Making: 3D printing","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn297"},"pn292":{"lastUpdateTime":1389591227096,"subcommitteeSplit":"A","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525547610,"label":"Empirical Methods, Quantitative"},"replication":{"dislikes":[],"lastTimeUpdated":1386524184023,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"label":"replication"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525604349,"label":"User Studies"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"repliCHI":{"dislikes":[],"lastTimeUpdated":1386524195560,"checked":true,"likes":["eva@ehornecker.de"],"label":"repliCHI"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946699}},"creationTime":143,"content":{"authorList":["Kasper Hornbk, University of Copenhagen","Sren Sander, University of Copenhagen","Javier Bargas-Avila, Google, Inc.","Jakob Grue Simonsen, University of Copenhagen"],"title":"Is Once Enough? On the Extent and Content of Replications in Human-Computer Interaction","paperOrNote":"Paper","fullAbstract":"A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, authors mostly agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal extra effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications. ","shortAbstract":"A replication is an attempt to confirm an earlier study's findings. It","id":"pn292"},"session":"Methods and Models: new HCI paradigms","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn292"},"pn1171":{"lastUpdateTime":1389221516569,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["kgajos@eecs.harvard.edu","tjvg@di.fc.ul.pt"],"lastUpdateTime":1386527089398,"label":"Older Adults"},"Motivation":{"dislikes":[],"lastTimeUpdated":1386527123460,"checked":true,"likes":[],"label":"Motivation"},"Exergames":{"dislikes":[],"lastTimeUpdated":1386526260073,"checked":true,"likes":["kgajos@eecs.harvard.edu","tjvg@di.fc.ul.pt","joanna@cs.ub.ca"],"label":"Exergames"},"health and behavior change":{"dislikes":[],"lastTimeUpdated":1386527160264,"checked":true,"likes":[],"label":"health and behavior change"},"Health Care":{"checked":true,"dislikes":[],"likes":["kgajos@eecs.harvard.edu"],"lastUpdateTime":123456789,"label":"Health Care"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527414396,"label":"User Studies"},"Rehabilitation":{"dislikes":[],"lastTimeUpdated":1386527299127,"checked":true,"likes":["kgajos@eecs.harvard.edu"],"label":"Rehabilitation"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486628}},"creationTime":860,"content":{"authorList":["Stephen Uzor, Glasgow Caledonian University","Lynne Baillie, Glasgow Caledonian University"],"title":"Investigating the Long-Term Use of Exergames in the Home with Elderly Fallers","paperOrNote":"Paper","fullAbstract":"Rehabilitation has been shown to significantly reduce the risk of falling in older adults. However, low adherence to rehabilitation exercises in the home means that seniors often do not get the therapy that they require. We propose that the use of tailored exergames could encourage adherence to falls rehabilitation in the home, as exergames have proved successful in clinical settings. We describe the results from the first known study to investigate the long-term (12 weeks) use of exergames, designed in close collaboration with elderly users, for falls rehabilitation in the home. The study results suggest that there is an untapped potential of exergames for home rehabilitation use, as the findings show that there was better adherence to exercise in participants who used the exergames, versus those who used standard care (booklets). Finally, we make recommendations for designers, on the design of exergames for the rehabilitation of elderly fallers.","shortAbstract":"Rehabilitation has been shown to significantly reduce the risk of fall","id":"pn1171"},"session":"Health: HCI for Rehabilitation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1171"},"pn1179":{"lastUpdateTime":1389238815508,"subcommitteeSplit":"","labels":{"Camera-based UIs":{"checked":true,"dislikes":[],"likes":["roudauta@gmail.com","dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Presentation tool":{"dislikes":[],"lastTimeUpdated":1386524359149,"checked":true,"likes":[],"label":"Presentation tool"},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524580161,"label":"Prototyping"},"Crazy ideas":{"dislikes":[],"lastTimeUpdated":1386523918032,"checked":true,"likes":[],"label":"Crazy ideas"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Software architecture and engineering":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Software architecture and engineering"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081860}},"creationTime":866,"content":{"authorList":["Xiang Li, Interfaculty Initiative in Information Studies of The univ of Tokyo","Jun Rekimoto, The University of Tokyo"],"title":"SmartVoice: A Presentation Support System For Overcoming the Language Barrier","paperOrNote":"Paper","fullAbstract":"In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose \"SmartVoice\", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.","shortAbstract":"In most cases, speeches or presentations at an international event are","id":"pn1179"},"session":"Systems: Presentations","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1179"},"pn1375":{"lastUpdateTime":1389285590040,"subcommitteeSplit":"","labels":{"forums":{"checked":false,"lastUpdateTime":1386523419045,"dislikes":[],"label":"forums","lastTimeUpdated":1386522045222,"likes":[]},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523424108,"label":"Prototyping"},"Multilingual communication":{"dislikes":[],"lastTimeUpdated":1386523915840,"checked":true,"likes":["teevan@gmail.com"],"label":"Multilingual communication"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523423274,"label":"User Studies"},"Instant Annotation":{"checked":false,"lastUpdateTime":1386523229371,"dislikes":[],"label":"Instant Annotation","lastTimeUpdated":1386522836181,"likes":[]},"Annotation":{"dislikes":[],"lastTimeUpdated":1386522182872,"checked":true,"likes":["myriam.lewkowicz@utt.fr","Marilyn.McGee-Lennon@glasgow.ac.uk","gabriela.avram@gmail.com"],"label":"Annotation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556618}},"creationTime":1040,"content":{"authorList":["Na Li, Pennsylvania State University","Mary Beth Rosson, Pennsylvania State University"],"title":"Using Annotations in Online Group Chats","paperOrNote":"Note","fullAbstract":"Annotating documents has long been a widely used strategy for distilling important content and externalizing related thoughts and ideas in context. No one has studied the activ- ity of annotating dynamic texts, such as online chat, alt- hough online conversation is an important communication media for global companies. In this paper, we investigate Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the use of the enhanced chat tool to a standard chat tool for multilingual groups doing a brain- storming and decision-making task. Results show that group satisfaction and perceived control of the conversation are enhanced for the participants who used IA. We also report new patterns of annotation use and discuss design implications for collaborative annotation tools.","shortAbstract":"Annotating documents has long been a widely used strategy for distilli","id":"pn1375"},"session":"HCI4D: Multilingual Communication","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1375"},"pn1377":{"lastUpdateTime":1388766320872,"subcommitteeSplit":"A","labels":{"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Medication":{"dislikes":[],"lastTimeUpdated":1386522948026,"checked":true,"likes":["jkientz@uw.edu","weibel@ucsd.edu"],"label":"Medication"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188193}},"creationTime":1042,"content":{"authorList":["Matthew Lee, Philips Research","Anind Dey, Carnegie Mellon University"],"title":"Real-time Feedback for Improving Medication Taking","paperOrNote":"Paper","fullAbstract":"Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken.  In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through self-regulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.","shortAbstract":"Medication taking is a self-regulatory process that requires individua","id":"pn1377"},"session":"Health: Health and Everyday Life","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1377"},"pn1372":{"lastUpdateTime":1389591833186,"subcommitteeSplit":"A","labels":{"Social Media":{"checked":false,"lastUpdateTime":1386523789848,"dislikes":[],"label":"Social Media","lastTimeUpdated":1386523707504,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com","jws@microsoft.com"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Accessibility":{"checked":false,"lastUpdateTime":1386523786204,"dislikes":[],"label":"Accessibility","lastTimeUpdated":1386523686234,"likes":[]},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com","xiangcao@acm.org","roudauta@gmail.com","kris.luyten@uhasselt.be"],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Machine Learning":{"checked":false,"lastUpdateTime":1386523787056,"dislikes":[],"label":"Machine Learning","lastTimeUpdated":1386523692320,"likes":[]},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Crowd-Powered Systems":{"checked":false,"lastUpdateTime":1386523791708,"dislikes":[],"label":"Crowd-Powered Systems","lastTimeUpdated":1386523670596,"likes":[]},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081858}},"creationTime":1037,"content":{"authorList":["Alireza Sahami, University of Stuttgart","Yomna Abdelrahman, University of Stuttgart","Stefan Schneegass, University of Stuttgart","Mohammadreza Khalilbeigi, Darmstadt University of Technology","Niels Henze, University of Stuttgart","Albrecht Schmidt, University of Stuttgart"],"title":"Exploiting Thermal Reflection for Interactive Systems","paperOrNote":"Paper","fullAbstract":"Thermal cameras have recently drawn attention of HCI researchers as a new sensory system enabling novel interactive systems. They are robust to illumination changes and make it easy to separate human bodies from the image background. Far-infrared radiation, however, has another characteristic that distinguishes thermal cameras from their RGB or depth counterparts, namely thermal reflection. Common surfaces reflect thermal radiation differently than visual light and can become a perfect thermal mirror. In this paper, we show that through thermal reflection, thermal cameras can sense the space beyond their direct field of view. A thermal camera can sense areas besides and even behind the camera' field of view through thermal reflection. We investigate how thermal reflection can increase the interaction space of projected surfaces using camera-projection systems. We moreover discuss the reflection characteristics of common surfaces in our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept prototype, we demonstrate the increased interaction space for hand-held camera-projection system. Furthermore, we depict a number of promising application examples that can largely benefit from the thermal reflection characteristic of surfaces.","shortAbstract":"Thermal cameras have recently drawn attention of HCI researchers as a ","id":"pn1372"},"session":"Displays: Novel Mobile Displays (UIST)","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1372"},"pn621":{"lastUpdateTime":1388786174911,"subcommitteeSplit":"","labels":{"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["no@spam.org","sszhao@yahoo.com","wolfgang@cse.yorku.ca","bulling@mpi-inf.mpg.de","benko@microsoft.com"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Driving":{"dislikes":[],"lastTimeUpdated":1386525697069,"checked":true,"likes":["sriramable@gmail.com","benko@microsoft.com","no@spam.org"],"label":"Driving"},"Transport":{"checked":true,"dislikes":[],"likes":["no@spam.org"],"lastUpdateTime":123456789,"label":"Transport"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644801}},"creationTime":391,"content":{"authorList":["Felix Lauber, University of Munich (LMU)","Andreas Butz, "],"title":"In-Your-Face, Yet Unseen? Improving Head-Stabilized Warnings to Reduce Reaction Time","paperOrNote":"Note","fullAbstract":"One unique property of head-mounted displays (HMD) is that content can easily be displayed at a fixed position within the users field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulation, comparing different warning visualizations within a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.","shortAbstract":"One unique property of head-mounted displays (HMD) is that content can","id":"pn621"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn621"},"pn2522":{"lastUpdateTime":1389284843631,"subcommitteeSplit":"B","labels":{"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["rob.comber@ncl.ac.uk","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Smart Home":{"dislikes":[],"lastTimeUpdated":1386522378288,"checked":true,"likes":[],"label":"Smart Home"},"End-user Programming":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"End-user Programming"},"Home":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","jonfroehlich@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446315}},"creationTime":2027,"content":{"authorList":["Blase Ur, Carnegie Mellon University","Elyse McManus, Computer Science","Melwyn Pak, Brown University","Michael Littman, Brown University"],"title":"If I Could Do A Little More, Then It Would Be Practical: Trigger-Action Programming in the Smart Home","paperOrNote":"Paper","fullAbstract":"We investigate the practicality of enabling average users to customize smart-home devices using trigger-action (if,then) programming. We find that trigger-action programming can express the majority of smart-home behaviors submitted by participants in an online study. We identify an important class of triggers, those requiring machine learning, that has received little research attention. Next, we evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that users desire a sufficiently large number of unique interactions that end-user programming should not be subsumed by an app store. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.","shortAbstract":"We investigate the practicality of enabling average users to customize","id":"pn2522"},"session":"UBI: Smart Homes","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2522"},"pn2525":{"lastUpdateTime":1389238827699,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528873255,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Smartphones":{"dislikes":[],"lastTimeUpdated":1386529542688,"checked":true,"likes":["lorrie@acm.org"],"label":"Smartphones"},"Context-Aware Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Context-Aware Computing"},"Privacy":{"checked":true,"dislikes":[],"likes":["david.kirk@ncl.ac.uk","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Privacy"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"phones":{"dislikes":[],"lastTimeUpdated":1386524284610,"checked":true,"likes":[],"label":"phones"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"mobile":{"checked":false,"lastUpdateTime":1386525540672,"dislikes":[],"label":"mobile","lastTimeUpdated":1386525533220,"likes":[]},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"mobile phone":{"dislikes":[],"lastTimeUpdated":1386525559713,"checked":true,"likes":[],"label":"mobile phone"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"mobile apps":{"dislikes":[],"lastTimeUpdated":1386525551196,"checked":true,"likes":[],"label":"mobile apps"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386525604543,"checked":true,"likes":["david.kirk@ncl.ac.uk"],"label":"Handheld Devices and Mobile Computing"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032771}},"creationTime":2028,"content":{"authorList":["Irina Shklovski, IT University of Copenhagen","Scott Mainwaring, Intel Research"],"title":"Creepiness in App Space","paperOrNote":"Paper","fullAbstract":"Smartphones are playing an increasingly intimate role in everyday life.  However, users can be surprised when informed of the data collecting and distributing activities of apps they install.  We report on a qualitative study of smartphone users in two western European countries, in which users were confronted with app behaviors and their reactions assessed.  Users felt their personal space had been violated in creepy ways.  Using Altmans notions of personal space and territoriality, and Nissenbaums theory of contextual integrity, we account for these emotional reactions and suggest that they point to important underlying issues, even when users continue using apps they find creepy.","shortAbstract":"Smartphones are playing an increasingly intimate role in everyday life","id":"pn2525"},"session":"Security: Privacy","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2525"},"pn1954":{"lastUpdateTime":1389236111891,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386521582898,"checked":true,"likes":[],"label":"social media"},"local communities":{"dislikes":[],"lastTimeUpdated":1386522999929,"checked":true,"likes":[],"label":"local communities"},"urban":{"dislikes":[],"lastTimeUpdated":1386522483910,"checked":true,"likes":["gutwin@cs.usask.ca","myriam.lewkowicz@utt.fr","teevan@gmail.com"],"label":"urban"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523455653,"label":"Social Computing and Social Navigation"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523452243,"label":"Empirical Methods, Qualitative"},"hyperlocal":{"dislikes":[],"lastTimeUpdated":1386522121659,"checked":true,"likes":[],"label":"hyperlocal"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523453994,"label":"User Studies"},"geography":{"dislikes":[],"lastTimeUpdated":1386522498527,"checked":true,"likes":[],"label":"geography"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556754}},"creationTime":1540,"content":{"authorList":["Christina Masden, Georgia Institute of Technology","Catherine Grevet, Georgia Institute of Technology","Rebecca Grinter, Georgia Institute of Technology","Eric Gilbert, Georgia Institute of Technology","W. Keith Edwards, Georgia Institute of Technology"],"title":"Tensions in Scaling-up Community Social Media: A Multi-Neighborhood Study of Nextdoor","paperOrNote":"Paper","fullAbstract":"This paper presents a study of Nextdoor, a social media system designed to support local neighborhoods. While not the first system designed to support community engagement, Nextdoor has a number of attributes that make it distinct. Our study, across three communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich ecosystem of community-oriented social media, but is being appropriated by its users for use in different ways than these existing media. Nextdoor also raises tensions in how it defines the boundaries of neighborhoods, and in the privacy issues it raises among its users. ","shortAbstract":"This paper presents a study of Nextdoor, a social media system designe","id":"pn1954"},"session":"HCI4D: City Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1954"},"pn1958":{"lastUpdateTime":1389285431303,"subcommitteeSplit":"","labels":{"Video Content / Communications":{"checked":true,"dislikes":[],"likes":["xiangcao@acm.org","kris.luyten@uhasselt.be","dan@danielashbrook.com","jws@microsoft.com"],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"Telepresence":{"dislikes":[],"lastTimeUpdated":1386537134951,"checked":true,"likes":[],"label":"Telepresence"},"Augmented Reality and Projection":{"dislikes":[],"lastTimeUpdated":1386524051249,"checked":true,"likes":[],"label":"Augmented Reality and Projection"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081885}},"creationTime":1542,"content":{"authorList":["ye pan, University College London","Anthony Steed, University College London"],"title":"A gaze-preserving situated multiview telepresence system","paperOrNote":"Note","fullAbstract":"Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical video conferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone without crosstalk. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.","shortAbstract":"Gaze, attention, and eye contact are important aspects of face to face","id":"pn1958"},"session":"Social: Connecting over Video","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1958"},"pn2454":{"lastUpdateTime":1389221840890,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386531909022,"checked":true,"likes":["mdixon@cs.washington.edu","olwal@mit.edu"],"label":"Handheld Devices and Mobile Computing"},"Keyboards":{"dislikes":[],"lastTimeUpdated":1386532048004,"checked":true,"likes":["fanny@dgp.toronto.edu","olwal@mit.edu"],"label":"Keyboards"},"Machine Learning":{"dislikes":[],"lastTimeUpdated":1386532236158,"checked":true,"likes":[],"label":"Machine Learning"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386531644331,"checked":true,"likes":["fanny@dgp.toronto.edu","olwal@mit.edu"],"label":"Text Entry"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840644}},"creationTime":1966,"content":{"authorList":["Daryl Weir, University of Glasgow","Henning Pohl, University of Hanover","Simon Rogers, University of Glasgow","Keith Vertanen, Montana Tech","Per Ola Kristensson, University of St Andrews"],"title":"Uncertain Text Entry on Mobile Devices","paperOrNote":"Paper","fullAbstract":"Modern mobile devices typically rely on touchscreen keyboards for input. Unfortunately, users often struggle to enter text accurately on virtual keyboards. While most mobile devices rely on autocorrection methods to help improve accuracy, existing methods only offer very basic correction models. We undertook a systematic investigation into how to best utilize probabilistic information to improve touchscreen keyboards. We incorporate a state-of-the-art touch model that can learn the tap idiosyncrasies of a particular user, and show in an evaluation that character error rate can be reduced by up to 7% over a baseline, and by up to 1.3% over a leading commercial keyboard. We furthermore investigate how users can explicitly control autocorrection via how hard they touch.","shortAbstract":"Modern mobile devices typically rely on touchscreen keyboards for inpu","id":"pn2454"},"session":"UIST: novel keyboards","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2454"},"pn2451":{"lastUpdateTime":1389221625522,"subcommitteeSplit":"","labels":{"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["fanny@dgp.toronto.edu"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["mdixon@cs.washington.edu"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840623}},"creationTime":1964,"content":{"authorList":["Nicolas Mangano, University of California, Irvine","Thomas LaToza, UC Irvine","Marian Petre, The Open University","Andre Van der hoek, University of California Irvine"],"title":"Supporting Informal Design with Interactive Whiteboards","paperOrNote":"Paper","fullAbstract":"Whiteboards serve an important role in supporting informal design, providing a fluid and flexible medium for collaborative design. Interactive whiteboards offer the potential for enhanced support for manipulating content, managing sketches, and distributed work, but little is known about how this support affects the practice of informal design. To understand the opportunities and challenges, we first conducted a literature review, identifying 14 behaviors that occur during informal design. We then designed an interactive whiteboard system to support all of these behaviors and deployed the system to a research group and two groups of professional designers. Through usage logs and interviews, we examined the effects of interactivity on whiteboard use across a wide spectrum of design behaviors, identifying ways in which interactive whiteboards support the practices used in physical whiteboards and where they enable designers to work more effectively.","shortAbstract":"Whiteboards serve an important role in supporting informal design, pro","id":"pn2451"},"session":"Art: Image and Animation Authoring","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2451"},"pn1883":{"lastUpdateTime":1389591728355,"subcommitteeSplit":"","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532483265,"label":"Older Adults"},"Office and Workplace":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532492910,"label":"Office and Workplace"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532602744,"label":"Usability Testing and Evaluation"},"shape changing interfaces":{"checked":false,"lastUpdateTime":1386532471352,"dislikes":[],"label":"shape changing interfaces","lastTimeUpdated":1386531929297,"likes":["eve.hoggan@hiit.fi"]},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532494829,"label":"Prototyping"},"Tangible UIs":{"checked":false,"dislikes":[],"likes":["mdixon@cs.washington.edu"],"lastUpdateTime":1386532477930,"label":"Tangible UIs"},"Defromable Interfaces":{"checked":false,"lastUpdateTime":1386532596196,"dislikes":[],"label":"Defromable Interfaces","lastTimeUpdated":1386532163195,"likes":[]},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532490847,"label":"User Interface Design"},"User and Cognitive models":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532488912,"label":"User and Cognitive models"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532487806,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386532603916,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532479782,"label":"Augmented Reality and Tangible UI"},"Home":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532485332,"label":"Home"},"deformable interfaces":{"dislikes":[],"lastTimeUpdated":1386532598742,"checked":true,"likes":["yutak@acm.org","tomer@moscovich.net"],"label":"deformable interfaces"},"Children":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532480841,"label":"Children"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840564}},"creationTime":1477,"content":{"authorList":["Teemu Ahmaniemi, Nokia Research Center","Johan Kildal, Nokia","Merja Haveri, Cresence Ltd."],"title":"What is a Device Bending Gesture Really Good for?","paperOrNote":"Paper","fullAbstract":"Device deformation input has produced many gestures and proposed use cases for those gestures. We identify that the gesture/use-case pairings proposed by interaction designers are often driven by factors relating improved tangibility, spatial directionality and strong metaphorical bonds. With this starting point, we argue that some of the designs may not make use of the full potential of deformation gestures as continuous, bipolar input techniques. In two user studies, we revisited the basics of deformation input taking a systematic look at the question of matching gestures with use cases in two user studies. We found that bend input to control different continuous bipolar tasks produced comparable UX. This highlights the versatility of this dynamic input technique with independence of the expected effects from tangibility, directionality and choice of metaphor. We also identify relative strengths of absolute and derivative mappings, and report a Fitts law study for device bending input.","shortAbstract":"Device deformation input has produced many gestures and proposed use c","id":"pn1883"},"session":"Displays: Displays (UIST)","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1883"},"pn1881":{"lastUpdateTime":1389236481152,"subcommitteeSplit":"","labels":{"intertextuality":{"dislikes":[],"lastTimeUpdated":1386523115774,"checked":true,"likes":[],"label":"intertextuality"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["emailaddress","myriam.lewkowicz@utt.fr","gabriela.avram@gmail.com"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"enterprise":{"dislikes":[],"lastTimeUpdated":1386531349517,"checked":true,"likes":[],"label":"enterprise"},"Document management":{"dislikes":[],"lastTimeUpdated":1386522980081,"checked":true,"likes":[],"label":"Document management"},"Ethnography":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523230311,"label":"Ethnography"},"Enterprise":{"checked":false,"lastUpdateTime":1386531351488,"dislikes":[],"label":"Enterprise","lastTimeUpdated":1386521888366,"likes":[]},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522320369,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556697}},"creationTime":1475,"content":{"authorList":["Lars Rune Christensen, Aalborg University","Pernille Bjorn, "],"title":"Documentscape: Intertextuality, Sequentiality & Autonomy at Work","paperOrNote":"Paper","fullAbstract":"On the basis of an ethnographic field study this article introduces the concept of documentscape to the analysis of document-centric work practices. The concept of documentscape refers to the entire ensemble of documents in their mutual intertextual interlocking. Providing empirical data from a global software development case, we show how hierarchical structures and sequentially across the interlocked documents are critical to how actors make sense of the work of others and what to do next in a geographical distributed setting. Furthermore, we found that while each document is created as part of a quasi-sequential order, it does not make the document, as a single entity, into a stable object. Instead, we found that the documents were malleable and dynamic while suspended in the intertextual structures. Our concept of documentscape points to how hierarchical structures, sequentiality of documents, and an authorless nature, serve as a constitutive platform for the development of iterative and emergent work practices. Making it possible for highly distributed actors to collaborate with limited communication as the documentscape serve as a vehicle of coordination. ","shortAbstract":"On the basis of an ethnographic field study this article introduces th","id":"pn1881"},"session":"CSCW: Document and Intertextuality","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1881"},"pn2041":{"lastUpdateTime":1389222102553,"subcommitteeSplit":"","labels":{"Tangible UIs":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"shape changing interfaces":{"dislikes":[],"lastTimeUpdated":1386531741965,"checked":true,"likes":["rsodhi2@illinois.edu"],"label":"shape changing interfaces"},"deformable interfaces":{"dislikes":[],"lastTimeUpdated":1386532589514,"checked":true,"likes":[],"label":"deformable interfaces"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532027774,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840609}},"creationTime":1612,"content":{"authorList":["Raf Ramakers, Hasselt University - tUL - iMinds","Johannes Schning, Hasselt University - tUL - iMinds","Kris Luyten, Hasselt University - tUL - iMinds"],"title":"Paddle: Highly Deformable Mobile Devices with Physical Controls","paperOrNote":"Paper","fullAbstract":"We present Paddle, a class of highly deformable mobile devices that can be transformed to various special purpose controls to bring physical controls to mobile devices. Physical controls have the advantage of exploiting our innate skills for manipulating objects in the real world. We demonstrate a Paddle device that uses the engineering principles of 3D puzzles and show that this offers a wide variety of form factors in a single device that can serve as physical controls. We explore physical interaction techniques for Paddle devices and conduct an in-depth study to evaluate these physical controls. Our findings show that physical controls provide several benefits over traditional touch interaction techniques commonly used on mobile phones.","shortAbstract":"We present Paddle, a class of highly deformable mobile devices that ca","id":"pn2041"},"session":"UIST: Shape-Changers","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2041"},"pn2046":{"lastUpdateTime":1389221094245,"subcommitteeSplit":"A","labels":{"gaming":{"dislikes":[],"lastTimeUpdated":1386523081338,"checked":true,"likes":[],"label":"gaming"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":["lennart.nacke@uoit.ca"],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"procedural content":{"dislikes":[],"lastTimeUpdated":1386523056650,"checked":true,"likes":[],"label":"procedural content"},"Automation":{"dislikes":[],"lastTimeUpdated":1386523340736,"checked":true,"likes":[],"label":"Automation"},"games":{"dislikes":[],"lastTimeUpdated":1386523040220,"checked":true,"likes":[],"label":"games"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523063674,"label":"User Experience Design / Experience Design"},"PCG":{"dislikes":[],"lastTimeUpdated":1386523048001,"checked":true,"likes":[],"label":"PCG"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711791}},"creationTime":1617,"content":{"authorList":["Gillian Smith, Northeastern University"],"title":"Understanding Procedural Content Generation: A Design-Centric Analysis of the Role of PCG in Games","paperOrNote":"Paper","fullAbstract":"Games that use procedural content generation (PCG) do so in a wide variety of ways and for several different reasons. One of the most common reasons cited by PCG system creators and game designers is improving replayabilityby providing a means for automatically creating near-infinite amounts of content, the player can come back and replay the game and refine her strategies over a long period of time. However, this notion of replayability is both overly broad and incomplete as a motivation for PCG. This paper contributes an analytical framework and associated common vocabulary for understanding the role of PCG in games from a design standpoint, with an aim of unpacking some of the broad justifications for PCG use in games, and bringing together technical concerns in designing PCG systems with design concerns related to creating engaging playable experiences.","shortAbstract":"Games that use procedural content generation (PCG) do so in a wide var","id":"pn2046"},"session":"Games: Games","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2046"},"pn2048":{"lastUpdateTime":1389236351048,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Design patterns":{"dislikes":[],"lastTimeUpdated":1386522155050,"checked":true,"likes":[],"label":"Design patterns"},"design theory":{"dislikes":[],"lastTimeUpdated":1386531237935,"checked":true,"likes":[],"label":"design theory"},"constructive design research":{"dislikes":[],"lastTimeUpdated":1386522186398,"checked":true,"likes":[],"label":"constructive design research"},"Design Theory":{"checked":false,"lastUpdateTime":1386531240294,"dislikes":[],"label":"Design Theory","lastTimeUpdated":1386522122658,"likes":["bilge@cs.wisc.edu","wendyju@stanford.edu","aantle@sfu.ca"]},"Experience Strategy":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Experience Strategy"},"research through design":{"dislikes":[],"lastTimeUpdated":1386522165501,"checked":true,"likes":[],"label":"research through design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"framing constructs":{"dislikes":[],"lastTimeUpdated":1386522195899,"checked":true,"likes":[],"label":"framing constructs"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"strong concepts":{"dislikes":[],"lastTimeUpdated":1386522158248,"checked":true,"likes":[],"label":"strong concepts"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755904}},"creationTime":1619,"content":{"authorList":["Peter Dalsgaard, Aarhus University","Christian Dindler, Aarhus University"],"title":"Peepholes: A Bridging Concept for Designing Engaging Interactive Systems","paperOrNote":"Paper","fullAbstract":"We present the concept of Peepholes as a particular means for spurring user curiosity and engagement. We propose that Peepholes may be understood as a bridging concept: a form of knowledge residing between theory and design practice. As an intermediate form of knowledge, we argue that bridging concepts such as Peepholes have three defining constituents: a theoretical foundation, a set of design articulations, and a range of exemplars that demonstrate the scope and potential of their application. We present an analysis of the concept of Peepholes in terms of these three defining constituents, and argue that bridging concepts in general, and peepholes in particular, provide a form of knowledge that is useful for both researchers and interaction design practitioners.","shortAbstract":"We present the concept of Peepholes as a particular means for spurring","id":"pn2048"},"session":"Design: Design Theory","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2048"},"pn1773":{"lastUpdateTime":1389238815508,"subcommitteeSplit":"C","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527341166,"label":"E-Learning and Education"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["tjvg@di.fc.ul.pt","christopher.power@york.ac.uk","erinacarroll@gmail.com"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Time Management":{"dislikes":[],"lastTimeUpdated":1386527454832,"checked":true,"likes":[],"label":"Time Management"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527340255,"label":"User Interface Design"},"Systems":{"checked":false,"lastUpdateTime":1386527475860,"dislikes":[],"label":"Systems","lastTimeUpdated":1386526395784,"likes":["erinacarroll@gmail.com"]},"Awareness Support":{"dislikes":[],"lastTimeUpdated":1386527460810,"checked":true,"likes":[],"label":"Awareness Support"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527043973,"label":"Empirical Methods, Qualitative"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486639}},"creationTime":1383,"content":{"authorList":["Ha Trinh, Microsoft Research Asia","Koji Yatani, Microsoft Research Asia","Darren Edge, Microsoft Research Asia"],"title":"PitchPerfect: Integrated Rehearsal Environment for Structured Presentation Preparation","paperOrNote":"Paper","fullAbstract":"Rehearsal is a critical component of preparing to give an oral presentation, yet it is frequently abbreviated, performed in ways that are inefficient or ineffective, or simply omitted. We conducted an exploratory study to understand the relationship between the theory and practice of presentation rehearsal, classifying our qualitative results into five themes to motivate more structured rehearsal support deeply integrated in slide presentation software. In a within-subject study (N=12) comparing against participants existing rehearsal practices, we found that our resulting PitchPerfect system significantly improved overall presentation quality and content coverage as well as providing greater support for content mastery, time management, and confidence building.","shortAbstract":"Rehearsal is a critical component of preparing to give an oral present","id":"pn1773"},"session":"Systems: Presentations","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1773"},"pn1776":{"lastUpdateTime":1389238827699,"subcommitteeSplit":"","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528507210,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Multi-Device User Interfaces":{"dislikes":[],"lastTimeUpdated":1386524575530,"checked":true,"likes":[],"label":"Multi-Device User Interfaces"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["roudauta@gmail.com"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Privacy":{"checked":true,"dislikes":[],"likes":["lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Privacy"},"personalization":{"checked":false,"lastUpdateTime":1386537068401,"dislikes":[],"label":"personalization","lastTimeUpdated":1386537061414,"likes":[]},"public displays":{"dislikes":[],"lastTimeUpdated":1386523992748,"checked":true,"likes":["lorrie@acm.org"],"label":"public displays"},"Personalization":{"dislikes":[],"lastTimeUpdated":1386537063920,"checked":true,"likes":[],"label":"Personalization"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081832}},"creationTime":1386,"content":{"authorList":["Nigel Davies, Lancaster University","Marc Langheinrich, University of Lugano","Sarah Clinch, Lancaster University","Ivan Elhart, University of Lugano","Adrian Friday, Lancaster University","Thomas Kubitza, University of Stuttgart","Bholanathsingh Surajbali, Lancaster University"],"title":"Personalisation and Privacy in Future Pervasive Display Networks","paperOrNote":"Paper","fullAbstract":"Large-scale digital signage systems are becoming increasingly commonplace. Traditionally these systems have been used to broadcast general-interest adverts and information to passers-by. However, there is increasing interest in using digital signage to deliver highly personalised content such as personalised travel information, adverts that match a viewers buying profile or news on relevant topics. The shift from a simple broadcast medium to a more personalised and interactive system presents a number of significant architectural design challenges. In particular, how best to provide personalisation without unduly compromising viewers' privacy. While previous research has focused on understanding specific elements of the overall vision, our work presents details of the first significant attempt at a system that integrates future pervasive display networks and mobile devices to support display personalisation while preserving users' privacy. ","shortAbstract":"Large-scale digital signage systems are becoming increasingly commonpl","id":"pn1776"},"session":"Security: Privacy","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1776"},"pn1414":{"lastUpdateTime":1389285580072,"subcommitteeSplit":"A","labels":{"Lost In Translation":{"dislikes":[],"lastTimeUpdated":1386523604989,"checked":true,"likes":["dabbish@cmu.edu","sameer.patil@hiit.fi","beverly_harrison@yahoo.com"],"label":"Lost In Translation"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Lost and Found in Translation":{"dislikes":[],"lastTimeUpdated":1386524918686,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Lost and Found in Translation"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946712}},"creationTime":1077,"content":{"authorList":["Ari Hautasaari, NTT Communication Science Labs","Naomi Yamashita, NTT Communication Science Labs","Ge Gao, Cornell University"],"title":"Maybe It Was a Joke - Emotion Detection in Text-Only Communication by Non-Native English Speakers","paperOrNote":"Paper","fullAbstract":"Previous studies have shown that people can effectively detect emotions in text-only messages written in their native languages. But is this the same for non-native speakers? In this paper, we conduct an experiment where native English speakers (NS) and Japanese non-native English speakers (NNS) rate the emotional tone in real text-only messages written by native English-speaking authors. They also annotate all emotional cues (words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS ratings and annotations are calculated by comparing their average correlations with author ratings and annotations used as the optimal standard. Our results conclude that NNS are significantly less accurate at detecting emotions in messages, especially when the messages include highly negative words. Although NNS are as accurate as NS at detecting emotional cues, they are not able to make use of symbols (exclamation marks) and emoticons to detect the emotional tone of text-only messages.","shortAbstract":"Previous studies have shown that people can effectively detect emotion","id":"pn1414"},"session":"HCI4D: Lost and Found in Translation","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1414"},"pn1417":{"lastUpdateTime":1389591221031,"subcommitteeSplit":"A","labels":{"it's not correlation":{"checked":false,"lastUpdateTime":1386524844215,"dislikes":[],"label":"it's not correlation","lastTimeUpdated":1386524804600,"likes":[]},"causal interactions":{"dislikes":[],"lastTimeUpdated":1386524191136,"checked":true,"likes":[],"label":"causal interactions"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"design for learning":{"dislikes":[],"lastTimeUpdated":1386524839668,"checked":true,"likes":[],"label":"design for learning"},"cause and effect":{"dislikes":[],"lastTimeUpdated":1386525385203,"checked":true,"likes":[],"label":"cause and effect"},"design guidelines":{"dislikes":[],"lastTimeUpdated":1386524781231,"checked":true,"likes":[],"label":"design guidelines"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Causal Encounters":{"dislikes":[],"lastTimeUpdated":1386525172400,"checked":true,"likes":["asellen@microsoft.com"],"label":"Causal Encounters"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946694}},"creationTime":1080,"content":{"authorList":["Adam Darlow, Brown University","Gideon Goldin, Brown University","Steven Sloman, Brown University"],"title":"Causal Interactions","paperOrNote":"Paper","fullAbstract":"In this paper we present two design guidelines, causal order and continuity, to be used as rules of thumb for designing intuitive interactions based on principles of causal reasoning. We propose that designing interactions to behave like real-world systems of cause and effect makes them more intuitive and using basic principles avoids the limitations inherent in using specific metaphors.  In three experiments, participants solved puzzles using variations of a novel graphical interface. Participants using interfaces that were consistent with the causal guidelines consistently solved the puzzle faster than participants using inconsistent interfaces. We discuss which common interactions are consistent with the causal guidelines and where it is likely to apply successfully. In addition to the causal order guidelines inherent utility, it demonstrates how principles of causal psychology can be applied to help interface designers better convey the functionality of their interfaces.","shortAbstract":"In this paper we present two design guidelines, causal order and conti","id":"pn1417"},"session":"Methods and Models: new HCI paradigms","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1417"},"pn1410":{"lastUpdateTime":1389221957843,"subcommitteeSplit":"B","labels":{"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["daverandall2008@gmail.com"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Wikipedia":{"dislikes":[],"lastTimeUpdated":1386525287819,"checked":true,"likes":[],"label":"Wikipedia"},"wiki wiki wiki":{"dislikes":[],"lastTimeUpdated":1386524219733,"checked":true,"likes":[],"label":"wiki wiki wiki"},"communities":{"dislikes":[],"lastTimeUpdated":1386525306964,"checked":true,"likes":["spdow@cs.cmu.edu"],"label":"communities"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032707}},"creationTime":1074,"content":{"authorList":["Haiyi Zhu, Carnegie Mellon University","Robert Kraut, Carnegie Mellon University","Aniket Kittur, Carnegie Mellon University"],"title":"The Impact of Membership Overlap on the Survival of Online Communities","paperOrNote":"Paper","fullAbstract":"Online communities play an important role in society. In this paper, we study the effects of membership overlap on the survival of online communities. By analyzing the historical data of 5673 Wikia communities, we find that higher levels of membership overlap are positively associated with greater survival rate of online communities relative to lower levels of membership overlap. Furthermore, we find that it is beneficial for new communities to have shared members who play a central role in other mature communities. These findings contribute new insight into an important mechanism underlying successful online communities, and provide practical guidance for leaders of online communities to better manage their communities.","shortAbstract":"Online communities play an important role in society. In this paper, w","id":"pn1410"},"session":"Social: Online Communities","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1410"},"pn1413":{"lastUpdateTime":1387325177300,"subcommitteeSplit":"A","labels":{"Health and social media":{"dislikes":[],"lastTimeUpdated":1386523147040,"checked":true,"likes":["Jina.huh@gmail.com","wilcox@cc.gatech.edu","mentis@umbc.edu"],"label":"Health and social media"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"search":{"dislikes":[],"lastTimeUpdated":1386525986856,"checked":true,"likes":["bellotti@parc.com"],"label":"search"},"big data":{"dislikes":[],"lastTimeUpdated":1386522957050,"checked":true,"likes":[],"label":"big data"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188158}},"creationTime":1076,"content":{"authorList":["Munmun De Choudhury, Microsoft Research","Meredith Morris, Microsoft Research","Ryen White, Microsoft Research"],"title":"Seeking and Sharing Health Information Online: Comparing Search Engines and Social Media","paperOrNote":"Paper","fullAbstract":"Search engines and social media are two of the most commonly used online services; in this paper, we examine how users appropriate these platforms for online health activities via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activities. We reflect on the implications of our results for designing search engines, social media, and social search tools that better support peoples health information seeking and sharing needs.","shortAbstract":"Search engines and social media are two of the most commonly used onli","id":"pn1413"},"session":"Information in Use","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1413"},"pn2193":{"lastUpdateTime":1389284833413,"subcommitteeSplit":"B","labels":{"Economics & HCI":{"dislikes":[],"lastTimeUpdated":1386522222350,"checked":true,"likes":[],"label":"Economics & HCI"},"Social justice":{"dislikes":[],"lastTimeUpdated":1386523073480,"checked":true,"likes":[],"label":"Social justice"},"Sustainability":{"dislikes":[],"lastTimeUpdated":1386522243290,"checked":true,"likes":["ztoups@nmsu.edu"],"label":"Sustainability"},"Prosociality":{"dislikes":[],"lastTimeUpdated":1386522889881,"checked":true,"likes":[],"label":"Prosociality"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"HCI in Economic Life":{"dislikes":[],"lastTimeUpdated":1386523081752,"checked":true,"likes":[],"label":"HCI in Economic Life"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755929}},"creationTime":1752,"content":{"authorList":["John Harvey, University of Nottingham","David Golightly, University of Nottingham","Andrew Smith, University of Nottingham"],"title":"HCI as a means to prosociality in the economy","paperOrNote":"Paper","fullAbstract":"HCI research often involves intervening in the economic lives of people, but researchers only rarely give explicit consideration to what actually constitutes prosociality in the economy.   Much has been said previously regarding sustainability but this has largely focused on environmental rather than interpersonal relations.  This paper provides an analysis of how prosocial HCI has been discussed and continues to define itself as a research field.  Based on a corpus of published works, we describe a variety of genres of work relating to prosocial HCI.  Key intellectual differences are then explored, including the epistemological and ethical positions involved in designing for prosocial outcomes as well as how HCI researchers posit economic decision-making.  Finally, emerging issues and opportunities for further debate and collaboration are discussed in turn. ","shortAbstract":"HCI research often involves intervening in the economic lives of peopl","id":"pn2193"},"session":"HCI4D: Shopping and Economy","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2193"},"pn590":{"lastUpdateTime":1389591632387,"subcommitteeSplit":"","labels":{"Death":{"dislikes":[],"lastTimeUpdated":1386522052039,"checked":true,"likes":[],"label":"Death"},"Caring for people":{"dislikes":[],"lastTimeUpdated":1386523148904,"checked":true,"likes":["depaula@acm.org","dtatar@cs.vt.edu"],"label":"Caring for people"},"ephemera":{"dislikes":[],"lastTimeUpdated":1386523669024,"checked":true,"likes":[],"label":"ephemera"},"Ephemera":{"checked":false,"lastUpdateTime":1386523787966,"dislikes":[],"label":"Ephemera","lastTimeUpdated":1386523559756,"likes":[]},"Life changes":{"dislikes":[],"lastTimeUpdated":1386523123908,"checked":true,"likes":[],"label":"Life changes"},"Facebook":{"dislikes":[],"lastTimeUpdated":1386523725536,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"Facebook"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522118593,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522120494,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523183257,"label":"Social Computing and Social Navigation"},"Data ownership":{"dislikes":[],"lastTimeUpdated":1386523149850,"checked":true,"likes":[],"label":"Data ownership"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522115437,"label":"Computer Supported Cooperative Work (CSCW)"},"data management":{"dislikes":[],"lastTimeUpdated":1386522967503,"checked":true,"likes":[],"label":"data management"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556762}},"creationTime":369,"content":{"authorList":["Jed Brubaker, University of California, Irvine","Lynn Dombrowski, University of California, Irvine","Anita Gilbert, University of California, Irvine","Nafiri Kusumakaulika, University of California, Irvine","Gillian Hayes, University of California Irvine"],"title":"Stewarding a Legacy: Responsibilities and Relationships in the Management of Post-mortem Data","paperOrNote":"Paper","fullAbstract":"This paper extends research on the giving and inheriting of digital artifacts by examining social network site accounts port-mortem. Given the important role that social network sites play in online bereavement practices, we conducted a series of in-depth qualitative interviews to explore issues around inheritance and post-mortem data management of Facebook accounts. We found that participants focused less on ownership of the data, and instead on authorization, management, and the responsibility of maintaining an account post-mortem. Subsequently, we argue for stewardship as an alternative to inheritance for framing post-mortem data management practices. Analysis of post-mortem data management activities highlights how stewards are accountable and responsible to the deceased and various survivors. However, weighing competing responsibilities is complicated by varied relationships with disparate survivors, as well as the inability to consult with the deceased. Based on our findings, we claim that post-mortem solutions need to account for the needs of stewards in addition to those of the deceased and survivors. We suggest that a model of stewardship better accounts for the interpersonal responsibilities that accompany online data than inheritance alone.","shortAbstract":"This paper extends research on the giving and inheriting of digital ar","id":"pn590"},"session":"People: Personal Information","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn590"},"pn1569":{"lastUpdateTime":1389238262241,"subcommitteeSplit":"C","labels":{"ludic engagement":{"dislikes":[],"lastTimeUpdated":1386527510045,"checked":true,"likes":[],"label":"ludic engagement"},"Guided experiences":{"dislikes":[],"lastTimeUpdated":1386526392601,"checked":true,"likes":["andrew.sears@rit.edu"],"label":"Guided experiences"},"Auditory Interface Design":{"dislikes":[],"lastTimeUpdated":1386527229502,"checked":true,"likes":[],"label":"Auditory Interface Design"},"Entertainment":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527177397,"label":"Entertainment"},"Music":{"dislikes":[],"lastTimeUpdated":1386526801747,"checked":true,"likes":["erinacarroll@gmail.com","Mark.blythe@northumbria.ac.uk"],"label":"Music"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527184375,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"lastUpdateTime":1386527183504,"dislikes":[],"label":"User Experience Design / Experience Design","lastTimeUpdated":1386526252810,"likes":["kash@diku.dk"]},"location media":{"checked":true,"lastUpdateTime":1386526341571,"dislikes":[],"label":"location media","lastTimeUpdated":1386526330820,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486637}},"creationTime":1214,"content":{"authorList":["Adrian Hazzard, The University of Nottingham","Steve Benford, The University of Nottingham","Gary Burnett, The University of Nottingham"],"title":"Walk this Way: Musically Guided Walking Experiences","paperOrNote":"Paper","fullAbstract":"Musical soundtracks will be important features of future locative experiences from tours to games. We present a study designed to uncover potential relationships between higher-level musical structures such as harmony, melody, timbre, dynamic intensity and punctuation and users spatial experiences. We observed twenty-two participants exploring an open field while listening to four contrasting musical compositions, and then interviewed them afterwards. We report their different approaches to interpreting the music, strategies for mapping zones, choice of stopping destinations, and their awareness and appreciation of the music. Our discussion of these findings in relation to the literature leads us to propose six initial principles to guide the composition of mobile and locative soundtracks, and also to articulate a three-layer framework of global, regional and local attachment to help guide the attachment of musical features to different regions within a locative experience. ","shortAbstract":"Musical soundtracks will be important features of future locative expe","id":"pn1569"},"session":"Art: Museum Experience","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1569"},"pn443":{"lastUpdateTime":1389221814307,"subcommitteeSplit":"A","labels":{"Play":{"dislikes":[],"lastTimeUpdated":1386523716654,"checked":true,"likes":[],"label":"Play"},"mobile":{"dislikes":[],"lastTimeUpdated":1386523220146,"checked":true,"likes":[],"label":"mobile"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526565835,"label":"User-Centered Design / Human-Centered Design"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":1386526563991,"label":"User Experience Design / Experience Design"},"Children":{"checked":true,"dislikes":[],"likes":["J.Good@sussex.ac.uk","a.parker@neu.edu"],"lastUpdateTime":123456789,"label":"Children"},"Literacy":{"dislikes":[],"lastTimeUpdated":1386523208128,"checked":true,"likes":[],"label":"Literacy"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188245}},"creationTime":259,"content":{"authorList":["Gavin Wood, Newcastle University","John Vines, Newcastle University","Madeline Balaam, Culture Lab, University of Newcastle","Nick Taylor, University of Dundee","Thomas Smith, Newcastle University","Clara Crivellaro, Newcastle University","Peter Wright, Newcastle University"],"title":"The Department of Hidden Stories: Playful Digital Storytelling for Children in a Public Library","paperOrNote":"Paper","fullAbstract":"We consider the design of the Department of Hidden Stories (DoHS), a mobile-based game to support playful digital storytelling among primary school children within public libraries. Through a process of collaborative design with library staff and childrens writers we designed and evaluated DoHS to support the potential for playful storytelling through interactions with books. We explore how to balance the expectations of a child-at-play and the requirement to further develop their creative reading and writing skills. Based on our experiences we recommend that designers create playful digitally based activities that encourage children to explore libraries and experience new interactions with physical books.","shortAbstract":"We consider the design of the Department of Hidden Stories (DoHS), a m","id":"pn443"},"session":"Art: Narratives and Storytelling","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn443"},"pn139":{"lastUpdateTime":1389238054489,"subcommitteeSplit":"A","labels":{"Kinecting People":{"dislikes":[],"lastTimeUpdated":1386524064143,"checked":true,"likes":["sameer.patil@hiit.fi","paul.marshall@ucl.ac.uk"],"label":"Kinecting People"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525532440,"label":"Empirical Methods, Quantitative"},"audience interaction":{"dislikes":[],"lastTimeUpdated":1386524035695,"checked":true,"likes":[],"label":"audience interaction"},"Video Games":{"dislikes":[],"lastTimeUpdated":1386524076165,"checked":true,"likes":["eva@ehornecker.de","dabbish@cmu.edu","paul.marshall@ucl.ac.uk"],"label":"Video Games"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526687927,"label":"Social Computing and Social Navigation"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946688}},"creationTime":29,"content":{"authorList":["John Downs, The University of Melbourne","Frank Vetere, The University of Melbourne","Steve Howard, The University of Melbourne","Steve Loughnan, The University of Melbourne","Wally Smith, The University of Melbourne"],"title":"Audience Experience in Social Videogaming","paperOrNote":"Paper","fullAbstract":"Videogames are often played socially with both co-players and audiences. Audience members' experiences are not well understood, nor are the factors of videogaming sessions that influence their experience. We conducted a study to examine the effects of game physicality and turn anticipation on audience members' experiences in social videogaming sessions. Pairs of participants played games under three conditions of physicality (controller-based, Wii, and Kinect) and their expectation of turn taking was manipulated. Their enjoyment, game engagement, social engagement and sense of participation were measured. We found that the introduction of turn taking into the session had positive effects for audience members - both anticipated and residual play effects - and that Kinect gameplay resulted in a more enjoyable experience for audience members. We argue that audience members' experience changes as they become more active within a session, and suggest there are design opportunities between purely active 'players' and passive 'audience members'.","shortAbstract":"Videogames are often played socially with both co-players and audience","id":"pn139"},"session":"People: Kinecting People","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn139"},"pn138":{"lastUpdateTime":1389221840890,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386530328930,"checked":true,"likes":[],"label":"Gestural interaction"},"gestures":{"dislikes":[],"lastTimeUpdated":1386531518988,"checked":true,"likes":[],"label":"gestures"},"Gestural Interaction":{"checked":false,"lastUpdateTime":1386530331200,"dislikes":[],"label":"Gestural Interaction","lastTimeUpdated":1386525534609,"likes":[]},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["abe.karnik@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386525553900,"checked":true,"likes":[],"label":"Text Entry"},"Gesture":{"checked":false,"lastUpdateTime":1386531515780,"dislikes":[],"label":"Gesture","lastTimeUpdated":1386525240148,"likes":[]},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644736}},"creationTime":28,"content":{"authorList":["Anders Markussen, University of Copenhagen","Mikkel Jakobsen, University of Copenhagen","Kasper Hornbk, University of Copenhagen"],"title":"Vulture: A Mid-Air Word-Gesture Keyboard","paperOrNote":"Paper","fullAbstract":"Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users movement orthogonally onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text entry rates of 20 Words Per Minute (WPM) and find hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28 WPM, 59% of the text entry rate of direct touch input. Participants recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.","shortAbstract":"Word-gesture keyboards enable fast text entry by letting users draw th","id":"pn138"},"session":"UIST: novel keyboards","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn138"},"pn916":{"lastUpdateTime":1388781129415,"subcommitteeSplit":"","labels":{"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","steimle@media.mit.edu"],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Augmented Reality":{"dislikes":[],"lastTimeUpdated":1386525749769,"checked":true,"likes":[],"label":"Augmented Reality"},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["davidmcgookin@gmail.com","steimle@media.mit.edu"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","steimle@media.mit.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386542939197,"label":"User Studies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644739}},"creationTime":640,"content":{"authorList":["Klen opi Pucihar, Lancaster University","Paul Coulton, Lancaster University","Jason Alexander, Lancaster University"],"title":"The Use of Surrounding Visual Context in Handheld AR: Device vs. User Perspective Rendering","paperOrNote":"Paper","fullAbstract":"The magic-lens paradigm, a common approach to handheld Augmented Reality (AR) presents the user with dual-views: the augmented-view (magic-lens) that appears on the device, and the real-view of the surroundings (what user can see around the perimeter of the device). The augmented view is typically implemented by rendering the video captured by the rear-facing camera directly onto the devices screen. This results in dual-perspectivesthe real world being captured from the devices perspective rather than the users perspective (what an observer would see looking through a transparent glass pane). These differences manifest themselves in misaligned and incorrectly scaled transparency causing the dual-view problem. \\ This paper presents a user study comparing device- and fixed Point-of-View (POV) user-perspective magic-lens types to analyze the effect of the dual-view problem on the use of the surrounding visual context in handheld AR. The results confirm the dual-view problem, a result of dual-perspective, has a significant effect on the use of the surrounding context. The study also pinpoints magnification (not the dual-view problem) as the key factor explaining the correlation between magic-lens size and the increased intensity of the magic-lens type effect. From results, we derive a set of guidelines to supports the design of future magic-lenses.  \\ ","shortAbstract":"The magic-lens paradigm, a common approach to handheld Augmented Reali","id":"pn916"},"session":"3D: The third dimension","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn916"},"pn1188":{"lastUpdateTime":1389222165018,"subcommitteeSplit":"","labels":{"Stress":{"checked":false,"lastUpdateTime":1386531775282,"dislikes":[],"label":"Stress","lastTimeUpdated":1386526956512,"likes":[]},"Office and Workplace":{"checked":false,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":1386531745361,"label":"Office and Workplace"},"Emotion and Affective User Interface":{"checked":false,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":1386531749774,"label":"Emotion and Affective User Interface"},"Affective computing":{"dislikes":[],"lastTimeUpdated":1386528390462,"checked":true,"likes":[],"label":"Affective computing"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["wmoncur@dundee.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":1386531758453,"label":"User Studies"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165048}},"creationTime":875,"content":{"authorList":["Javier Hernandez, MIT","Pablo Paredes, Electrical Engineering and Computer Science Department","Asta Roseway, Microsoft Research","Mary Czerwinski, Microsoft Research"],"title":"Under Pressure: Sensing Stress of Computer Users","paperOrNote":"Paper","fullAbstract":"Recognizing when computer users are stressed can help reduce their frustration and prevent a large variety of negative health conditions associated with chronic stress. However, measuring stress non-invasively and continuously at work remains an open challenge. This work explores the possibility of using a pressure-sensitive keyboard and a capacitive mouse to discriminate between stressful and relaxed conditions in a laboratory study. During a 30 minute session, 24 participants performed several computerized tasks consisting of expressive writing, text transcription, and mouse clicking. During the stressful conditions, the large majority of the participants showed significantly increased typing pressure (>79% of the participants) and more contact with the surface of the mouse (75% of the participants). We discuss the potential implications of this work and provide recommendations for future work.","shortAbstract":"Recognizing when computer users are stressed can help reduce their fru","id":"pn1188"},"session":"Health: Stress","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1188"},"pn1186":{"lastUpdateTime":1389222102553,"subcommitteeSplit":"","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["forlines@alumni.cmu.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"shape-changing interfaces":{"checked":false,"lastUpdateTime":1386525263895,"dislikes":[],"label":"shape-changing interfaces","lastTimeUpdated":1386525221134,"likes":[]},"shape changing interfaces":{"dislikes":[],"lastTimeUpdated":1386525260567,"checked":true,"likes":["j.alexander@lancaster.ac.uk","sriramable@gmail.com","no@spam.org"],"label":"shape changing interfaces"},"Tangible UIs":{"dislikes":[],"lastTimeUpdated":1386525923141,"checked":true,"likes":[],"label":"Tangible UIs"},"Multi-modal interfaces":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525159799,"label":"Multi-modal interfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644840}},"creationTime":873,"content":{"authorList":["Panteleimon Dimitriadis, Lancaster University","Jason Alexander, Lancaster University"],"title":"Evaluating the Effectiveness of Physical Shape-Change for In-pocket Mobile Device Notifications","paperOrNote":"Note","fullAbstract":"Audio and vibrotactile output are the standard mechanisms mobile devices use to attract their owners attention. Yet in busy and noisy environments, or when the user is physically active, these channels sometimes fail. Recent work has explored the use of physical shape-change as an additional method for conveying notifications when the device is in-hand or viewable. However, we do not yet understand the effectiveness of physical shape-change as a method for communicating in-pocket notifications. This paper presents three robustly implemented, mobile-device sized shape-changing devices, and two user studies to evaluate their effectiveness at conveying notifications. The studies reveal that different types and configurations of shape-change convey different levels of urgency, and that shape-changing notifications are missed less often and recognized more quickly than traditional mobile device vibration.","shortAbstract":"Audio and vibrotactile output are the standard mechanisms mobile devic","id":"pn1186"},"session":"UIST: Shape-Changers","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1186"},"pn1182":{"lastUpdateTime":1389286103691,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523461340,"label":"E-Learning and Education"},"In School":{"dislikes":[],"lastTimeUpdated":1386523448065,"checked":true,"likes":["lana@research.att.com"],"label":"In School"},"Education":{"dislikes":[],"lastTimeUpdated":1386523464761,"checked":true,"likes":["quintana@umich.edu"],"label":"Education"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["quintana@umich.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"classroom learning & teaching":{"dislikes":[],"lastTimeUpdated":1386523647725,"checked":true,"likes":[],"label":"classroom learning & teaching"},"inquiry learning":{"dislikes":[],"lastTimeUpdated":1386523405309,"checked":true,"likes":[],"label":"inquiry learning"},"Children":{"checked":true,"dislikes":[],"likes":["hilary.hutchinson@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188170}},"creationTime":869,"content":{"authorList":["Michelle Lui, University of Toronto","Alex Kuhn, University of Michigan","Alisa Acosta, University of Toronto","Chris Quintana, University of Michigan","James D. Slotta, University of Toronto"],"title":"Supporting Learners in Collecting and Exploring Data from Immersive Simulations in Collective Inquiry","paperOrNote":"Paper","fullAbstract":"Digitally augmented physical spaces (e.g. smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers data through large visualizations displayed at the front of the room.  Two iterations of the design showed that when students were able to use the collective results of their classmates observations as a resource, they were able to construct quality explanations. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. The visualizations were revised between the trials to support both teacher and students in reviewing patterns of collected data to inform ad hoc discussions and more formal teacher-led sessions. ","shortAbstract":"Digitally augmented physical spaces (e.g. smart classrooms) offer oppo","id":"pn1182"},"session":"HCI4D: Learning and Education","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1182"},"pn1183":{"lastUpdateTime":1389221181945,"subcommitteeSplit":"A","labels":{"Game User Research":{"checked":false,"lastUpdateTime":1386523218857,"dislikes":[],"label":"Game User Research","lastTimeUpdated":1386523035761,"likes":[]},"Exergames":{"dislikes":[],"lastTimeUpdated":1386523234803,"checked":true,"likes":[],"label":"Exergames"},"Entertainment":{"checked":true,"dislikes":[],"likes":["lennart.nacke@uoit.ca"],"lastUpdateTime":123456789,"label":"Entertainment"},"game":{"dislikes":[],"lastTimeUpdated":1386523241327,"checked":true,"likes":["younlim.cixd@gmail.com","lennart.nacke@uoit.ca"],"label":"game"},"Music":{"dislikes":[],"lastTimeUpdated":1386523061710,"checked":true,"likes":[],"label":"Music"},"movement interaction":{"dislikes":[],"lastTimeUpdated":1386522953096,"checked":true,"likes":[],"label":"movement interaction"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711729}},"creationTime":870,"content":{"authorList":["Florian Mueller, RMIT University","Katherine Isbister, Polytechnic Institute of New York University"],"title":"Movement-Based Game Guidelines","paperOrNote":"Paper","fullAbstract":"Movement-based digital games are becoming increasingly popular, yet there is limited comprehensive guidance on how to design these games. We present a set of guidelines for movement-based game design that has emerged from our research-based game development practice. These guidelines have been examined and refined by 14 movement-based game design experts with experience in the academic, independent and commercial game development domains. We contextualize the guidelines using current findings about movement-based game and interaction design, taken from both published research papers and game design venues. Our primary contribution is a body of generative intermediate-level knowledge in the design research tradition that is readily accessible and actionable for the design of future movement-based games.","shortAbstract":"Movement-based digital games are becoming increasingly popular, yet th","id":"pn1183"},"session":"Games: Exergame Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1183"},"pn1341":{"lastUpdateTime":1389221957843,"subcommitteeSplit":"","labels":{"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"entreprise communities":{"dislikes":[],"lastTimeUpdated":1386522944850,"checked":true,"likes":[],"label":"entreprise communities"},"Management of Online Communities":{"dislikes":[],"lastTimeUpdated":1386523780780,"checked":true,"likes":[],"label":"Management of Online Communities"},"goals":{"dislikes":[],"lastTimeUpdated":1386521396223,"checked":true,"likes":[],"label":"goals"},"enterprise":{"dislikes":[],"lastTimeUpdated":1386521737861,"checked":true,"likes":["teevan@gmail.com"],"label":"enterprise"},"forums":{"dislikes":[],"lastTimeUpdated":1386522004698,"checked":true,"likes":[],"label":"forums"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556786}},"creationTime":1009,"content":{"authorList":["Tara Matthews, IBM Research - Almaden","Jilin Chen, IBM Research - Almaden","Steve Whittaker, University of California at Santa Cruz","Aditya Pal, IBM Research - Almaden","Haiyi Zhu, Carnegie Mellon University","Hernan Badenes, IBM","Barton Smith, IBM Research - Almaden"],"title":"Goals and Perceived Success of Online Enterprise Communities: What Is Important to Leaders & Members?","paperOrNote":"Paper","fullAbstract":"Online communities are successful only if they achieve their goals. Goals relate to the value a community offers, also providing ways to assess success. Despite this, there has been little direct study of community goals. We examine the goals of enterprise online communities, assessing their importance for leaders, how goals influence member perceptions of community value, and how goals relate to success measures proposed in the literature. We find that most communities have multiple goals with common goals being learning, reuse of resources, collaboration, networking, influencing change, and innovation. Leaders and members agree that all of these goals are at least moderately important. However, leader and member perceptions of success on goals do not align with each other, or with commonly used behavioral success measures. We conclude that simple behavioral measures and leader perceptions are not good success metrics, and propose alternative measures based on specific goals that members and leaders judge most important.","shortAbstract":"Online communities are successful only if they achieve their goals. Go","id":"pn1341"},"session":"Social: Online Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1341"},"pn1343":{"lastUpdateTime":1389222141946,"subcommitteeSplit":"","labels":{"Social Systems":{"dislikes":[],"lastTimeUpdated":1386523494916,"checked":true,"likes":[],"label":"Social Systems"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523619566,"label":"Empirical Methods, Quantitative"},"Q&A":{"dislikes":[],"lastTimeUpdated":1386522716299,"checked":true,"likes":["teevan@gmail.com","smunson@uw.edu","emailaddress"],"label":"Q&A"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521533103,"checked":true,"likes":[],"label":"crowdsourcing"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523621865,"label":"User Interface Design"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523250523,"label":"Social Computing and Social Navigation"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523624237,"label":"User Studies"},"Semi-autonomous systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Semi-autonomous systems"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556695}},"creationTime":1011,"content":{"authorList":["Tiziano Piccardi, Xerox Research Centre Europe","Gregorio Convertino, Xerox Research Center Europe","Massimo Zancanaro, FBK","Ji Wang, Xerox Research Centre Europe","Cedric Archambeau, Xerox Research Center Europe"],"title":"Towards Crowd-based Customer Service: A Mixed-Initiative Tool for Managing Q&A Sites","paperOrNote":"Paper","fullAbstract":"Q&A sites have emerged as an efficient way to address questions in various domains by leveraging crowd knowledge. However they lack sufficient reliability to be used as the sole basis for customer service applications. In this paper, we propose a mixed-initiative approach to integrate a Q&A site based on a crowd of volunteers with a standard operator-based help desk, ensuring quality of customer service. We built a proof-of-concept mixed-initiative tool that helps a crowd manager to decide if a question will get a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated operator. A user experiment found that our tool reduced the participants cognitive load and improved their performance, in terms of precision and recall. In particular, those with higher performance benefited more than those with lower performance.","shortAbstract":"Q&A sites have emerged as an efficient way to address questions in var","id":"pn1343"},"session":"Social: Do Ask Do Tell","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1343"},"pn1347":{"lastUpdateTime":1389285590040,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386521590567,"checked":true,"likes":[],"label":"social media"},"global":{"dislikes":[],"lastTimeUpdated":1386522142179,"checked":true,"likes":[],"label":"global"},"Internationalization / Localization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Internationalization / Localization"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523591193,"label":"Empirical Methods, Quantitative"},"Twitter":{"dislikes":[],"lastTimeUpdated":1386522597691,"checked":true,"likes":["jacovi@il.ibm.com","sfussell@cornell.edu"],"label":"Twitter"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Multilingual communication":{"dislikes":[],"lastTimeUpdated":1386522712890,"checked":true,"likes":["jacovi@il.ibm.com","sfussell@cornell.edu","myriam.lewkowicz@utt.fr","teevan@gmail.com"],"label":"Multilingual communication"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523592822,"label":"Computer-Mediated Communication"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523594085,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556683}},"creationTime":1015,"content":{"authorList":["Scott Hale, Oxford Internet Institute, University of Oxford"],"title":"Global Connectivity and Multilinguals in the Twitter Network","paperOrNote":"Paper","fullAbstract":"This article analyzes the global connectivity of the Twitter retweet and mentions network and the role of users engaging with content in multiple languages (referred to as multilingual users). The network is heavily structured by language with most mentions and retweets directed to users writing in the same language. Users writing in multiple languages are more active, authoring more tweets than monolingual users (users writing in one language). However, multilingual  users are no more likely to be retweeted or mentioned. These multilingual users play a unique bridging role in the global connectivity of the network. The level of introversion from speakers in each language collectively does not correlate straightforwardly with the size of the user base as predicted by previous research. Finally, the English language does collectively play more of a bridging role than other languages, but the role played collectively by multilingual users across different languages is the largest bridging force in the network.","shortAbstract":"This article analyzes the global connectivity of the Twitter retweet a","id":"pn1347"},"session":"HCI4D: Multilingual Communication","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1347"},"pn1969":{"lastUpdateTime":1388776832811,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Automotive":{"dislikes":[],"lastTimeUpdated":1386524176510,"checked":true,"likes":[],"label":"Automotive"},"Activity recognition":{"dislikes":[],"lastTimeUpdated":1386524667784,"checked":true,"likes":[],"label":"Activity recognition"},"Vehicular":{"dislikes":[],"lastTimeUpdated":1386524066161,"checked":true,"likes":[],"label":"Vehicular"},"Sensing":{"dislikes":[],"lastTimeUpdated":1386524139330,"checked":true,"likes":["roudauta@gmail.com"],"label":"Sensing"},"Transport":{"dislikes":[],"lastTimeUpdated":1386523944469,"checked":true,"likes":[],"label":"Transport"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081865}},"creationTime":1553,"content":{"authorList":["Jin-Hyuk Hong, Carnegie Mellon University","Ben Margines, Carnegie-Mellon University","Anind K. Dey, Carnegie Mellon University"],"title":"A Smartphone-based Sensing Platform to Model Aggressive Driving Behaviors","paperOrNote":"Paper","fullAbstract":"Driving aggressively increases the risk of accidents. Assessing a persons driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an in-vehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone. ","shortAbstract":"Driving aggressively increases the risk of accidents. Assessing a pers","id":"pn1969"},"session":"Transportation: Driving Me Mental","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1969"},"pn2463":{"lastUpdateTime":1389238827699,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528574712,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Privacy":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","com@psychology.nottingham.ac.uk","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Privacy"},"Facebook":{"dislikes":[],"lastTimeUpdated":1386523310746,"checked":true,"likes":["lorrie@acm.org"],"label":"Facebook"},"nudges":{"dislikes":[],"lastTimeUpdated":1386525887068,"checked":true,"likes":[],"label":"nudges"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","com@psychology.nottingham.ac.uk"],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"awareness":{"dislikes":[],"lastTimeUpdated":1386523123418,"checked":true,"likes":[],"label":"awareness"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032716}},"creationTime":1975,"content":{"authorList":["Yang Wang, Syracuse University","Pedro Leon, Carnegie Mellon University","Lorrie Cranor, Carnegie Mellon University","Alessandro Acquisti, Carnegie Mellon University","Norman Sadeh, Carnegie Mellon University","Alain Forget, Carnegie Mellon University"],"title":"Nudging Users Toward Better Information Disclosure: A Field Trial of Privacy Nudges in Facebook","paperOrNote":"Paper","fullAbstract":"Anecdotal evidence and scholarly research have shown that Internet users often experience regret over their online disclosures. To help individuals avoid regrettable online experiences, we designed mechanisms that nudge users to consider the content and context of their online disclosures more carefully. Following an iterative design-evaluate process, we created and tested a series of privacy nudges for Facebook. We tested the final nudge design in a 3-week pilot study with 24 Facebook users, followed by a 6-week field trial with 28 Facebook users. Quantitative and qualitative results at the aggregate and per-participant level suggest that privacy nudges positively impacted approximately half of our participants. We discuss challenges and key implications for designing and testing systems to nudge users to be more thoughtful about their online disclosures.","shortAbstract":"Anecdotal evidence and scholarly research have shown that Internet use","id":"pn2463"},"session":"Security: Privacy","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2463"},"pn2464":{"lastUpdateTime":1389222230397,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386532063544,"checked":true,"likes":["fanny@dgp.toronto.edu","Nchen@microsoft.com","tomer@moscovich.net"],"label":"Text Entry"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Keyboards":{"dislikes":[],"lastTimeUpdated":1386531960598,"checked":true,"likes":["fanny@dgp.toronto.edu","tomer@moscovich.net","j.d.hook@ncl.ac.uk"],"label":"Keyboards"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840656}},"creationTime":1976,"content":{"authorList":["Xiaojun Bi, Google, Inc.","Tom Ouyang, Google, Inc.","Shumin Zhai, Google, Inc."],"title":"Both Complete and Correct? Multi-Objective Optimization of Touchscreen Keyboard","paperOrNote":"Paper","fullAbstract":"Correcting erroneous input (i.e., correction) and completing words based on partial input (i.e., completion) are two important smart capabilities of modern intelligent touchscreen keyboards. However little is known in the literature whether these two capabilities are conflicting or compatible with each other in keyboard parameter tuning. Applying computational optimization methods, this work explores the optimality issues related to them. The work demonstrates that it is possible to simultaneously optimize the keyboard algorithm for both correction and completion. The keyboard simultaneously optimized for both introduces no compromise to correction and only slight compromise to completion when compared to the keyboards exclusively optimized for one objective. Our research also proves the effectiveness of the proposed optimization method in keyboard algorithm design, which is based on Pareto multi-objective optimization and the Metropolis algorithm.  For the development and test datasets used in our experiments, computational optimization could improve correction accuracy rate by 8.3% and completion power by 17.7%. ","shortAbstract":"Correcting erroneous input (i.e., correction) and completing words bas","id":"pn2464"},"session":"UIST: Text Entry and Evaluation","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2464"},"pn2293":{"lastUpdateTime":1388766330700,"subcommitteeSplit":"A","labels":{"Body":{"dislikes":[],"lastTimeUpdated":1386523265112,"checked":true,"likes":["mentis@umbc.edu"],"label":"Body"},"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523476847,"label":"E-Learning and Education"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523616188,"label":"Empirical Methods, Qualitative"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188154}},"creationTime":1835,"content":{"authorList":["Helena Mentis, University of Maryland, Baltimore County","Amine Chellali, Universit d'Evry Val d'Essonne"],"title":"Learning to See the Body: Instruction Practices during Laparoscopic Surgical Procedures","paperOrNote":"Paper","fullAbstract":"Learning the practices and the performance of physically manipulating instruments in minimally invasive surgeries is an impetus for the development of surgical training simulators.  However, an often-overlooked aspect of surgical training is learning how to see the body through the various imaging mechanisms.  With this study, we address the ways in which surgeons demonstrate and instruct residents in seeing the body during minimally invasive surgical procedures.  Drawing on observations and analysis of video recordings of minimally invasive surgical operations, we examine how particular anatomy and movement within the body to see and conceptualize that anatomy are made visible by the instructive practices of the surgeon.  We use these findings to discuss further directions for minimally invasive surgical training through mechanisms for making the body visible during situated surgical training.","shortAbstract":"Learning the practices and the performance of physically manipulating ","id":"pn2293"},"session":"Health: HealthyCHI","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2293"},"pn2294":{"lastUpdateTime":1389236301173,"subcommitteeSplit":"B","labels":{"social computing":{"dislikes":[],"lastTimeUpdated":1386530592106,"checked":true,"likes":[],"label":"social computing"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386522562700,"checked":true,"likes":[],"label":"Handheld Devices and Mobile Computing"},"non-work group activity":{"dislikes":[],"lastTimeUpdated":1386522368422,"checked":true,"likes":[],"label":"non-work group activity"},"Social Computing":{"checked":false,"lastUpdateTime":1386530594201,"dislikes":[],"label":"Social Computing","lastTimeUpdated":1386525670700,"likes":[]},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["david.kirk@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032758}},"creationTime":1836,"content":{"authorList":["Richard Schuler, New Jersey Institute of Technology","Sukeshini Grandhi, Eastern Connecticut State University","Julia Mayer, New Jersey Institute of Technology","Steve Ricken, New Jersey Institute of Technology","Quentin (Gad) Jones, New Jersey Institute of Technology"],"title":"The Doing of Doing Stuff: Understanding the Coordination of Social Group-Activities","paperOrNote":"Paper","fullAbstract":"This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how such coordination is performed as well as the challenges people face. The findings highlight how people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. While at the same time the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating parties. This in turn, often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.","shortAbstract":"This paper explores how the adoption of mobile and social computing te","id":"pn2294"},"session":"CSCW: Coordination & Collaboration","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2294"},"pn589":{"lastUpdateTime":1389591766126,"subcommitteeSplit":"","labels":{"Wearable computing":{"dislikes":[],"lastTimeUpdated":1386532168422,"checked":true,"likes":[],"label":"Wearable computing"},"Concept Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Concept Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu"],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840581}},"creationTime":368,"content":{"authorList":["Barrett Ens, University of Manitoba","Rory Finnegan, University of Manitoba","Pourang Irani, University of Manitoba"],"title":"The Personal Cockpit: A Spatial Window Layout for Effective Task Switching on Head-Worn Displays","paperOrNote":"Paper","fullAbstract":"As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate touch-capable virtual windows. Through a design-space exploration, we run a series of user studies to determine the optimal layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between typical mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40% improvement in application switching time. We follow with a demonstration of several useful implementations and a discussion of important problems for future implementation of our design on current and future wearable devices.","shortAbstract":"As wearable computing goes mainstream, we must improve the state of in","id":"pn589"},"session":"Displays: Head-Worn Displays (UIST)","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn589"},"pn583":{"lastUpdateTime":1389591360286,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531966585,"checked":true,"likes":["eve.hoggan@hiit.fi"],"label":"Touch Input"},"Inference":{"dislikes":[],"lastTimeUpdated":1386531952570,"checked":true,"likes":[],"label":"Inference"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["Nchen@microsoft.com"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Machine Learning":{"dislikes":[],"lastTimeUpdated":1386531959985,"checked":true,"likes":[],"label":"Machine Learning"},"social inference":{"dislikes":[],"lastTimeUpdated":1386531956347,"checked":true,"likes":[],"label":"social inference"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386532177453,"checked":true,"likes":[],"label":"Multitouch"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Drawing":{"dislikes":[],"lastTimeUpdated":1386531932086,"checked":true,"likes":[],"label":"Drawing"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840671},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389106011107}},"creationTime":364,"content":{"authorList":["Julia Schwarz, Carnegie Mellon University","Robert Xiao, Carnegie Mellon University","Jennifer Mankoff, Carnegie Mellon University","Scott Hudson, Carnegie Mellon University","Chris Harrison, Carnegie Mellon University"],"title":"Probabilistic Palm Rejection Using Spatiotemporal Touch Features and Iterative Classification","paperOrNote":"Note","fullAbstract":"Tablet computers are often called upon to emulate classical pen-and-paper input. However, touchscreens typically lack the means to distinguish between legitimate touches and touches with the palm or other parts of the hand. Users are then forced to rest their palms elsewhere or hover above the screen, resulting in ergonomic and usability problems. We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts to reject palms. Our system improves upon previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while correctly passing 98% of stylus inputs.","shortAbstract":"Tablet computers are often called upon to emulate classical pen-and-pa","id":"pn583"},"session":"Methods and Models: User Model 1","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn583"},"pn581":{"lastUpdateTime":1389236332031,"subcommitteeSplit":"B","labels":{"Critical infrastructures":{"dislikes":[],"lastTimeUpdated":1386522692889,"checked":true,"likes":[],"label":"Critical infrastructures"},"critical design":{"dislikes":[],"lastTimeUpdated":1386521977046,"checked":true,"likes":["wendyju@stanford.edu","aantle@sfu.ca","silvia.lindtner@gmail.com"],"label":"critical design"},"big data":{"dislikes":[],"lastTimeUpdated":1386522727059,"checked":true,"likes":["wendyju@stanford.edu"],"label":"big data"},"Feminist HCI":{"dislikes":[],"lastTimeUpdated":1386522661639,"checked":true,"likes":[],"label":"Feminist HCI"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"Infrastructures":{"dislikes":[],"lastTimeUpdated":1386522682627,"checked":true,"likes":[],"label":"Infrastructures"},"Web 2.0":{"dislikes":[],"lastTimeUpdated":1386522655748,"checked":true,"likes":[],"label":"Web 2.0"},"Information Architecture":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Information Architecture"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755893}},"creationTime":362,"content":{"authorList":["Melanie Feinberg, The University of Texas at Austin","Daniel Carter, The University of Texas at Austin","Julia Bullard, The University of Texas at Austin"],"title":"Always Somewhere, Never There: Using Critical Design to Understand Database Interactions","paperOrNote":"Paper","fullAbstract":"Structured databases achieve effective searching and sorting by enacting sharply delineated category boundaries around their contents. While this enables precise retrieval, it also distorts identities that exist between category lines. A choice between Single and Married, for example, blurs distinctions within the Single group: single, for example, merely because same-sex marriage is not legal in ones locality. Sociologists Susan Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts of information systems. To minimize residuality, traditional practice for descriptive metadata seeks to demarcate clear and objective classes. In this study, we use critical design to question this position by creating information collections that foreground the residual, instead of diminishing it. We then interrogate our design experiments with solicited critical responses from invited experts and student designers. Inspired by the anthropologist Tim Ingold, we argue that our experiments illuminate a form of interacting with databases characterized by notions of wayfaring, or inhabiting a space, as opposed to notions of transport, or reaching a known destination. We suggest that the form of coherence that shapes a wayfaring database is enacted through its flow, or fluid integration between structure and content.","shortAbstract":"Structured databases achieve effective searching and sorting by enacti","id":"pn581"},"session":"Design: Critical Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn581"},"pn586":{"lastUpdateTime":1387315711726,"subcommitteeSplit":"A","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Human-Robot Interaction":{"dislikes":[],"lastTimeUpdated":1386522889308,"checked":true,"likes":[],"label":"Human-Robot Interaction"},"Design patterns":{"dislikes":[],"lastTimeUpdated":1386523814663,"checked":true,"likes":[],"label":"Design patterns"},"Robots":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr","carmster@gmail.com"],"lastUpdateTime":123456789,"label":"Robots"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711726}},"creationTime":366,"content":{"authorList":["Allison Saupp, ","Bilge Mutlu, University of Wisconsin, Madison"],"title":"Design Patterns for Exploring and Prototyping Human-Robot Interactions","paperOrNote":"Paper","fullAbstract":"Robotic products are envisioned to offer rich interactions in a wide range of environments. While their specific roles will vary across applications, these products will draw on fundamental building blocks of interaction, such as greeting people, narrating information, providing instructions, and asking and answering questions. In this paper, we explore how such building blocks might serve as interaction design patterns that enable design exploration and prototyping for human-robot interaction. To construct a pattern library, we observed human interactions across different scenarios and identified seven patterns, such as question-answer pairs. We then designed and implemented Interaction Blocks, a visual authoring environment that enabled prototyping of robot interactions using these patterns. Design sessions with designers and developers demonstrated the promise of using a pattern language for designing robot interactions, confirmed the usability of our authoring environment, and provided insights into future research on support tools for human-robot interaction design.","shortAbstract":"Robotic products are envisioned to offer rich interactions in a wide r","id":"pn586"},"session":"Human-Robot Interaction","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn586"},"pn1579":{"lastUpdateTime":1389221983645,"subcommitteeSplit":"B","labels":{"arts":{"dislikes":[],"lastTimeUpdated":1386522146721,"checked":true,"likes":["ztoups@nmsu.edu","stuart@tropic.org.uk"],"label":"arts"},"Performance Metrics":{"checked":false,"dislikes":[],"likes":["wendyju@stanford.edu","ztoups@nmsu.edu"],"lastUpdateTime":1386522744307,"label":"Performance Metrics"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Experience Strategy":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Experience Strategy"},"dance/movement":{"dislikes":[],"lastTimeUpdated":1386522102828,"checked":true,"likes":["ztoups@nmsu.edu","stuart@tropic.org.uk","aantle@sfu.ca","wendyju@stanford.edu"],"label":"dance/movement"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"User Interface Design"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"movement interaction":{"dislikes":[],"lastTimeUpdated":1386522765898,"checked":true,"likes":["aantle@sfu.ca","wendyju@stanford.edu"],"label":"movement interaction"},"Wearable technology":{"dislikes":[],"lastTimeUpdated":1386522169478,"checked":true,"likes":[],"label":"Wearable technology"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755977}},"creationTime":1223,"content":{"authorList":["Diego Silang Maranan, Simon Fraser University","Sarah Fdili Alaoui, Simon Fraser University","Thecla Schiphorst, Simon Fraser University, SFU","Philippe Pasquier, Simon Fraser University","Pattarawut Subyen, Simon Fraser University"],"title":"Desiging For Movement: Evaluating Computational Models using LMA Effort Qualities","paperOrNote":"Paper","fullAbstract":"While accelerometers have been used in movement recognition systems, acceleration data is rarely used to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a machine learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single-accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions.","shortAbstract":"While accelerometers have been used in movement recognition systems, a","id":"pn1579"},"session":"Art: Performance 2","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1579"},"pn455":{"lastUpdateTime":1389285684614,"subcommitteeSplit":"A","labels":{"End-user programming":{"checked":false,"lastUpdateTime":1386526699136,"dislikes":[],"label":"End-user programming","lastTimeUpdated":1386524986115,"likes":[]},"World Wide Web and Hypermedia":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527410042,"label":"World Wide Web and Hypermedia"},"Semantic Web":{"checked":false,"lastUpdateTime":1386526707892,"dislikes":[],"label":"Semantic Web","lastTimeUpdated":1386524892501,"likes":[]},"End-user Programming":{"checked":true,"dislikes":[],"likes":["haochuan@cs.nthu.edu.tw"],"lastUpdateTime":123456789,"label":"End-user Programming"},"Development Tools / Toolkits / Programming Environments":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526710289,"label":"Development Tools / Toolkits / Programming Environments"},"Web 2.0":{"dislikes":[],"lastTimeUpdated":1386526597105,"checked":true,"likes":["haochuan@cs.nthu.edu.tw"],"label":"Web 2.0"},"Information Architecture":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526706739,"label":"Information Architecture"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946642}},"creationTime":270,"content":{"authorList":["Edward Benson, MIT CSAIL","David Karger, MIT CSAIL"],"title":"End-Users Publishing Structured Information on the Web: An Observational Study of What, Why, and How","paperOrNote":"Paper","fullAbstract":"  End-users are accustomed to filtering and browsing styled collections of data \\   on professional web sites, but they have few ways to create and publish such \\   information architectures for themselves. This paper presents a \\   full-lifecycle analysis of the Exhibit framework---an end-user tool which \\   provides such functionality---to understand the needs, capabilities, and \\   practices of this class of users. We include interviews, as well as analysis \\   of over 1,800 visualizations and 200,000 web interactions with these \\   visualizations. Our analysis reveals important findings about this user \\   population which generalize to the task of providing better end-user \\   structured content publication tools. ","shortAbstract":"  End-users are accustomed to filtering and browsing styled collection","id":"pn455"},"session":"Web: Web","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn455"},"pn121":{"lastUpdateTime":1389285647205,"subcommitteeSplit":"C","labels":{"Persuasive Games":{"dislikes":[],"lastTimeUpdated":1386526913889,"checked":true,"likes":[],"label":"Persuasive Games"},"Entertainment":{"checked":true,"dislikes":[],"likes":["erinacarroll@gmail.com"],"lastUpdateTime":123456789,"label":"Entertainment"},"Social and Legal issues":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526844974,"label":"Social and Legal issues"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527155091,"label":"Universal (or Disability)  Access"},"Persuasive Design":{"checked":true,"lastUpdateTime":1386526922421,"dislikes":[],"label":"Persuasive Design","lastTimeUpdated":1386526351283,"likes":[]},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526828366,"label":"User Interface Design"},"games":{"dislikes":[],"lastTimeUpdated":1386526402381,"checked":true,"likes":["joanna@cs.ub.ca","awaller@computing.dundee.ac.uk","kash@diku.dk","erinacarroll@gmail.com"],"label":"games"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486623}},"creationTime":17,"content":{"authorList":["Kathrin Gerling, University of Saskatchewan","Regan Mandryk, University of Saskatchewan","Max Birk, University of Saskatchewan","Matthew Miller, University of Saskatchewan","Rita Orji, University of Saskatchewan"],"title":"The Effects of Embodied Persuasive Games in Player Attitudes Toward People with Disabilities","paperOrNote":"Paper","fullAbstract":"People with disabilities face barriers in their daily lives, many of which are created by people who surround them. Promoting positive attitudes towards persons with disabilities is an integral step in removing these barriers and improving their quality of life. In this context, persuasive games offer an opportunity of encouraging attitude change. We created a wheelchair-controlled persuasive game to study how embodied interaction can be applied to influence player attitudes over time. Our results show that the game intervention successfully raised awareness for challenges that people with disabilities face, and that embodied interaction is a more effective approach than traditional input in terms of retaining attitude change over time. Based on these findings, we provide design strategies for embodied interaction in persuasive games, and outline how our findings can be leveraged to help designers create effective persuasive experiences beyond games.","shortAbstract":"People with disabilities face barriers in their daily lives, many of w","id":"pn121"},"session":"Health: Persuade Me","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn121"},"pn122":{"lastUpdateTime":1389221181945,"subcommitteeSplit":"C","labels":{"Exergames":{"dislikes":[],"lastTimeUpdated":1386526242742,"checked":true,"likes":["karyn.moffatt@mcgill.ca","christopher.power@york.ac.uk","mtory@cs.uvic.ca"],"label":"Exergames"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527161310,"label":"Universal (or Disability)  Access"},"games":{"dislikes":[],"lastTimeUpdated":1386526250763,"checked":true,"likes":["awaller@computing.dundee.ac.uk"],"label":"games"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"rehabilitation":{"checked":false,"lastUpdateTime":1386527176221,"dislikes":[],"label":"rehabilitation","lastTimeUpdated":1386526287031,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486656}},"creationTime":18,"content":{"authorList":["Kathrin Gerling, University of Saskatchewan","Matthew Miller, University of Saskatchewan","Regan Mandryk, University of Saskatchewan","Max Birk, University of Saskatchewan","Jan Smeddinck, University of Saskatchewan"],"title":"Effects of Balancing  Exergames for Physical Abilities on Player Performance, Experience and Self-Esteem","paperOrNote":"Paper","fullAbstract":"Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how balancing approach affects performance, experience, and self-esteemespecially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.","shortAbstract":"Game balancing can help players with different skill levels play multi","id":"pn122"},"session":"Games: Exergame Design","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn122"},"pn906":{"lastUpdateTime":1389221887645,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["tjvg@di.fc.ul.pt","kgajos@eecs.harvard.edu"],"lastUpdateTime":1386527080654,"label":"Older Adults"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527378503,"label":"Empirical Methods, Quantitative"},"cognition":{"checked":false,"lastUpdateTime":1386527394875,"dislikes":[],"label":"cognition","lastTimeUpdated":1386527141258,"likes":[]},"Cross-cultural studies":{"dislikes":[],"lastTimeUpdated":1386527599321,"checked":true,"likes":[],"label":"Cross-cultural studies"},"Health Care":{"checked":false,"dislikes":[],"likes":["joanna@cs.ub.ca"],"lastUpdateTime":1386527601432,"label":"Health Care"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527548235,"label":"User Interface Design"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486651}},"creationTime":632,"content":{"authorList":["Shathel Haddad, University of British Columbia","Joanna McGrenere, University of Brisith Columbia","Claudia Jacova, University of British Columbia"],"title":"Interface Design for Older Adults with Varying Cultural Attitudes toward Uncertainty","paperOrNote":"Paper","fullAbstract":"This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a home-based computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task). By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it. We provide cultural design guidelines for older Western Caucasians and East Asians in interaction contexts characterized by uncertainty.","shortAbstract":"This work reports on the design and evaluation of culturally appropria","id":"pn906"},"session":"Health: Older Adults","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn906"},"pn905":{"lastUpdateTime":1389235997798,"subcommitteeSplit":"A","labels":{"social capital":{"dislikes":[],"lastTimeUpdated":1386524600317,"checked":true,"likes":[],"label":"social capital"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"Sustainability":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Sustainability"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524575173,"label":"Computer-Mediated Communication"},"low income":{"dislikes":[],"lastTimeUpdated":1386524594016,"checked":true,"likes":["lorrie@acm.org","Brumby@cs.ucl.ac.uk","haochuan@cs.nthu.edu.tw","sameer.patil@hiit.fi"],"label":"low income"},"Social Capitalism":{"dislikes":[],"lastTimeUpdated":1386525859079,"checked":true,"likes":[],"label":"Social Capitalism"},"ICTD":{"dislikes":[],"lastTimeUpdated":1386531644983,"checked":true,"likes":[],"label":"ICTD"},"HCI and finance":{"checked":false,"lastUpdateTime":1386525809575,"dislikes":[],"label":"HCI and finance","lastTimeUpdated":1386524928609,"likes":["Brumby@cs.ucl.ac.uk"]},"ICT":{"checked":false,"lastUpdateTime":1386531646568,"dislikes":[],"label":"ICT","lastTimeUpdated":1386524607771,"likes":[]},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946640}},"creationTime":631,"content":{"authorList":["Tawanna Dillahunt, University of Michigan"],"title":"Fostering Social Capital in Economically Distressed Communities","paperOrNote":"Paper","fullAbstract":"Past Information and Communication Technology (ICT) literature suggests that engaging in meaningful activities with ICTs may be related to socio-economic security, social inclusion, empowerment, and increased social capital. However, research suggests that those already high in social capital are most likely to reap these benefits. We conduct a preliminary study to explore how individuals in a economically distressed population with limited social capital use technologies to increase social capital and to achieve socio-economic security. We identify challenges for ICTs designed to build social capital and provide context for issues such as distrust within communities and limited access to bridging ties. We shed light on how ICTs can assist populations that could benefit the most from increased social capital and economic security.","shortAbstract":"Past Information and Communication Technology (ICT) literature suggest","id":"pn905"},"session":"HCI4D: CHI for Social Development","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn905"},"pn1199":{"lastUpdateTime":1389285431303,"subcommitteeSplit":"B","labels":{"Tactile and Haptic UIs":{"dislikes":[],"lastTimeUpdated":1386522076979,"checked":true,"likes":[],"label":"Tactile and Haptic UIs"},"Remote Interaction":{"dislikes":[],"lastTimeUpdated":1386522348070,"checked":true,"likes":[],"label":"Remote Interaction"},"Human-robot interaction":{"checked":false,"lastUpdateTime":1386522837057,"dislikes":[],"label":"Human-robot interaction","lastTimeUpdated":1386522782968,"likes":[]},"Robots":{"checked":false,"lastUpdateTime":1386522834711,"dislikes":[],"label":"Robots","lastTimeUpdated":1386522357033,"likes":[]},"telepresence":{"dislikes":[],"lastTimeUpdated":1386532024720,"checked":true,"likes":[],"label":"telepresence"},"Telepresence":{"checked":false,"lastUpdateTime":1386532027073,"dislikes":[],"label":"Telepresence","lastTimeUpdated":1386522319884,"likes":[]},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"HRI":{"checked":false,"lastUpdateTime":1386522835843,"dislikes":[],"label":"HRI","lastTimeUpdated":1386522776197,"likes":[]},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755972}},"creationTime":886,"content":{"authorList":["Hideyuki Nakanishi, Osaka University","Kazuaki Tanaka, Osaka University","Yuya Wada, Osaka University"],"title":"Remote Handshaking: Touch Enhances Video-Mediated Social Telepresence","paperOrNote":"Paper","fullAbstract":"Since past studies on haptic and non-haptic communication have tended to be isolated from each other, it has remained unclear whether a touch channel can still enrich mediated communication where video and audio channels are already available. To clarify this, we analyzed remote handshaking in which a robot hand that was attached just under a videoconferencing terminals display moved according to the opening and closing motion of a conversation partners hand. Combining touch and video channels raises a question as to whether the partners action of touching a haptic device should be remotely visible. If it can be invisible, the action may be unnecessary, and a unilaterally controlled device may be enough to establish an effective touch channel. Our analysis revealed significant effects of adding touch to videoconferencing and also the superiority of mutual touch in which the partners action needs to occur but should be invisible.","shortAbstract":"Since past studies on haptic and non-haptic communication have tended ","id":"pn1199"},"session":"Social: Connecting over Video","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1199"},"pn1190":{"lastUpdateTime":1389236125639,"subcommitteeSplit":"B","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755943}},"creationTime":877,"content":{"authorList":["Joohee Park, KAIST","Young-Woo Park, KAIST","Tek-Jin Nam, KAIST"],"title":"Wrigglo: Shape-Changing Peripheral for Interpersonal Mobile Communication","paperOrNote":"Note","fullAbstract":"In this paper, we introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of users to share wriggling movements with one another. Attached to a smart phone, Wrigglo captures the senders motions and activates the receivers Wrigglo which repeats the motion simultaneously. The result of our in-lab use observation with twelve couples showed that Wrigglo supported emotional and functional roles of body gestures and postures, creating vocabularies related to the motion of specific body parts and, to some extent, reflected the connected users presence through the devices movement. We conclude by discussing implications to improve Wrigglo as a future shape-changing mobile peripheral.","shortAbstract":"In this paper, we introduce Wrigglo, a shape-changing smart phone peri","id":"pn1190"},"session":"Social: Computer Mediated Romance","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1190"},"pn1193":{"lastUpdateTime":1389590776110,"subcommitteeSplit":"","labels":{"spatial audio":{"dislikes":[],"lastTimeUpdated":1386525732172,"checked":true,"likes":[],"label":"spatial audio"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Empirical Methods, Quantitative":{"dislikes":[],"lastTimeUpdated":1386525719882,"checked":true,"likes":[],"label":"Empirical Methods, Quantitative"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["benko@microsoft.com","bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Audio AR":{"dislikes":[],"lastTimeUpdated":1386525229523,"checked":true,"likes":[],"label":"Audio AR"},"spatial sound":{"dislikes":[],"lastTimeUpdated":1386525472040,"checked":true,"likes":[],"label":"spatial sound"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644752}},"creationTime":880,"content":{"authorList":["Georgios Marentakis, Institute for Electronic Music and Acoustics","Rudolf Liepins, Kunstuniversitt Graz"],"title":"Evaluation of Hear-Through Sound Localization","paperOrNote":"Note","fullAbstract":"Listening to audio with contemporary systems relies heavily on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present a perceptual study where we evaluate sound localization when using such a hear-through system in comparison to unblocked ears, normal earphones, and  open headphones. Although in comparison to open headphones localization performance using the hear-through system is improved, we find that it is also compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. Possible improvements to hear-through system design are discussed.","shortAbstract":"Listening to audio with contemporary systems relies heavily on using e","id":"pn1193"},"session":"UBI: Audio Interaction","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1193"},"pn1192":{"lastUpdateTime":1389284843631,"subcommitteeSplit":"B","labels":{"Home":{"checked":true,"dislikes":[],"likes":["rcm@mit.edu","rob.comber@ncl.ac.uk","jonfroehlich@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"sustainability_and_everyday_practice":{"dislikes":[],"lastTimeUpdated":1386522369088,"checked":true,"likes":["hazas@comp.lancs.ac.uk","rob.comber@ncl.ac.uk"],"label":"sustainability_and_everyday_practice"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Sustainability":{"checked":true,"dislikes":[],"likes":["rcm@mit.edu","rob.comber@ncl.ac.uk","jonfroehlich@gmail.com","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Sustainability"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446271},"Smart Home":{"label":"Smart Home","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1388762489715}},"creationTime":879,"content":{"authorList":["Enrico Costanza, University of Southampton","Joel Fischer, The University of Nottingham","James Colley, University of Nottingham","Tom Rodden, University of Nottingham","Sarvapali Ramchurn, University of Southampton","Nicholas Jennings, University of Southampton"],"title":"Doing the Laundry with Agents: a Field Trial of a Future Smart Energy System in the Home","paperOrNote":"Paper","fullAbstract":"Future energy systems that rely on renewable energy may bring about a radical shift in how we use energy in our homes. We developed a future scenario with highly variable, real-time electricity prices due to a grid that mainly relies on renewables. We designed and deployed a smart home energy system, built around an autonomous agent, that enables users to effectively use the washing machine in this scenario. An interactive system is used to book timeslots of washing machine use so that the agent can minimise cost by charging a battery at times when electricity is cheap. In order to uncover the socio-technical challenges around integrating new technologies into everyday routines we carried out a deployment in 10 households. The findings show various ways in which our scenario and system influenced existing everyday routines of planning and doing laundry. Participants orientation and reasoning suggests that system agency is largely invisible. We discuss implications for integrating mixed-initiative interaction for future smart energy systems, such as configuration, visibility and control into the context of peoples everyday routines.","shortAbstract":"Future energy systems that rely on renewable energy may bring about a ","id":"pn1192"},"session":"UBI: Smart Homes","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1192"},"pn639":{"lastUpdateTime":1388766320872,"subcommitteeSplit":"","labels":{"Office and Workplace":{"checked":true,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["elaw@mcs.le.ac.uk","marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Emotion and Affective User Interface":{"dislikes":[],"lastTimeUpdated":1386528270334,"checked":true,"likes":["wmoncur@dundee.ac.uk"],"label":"Emotion and Affective User Interface"},"Health Care":{"checked":true,"dislikes":[],"likes":["david.geerts@soc.kuleuven.be","wmoncur@dundee.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Health Care"},"Human error":{"dislikes":[],"lastTimeUpdated":1386528310446,"checked":true,"likes":[],"label":"Human error"},"emotion and user performance":{"dislikes":[],"lastTimeUpdated":1386527688292,"checked":true,"likes":[],"label":"emotion and user performance"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165063}},"creationTime":408,"content":{"authorList":["Paul Cairns, University of York","Pratyush Pandab, University of York","Christopher Power, University of York"],"title":"The Influence of Emotion on Number Entry Errors","paperOrNote":"Note","fullAbstract":"Given the proliferation of devices like infusion pumps in hospitals, number entry and in particular number entry error is an emerging important concern in HCI. There are clearly design features that could greatly improve accuracy in entering numbers but the context of the task could also play an important role. In particular, the emotional state of a person is known to strongly influence their response to a difficult situation and hence the errors that they make. In this paper, we consider the impact of the emotional state of the user on the accuracy with which people enter numbers. Our experiment shows that participants who are in a more positive emotional state are more accurate. The effect is small but could be very important when considering the potentially highly-charged emotional contexts where many healthcare devices are used. \\ ","shortAbstract":"Given the proliferation of devices like infusion pumps in hospitals, n","id":"pn639"},"session":"Health: Health and Everyday Life","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn639"},"pn1354":{"lastUpdateTime":1389285590040,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523468095,"label":"E-Learning and Education"},"Play":{"dislikes":[],"lastTimeUpdated":1386523421567,"checked":true,"likes":[],"label":"Play"},"young children":{"dislikes":[],"lastTimeUpdated":1386523060820,"checked":true,"likes":[],"label":"young children"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386523082760,"label":"Agents and Intelligent Systems"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523380685,"label":"User Studies"},"Children":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Children"},"Literacy":{"dislikes":[],"lastTimeUpdated":1386523338820,"checked":true,"likes":["lana@research.att.com"],"label":"Literacy"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188196}},"creationTime":1021,"content":{"authorList":["Anuj Tewari, UC Berkeley","John Canny, UC Berkeley"],"title":"What Did Spot Hide?: A Question-Answering Game For Preschool Children","paperOrNote":"Paper","fullAbstract":"The preschool literacy gap is one of the most difficult challenges for education in the US. Children in the lowest SES (Socio-Economic Status) quartile have less than half the working vocabulary of those in the top quartile at age 3. On the other hand, preschool children are incessantly inquisitive, and will readily engage in question answering and asking activities if given the opportunity. We argue here that question asking/answering technologies can play a major role in early literacy. We describe the design and evaluation of a conversational agent called Spot, with the goal of engaging children in a 20-questions game. Towards this goal, we conducted a feasibility study to determine if childrens questions are on-topic and suitable for ASR/dialogue systems. We evaluated Spots performance at conducting a game of 20-questions against that of a human partner.","shortAbstract":"The preschool literacy gap is one of the most difficult challeng","id":"pn1354"},"session":"HCI4D: Multilingual Communication","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1354"},"pn1351":{"lastUpdateTime":1389592113076,"subcommitteeSplit":"A","labels":{"interruption":{"dislikes":[],"lastTimeUpdated":1386524272904,"checked":true,"likes":[],"label":"interruption"},"productivity":{"dislikes":[],"lastTimeUpdated":1386524276928,"checked":true,"likes":[],"label":"productivity"},"workflow":{"dislikes":[],"lastTimeUpdated":1386524285910,"checked":true,"likes":[],"label":"workflow"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524590623,"label":"Empirical Methods, Quantitative"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["mark.hancock@uwaterloo.ca"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Computer Supported Collaborative Boredom":{"dislikes":[],"lastTimeUpdated":1386525767679,"checked":true,"likes":[],"label":"Computer Supported Collaborative Boredom"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":["mark.hancock@uwaterloo.ca"],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"I'm bored/board":{"dislikes":[],"lastTimeUpdated":1386525739406,"checked":true,"likes":[],"label":"I'm bored/board"},"Personal Informatics":{"dislikes":[],"lastTimeUpdated":1386524607596,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"Personal Informatics"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946656}},"creationTime":1019,"content":{"authorList":["Gloria Mark, University of California, Irvine","Shamsi Iqbal, Microsoft Research","Mary Czerwinski, Microsoft Research","Paul Johns, Microsoft Research"],"title":"Bored Tuesdays and Focused Afternoons: The Rhythm of Attention and Online Activity in the Workplace","paperOrNote":"Paper","fullAbstract":"While distractions due to digital media have received attention in HCI, we examine instead focused attention in the workplace. We logged digital activity and continually probed perspectives of 32 information workers for five days in situ to understand how attentional states change with context. We present a framework of how engagement and challenge in work relate to focus, bored, and rote work. Overall, we find more focused attention than boredom in the workplace. Reported focus peaks mid-afternoon while boredom is highest in the morning. People are happiest doing rote work; we show that focused work can involve stress. We identified higher levels of boredom mid-week. Online activities are associated with different attentional states, showing different patterns at beginning and end of day, and before and after a mid-day break. Our study shows how rhythms of attentional states are associated with context and time, even in a dynamic workplace environment.","shortAbstract":"While distractions due to digital media have received attention in HCI","id":"pn1351"},"session":"CSCW: Interruptions and Distractions","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1351"},"pn838":{"lastUpdateTime":1389591213496,"subcommitteeSplit":"A","labels":{"Design Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Planning"},"sustainability_and_everyday_practice":{"checked":false,"lastUpdateTime":1386524877746,"dislikes":[],"label":"sustainability_and_everyday_practice","lastTimeUpdated":1386524874449,"likes":[]},"theories for HCI":{"dislikes":[],"lastTimeUpdated":1386524958923,"checked":true,"likes":[],"label":"theories for HCI"},"new directions for hci":{"dislikes":[],"lastTimeUpdated":1386525646731,"checked":true,"likes":[],"label":"new directions for hci"},"The Road Ahead":{"dislikes":[],"lastTimeUpdated":1386525979112,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Road Ahead"},"Ethnography":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525050035,"label":"Ethnography"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525614466,"label":"User Studies"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946704}},"creationTime":570,"content":{"authorList":["Kari Kuutti, University of Oulu"],"title":"Identifying the Emerging Practice Focus of HCI research","paperOrNote":"Paper","fullAbstract":"The paper suggests that several issues related to recent turbulence of HCI research field can be interpreted as indicators of the emergence of a novel research focus, practice as it is understood in social sciences. The practice orientation has been present in HCI already quite long, but only in fringes and special subcommunities, while now it is becoming more central. There has been a somewhat similar practice turn going on in social sciences already two decades, but the this connection has not been recognized in HCI, because the rise of practice orientation in HCI has not been a conscious and reflective movement but a tacit and spontaneous one. The paper suggests that it would be beneficial to use the more mature discussion in social sciences as a reference point for HCI.  HCI has also develop its own practice approach because of the weakness of practice research in social sciences to deal with emergent practices, which are centrally important for HCI. ","shortAbstract":"The paper suggests that several issues related to recent turbulence of","id":"pn838"},"session":"Methods and Models: new HCI paradigms","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn838"},"pn2128":{"lastUpdateTime":1389286027763,"subcommitteeSplit":"B","labels":{"search":{"dislikes":[],"lastTimeUpdated":1386522245824,"checked":true,"likes":["dr.mark.j.perry@googlemail.com","m.rouncefield@lancaster.ac.uk","l.ciolfi@shu.ac.uk"],"label":"search"},"User Studies":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":123456789,"label":"User Studies"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032698}},"creationTime":1692,"content":{"authorList":["Catherine Marshall, Microsoft Research","Sin Lindley, Microsoft Research"],"title":"Well, Im Competing with a Curry, Basically: Motivations and Strategies for Self-Search","paperOrNote":"Paper","fullAbstract":"We present findings from a qualitative study of self-search, also known as ego or vanity search. Participants were asked to search for themselves in the context of a broader study about personal online content, on their own computers and using the browsers and queries they would normally adopt. Our analysis leads us to present five motivations for self-search: as a form of identity management; as a way to discover reactions to and re-use of user-generated media; as a means of re-finding; as a form of entertainment; and as an activity that could reveal genuinely lost or forgotten content. Strategies differ according to motivation, and can also differ markedly from typical information-seeking strategies, with users looking deep into the results and using image search to highlight content about themselves. We argue that two dimensions underpin ways of improving self-search: controllability and expectedness, and discuss what these dimensions imply for design.","shortAbstract":"We present findings from a qualitative study of self-search, also know","id":"pn2128"},"session":"Systems: Desktop Search and History","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2128"},"pn1978":{"lastUpdateTime":1389235997798,"subcommitteeSplit":"B","labels":{"ICT4D":{"checked":false,"lastUpdateTime":1386531688527,"dislikes":[],"label":"ICT4D","lastTimeUpdated":1386523003682,"likes":["dr.mark.j.perry@googlemail.com"]},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"ITCD":{"checked":false,"lastUpdateTime":1386531671341,"dislikes":[],"label":"ITCD","lastTimeUpdated":1386531664277,"likes":[]},"ICTD":{"dislikes":[],"lastTimeUpdated":1386531682628,"checked":true,"likes":["hq@northwestern.edu"],"label":"ICTD"},"hci4d":{"checked":false,"lastUpdateTime":1386523017216,"dislikes":[],"label":"hci4d","lastTimeUpdated":1386522253691,"likes":[]},"heritage":{"dislikes":[],"lastTimeUpdated":1386522243019,"checked":true,"likes":[],"label":"heritage"},"communities":{"dislikes":[],"lastTimeUpdated":1386524564920,"checked":true,"likes":[],"label":"communities"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032768}},"creationTime":1561,"content":{"authorList":["Mara Balestrini, University College London","Jon Bird, University College London","Paul Marshall, University College London","Alberto Zaro, Proyecto Intemperie","Yvonne Rogers, University College London"],"title":"Understanding Sustained Community Engagement: A Case Study in Heritage Preservation in Rural Argentina","paperOrNote":"Paper","fullAbstract":"HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by a wide range of stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy. We analyse why CrowdMemo was successful and provide five recommendations for facilitating sustained community engagement.","shortAbstract":"HCI projects are increasingly evaluating technologies in the wild, whi","id":"pn1978"},"session":"HCI4D: CHI for Social Development","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1978"},"pn1009":{"lastUpdateTime":1388765615245,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522090354,"label":"Empirical Methods, Quantitative"},"aggregating social network data":{"dislikes":[],"lastTimeUpdated":1386522458789,"checked":true,"likes":["smunson@uw.edu"],"label":"aggregating social network data"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523523620,"label":"Social Computing and Social Navigation"},"Health Care":{"checked":true,"dislikes":[],"likes":["gabriela.avram@gmail.com","jacovi@il.ibm.com","teevan@gmail.com"],"lastUpdateTime":123456789,"label":"Health Care"},"Social Network Sites":{"dislikes":[],"lastTimeUpdated":1386522318553,"checked":true,"likes":[],"label":"Social Network Sites"},"Twitter":{"dislikes":[],"lastTimeUpdated":1386522619291,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"Twitter"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522087153,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556757}},"creationTime":722,"content":{"authorList":["Aron Culotta, Illinois Institute of Technology"],"title":"Estimating County Health Statistics with Twitter","paperOrNote":"Paper","fullAbstract":"Understanding the relationships among environment, behavior, and health is a \\ core concern of public health researchers. While a number of recent studies \\ have investigated the use of social media to track infectious diseases such as \\ influenza, little work has been done to determine if other health concerns can \\ be inferred. In this paper, we present a large-scale study of 27 \\ health-related statistics, including obesity, health insurance coverage, \\ access to healthy foods, and teen birth rates. We perform a linguistic \\ analysis of the Twitter activity in the top 100 most populous counties in the \\ U.S., and find a significant correlation with 9 of the 27 health \\ statistics. When compared to traditional models based on demographic \\ variables alone, we find that augmenting models with Twitter-derived \\ information improves predictive accuracy for 20 of 27 statistics, suggesting \\ that this new methodology can complement existing approaches.","shortAbstract":"Understanding the relationships among environment, behavior, and healt","id":"pn1009"},"session":"Health: Social Media and Health","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1009"},"pn1976":{"lastUpdateTime":1389238893968,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Experience Strategy":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Experience Strategy"},"Authentication":{"checked":false,"lastUpdateTime":1386521761602,"dislikes":[],"label":"Authentication","lastTimeUpdated":1386521712298,"likes":[]},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386521996829,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"CAPTCHAs":{"dislikes":[],"lastTimeUpdated":1386521652050,"checked":true,"likes":[],"label":"CAPTCHAs"},"Security":{"checked":true,"dislikes":[],"likes":["ajbrush@microsoft.com","egelman@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de","rob.comber@ncl.ac.uk","a.sasse@cs.ucl.ac.uk","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Security"},"User Studies":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446282}},"creationTime":1559,"content":{"authorList":["Elie Bursztein, Google, Inc.","Angelique Moscicki, Google, Inc.","Celine Fabry, Stanford University","Steven Bethard, Stanford University","John C. Mitchell, Stanford University","Dan Jurafsky, Stanford University"],"title":"Easy Does It:  More Usable CAPTCHAs","paperOrNote":"Paper","fullAbstract":"Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. \\  \\ In this paper we describe how we designed two new CAPTCHA schemes for <anonymized> that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the usability of different feature combinations. Then we studied user preferences using Googles consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes rst on Mechanical Turk and then on a fraction of production trafc. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7% improvement.","shortAbstract":"Websites present users with puzzles called CAPTCHAs to curb abuse caus","id":"pn1976"},"session":"Security: Security","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1976"},"pn169":{"lastUpdateTime":1389236520278,"subcommitteeSplit":"B","labels":{"Value-Sensitive Design":{"dislikes":[],"lastTimeUpdated":1386521847099,"checked":true,"likes":[],"label":"Value-Sensitive Design"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"E-Government":{"dislikes":[],"lastTimeUpdated":1386522791225,"checked":true,"likes":[],"label":"E-Government"},"E-Governmentt":{"checked":false,"lastUpdateTime":1386522774012,"dislikes":[],"label":"E-Governmentt","lastTimeUpdated":1386522507517,"likes":[]},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446250}},"creationTime":49,"content":{"authorList":["Amy Voida, Indiana University, Indianapolis (IUPUI)","Lynn Dombrowski, University of California, Irvine","Gillian Hayes, University of California, Irvine","Melissa Mazmanian, University of California, Irvine"],"title":"Shared Values/Conflicting Logics: Working Around E-Government Systems","paperOrNote":"Paper","fullAbstract":"In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that resultnot from different stakeholders with different valuesbut from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared valuesefficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the pubic that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.","shortAbstract":"In this paper, we describe results from fieldwork conducted at a socia","id":"pn169"},"session":"HCI4D: doing the right thing - ethics","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn169"},"pn2472":{"lastUpdateTime":1389221135554,"subcommitteeSplit":"","labels":{"E-Learning and Education":{"dislikes":[],"lastTimeUpdated":1386527691544,"checked":true,"likes":["judy.kay@gmail.com"],"label":"E-Learning and Education"},"gamification":{"dislikes":[],"lastTimeUpdated":1386527165278,"checked":true,"likes":["e.karapanos@gmail.com","judy.kay@gmail.com"],"label":"gamification"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"technology-enhanced learning":{"dislikes":[],"lastTimeUpdated":1386527214148,"checked":true,"likes":[],"label":"technology-enhanced learning"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165023}},"creationTime":1983,"content":{"authorList":["Wei Li, Autodesk Research","Tovi Grossman, Autodesk Research","George Fitzmaurice, Autodesk Research"],"title":"CADament: A Gamified Multiplayer Software Tutorial System","paperOrNote":"Paper","fullAbstract":"We present CADament, a gamified multiplayer tutorial system for learning AutoCAD. Compared with existing gamified software tutorial systems, CADament generates engaging learning experience through competitions. We investigated two variations of our game, where over-the-shoulder learning was simulated by providing viewports into other players screens. We propose a novel lab study methodology where participants compete with one another, and we study learning transfer effects by tracking the migration of strategies between players during the study session. .Our study shows that CADament has an advantage over pre-authored tutorials for improving learners performance, increasing motivation, and stimulating knowledge transfer. ","shortAbstract":"We present CADament, a gamified multiplayer tutorial system for learni","id":"pn2472"},"session":"Games: Education Games","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2472"},"pn532":{"lastUpdateTime":1389285431303,"subcommitteeSplit":"B","labels":{"telepresence":{"dislikes":[],"lastTimeUpdated":1386523096388,"checked":true,"likes":[],"label":"telepresence"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523208819,"label":"Computer Supported Cooperative Work (CSCW)"},"Video Content / Communications":{"checked":false,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com"],"lastUpdateTime":1386523207117,"label":"Video Content / Communications"},"Robots":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Robots"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032742}},"creationTime":323,"content":{"authorList":["Irene Rae, University of Wisconsin, Madison","Bilge Mutlu, University of Wisconsin, Madison","Leila Takayama, Willow Garage"],"title":"Bodies in Motion: Mobility, Presence, and Task Awareness in Telepresence","paperOrNote":"Paper","fullAbstract":"Robotic telepresence systems, videoconferencing systems that allow a remote user to drive around in another location, have expanded the design space for supporting videomediated communications. These systems, which are seeing increasing use in business and medical settings, are unique in their ability to grant the remote user mobility in a physical environment. While this mobility promises increased feelings of \"being there\" for remote users and thus greater support for task collaboration, whether these promises are borne out and whether they provide benefits in task performance is unknown. To better understand the role that mobility plays in shaping the remote users sense of presence and its potential benefits, we conducted a two-by-two (mobility: non-mobile vs. mobile; task demands for mobility: low vs. high) controlled laboratory experiment. We had participants (N = 40) collaborate in a construction task with a confederate via a robotic telepresence system. Our results showed that mobility significantly increased the remote users feelings of presence, particularly in tasks with high mobility requirements, but decreased task performance. Our findings highlight the positive effects of mobility on feelings of \"being there,\" while illustrating the need to design support for effective use of mobility in tasks with high mobility requirements. \\ ","shortAbstract":"Robotic telepresence systems, videoconferencing systems that allow a r","id":"pn532"},"session":"Social: Connecting over Video","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn532"},"pn1750":{"lastUpdateTime":1389221135554,"subcommitteeSplit":"B","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Large-Scale User Studies":{"dislikes":[],"lastTimeUpdated":1386522517225,"checked":true,"likes":[],"label":"Large-Scale User Studies"},"games":{"dislikes":[],"lastTimeUpdated":1386522311748,"checked":true,"likes":["ztoups@nmsu.edu","wendyju@stanford.edu"],"label":"games"},"User Studies":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca","ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"Children":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca","ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Children"},"Transport":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Transport"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755939}},"creationTime":1363,"content":{"authorList":["Ian Dunwell, Coventry University","Panagiotis Petridis, Coventry University","Sylvester Arnab, Coventry University","Sara de Freitas, Coventry University","Petros Lameras, Coventry University","Craig Stewart, Coventry University","Maurice Hendrix, Coventry University"],"title":"A Game-Based Learning Approach to Road Safety: The Code of Everand","paperOrNote":"Paper","fullAbstract":"Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028),  and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=31). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content, though must be coupled with a pedagogical design capable of capitalizing on this contact time though a game-based medium.","shortAbstract":"Game and gamification elements are increasingly seeing use as part of ","id":"pn1750"},"session":"Games: Education Games","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1750"},"pn1756":{"lastUpdateTime":1389221950963,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tangible UIs"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032789}},"creationTime":1368,"content":{"authorList":["Ayman Alzayat, University of Waterloo","Mark Hancock, University of Waterloo","Miguel Nacenta, University of St Andrews"],"title":"Quantitative Measurement of Virtual vs. Physical Object Embodiment through Kinesthetic Figural After Effects","paperOrNote":"Paper","fullAbstract":"Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of the natural, physical-like interactions they support. We present a pair of studies that empirically investigates the psychophysiological effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of figural after effectsa change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence that suggests a psychophysiological difference in our response to physical and virtual objects, and discuss a future research direction that explores measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.","shortAbstract":"Over the past decade, multi-touch surfaces have become commonplace, wi","id":"pn1756"},"session":"UIST: On the surface","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1756"},"pn1758":{"lastUpdateTime":1388776604979,"subcommitteeSplit":"A","labels":{"Stereoscopic 3D (S3D)":{"dislikes":[],"lastTimeUpdated":1386523321394,"checked":true,"likes":["lennart.nacke@uoit.ca"],"label":"Stereoscopic 3D (S3D)"},"Stereoscopic":{"checked":false,"lastUpdateTime":1386523828857,"dislikes":[],"label":"Stereoscopic","lastTimeUpdated":1386522962889,"likes":["joonhwan@snu.ac.kr","lennart.nacke@uoit.ca"]},"Game User Research":{"checked":false,"lastUpdateTime":1386523305292,"dislikes":[],"label":"Game User Research","lastTimeUpdated":1386523229815,"likes":[]},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"game":{"checked":true,"lastUpdateTime":1386531475784,"dislikes":[],"label":"game","lastTimeUpdated":1386523311150,"likes":["lennart.nacke@uoit.ca"]},"games":{"dislikes":[],"lastTimeUpdated":1386531472340,"checked":true,"likes":[],"label":"games"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711798}},"creationTime":1370,"content":{"authorList":["Jonas Schild, University of Duisburg-Essen","Joseph LaViola, University of Central Florida","Maic Masuch, University of Duisburg-Essen"],"title":"Altering Gameplay Behavior using Stereoscopic 3D Vision-Based Video Game Design","paperOrNote":"Paper","fullAbstract":"We explore the benefits of and player behavior in stereoscopic 3D (S3D) gaming using Deepress3D, a video game specifically designed for S3D viewing. Based on established S3D game design principles, the game offers multiple viewing perspectives and provides visual comfort through static perspectives and individual parallaxes. The game mechanics rely on depth perception in time-pressured spatial conflicts and allow for different, evenly matched player strategies. \\  \\ Our between subjects user study compared stereoscopic versus monoscopic gameplay.  Besides user-reported data on presence, simulator sickness, and game experience, Deepress3D collected performance and behavioral data. Confirming previous results, the stereo group reported a higher spatial presence. For the first time, our game metrics indicate that S3D vision can measurably change player behavior depending on actual game content and level design, without necessarily affecting performance or emotional experience. These findings indicate the potential of addressing stereo players as distinguished category in game balancing.","shortAbstract":"We explore the benefits of and player behavior in stereoscopic 3D (S3D","id":"pn1758"},"session":"3D: The third dimension","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1758"},"pn1992":{"lastUpdateTime":1389221625522,"subcommitteeSplit":"","labels":{"Content Strategy / Content Creation":{"dislikes":[],"lastTimeUpdated":1386525600163,"checked":true,"likes":[],"label":"Content Strategy / Content Creation"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["elm@purdue.edu"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Sketching":{"dislikes":[],"lastTimeUpdated":1386525789393,"checked":true,"likes":[],"label":"Sketching"},"Creativity Support Tools":{"dislikes":[],"lastTimeUpdated":1386525726937,"checked":true,"likes":[],"label":"Creativity Support Tools"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644759}},"creationTime":1572,"content":{"authorList":["William Benjamin, Purdue University","Senthil Chandrasegaran, Purdue University","Devarajan Ramanujan, Purdue University","Niklas Elmqvist, Purdue University","SVN Vishwanathan, Purdue University","Karthik Ramani, Purdue University"],"title":"Juxtapoze: Supporting Serendipity and Creative Expression in Clipart Compositions","paperOrNote":"Paper","fullAbstract":"Juxtapoze is a clipart composition workflow that supports \\   creative expression and serendipitous discoveries in the shape \\   domain. \\   We achieve creative expression by supporting a workflow of \\   searching, editing, and composing: \\   the user queries the shape database using strokes, selects the \\   desired search result, and finally modifies the selected image \\   before composing it into the overall drawing. \\   Serendipitous discovery of shapes is facilitated by allowing \\   multiple exploration channels, such as doodles, shape filtering, and \\   relaxed search. \\   Results from a qualitative evaluation show that Juxtapoze  makes \\   the process of creating image compositions enjoyable and supports \\   creative expression and serendipity.","shortAbstract":"Juxtapoze is a clipart composition workflow that supports \\   creative","id":"pn1992"},"session":"Art: Image and Animation Authoring","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1992"},"pn2266":{"lastUpdateTime":1389238200057,"subcommitteeSplit":"","labels":{"Economics & HCI":{"dislikes":[],"lastTimeUpdated":1386531529846,"checked":true,"likes":[],"label":"Economics & HCI"},"Handheld Devices and Mobile Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531576782,"label":"Handheld Devices and Mobile Computing"},"Organizational Culture / Organizational Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Organizational Culture / Organizational Planning"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Business Strategy":{"dislikes":[],"lastTimeUpdated":1386531555901,"checked":true,"likes":[],"label":"Business Strategy"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"availability":{"dislikes":[],"lastTimeUpdated":1386531516677,"checked":true,"likes":[],"label":"availability"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["eve.hoggan@hiit.fi","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840626}},"creationTime":1813,"content":{"authorList":["Melissa Mazmanian, Department of Informatics, UC Irvine","Ingrid Erickson, Rutgers University"],"title":"The Product of Availability: Understanding the Economic Underpinnings of Constant Connectivity","paperOrNote":"Paper","fullAbstract":"Constant connectivity and accessibility to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability is possible and presumed. Scholars have explored how new technological capacities, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. Current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm. In this paper we use qualitative data to illustrate how total availability is an integral aspect of the product offered by elite professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge and offer two conceptual provocations. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes","shortAbstract":"Constant connectivity and accessibility to clients is the rule rather ","id":"pn2266"},"session":"People: constant connectivity","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2266"},"pn1503":{"lastUpdateTime":1389285480381,"subcommitteeSplit":"A","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386524111261,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Crowd-Powered Systems"},"Crowd-sourcing actions":{"checked":false,"lastUpdateTime":1386524133040,"dislikes":[],"label":"Crowd-sourcing actions","lastTimeUpdated":1386523795327,"likes":[]},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081835},"was Viz Vis Aesthetics":{"label":"was Viz Vis Aesthetics","checked":false,"likes":[],"dislikes":[],"lastTimeUpdated":1389107377638,"lastUpdateTime":1389107381316},"was Vis Vis Sys design":{"label":"was Vis Vis Sys design","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389107397371}},"creationTime":1159,"content":{"authorList":["Nicholas Kong, University of California, Berkeley","Marti Hearst, University of California Berkeley","Maneesh Agrawala, University of California, Berkeley"],"title":"Extracting References Between Text and Charts via Crowdsourcing","paperOrNote":"Paper","fullAbstract":"News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. Yet, connecting the text with the corresponding parts of a chart can be challenging. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply our clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.38; an improvement of 29%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.","shortAbstract":"News articles, reports, blog posts and academic papers often include g","id":"pn1503"},"session":"CSCW: Crowds and Creativity","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1503"},"pn2084":{"lastUpdateTime":1389221083200,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532249433,"label":"Empirical Methods, Quantitative"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com","marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386532238829,"label":"User Studies"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386527116236,"checked":true,"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"],"label":"Handheld Devices and Mobile Computing"},"Entertainment":{"checked":true,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165009}},"creationTime":1652,"content":{"authorList":["Paul Cairns, University of York","Jing Li, University of York","Wendy Wang, University of York","A. Imran Nordin, University of York"],"title":"The influence of controllers on immersion in mobile games","paperOrNote":"Paper","fullAbstract":"The controls for digital games understandably have an important part in building up the gaming experiences that people have. Whilst there is substantial work on innovative controllers for consoles, like the XBox Kinect, relatively little has been done to understand the effect of the different control mechanisms that can be used to play games on mobile devices like smartphones. This paper reports two experiments that look at the influence of the game controls on the experience of immersion in mobile games. We use a framework of natural mappings of game controllers as a way to structure the studies. It seems that where there is an a prior natural mapping, this will improve immersion in the game but in the absence of a prior mapping, naturalness alone is not sufficient to account for immersion. This opens up the need for a more thorough investigation of this area.","shortAbstract":"The controls for digital games understandably have an important part i","id":"pn2084"},"session":"Games: Fun N Play","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2084"},"pn337":{"lastUpdateTime":1389107727609,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525163982,"label":"Visualization"},"Time-series Data":{"dislikes":[],"lastTimeUpdated":1386525867899,"checked":true,"likes":["elm@purdue.edu"],"label":"Time-series Data"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525164928,"label":"User Interface Design"},"Dynamic Visualization":{"dislikes":[],"lastTimeUpdated":1386525614845,"checked":true,"likes":[],"label":"Dynamic Visualization"},"information visualization":{"checked":false,"lastUpdateTime":1386525943362,"dislikes":[],"label":"information visualization","lastTimeUpdated":1386525154203,"likes":["pierre.dragice@gmail.com","petra.isenberg@inria.fr","dan@microsoft.com"]},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525319519,"checked":true,"likes":["petra.isenberg@inria.fr","dan@microsoft.com","aquigley@st-andrews.ac.uk","forlines@alumni.cmu.edu"],"label":"Information Visualization"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644798}},"creationTime":168,"content":{"authorList":["Benjamin Bach, INRIA","Emmanuel Pietriga, INRIA, Orsay, France & INRIA Chile","Jean-Daniel Fekete, INRIA"],"title":"Visualizing Dynamic Networks with Matrix Cubes","paperOrNote":"Paper","fullAbstract":"Designing visualizations for dynamic networks has proven to be quite a challenge, both because the data are inherently complex and hard to represent, and because the tasks associated with their visual exploration are often cognitively demanding ones. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people apprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations systematically result in 2D visualizations that emphasize different aspects of the dynamic network, each one better suited to different types of visual analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them, and report on their successful use by two domain experts, an astronomer and a neurologist.","shortAbstract":"Designing visualizations for dynamic networks has proven to be quite a","id":"pn337"},"session":"Viz: Novel Visual Elements","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn337"},"pn330":{"lastUpdateTime":1388776618754,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Visualization"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"3D Modeling":{"dislikes":[],"lastTimeUpdated":1386531648797,"checked":true,"likes":[],"label":"3D Modeling"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840651}},"creationTime":165,"content":{"authorList":["Hsiang-Ting Chen, Department of Computer Science","Tovi Grossman, Autodesk Research","Li-Yi Wei, The University of Hong Kong","Ryan Schmidt, Autodesk Research","Bjorn Hartmann, University of California, Berkeley","George Fitzmaurice, Autodesk Research","Maneesh Agrawala, University of California, Berkeley"],"title":"History Assisted View Authoring for 3D Models","paperOrNote":"Paper","fullAbstract":"3D modelers often wish to showcase their models and associated workflows for review, tutorial, and visualization purposes. This may consist of generating static viewpoints across versions of the model, or authoring animated fly-throughs. Unfortunately, manually creating such views is often tedious and few automatic methods are designed to interactively assist the modelers on view authoring process. We present a new view authoring system that supports automatic creation of informative view points, view paths, and view surfaces, allowing authors to create interactive summaries and viewpoint collages of a model. The key concept of our implementation is to analyze the models workflow history, to infer important regions of the model and representative viewpoints of those areas. An evaluation indicated that the viewpoints generated by our algorithm are comparable to those manually selected by the modeler. In addition, participants of a user study found our system easy to use and provides an effective alternative for authoring viewpoint summaries.","shortAbstract":"3D modelers often wish to showcase their models and associated workflo","id":"pn330"},"session":"3D: 3D modeling","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn330"},"pn150":{"lastUpdateTime":1389285494405,"subcommitteeSplit":"","labels":{"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521694279,"checked":true,"likes":["myriam.lewkowicz@utt.fr"],"label":"crowdsourcing"},"aggregating social network data":{"dislikes":[],"lastTimeUpdated":1386522448938,"checked":true,"likes":[],"label":"aggregating social network data"},"prediction":{"dislikes":[],"lastTimeUpdated":1386523558662,"checked":true,"likes":["teevan@gmail.com"],"label":"prediction"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523552589,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556749}},"creationTime":37,"content":{"authorList":["Clifton Forlines, Draper Laboratory","Sarah Miller, C.S. Draper Laboratory","Leslie Guelcher, ","Robert Bruzzi, Mercyhurst University"],"title":"Crowdsourcing the Future: Predictions Made with a Social Network","paperOrNote":"Paper","fullAbstract":"Researchers have long known that aggregate estimations built from the collected opinions of a large group of people often outperform the estimations of individual experts. This phenomenon is generally described as the Wisdom of Crowds. This approach has shown promise with respect to the task of accurately forecasting future events. Previous research has demonstrated the value of utilizing meta-forecasts (forecasts about what others in the group will predict) when aggregating group predictions. In this paper, we describe an extension to meta-forecasting and demonstrate the value of modeling the familiarity among a populations members (its social network) and applying this model to forecast aggregation. A pair of studies demonstrates the value of taking this model into account, and the described technique produces aggregate forecasts for future events that are significantly better than the standard Wisdom of Crowds approach as well as previous meta-forecasting techniques.","shortAbstract":"Researchers have long known that aggregate estimations built from the ","id":"pn150"},"session":"CSCW: Crowdsourcing","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn150"},"pn155":{"lastUpdateTime":1389284843631,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386521827725,"checked":true,"likes":["elainemayhuang@gmail.com","jfc@cs.berkeley.edu"],"label":"Field Study"},"sustainability_and_everyday_practice":{"dislikes":[],"lastTimeUpdated":1386522681966,"checked":true,"likes":["hazas@comp.lancs.ac.uk","rob.comber@ncl.ac.uk"],"label":"sustainability_and_everyday_practice"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Sustainability":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","jfc@cs.berkeley.edu","rob.comber@ncl.ac.uk","jonfroehlich@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Sustainability"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Home":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","jfc@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Home"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446258}},"creationTime":40,"content":{"authorList":["Oliver Bates, Lancaster University","Mike Hazas, ","Janine Morley, Lancaster University","Adrian Clear, Lancaster University","Adrian Friday, Lancaster University"],"title":"Towards an Holistic View of the Energy and Environmental Impacts of Domestic Media and IT","paperOrNote":"Paper","fullAbstract":"To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and portable electronics such as mobile phones and laptops.   \\ However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology.  \\ Such awareness is needed to inform researchers on how best to prioritise research efforts around digital media and IT.   \\ Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. \\ In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might modify the energy and emissions impacts.","shortAbstract":"To date, research in sustainable HCI has dealt with eco-feedback, usag","id":"pn155"},"session":"UBI: Smart Homes","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn155"},"pn1745":{"lastUpdateTime":1389236747529,"subcommitteeSplit":"A","labels":{"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386536999677,"label":"Computer-Mediated Communication"},"Animation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Animation"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526548140,"label":"User Experience Design / Experience Design"},"Children":{"checked":true,"dislikes":[],"likes":["hilary.hutchinson@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"Virtual Agents":{"dislikes":[],"lastTimeUpdated":1386523699662,"checked":true,"likes":[],"label":"Virtual Agents"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188222}},"creationTime":1358,"content":{"authorList":["Jennifer Hyde, Carnegie Mellon University","Sara Kiesler, Carnegie Mellon University","Jessica Hodgins, Carnegie Mellon University","Elizabeth Carter, Carnegie Mellon University"],"title":"Conversing with Children: Cartoon and Video People Elicit Similar Conversational Behaviors","paperOrNote":"Paper","fullAbstract":"Interactive animated characters have the potential to engage and educate children but there is little research on childrens interactions with animated characters and real people. We conducted an experiment with 64 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as another person. A subset of the participants interacted with characters that displayed abnormal facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in childrens conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited abnormal motion. These results suggest that children may be resilient to interactive animated characters and will interact as they would with a person.","shortAbstract":"Interactive animated characters have the potential to engage and educa","id":"pn1745"},"session":"HCI4D: Engage & Educate Children","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1745"},"pn1325":{"lastUpdateTime":1389235997798,"subcommitteeSplit":"A","labels":{"human rights":{"dislikes":[],"lastTimeUpdated":1386524746889,"checked":true,"likes":[],"label":"human rights"},"curation":{"dislikes":[],"lastTimeUpdated":1386523819687,"checked":true,"likes":[],"label":"curation"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["eva@ehornecker.de","adf"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"cultural archives":{"dislikes":[],"lastTimeUpdated":1386523842433,"checked":true,"likes":[],"label":"cultural archives"},"Values":{"checked":false,"lastUpdateTime":1386528656176,"dislikes":[],"label":"Values","lastTimeUpdated":1386523802955,"likes":[]},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"values":{"dislikes":[],"lastTimeUpdated":1386528654768,"checked":true,"likes":[],"label":"values"},"User Studies":{"checked":false,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":1386525617844,"label":"User Studies"},"war and peace":{"dislikes":[],"lastTimeUpdated":1386523870101,"checked":true,"likes":[],"label":"war and peace"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"ethics":{"dislikes":[],"lastTimeUpdated":1386523854935,"checked":true,"likes":["vlh@acm.org"],"label":"ethics"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946682}},"creationTime":996,"content":{"authorList":["Abigail Durrant, Newcastle University","David Kirk, Newcastle University","Stuart Reeves, University of Nottingham"],"title":"Human Values in Curating a Human Rights Media Archive","paperOrNote":"Paper","fullAbstract":"Cultural institutions, such as museums, often work with and curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices to offer new opportunities for public and scholarly engagement. In this paper we report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interest in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan genocide are being captured and curated to support the centres humanitarian agenda and associated values. Whilst reflecting on the uniqueness of our case, we identify transferable curatorial concerns for human rights media communication within scholarly networks and to public audiences worldwide. We further elucidate interaction design challenges for supportive ICT in this endeavour, contributing to HCI discourses on value sensitive design and cultural engagement with sensitive materials. ","shortAbstract":"Cultural institutions, such as museums, often work with and curate pol","id":"pn1325"},"session":"HCI4D: CHI for Social Development","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1325"},"pn1742":{"lastUpdateTime":1389238017883,"subcommitteeSplit":"B","labels":{"search":{"checked":false,"lastUpdateTime":1386523485794,"dislikes":[],"label":"search","lastTimeUpdated":1386522188826,"likes":["dr.mark.j.perry@googlemail.com"]},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com"],"lastUpdateTime":1386523481906,"label":"Empirical Methods, Quantitative"},"World Wide Web and Hypermedia":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523489382,"label":"World Wide Web and Hypermedia"},"maps":{"checked":false,"lastUpdateTime":1386523487445,"dislikes":[],"label":"maps","lastTimeUpdated":1386522955931,"likes":[]},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032744},"Models":{"label":"Models","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1388783382686}},"creationTime":1355,"content":{"authorList":["Jon May, University of Plymouth","Tim Gamble, University of Bath"],"title":"Collocating Interface Objects: Zooming into Maps","paperOrNote":"Paper","fullAbstract":"May, Dean and Barnard used a theoretically based model of visual human-computer interaction to argue that interface objects should be collocated following screen changes such as a zoom-in to detail [7]. Many existing online maps do not follow this principle, but move a clicked point to the centre of the subsequent display, leaving the user looking at an unrelated location. This paper presents three experiments showing that collocating the point clicked so that the detailed location appears in the place previously occupied by the overview location makes the map easier to use, reflected in a reduction in eye movements and interaction duration. We discuss the benefit of basing design principles on theoretical models so that they can be extended to novel situations.","shortAbstract":"May, Dean and Barnard used a theoretically based model of visual human","id":"pn1742"},"session":"People: Location Location Location","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1742"},"pn806":{"lastUpdateTime":1389592126492,"subcommitteeSplit":"","labels":{"interruption":{"dislikes":[],"lastTimeUpdated":1386528985972,"checked":true,"likes":[],"label":"interruption"},"collaborative filtering":{"dislikes":[],"lastTimeUpdated":1386528210781,"checked":true,"likes":[],"label":"collaborative filtering"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"algorithms":{"dislikes":[],"lastTimeUpdated":1386528177211,"checked":true,"likes":[],"label":"algorithms"},"Usability Research":{"dislikes":[],"lastTimeUpdated":1386527652520,"checked":true,"likes":["marcodesa@gmail.com"],"label":"Usability Research"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532154048,"label":"Computer-Mediated Communication"},"Interruption management":{"dislikes":[],"lastTimeUpdated":1386528995487,"checked":true,"likes":[],"label":"Interruption management"},"Interruptions":{"dislikes":[],"lastTimeUpdated":1386532174209,"checked":true,"likes":[],"label":"Interruptions"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386528081662,"checked":true,"likes":[],"label":"Crowd-Powered Systems"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386532143581,"label":"User Experience Design / Experience Design"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165087}},"creationTime":544,"content":{"authorList":["Tammar Shrot, Bar-Ilan University","Avi Rosenfeld, Jerusalem College of Technology","Jennifer Golbeck, University of Maryland, College Park","Sarit Kraus, Bar-Ilan University"],"title":"Timing Interruptions to Improve User Performance","paperOrNote":"Paper","fullAbstract":"Interruptions can have significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. \\ Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training peri- ods that make them unsuitable for online collaborative envi- ronments where new users frequently participate. \\ In this paper, we present a novel synthesis between Collab- orative Filtering methods and machine learning classification algorithms to create a fast learning algorithm, CRISP. CRISP exploits the similarities between users in order to apply data from known users to new users, therefore requiring less in- formation on each person. Results from user studies indicate the algorithm significantly improves users performances in completing the task and their perception of how long it took to complete each task.","shortAbstract":"Interruptions can have significant impact on users working to complete","id":"pn806"},"session":"CSCW: Interruptions and Distractions","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn806"},"pn802":{"lastUpdateTime":1388765615245,"subcommitteeSplit":"","labels":{"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":["gabriela.avram@gmail.com"],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"selfmanagement":{"dislikes":[],"lastTimeUpdated":1386523558247,"checked":true,"likes":[],"label":"selfmanagement"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522194198,"label":"Empirical Methods, Quantitative"},"peer support":{"dislikes":[],"lastTimeUpdated":1386521260154,"checked":true,"likes":["myriam.lewkowicz@utt.fr"],"label":"peer support"},"Experience Strategy":{"checked":false,"lastUpdateTime":1386521256811,"dislikes":[],"label":"Experience Strategy","lastTimeUpdated":1386521254772,"likes":[]},"Social Q&A":{"dislikes":[],"lastTimeUpdated":1386523750846,"checked":true,"likes":[],"label":"Social Q&A"},"Health Care":{"checked":true,"dislikes":[],"likes":["teevan@gmail.com","jacovi@il.ibm.com","gabriela.avram@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk"],"lastUpdateTime":123456789,"label":"Health Care"},"social computing":{"dislikes":[],"lastTimeUpdated":1386521247555,"checked":true,"likes":[],"label":"social computing"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522192141,"label":"Computer-Mediated Communication"},"network of care":{"dislikes":[],"lastTimeUpdated":1386523821210,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"network of care"},"health":{"dislikes":[],"lastTimeUpdated":1386521817972,"checked":true,"likes":["dmrussell@gmail.com"],"label":"health"},"social support":{"dislikes":[],"lastTimeUpdated":1386521727722,"checked":true,"likes":[],"label":"social support"},"forums":{"dislikes":[],"lastTimeUpdated":1386522086139,"checked":true,"likes":[],"label":"forums"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556724}},"creationTime":540,"content":{"authorList":["Tatiana Vlahovic, Carnegie Mellon University ","Yi-Chia Wang, Carnegie Mellon University","Robert Kraut, Carnegie Mellon University","John Levine, University of Pittsburgh"],"title":"Support Matching and Satisfaction in an Online Breast Cancer Support Community","paperOrNote":"Paper","fullAbstract":"Research suggests that online health support benefits chronically ill users. Their satisfaction might be an indicator that they perceive group interactions as beneficial and a precursor to group commitment. We examined whether receiving emotional and informational support is satisfying in its own right, or whether satisfaction depends on matches between what users sought and what they received.  Two studies collected judgments in a breast cancer forum of support users sought, support they received, and their expressed satisfaction. While receiving emotional or informational support in general positively predicted satisfaction, users expressed more satisfaction when they sought and received informational support and less satisfaction when they sought informational support but received emotional support. On the other hand, they were equally satisfied with emotional and informational support after seeking emotional support. Implications for membership commitment and interventions in online support groups are discussed.","shortAbstract":"Research suggests that online health support benefits chronically ill ","id":"pn802"},"session":"Health: Social Media and Health","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn802"},"pn1036":{"lastUpdateTime":1388765615245,"subcommitteeSplit":"A","labels":{"emotion":{"dislikes":[],"lastTimeUpdated":1386524479578,"checked":true,"likes":[],"label":"emotion"},"non-native speakers":{"checked":false,"lastUpdateTime":1386526620480,"dislikes":[],"label":"non-native speakers","lastTimeUpdated":1386524488636,"likes":[]},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":["lorrie@acm.org"],"lastUpdateTime":1386526642571,"label":"Computer-Mediated Communication"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526646364,"label":"Social Computing and Social Navigation"},"Social Media and Habits":{"dislikes":[],"lastTimeUpdated":1386525475471,"checked":true,"likes":[],"label":"Social Media and Habits"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526643446,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946734}},"creationTime":740,"content":{"authorList":["Elizabeth Murnane, Microsoft Research","Scott Counts, Microsoft Research"],"title":"Unraveling Abstinence and Relapse: Smoking Cessation Reflected in Social Media","paperOrNote":"Paper","fullAbstract":"Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence and relapse during cessation attempts. Combining automatic and crowdsourced techniques, we detect users trying to quit smoking and analyze tweet and network data from a sample of 653 individuals over a two-year window of quitting. Guided by theory and practice, we derive behavioral, social, and emotional measures to compare users who abstain and relapse. We also examine the cessation process, demonstrating that Twitter can help chronicle how people go about quitting. Among other results, we show that those who fail in their smoking cessation are far heavier posters and use relatively less positive language, while those who succeed are more social in both network ties and in directed communication. We conclude with insights into how intelligent intervention systems can harness these signals to provide tailored cessation support.","shortAbstract":"Analysis of smokers' posts and behaviors on Twitter reveals factors im","id":"pn1036"},"session":"Health: Social Media and Health","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1036"},"pn1034":{"lastUpdateTime":1389236825484,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"dislikes":[],"lastTimeUpdated":1386522662693,"checked":true,"likes":[],"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"3d printing":{"dislikes":[],"lastTimeUpdated":1386521925607,"checked":true,"likes":[],"label":"3d printing"},"dance/movement":{"dislikes":[],"lastTimeUpdated":1386522327972,"checked":true,"likes":["wendyju@stanford.edu","aantle@sfu.ca"],"label":"dance/movement"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"movement interaction":{"dislikes":[],"lastTimeUpdated":1386522645088,"checked":true,"likes":[],"label":"movement interaction"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755931}},"creationTime":739,"content":{"authorList":["Rohit Khot, RMIT University","Florian Mueller, RMIT University","Larissa Hjorth, RMIT University"],"title":"Understanding Physical Activity through 3D Printed Material Artifacts","paperOrNote":"Paper","fullAbstract":"In this paper, we advocate a novel approach of representing physical activity in the form of material artifacts. By designing such material representations, we aim to understand what these artifacts might offer in terms of reflecting upon physical activity. For example, what types of affect do material artifacts, representing ones physical activity create for the user? In order to advance this understanding, we designed a system called SweatAtoms that transforms the physical activity data based on heart rate into 3D printed material artifacts. We conducted an in the wild study by deploying our system in six households for a period of two weeks each and providing them with 5 different material representations of their physical activity. We found that the material artifacts made participants more cautious about their involvement in physical activity and illustrated various levels of engagement with them. Along with reporting the gained insights from the deployments, we offer reflections on designing material representations for physical activity. We hope that our work will inspire designers to consider new possibilities afforded by digital fabrication to support users experience with physical activity by utilizing interactive technologies at our disposal.","shortAbstract":"In this paper, we advocate a novel approach of representing physical a","id":"pn1034"},"session":"Making: 3D printing","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1034"},"pn1032":{"lastUpdateTime":1389284833413,"subcommitteeSplit":"","labels":{"Shopping":{"dislikes":[],"lastTimeUpdated":1386521874060,"checked":true,"likes":[],"label":"Shopping"},"Video Content / Communications":{"dislikes":[],"lastTimeUpdated":1386523334383,"checked":true,"likes":["gabriela.avram@gmail.com"],"label":"Video Content / Communications"},"collaboration":{"dislikes":[],"lastTimeUpdated":1386523219100,"checked":true,"likes":[],"label":"collaboration"},"E-Commerce":{"checked":true,"dislikes":[],"likes":["emilee@gmail.com"],"lastUpdateTime":123456789,"label":"E-Commerce"},"Social Computing and Social Navigation":{"checked":false,"lastUpdateTime":1386523495669,"dislikes":[],"label":"Social Computing and Social Navigation","lastTimeUpdated":1386523398831,"likes":[]},"information search":{"dislikes":[],"lastTimeUpdated":1386524223782,"checked":true,"likes":[],"label":"information search"},"navigation":{"dislikes":[],"lastTimeUpdated":1386523296964,"checked":true,"likes":[],"label":"navigation"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523338827,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556741}},"creationTime":737,"content":{"authorList":["Yanzhen Yue, National University of Singapore","Xiaojuan Ma, Noah's Ark Lab","Zhenhui Jiang, National University of Singapore"],"title":"Share your View: Impact of Co-Navigation Support and Status Composition in Collaborative Online Shopping","paperOrNote":"Paper","fullAbstract":"Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers to extend purchase-oriented social interactions into the digital environment. Online vendors have been experimenting ways to facilitate this activity. However, more research needs to be done on identifying what feature can create a pleasing shopping experience and ultimately encourage spending. In this paper, we present an exploration of the impact of co-navigation supports, including location cue, split screen, and tightly-bonded shared view, on the experiences and performance of 60 co-shopper dyads. We also studied if status composition of shopping companions played a role in this process. By analyzing about 1800 minutes of eye-tracking data, video footages, and web logs, we found that split screen encouraged more diverse product search, tightly-bonded shared view enabled better coordination, and location cue was the least distracting. Co-buyers achieved better factual and inference understanding, though buyer-advisor dyads were more likely to stay together.","shortAbstract":"Collaborative online shopping, an emerging paradigm in e-commerce, all","id":"pn1032"},"session":"HCI4D: Shopping and Economy","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1032"},"pn1987":{"lastUpdateTime":1389221083200,"subcommitteeSplit":"B","labels":{"gaming":{"checked":true,"lastUpdateTime":1386522186943,"dislikes":[],"label":"gaming","lastTimeUpdated":1386522160939,"likes":[]},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Video Games":{"dislikes":[],"lastTimeUpdated":1386522161369,"checked":true,"likes":["jantin@gmail.com"],"label":"Video Games"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032787}},"creationTime":1567,"content":{"authorList":["Chek Tien Tan, University of Technology, Sydney","Tuck Wah Leong, University of Technology, Sydney","Songjia Shen, University of Technology, Sydney"],"title":"Combining Think-aloud and Physiological Data to Understand Video Game Experiences","paperOrNote":"Paper","fullAbstract":"Think-aloud protocols are common in evaluating video game player experiences but suffers from a lack of objectivity and timeliness. On the other hand, quantitative captures of physiological data are effective in providing detailed, unbiased and continuous responses of players, but lack contexts for interpretation. While both approaches contain pros and cons, an in-depth study of how both approaches can be used together in practice has not been performed. This paper compares video-cued retrospective think-aloud and physiological data collected in a video gameplay experiment. We observed that many interesting physiological responses did not feature in participants' think-aloud data, and also that sometimes reports of interesting experiences were not found in physiological data either. This study presents some of the challenges when combining these approaches and presents some guidelines to how we can combine think-aloud and quantitative capture of physiological data in order to gain deeper insights into understanding player experiences.","shortAbstract":"Think-aloud protocols are common in evaluating video game player exper","id":"pn1987"},"session":"Games: Fun N Play","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1987"},"pn1982":{"lastUpdateTime":1389591429727,"subcommitteeSplit":"B","labels":{"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"search":{"dislikes":[],"lastTimeUpdated":1386522182549,"checked":true,"likes":["oantti@mpi-inf.mpg.de"],"label":"search"},"prediction":{"dislikes":[],"lastTimeUpdated":1386524441670,"checked":true,"likes":[],"label":"prediction"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032704}},"creationTime":1564,"content":{"authorList":["David Kieras, University of Michigan","Anthony Hornof, University of Oregon"],"title":"Towards Accurate and Practical Predictive Models of Active-Vision-Based Visual Search","paperOrNote":"Paper","fullAbstract":"Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research.  This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an active vision approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze.  A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance.  The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search are thus feasible and should be further developed. \\ ","shortAbstract":"Being able to predict the performance of interface designs using model","id":"pn1982"},"session":"Methods and Models: The Eyes Have It","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1982"},"pn1983":{"lastUpdateTime":1389591711631,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"multi-display interfaces":{"dislikes":[],"lastTimeUpdated":1386525476941,"checked":true,"likes":["abe.karnik@gmail.com"],"label":"multi-display interfaces"},"Tabletop interaction":{"dislikes":[],"lastTimeUpdated":1386525161970,"checked":true,"likes":[],"label":"Tabletop interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"heck frickin' yeah":{"dislikes":[],"lastTimeUpdated":1386525649288,"checked":true,"likes":["benko@microsoft.com","abe.karnik@gmail.com","elm@purdue.edu","j.alexander@lancaster.ac.uk","davidmcgookin@gmail.com"],"label":"heck frickin' yeah"},"3D User Interfaces":{"dislikes":[],"lastTimeUpdated":1386525884608,"checked":true,"likes":[],"label":"3D User Interfaces"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["forlines@alumni.cmu.edu"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644744}},"creationTime":1565,"content":{"authorList":["Diego Martinez Plasencia, University of Bristol","Edward Joyce, Bristol","Sriram Subramanian, University of Bristol"],"title":"MisTable: Reach-through Personal Screens for Tabletops","paperOrNote":"Paper","fullAbstract":"We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface. These personal screens, built using fog, are both see-through and reach-through. Being see-through, provides direct line of sight of the personal screen and the elements behind it on the tabletop. Being reach-through, allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or space above it. The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user. Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences. Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions. We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.","shortAbstract":"We present MisTable, a tabletop system that combines a conventional ho","id":"pn1983"},"session":"Displays: Displays (UIST)","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1983"},"pn1667":{"lastUpdateTime":1389236332031,"subcommitteeSplit":"B","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Design Professions":{"dislikes":[],"lastTimeUpdated":1386523032191,"checked":true,"likes":[],"label":"Design Professions"},"Design practice":{"dislikes":[],"lastTimeUpdated":1386523191284,"checked":true,"likes":["reinecke@umich.edu","adf"],"label":"Design practice"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["fuzhiyong@tsinghua.edu.cn","reinecke@umich.edu"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755913},"was Viz Vis Aesthetics":{"label":"was Viz Vis Aesthetics","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389107287830}},"creationTime":1289,"content":{"authorList":["Colin M. Gray, Indiana University"],"title":"Evolution of Design Competence in UX Practice","paperOrNote":"Paper","fullAbstract":"There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design. This paper addresses the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift. We present a 12-week longitudinal data collection, including surveys and interviews, with participants beginning internships and full-time positions in UX. Students and early professionals were asked to assess their level of competence and factors that influenced competence. We propose a co-construction of identity between the designer and their environment, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time. Opportunities for future research based on this preliminary framing of early UX practice are addressed.","shortAbstract":"There has been increasing interest in the adoption of UX within corpor","id":"pn1667"},"session":"Design: Critical Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1667"},"pn2401":{"lastUpdateTime":1389236111891,"subcommitteeSplit":"","labels":{"Location":{"dislikes":[],"lastTimeUpdated":1386522583655,"checked":true,"likes":[],"label":"Location"},"urban":{"dislikes":[],"lastTimeUpdated":1386522338070,"checked":true,"likes":["myriam.lewkowicz@utt.fr","teevan@gmail.com","jacovi@il.ibm.com","gabriela.avram@gmail.com"],"label":"urban"},"city point of view":{"dislikes":[],"lastTimeUpdated":1386521917694,"checked":true,"likes":[],"label":"city point of view"},"curation":{"dislikes":[],"lastTimeUpdated":1386523011030,"checked":true,"likes":[],"label":"curation"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523464592,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523467221,"label":"Social Computing and Social Navigation"},"geography":{"dislikes":[],"lastTimeUpdated":1386522212214,"checked":true,"likes":["yardi@umich.edu"],"label":"geography"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523463590,"label":"User Experience Design / Experience Design"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523465438,"label":"Computer Supported Cooperative Work (CSCW)"},"geo tagging analytics":{"dislikes":[],"lastTimeUpdated":1386521900965,"checked":true,"likes":[],"label":"geo tagging analytics"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556770}},"creationTime":1925,"content":{"authorList":["Justin Cranshaw, Carnegie Mellon University","Kurt Luther, Carnegie Mellon University","Patrick Gage Kelley, University of New Mexico","Norman Sadeh, Carnegie Mellon University"],"title":"Curated City: Capturing Individual Mental Maps Through Social City Guides","paperOrNote":"Paper","fullAbstract":"We report on our design of Curated City, a novel social computing website that elicits people to express their mental maps of the city, as they chronicle their favorite experiences while building their own personal guide to the city's neighborhoods.  Although users make their own personal guides, they are immersed in a social experience where their own guides are influenced directly and indirectly by the guides of others.  We use a 2-week field trial involving 20 residents of Pittsburgh as a technological probe to explore the initial design decisions we made, and we further refine the design landscape through subject interviews.  Based on this study, we identify a set of design requirements that can contribute to the success of a scalable social platform aimed at capturing rich mental maps.","shortAbstract":"We report on our design of Curated City, a novel social computing webs","id":"pn2401"},"session":"HCI4D: City Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2401"},"pn2406":{"lastUpdateTime":1389236747529,"subcommitteeSplit":"B","labels":{"Plants":{"dislikes":[],"lastTimeUpdated":1386522829556,"checked":true,"likes":[],"label":"Plants"},"Living design":{"dislikes":[],"lastTimeUpdated":1386522788646,"checked":true,"likes":[],"label":"Living design"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Biological Computing":{"dislikes":[],"lastTimeUpdated":1386522754582,"checked":true,"likes":[],"label":"Biological Computing"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Prototyping":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Prototyping"},"Therapeutic Interfaces":{"dislikes":[],"lastTimeUpdated":1386523097936,"checked":true,"likes":[],"label":"Therapeutic Interfaces"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Children":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu","ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Children"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755979}},"creationTime":1929,"content":{"authorList":["Foad Hamidi, York University","Melanie Baljko, York University"],"title":"Rafigh: A Living Media Interface for Speech Intervention","paperOrNote":"Note","fullAbstract":"Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms growth is used to communicate how much speech is used \\ during interaction.","shortAbstract":"Digital games can engage children in therapeutic and learning activiti","id":"pn2406"},"session":"HCI4D: Engage & Educate Children","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2406"},"pn2317":{"lastUpdateTime":1389285647205,"subcommitteeSplit":"B","labels":{"Persuasive Games":{"dislikes":[],"lastTimeUpdated":1386522252179,"checked":true,"likes":[],"label":"Persuasive Games"},"E-Learning and Education":{"checked":true,"dislikes":[],"likes":["D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Emotion and Affective User Interface":{"checked":false,"dislikes":[],"likes":["daverandall2008@gmail.com"],"lastUpdateTime":1386522958032,"label":"Emotion and Affective User Interface"},"games":{"dislikes":[],"lastTimeUpdated":1386523273345,"checked":true,"likes":[],"label":"games"},"Children":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386522955556,"label":"Children"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032721}},"creationTime":1858,"content":{"authorList":["Dana Ruggiero, Bath Spa University"],"title":"Spent: Changing Students Affective Learning Toward Homelessness Through Persuasive Video Game Play","paperOrNote":"Paper","fullAbstract":"To investigate whether a persuasive game may serve as a way to increase affective learning about homelessness, this study examined the effects of persuasive rhetoric and ethos in a video game designed to put the player in the shoes of an almost-homeless person. Data were collected from 5139 students across four states. Examination revealed that playing the game or doing the reading significantly increased the affective learning score after treatment with the game group scoring 1.57 points higher and the reading group scoring .66 points higher out of a score of 6. Findings indicate that students who played Spent sustained significantly higher scores after three weeks. Moreover, the level of change in the game group was negatively correlated to the grade of the student for the ALS. Overall, findings suggest that when students play a video game that is designed using persuasive mechanics an affective change can be measured empirically.","shortAbstract":"To investigate whether a persuasive game may serve as a way to increas","id":"pn2317"},"session":"Health: Persuade Me","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2317"},"pn2074":{"lastUpdateTime":1388765600113,"subcommitteeSplit":"","labels":{"Cross-cultural studies":{"dislikes":[],"lastTimeUpdated":1386522620855,"checked":true,"likes":[],"label":"Cross-cultural studies"},"selfmanagement":{"dislikes":[],"lastTimeUpdated":1386523608981,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"selfmanagement"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"peer support":{"dislikes":[],"lastTimeUpdated":1386522404402,"checked":true,"likes":["smunson@uw.edu","myriam.lewkowicz@utt.fr"],"label":"peer support"},"Health Care":{"dislikes":[],"lastTimeUpdated":1386522374838,"checked":true,"likes":["jacovi@il.ibm.com","teevan@gmail.com"],"label":"Health Care"},"health":{"dislikes":[],"lastTimeUpdated":1386522391138,"checked":true,"likes":["gabriela.avram@gmail.com"],"label":"health"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523565053,"label":"Empirical Methods, Qualitative"},"network of care":{"dislikes":[],"lastTimeUpdated":1386523853877,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"network of care"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523563832,"label":"User Studies"},"forums":{"dislikes":[],"lastTimeUpdated":1386522105202,"checked":true,"likes":[],"label":"forums"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523565850,"label":"Computer Supported Cooperative Work (CSCW)"},"diabetes":{"dislikes":[],"lastTimeUpdated":1386522726910,"checked":true,"likes":[],"label":"diabetes"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556783}},"creationTime":1642,"content":{"authorList":["Xiaomu Zhou, Rutgers University","Si Sun, Rutgers University","Jiang Yang, IBM"],"title":"Sweet Home: Understanding Diabetes Management via a Chinese Online Community","paperOrNote":"Paper","fullAbstract":"China has overtaken India and the U.S. as host to the largest diabetic population in the world. Many problems exist in the Chinese healthcare system and very small numbers of diabetes patients receive treatment. Our paper reports on a case study through the lens of an online diabetes patient community, Sweet Home. We conducted interviews, participant observations, and text analysis to understand the health management of patients at Sweet Home. Our findings reveal that patients understanding of diabetes, their choice of treatments, their routine management, and their interactions with others (in the physical world) and among themselves (in the online world) are influenced by many factors: belief in traditional Chinese versus western medicine, cultural and social norms regarding social eating and drinking, conflicts over self-images, and responses to comments and pressures of coworkers. That is, social context may significantly affect patients behaviors and each individual patients actions may also help reshape the social context. We draw out implications for how our society as a whole may respond to these issues, from the perspective of public health, education, and information technology design.","shortAbstract":"China has overtaken India and the U.S. as host to the largest diabetic","id":"pn2074"},"session":"Health: Network of care","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2074"},"pn2274":{"lastUpdateTime":1389285647205,"subcommitteeSplit":"A","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Persuasive Technologies":{"dislikes":[],"lastTimeUpdated":1386523483207,"checked":true,"likes":[],"label":"Persuasive Technologies"},"Physical Fitness":{"dislikes":[],"lastTimeUpdated":1386523072203,"checked":true,"likes":["Jina.huh@gmail.com","weibel@ucsd.edu"],"label":"Physical Fitness"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Get Up! Technology for Physical Fitness":{"checked":false,"lastUpdateTime":1386523576434,"dislikes":[],"label":"Get Up! Technology for Physical Fitness","lastTimeUpdated":1386523266898,"likes":["weibel@ucsd.edu"]},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523450925,"label":"User Studies"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188219}},"creationTime":1818,"content":{"authorList":["Thomas Fritz, University of Zurich","Elaine Huang, University of Zurich","Gail Murphy, University of British Columbia","Thomas Zimmermann, Microsoft Research"],"title":"Persuasive Technology in the Real World: A Study of Long-Term Use of Activity Sensing Devices for Fitness","paperOrNote":"Paper","fullAbstract":"Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly in the wild contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.","shortAbstract":"Persuasive technology to motivate healthy behavior is a growing area o","id":"pn2274"},"session":"Health: Persuade Me","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2274"},"pn2277":{"lastUpdateTime":1389221191523,"subcommitteeSplit":"","labels":{"gaming":{"dislikes":[],"lastTimeUpdated":1386522642721,"checked":true,"likes":["myriam.lewkowicz@utt.fr","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"gaming"},"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386523241902,"label":"Tactile and Haptic UIs"},"Exergames":{"dislikes":[],"lastTimeUpdated":1386531405804,"checked":true,"likes":[],"label":"Exergames"},"exergames":{"checked":false,"lastUpdateTime":1386531407466,"dislikes":[],"label":"exergames","lastTimeUpdated":1386521769329,"likes":[]},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"exertion interfaces":{"dislikes":[],"lastTimeUpdated":1386521776382,"checked":true,"likes":[],"label":"exertion interfaces"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521791567,"label":"Input and Interaction Technologies"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556624}},"creationTime":1821,"content":{"authorList":["Mike Sheinin, University of Saskatchewan","Carl Gutwin, University of Saskatchewan"],"title":"Exertion in the Small: Improving Differentiation and Expressiveness in Sports Games with Physical Controls","paperOrNote":"Paper","fullAbstract":"Many sports video games contain elements such as running or throwing that are based on real-world physical activities, but the translation of these activities to game controllers means that the original physicality is lost. This results in games where players have limited opportunity to improve their physical skills, where there is little differentiation in peoples physical abilities, and where skills do not change over the course of a game. To explore ways of adding these elements back into sports games, we developed two games with small-scale physical controls for running and throwing  one game was a simple running race, and one was a team-based handball-style game called Jelly Polo. In two studies (three track-and-field tournaments for the running game, and a four-week league for Jelly Polo), we observed the effects of physical controls on gameplay. Our studies showed that the physical controls enabled substantial individual differences in running and passing skill, allowed people to increase their expertise over time, and led to fatigue-based changes in performance during a game. Physical controls increased the games challenge, complexity, and unpredictability, and dramatically improved player interest, expressiveness, and enjoyment. Our work shows that game designers should consider the idea of exertion in the small as a way to improve play experience in games based on physical activities.","shortAbstract":"Many sports video games contain elements such as running or throwing t","id":"pn2277"},"session":"Games: Exergames","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2277"},"pn2276":{"lastUpdateTime":1389284833413,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386521970991,"checked":true,"likes":["elainemayhuang@gmail.com","a.sasse@cs.ucl.ac.uk","nithyas@gmail.com"],"label":"Field Study"},"Visualization":{"dislikes":[],"lastTimeUpdated":1386521984278,"checked":true,"likes":["elainemayhuang@gmail.com"],"label":"Visualization"},"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":["elainemayhuang@gmail.com"],"lastUpdateTime":1386521990670,"label":"Ubiquitous Computing / Smart Environments"},"food":{"checked":false,"lastUpdateTime":1386531456980,"dislikes":[],"label":"food","lastTimeUpdated":1386521963024,"likes":[]},"Food":{"dislikes":[],"lastTimeUpdated":1386531453871,"checked":true,"likes":[],"label":"Food"},"health":{"dislikes":[],"lastTimeUpdated":1386521957244,"checked":true,"likes":[],"label":"health"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","jfc@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Home":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"Nutrition":{"dislikes":[],"lastTimeUpdated":1386522014613,"checked":true,"likes":[],"label":"Nutrition"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446322}},"creationTime":1820,"content":{"authorList":["Wolfgang Reitberger, Vienna University of Technology","Wolfgang Spreicer, Vienna University of Technology","Geraldine Fitzpatrick, Vienna University of Technology"],"title":"Nutriflect: Reflecting Collective Shopping Behavior and Nutrition","paperOrNote":"Paper","fullAbstract":"Peoples shopping behavior is being extensively tracked by grocery shopping chains. However, the resulting big data is mainly used to the benefit of the shops through data mining and highly personalized marketing, and not to the benefit of the people themselves. We present the Nutriflect system which utilizes users shopping data to inform them about their long term shopping behavior. In an initial study we conducted structured interviews in grocery stores. Based on the results we implemented our system that visualized a households collective shopping information via situated displays in order to raise awareness about shopping habits and to enable reflection about nutrition. The system worked without burdening the users with the manual entry of their eating habits. We evaluated the system in a 4 week field study in 8 household with 21 users. The results indicate that the system helped people to reflect about and improve their nutrition. ","shortAbstract":"Peoples shopping behavior is being extensively tracked by grocery s","id":"pn2276"},"session":"HCI4D: Shopping and Economy","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2276"},"pn1513":{"lastUpdateTime":1388776618754,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["fanny@dgp.toronto.edu"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Pen-based UIs":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Pen-based UIs"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840647}},"creationTime":1168,"content":{"authorList":["Michael Ortega, CNRS","Thomas Vincent, UJF-Grenoble1"],"title":"Direct Drawing of Long Curves on 3D Shapes with Automated Camera Control","paperOrNote":"Note","fullAbstract":"We present ACCD, an interaction technique that allows direct drawing of long curves on 3D shapes with a tablet display. ACCD reduces the number of explicit viewpoint manip- ulations by combining self-occlusion management and automated camera control. As such it enables drawing on occluded faces but also around a 3D shape while keeping a constant drawing precision. Our experimental results indicates the efficacy of ACCD over conventional drawing and viewpoint manipulation techniques.","shortAbstract":"We present ACCD, an interaction technique that allows direct drawing o","id":"pn1513"},"session":"3D: 3D modeling","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1513"},"pn1514":{"lastUpdateTime":1389222165018,"subcommitteeSplit":"A","labels":{"Stress":{"dislikes":[],"lastTimeUpdated":1386522930853,"checked":true,"likes":[],"label":"Stress"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526771263,"label":"Empirical Methods, Quantitative"},"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386530575484,"label":"Multimedia UIs"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["Jina.huh@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188203}},"creationTime":1169,"content":{"authorList":["David Sun, EECS, UC Berkeley","John Canny, UC Berkeley","Pablo Paredes, Electrical Engineering and Computer Science Department"],"title":"MouStress: Detecting Stress from Mouse Motion","paperOrNote":"Paper","fullAbstract":"Stress causes and exacerbates many physiological and mental health \\ problems.  Routine and unobtrusive monitoring of stress would enable a \\ variety of treatments, from break-taking to calming exercises. It may \\ also be a valuable tool for assessing effects (frustration, \\ difficulty) of using interfaces or applications. Custom sensing \\ hardware is a poor option, because of the need to buy/wear/use it \\ continuously, even before stress-related problems are evident. Here we \\ explore stress measurement from common computer mouse operations. We \\ use a simple model of arm-hand dynamics that captures muscle stiffness \\ during mouse movement. We show that the within-subject mouse-derived \\ stress measure is quite strong, even compared to concurrent \\ physiological sensor measurements. While our study used fixed mouse \\ tasks, the stress signal was still strong even when averaged across \\ widely varying task geometries. We argue that mouse sensing ``in the \\ wild\" may be feasible, by analyzing frequently-performed operations of \\ particular geometries. \\ ","shortAbstract":"Stress causes and exacerbates many physiological and mental health \\ p","id":"pn1514"},"session":"Health: Stress","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1514"},"pn1517":{"lastUpdateTime":1389238477951,"subcommitteeSplit":"A","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"diversity":{"dislikes":[],"lastTimeUpdated":1386522992287,"checked":true,"likes":[],"label":"diversity"},"Vulnerable groups":{"dislikes":[],"lastTimeUpdated":1386522985136,"checked":true,"likes":[],"label":"Vulnerable groups"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386538133624,"label":"Universal (or Disability)  Access"},"Children":{"checked":true,"dislikes":[],"likes":["lennart.nacke@uoit.ca","Mark.blythe@northumbria.ac.uk"],"lastUpdateTime":123456789,"label":"Children"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"neurological disorders":{"dislikes":[],"lastTimeUpdated":1386522975035,"checked":true,"likes":[],"label":"neurological disorders"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711758}},"creationTime":1172,"content":{"authorList":["Laura Benton, University of Birmingham","Asimina Vasalou, Institute of Education","Rilla Khaled, University of Malta","Hilary Johnson, University of Bath","Daniel Gooch, University of Birmingham"],"title":"Diversity for Design: A Framework for Involving Neurodiverse Children in the Technology Design Process","paperOrNote":"Paper","fullAbstract":"The neurodiversity movement seeks to positively reframe certain neurological conditions, such as autism spectrum disorders (ASD) and dyslexia, by focusing on their characteristic strengths. In recent years, neurodiverse children have increasingly been involved in the technology design process, but the design approaches adopted have focused mostly on overcoming difficulties of working with these children, leaving their strengths untapped. In this paper, we present a new PD framework, Diversity for Design (D4D), that provides guidance for technology designers working with neurodiverse children in establishing PD methods that capitalize on childrens strengths and also support potential difficulties. We present two case studies of use of our D4D framework, involving children with ASD and dyslexia, showing how it informed the development and refinement of PD methods tailored to these populations. In addition, we show how the D4D framework can be applied to other neurodiverse populations.","shortAbstract":"The neurodiversity movement seeks to positively reframe certain neurol","id":"pn1517"},"session":"Design: Participatory Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1517"},"pn1518":{"lastUpdateTime":1389221094245,"subcommitteeSplit":"A","labels":{"Entertainment":{"checked":true,"dislikes":[],"likes":["lennart.nacke@uoit.ca"],"lastUpdateTime":123456789,"label":"Entertainment"},"Alternate Reality Games":{"dislikes":[],"lastTimeUpdated":1386522858140,"checked":true,"likes":[],"label":"Alternate Reality Games"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Narrative":{"dislikes":[],"lastTimeUpdated":1386523807232,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"Narrative"},"Design Narrative":{"dislikes":[],"lastTimeUpdated":1386522876288,"checked":true,"likes":[],"label":"Design Narrative"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711768}},"creationTime":1173,"content":{"authorList":["Elizabeth Bonsignore, Human-Computer Interaction Lab","Vicki Moulder, Simon Fraser University","Carman Neustaedter, Simon Fraser University","Derek Hansen, Ira A. Fulton College of Engineering and Technology, Brigham Young University"],"title":"Design Elements of Authentic Interactive Fiction: Insights from Alternate Reality Game Designers","paperOrNote":"Note","fullAbstract":"This paper presents insights from designers of Alternate Reality Games (ARGs) regarding the design tactics they employ to integrate participatory storytelling and authentic fiction into the transmedia experiences they create. Our approach was motivated by recent efforts in HCI to more closely align the development of interaction design theory to the craft knowledge and experiences of designers themselves [14]. The resulting insights enhance our understanding of design approaches that a diverse group of ARG producers follow to create interactive, participatory narratives. We also outline narrative-specific themes to support designers who craft similar interactive experiences.","shortAbstract":"This paper presents insights from designers of Alternate Reality Games","id":"pn1518"},"session":"Games: Games","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1518"},"pn2095":{"lastUpdateTime":1389221957843,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386521564350,"checked":true,"likes":[],"label":"social media"},"social computing":{"dislikes":[],"lastTimeUpdated":1386521368362,"checked":true,"likes":[],"label":"social computing"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["gabriela.avram@gmail.com"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":["gabriela.avram@gmail.com"],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"enterprise":{"dislikes":[],"lastTimeUpdated":1386521568967,"checked":true,"likes":["depaula@acm.org"],"label":"enterprise"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522270460,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556657}},"creationTime":1663,"content":{"authorList":["Haiyi Zhu, Carnegie Mellon University","Jilin Chen, IBM Research - Almaden","Tara Matthews, IBM Research - Almaden","Aditya Pal, IBM Research - Almaden","Robert Kraut, Carnegie Mellon University"],"title":"Selecting an Effective Niche: An Ecological View of the Success of Online Communities","paperOrNote":"Paper","fullAbstract":"Online communities serve many important functions, but many of them fail to thrive. One important success factor is a communitys niche within the ecosystem of other communities. A community may fail either because it is overly specialized in terms of the topics it covers and members it attracts and thus intellectually or socially isolated, or overly broad, overlapping in topic or member audience with other communities and thus suffering from competition. In this work, we take an ecological view to understand how a communitys niche in a population of communities affects its success. We measured a community's niche through four dimensions: topic overlap, shared members, content linking, and shared offline organizational affiliation. We used a mixed-method approach, combining the quantitative analysis of 9495 online enterprise communities and interviews with community members. Our results show that too little or too much overlap in topic with other communities in an ecosystem causes a communitys activity to suffer. We also show that this main result is moderated in predictable ways by whether the community shares members with, links to content in, or shares an organizational affiliation with other ecosystem communities. These findings provide new insight on community success, guiding online community designers on how to effectively position their community within an ecosystem.","shortAbstract":"Online communities serve many important functions, but many of them fa","id":"pn2095"},"session":"Social: Online Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2095"},"pn2094":{"lastUpdateTime":1389591644732,"subcommitteeSplit":"","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528690689,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"warnings":{"checked":false,"lastUpdateTime":1386531511890,"dislikes":[],"label":"warnings","lastTimeUpdated":1386526221199,"likes":["lorrie@acm.org"]},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531527768,"label":"Empirical Methods, Quantitative"},"Privacy":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531520604,"label":"Privacy"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531522837,"label":"Computer-Mediated Communication"},"I'm (in)secure":{"checked":false,"lastUpdateTime":1386531508519,"dislikes":[],"label":"I'm (in)secure","lastTimeUpdated":1386526777469,"likes":[]},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526208819,"checked":true,"likes":["lorrie@acm.org","judy.kay@gmail.com"],"label":"Usable Security"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165093}},"creationTime":1662,"content":{"authorList":["Bo Zhang, The Pennsylvania State University","Mu Wu, The Pennsylvania State University","Hyunjin Kang, The Pennsylvania State University","Eun Go, The Pennsylvania State University","S. Shyam Sundar, The Pennsylvania State University"],"title":"Security Warnings Make Users Distrust the Messenger","paperOrNote":"Note","fullAbstract":"In order to address the increased privacy and security concerns raised by mobile communications, designers of mobile applications and websites have come up with a variety of warnings and appeals. While some interstitials warn about potential risk to personal information due to insecure network connections, others attempt to take users minds away from privacy concerns. How effective are they? We conducted an online experiment (N = 220) to find out. Our data show that both these strategies backfirewarnings make users less trusting of the site that issues them, and appeals to instant gratification make users more leery of the site. This is because users process these interstitials heuristically, not as systematically as designers seem to assume. These findings hold important implications for the design of cues in mobile interfaces.","shortAbstract":"In order to address the increased privacy and security concerns raised","id":"pn2094"},"session":"People: Personal Information","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2094"},"pn2096":{"lastUpdateTime":1389237026654,"subcommitteeSplit":"","labels":{"Third-party software add-on development":{"dislikes":[],"lastTimeUpdated":1386525286894,"checked":true,"likes":[],"label":"Third-party software add-on development"},"Software Engineering":{"dislikes":[],"lastTimeUpdated":1386525186966,"checked":true,"likes":[],"label":"Software Engineering"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca","bickmore@ccs.neu.edu"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644837}},"creationTime":1664,"content":{"authorList":["Shengdong Zhao, National University of Singapore","XIAOJUN MENG, National University of Singapore","Yongfeng Huang, National University of Singapore","Zhongyuan Zhang, National University of Singapore","James Eagan, Tlcom-ParisTech","Ramanathan Subramanian, University of Illinois at Urbana-Champaign"],"title":"WADE: Simplified GUI Add-on Development for Third-party Software","paperOrNote":"Paper","fullAbstract":"We present the WADE Integrated Development Environment (IDE), which simplifies interface and functionality modification of existing third-party software without access to source code. WADE clones the Graphical User Interface (GUI) of a host program through dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG fashion and (2) to software functionality. We compare WADE with an alternative state-of-the-art runtime toolkit overloading approach in a user-study, whose results demonstrate that WADE significantly simplifies the task of GUI-based add-on development.","shortAbstract":"We present the WADE Integrated Development Environment (IDE), which si","id":"pn2096"},"session":"Systems: GUIs","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn2096"},"pn2090":{"lastUpdateTime":1389238496089,"subcommitteeSplit":"","labels":{"Text Entry":{"dislikes":[],"lastTimeUpdated":1386532221151,"checked":true,"likes":["j.d.hook@ncl.ac.uk"],"label":"Text Entry"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Security":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Security"},"Biometrics":{"dislikes":[],"lastTimeUpdated":1386532280683,"checked":true,"likes":[],"label":"Biometrics"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840665}},"creationTime":1658,"content":{"authorList":["Ulrich Burgbacher, University of Mnster","Klaus Hinrichs, University of Mnster"],"title":"An Implicit Author Verification System for Text Messages Based on Gesture Typing Biometrics","paperOrNote":"Note","fullAbstract":"Gesture typing is a popular text input method used on smartphones. Gesture keyboards are based on word gestures that subsequently trace all letters of a word on a virtual keyboard. Instead of tapping a word key by key, the user enters a word gesture with a single continuous stroke. In this paper, we introduce an implicit user verification approach for short text messages that are entered with a gesture keyboard. We utilize the way people interact with gesture keyboards to extract behavioral biometric features. We propose a proof-of-concept classification framework that learns the gesture typing behavior of a person and is able to decide whether a gestured message was written by the legitimate user or an imposter. We conducted a user study to collect data from gesture keyboard users. This data is used to assess the performance of the classification framework, demonstrating that the technique has considerable promise.","shortAbstract":"Gesture typing is a popular text input method used on smartphones. Ges","id":"pn2090"},"session":"Security: Passwords","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2090"},"pn495":{"lastUpdateTime":1389221756152,"subcommitteeSplit":"","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":["no@spam.org","steimle@media.mit.edu"],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Gaze":{"dislikes":[],"lastTimeUpdated":1386525451344,"checked":true,"likes":["dan@microsoft.com","steimle@media.mit.edu","S.fairclough@ljmu.ac.uk","pierre.dragice@gmail.com","bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca"],"label":"Gaze"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Gaze Interaction":{"dislikes":[],"lastTimeUpdated":1386525441258,"checked":true,"likes":[],"label":"Gaze Interaction"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644784}},"creationTime":300,"content":{"authorList":["Jari Kangas, University of Tampere","Deepak Akkil, University of Tampere","Jussi Rantala, University of Tampere","Poika Isokoski, University of Tampere","Pivi Majaranta, University of Tampere","Roope Raisamo, University of Tampere"],"title":"Gaze Gestures and Haptic Feedback in Mobile Devices","paperOrNote":"Note","fullAbstract":"Anticipating the emergence of gaze tracking capable mobile devices, we are investigating the use of gaze as an input modality in handheld mobile devices. We conducted a study of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as an input method in a mobile device and vibrotactile feedback as a new alternative way to give confirmation of interaction events. Our results show that vibrotactile feedback significantly improved the use of gaze gestures. The tasks were completed faster and rated easier and more comfortable when vibrotactile feedback was provided.","shortAbstract":"Anticipating the emergence of gaze tracking capable mobile devices, we","id":"pn495"},"session":"UIST: Motion and Haptics","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn495"},"pn490":{"lastUpdateTime":1389222165018,"subcommitteeSplit":"","labels":{"Biofeedback":{"dislikes":[],"lastTimeUpdated":1386523125807,"checked":true,"likes":[],"label":"Biofeedback"},"Video Content / Communications":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523574249,"label":"Video Content / Communications"},"CMC":{"checked":false,"lastUpdateTime":1386523417899,"dislikes":[],"label":"CMC","lastTimeUpdated":1386523334676,"likes":[]},"Computer-Mediated Communication":{"checked":false,"lastUpdateTime":1386523573029,"dislikes":[],"label":"Computer-Mediated Communication","lastTimeUpdated":1386523421513,"likes":["smunson@uw.edu"]},"Biometrics":{"dislikes":[],"lastTimeUpdated":1386522877435,"checked":true,"likes":["kris.luyten@uhasselt.be"],"label":"Biometrics"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523574889,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556773}},"creationTime":296,"content":{"authorList":["Chiew Seng Sean Tan, Hasselt University - tUL - iMinds","Kris Luyten, Hasselt University - tUL - iMinds","Johannes Schning, Hasselt University - tUL - iMinds","Karin Coninx, Hasselt University - tUL - iMinds"],"title":"Investigating the Effects of using Biofeedback as Visual Stress Indicator during Video-mediated Collaboration","paperOrNote":"Paper","fullAbstract":"During remote assistance, the instructors guide workers through the problem and instruct them to perform unfamiliar operations. However, the workers' performance might deteriorate due to stress. Recent advances in psychophysiology and biosensor technology have shown that physiological responses of geographically distributed parties can be accessed and displayed as biofeedback. We argue that incorporating biofeedback in a video-mediated interface can improve communication and lead to lower stress for both instructors and workers. This paper presents a thorough investigation on mental workload and stress perceived by pairs of participants performing remote, video-mediated tasks. Twenty participants are paired up in an instructor-worker scenario with interface conditions differing in task, facial and biofeedback communication. Two self-report measures are used to assess mental workload and stress. Results show that pairs reported lower mental workload and stress when instructors are using the biofeedback as compared to using interfaces with facial view. Significant correlations were also found on the task performance with reducing stress (i.e. increased task engagement and decreased worry) for the instructors and declining mental workload (i.e. increased performance) for the workers. Our findings provide insights to advance the development of video-mediated interfaces for remote assistance.","shortAbstract":"During remote assistance, the instructors guide workers through the pr","id":"pn490"},"session":"Health: Stress","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn490"},"pn320":{"lastUpdateTime":1389222073366,"subcommitteeSplit":"A","labels":{"Perception":{"dislikes":[],"lastTimeUpdated":1386523393383,"checked":true,"likes":[],"label":"Perception"},"Design implications":{"dislikes":[],"lastTimeUpdated":1386523386907,"checked":true,"likes":[],"label":"Design implications"},"Modalities":{"dislikes":[],"lastTimeUpdated":1386522879710,"checked":true,"likes":[],"label":"Modalities"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Smell":{"dislikes":[],"lastTimeUpdated":1386522927252,"checked":true,"likes":[],"label":"Smell"},"user experience":{"dislikes":[],"lastTimeUpdated":1386522873787,"checked":true,"likes":[],"label":"user experience"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["e.v.d.hoven@tue.nl"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"human senses":{"dislikes":[],"lastTimeUpdated":1386523379898,"checked":true,"likes":[],"label":"human senses"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Self-reported experiences":{"dislikes":[],"lastTimeUpdated":1386522882343,"checked":true,"likes":[],"label":"Self-reported experiences"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711805}},"creationTime":159,"content":{"authorList":["Marianna Obrist, Newcastle University","Alexandre Tuch, University of Basel","Kasper Hornbk, Department of Computer Science, University of Copenhagen"],"title":"Opportunities for Odor: Experiences with Smell and Implications for Technology","paperOrNote":"Paper","fullAbstract":"Technologies for capturing and generating smell are emerging, and our ability to engineer such technologies and use them in HCI is rapidly developing. Our understanding of how these technologies match the experiences with smell that people have or want to have is surprisingly limited. We therefore investigate the experience of smell and the emotions that accompany it. We collect stories from 439 participants who have described personally memorable smell experiences by means of an online questionnaire. Based on the stories we develop 10 categories of smell experience. We explore the implications of the categories for smell-enhanced technology design by (a) probing participants to envision technologies that match their smell story and (b) having HCI researchers brainstorm technologies using the categories as design stimuli. We discuss how our findings can be beneficial for HCI research concerned with personal memories, momentary and first time experiences, and in relation to research on wellbeing.","shortAbstract":"Technologies for capturing and generating smell are emerging, and our ","id":"pn320"},"session":"UIST: sensible sensory","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn320"},"pn1200":{"lastUpdateTime":1389221773171,"subcommitteeSplit":"","labels":{"Multi-Device User Interfaces":{"dislikes":[],"lastTimeUpdated":1386532075818,"checked":true,"likes":["tomer@moscovich.net","olwal@mit.edu"],"label":"Multi-Device User Interfaces"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840699}},"creationTime":887,"content":{"authorList":["Peter Hamilton, University of Toronto","Daniel Wigdor, University of Toronto"],"title":"Conductor: Enabling and Understanding Cross-Device Interaction","paperOrNote":"Paper","fullAbstract":"The proliferation of inexpensive connected devices has created a situation where a person, at any given moment, is surrounded by interactive computers. Despite this fact, there are very few means by which a user may take advantage of this large number of screens. We present Conductor, a prototype framework which serves as an exemplar for the construction of cross-device applications. We present a series of interaction methods by which users can easily share information, chain tasks across devices, and manage sessions across devices. We also present a cross-device usage scenario which utilizes several cross-device applications built within our prototype framework. We also describe a user study, which helped us to understand how users will take advantage of a large number of devices in support of performance of a sense making task.","shortAbstract":"The proliferation of inexpensive connected devices has created a situa","id":"pn1200"},"session":"Systems: Multi-Device User Interfaces","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1200"},"pn1203":{"lastUpdateTime":1389285580072,"subcommitteeSplit":"A","labels":{"non-native speakers":{"dislikes":[],"lastTimeUpdated":1386524912426,"checked":true,"likes":["eva@ehornecker.de"],"label":"non-native speakers"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["eadar@mit.edu"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Lost and Found in Translation":{"dislikes":[],"lastTimeUpdated":1386524904438,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Lost and Found in Translation"},"Lost In Translation":{"dislikes":[],"lastTimeUpdated":1386525202379,"checked":true,"likes":["dabbish@cmu.edu","sameer.patil@hiit.fi","haochuan@cs.nthu.edu.tw"],"label":"Lost In Translation"},"Multilingual Interfaces":{"dislikes":[],"lastTimeUpdated":1386524000297,"checked":true,"likes":[],"label":"Multilingual Interfaces"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946710}},"creationTime":890,"content":{"authorList":["Bin Xu, Cornell University","Ge Gao, Cornell University","Susan Fussell, Cornell University","Dan Cosley, Cornell University"],"title":"Helping People Use Machine Translation by Showing Two Versions","paperOrNote":"Note","fullAbstract":"We propose to improve real-time communication between people who do not share a common language by making potential problems in the machine translation process more transparent. We developed a prototype chat tool that displays two parallel translations of each chat turn, with the thought that comparing the translations might both highlight problems and provide resources for resolving them. We conducted a user study to investigate how people use and like such an interface compared to a standard single-translation interface. On balance, users preferred two translations to one, using them to both notice differences and infer meaning from uncertain translations, with no increase in workload. This suggests that this specific interface may help improve cross-lingual communication in practical applications, and lays the groundwork for a larger design space around systems that make possible errors visible to support communication.","shortAbstract":"We propose to improve real-time communication between people who do no","id":"pn1203"},"session":"HCI4D: Lost and Found in Translation","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1203"},"pn924":{"lastUpdateTime":1389221709637,"subcommitteeSplit":"","labels":{"social computing":{"checked":false,"lastUpdateTime":1386523665617,"dislikes":[],"label":"social computing","lastTimeUpdated":1386523519736,"likes":["dmrussell@gmail.com"]},"bad reputation":{"dislikes":[],"lastTimeUpdated":1386522980438,"checked":true,"likes":[],"label":"bad reputation"},"social computing issues":{"dislikes":[],"lastTimeUpdated":1386523619616,"checked":true,"likes":[],"label":"social computing issues"},"Privacy":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523591442,"label":"Privacy"},"Landauer Trouble with Computer":{"dislikes":[],"lastTimeUpdated":1386523755135,"checked":true,"likes":[],"label":"Landauer Trouble with Computer"},"Reputation":{"dislikes":[],"lastTimeUpdated":1386523502776,"checked":true,"likes":[],"label":"Reputation"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523584869,"label":"Empirical Methods, Qualitative"},"reputation management":{"dislikes":[],"lastTimeUpdated":1386522468884,"checked":true,"likes":[],"label":"reputation management"},"online reputation":{"dislikes":[],"lastTimeUpdated":1386522947440,"checked":true,"likes":[],"label":"online reputation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556671}},"creationTime":647,"content":{"authorList":["Allison Woodruff, Google"],"title":"Necessary, Unpleasant, and Disempowering: Reputation Management in the Internet Age","paperOrNote":"Paper","fullAbstract":"In this paper, we report on a qualitative study of how users manage their reputation online. We focus particularly on people who are bothered by content online about themselves and how they manage reputation damage and repair. We describe how users view reputation management chores as necessary but unpleasant, and how they feel disempowered to affect their online reputation. Participants were unable to identify feasible repair mechanisms and ultimately failed to resolve their problems. Given the current state of dysfunction indicated by our findings, we advocate for increased HCI research attention to this area.","shortAbstract":"In this paper, we report on a qualitative study of how users manage th","id":"pn924"},"session":"Social: Lonely, Sad and Awful","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn924"},"pn142":{"lastUpdateTime":1389222115080,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531851628,"checked":true,"likes":["olwal@mit.edu"],"label":"Touch Input"},"Smartwatches":{"dislikes":[],"lastTimeUpdated":1386531880158,"checked":true,"likes":["Nchen@microsoft.com","eve.hoggan@hiit.fi","tomer@moscovich.net"],"label":"Smartwatches"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"full body interaction":{"dislikes":[],"lastTimeUpdated":1386531946642,"checked":true,"likes":[],"label":"full body interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386536941791,"checked":true,"likes":[],"label":"Wearables"},"Wearable":{"checked":false,"lastUpdateTime":1386536952102,"dislikes":[],"label":"Wearable","lastTimeUpdated":1386532462766,"likes":["tomer@moscovich.net"]},"Multi-Device User Interfaces":{"dislikes":[],"lastTimeUpdated":1386532326370,"checked":true,"likes":["olwal@mit.edu"],"label":"Multi-Device User Interfaces"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840676}},"creationTime":32,"content":{"authorList":["Xiang 'Anthony' Chen, Carnegie Mellon University","Tovi Grossman, Autodesk Research","Daniel Wigdor, University of Toronto","George Fitzmaurice, Autodesk Research"],"title":"Duet: Exploring Joint Interactions  on a Smart Phone and a Smart Watch","paperOrNote":"Paper","fullAbstract":"The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet  an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This allows us to transform the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on the Duet system provides insights, observations, and guidance for future work. ","shortAbstract":"The emergence of smart devices (e.g., smart watches and smart eyewear)","id":"pn142"},"session":"UIST: Small Devices","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn142"},"pn147":{"lastUpdateTime":1388776618754,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Video":{"dislikes":[],"lastTimeUpdated":1386531641520,"checked":true,"likes":["fanny@dgp.toronto.edu"],"label":"Video"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"cinematography":{"dislikes":[],"lastTimeUpdated":1386531669320,"checked":true,"likes":[],"label":"cinematography"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531632332,"label":"User Interface Design"},"Process Improvement":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531622266,"label":"Process Improvement"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531625201,"label":"Input and Interaction Technologies"},"Animation":{"dislikes":[],"lastTimeUpdated":1386531698819,"checked":true,"likes":[],"label":"Animation"},"photography":{"dislikes":[],"lastTimeUpdated":1386532662573,"checked":true,"likes":[],"label":"photography"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840708}},"creationTime":36,"content":{"authorList":["Neel Joshi, Microsoft Research","Dan Morris, Microsoft Research","Michael Cohen, Microsoft Research"],"title":"Interactively Stylizing Camera Motion","paperOrNote":"Note","fullAbstract":"Movie directors and cinematographers impart style onto video using techniques that are learned through years of experience: camera movement, framing, color, lighting, etc.  Without this requisite experience, and without expensive equipment, it very difficult to control stylistic aspects of a video. We introduce a novel approach for post-hoc editing of one specific aspect of cinematography -- camera motion style -- via an equalizer-like set of controls that manipulates the power spectra of a video's apparent motion path. We explore free manipulation of apparent camera motion as well as the transfer of motion styles from an example video to a new video to create a wide range of stylistic variations. We report on a user study confirming the ability of non-expert users to create motion styles.","shortAbstract":"Movie directors and cinematographers impart style onto video using tec","id":"pn147"},"session":"3D: 3D modeling","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn147"},"pn1330":{"lastUpdateTime":1389238696698,"subcommitteeSplit":"","labels":{"social impact":{"dislikes":[],"lastTimeUpdated":1386521356335,"checked":true,"likes":["teevan@gmail.com","dmrussell@gmail.com"],"label":"social impact"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":1386523474480,"label":"Empirical Methods, Quantitative"},"Twitter":{"dislikes":[],"lastTimeUpdated":1386522507875,"checked":true,"likes":["yardi@umich.edu","gabriela.avram@gmail.com"],"label":"Twitter"},"Social data analysis":{"dislikes":[],"lastTimeUpdated":1386522244803,"checked":true,"likes":[],"label":"Social data analysis"},"Crisis computing":{"dislikes":[],"lastTimeUpdated":1386522221227,"checked":true,"likes":["yardi@umich.edu"],"label":"Crisis computing"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523475600,"label":"Social Computing and Social Navigation"},"Politics":{"dislikes":[],"lastTimeUpdated":1386522853055,"checked":true,"likes":[],"label":"Politics"},"social network and social movement":{"dislikes":[],"lastTimeUpdated":1386522852393,"checked":true,"likes":[],"label":"social network and social movement"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556718}},"creationTime":1000,"content":{"authorList":["Munmun De Choudhury, Microsoft Research","Andres Monroy-Hernandez, Microsoft","Gloria Mark, University of California, Irvine"],"title":"Narco Emotions: Affect and Desensitization in Social Media during the Mexican Drug War","paperOrNote":"Paper","fullAbstract":"Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine relationships of three established affect measures: negative affect, activation, and dominance as observed on Twitter to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010-Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.","shortAbstract":"Social media platforms have emerged as prominent information sharing e","id":"pn1330"},"session":"HCI4D: PolitiCHI","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1330"},"pn1333":{"lastUpdateTime":1389285431303,"subcommitteeSplit":"","labels":{"Video Content / Communications":{"dislikes":[],"lastTimeUpdated":1386522430399,"checked":true,"likes":[],"label":"Video Content / Communications"},"geocaching":{"dislikes":[],"lastTimeUpdated":1386522905026,"checked":true,"likes":[],"label":"geocaching"},"smart city":{"dislikes":[],"lastTimeUpdated":1386523282067,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"smart city"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523657165,"label":"Computer-Mediated Communication"},"Location":{"dislikes":[],"lastTimeUpdated":1386522681745,"checked":true,"likes":["yardi@umich.edu"],"label":"Location"},"geography":{"dislikes":[],"lastTimeUpdated":1386522676495,"checked":true,"likes":["yardi@umich.edu"],"label":"geography"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522397989,"label":"Computer Supported Cooperative Work (CSCW)"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522404133,"label":"Empirical Methods, Qualitative"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556727}},"creationTime":1002,"content":{"authorList":["Jason Procyk, Simon Fraser University, Surrey","Carman Neustaedter, Simon Fraser University","Carolyn Pang, Simon Fraser University","Anthony Tang, University of Calgary","Tejinder Judge, Google Inc. "],"title":"Exploring Video Streaming in Public Settings: Shared Geocaching Over Distance Using Mobile Video Chat","paperOrNote":"Paper","fullAbstract":"Our research explores the use of mobile video chat in public spaces by people participating in parallel experiences, where both a local and remote person are doing the same activity together at the same time. We prototyped a wearable video chat experience and had pairs of friends and family members participate in Shared Geocaching over distance.  Our results show that video streaming works best for navigation tasks but is more challenging to use for fine-grained searching tasks. Video streaming also creates a very intimate experience with a remote partner, but this can lead to distraction from the real world and even safety concerns. Overall, privacy concerns with streaming from a public space were not typically an issue, however, people tended to rely on assumptions of what was acceptable. The implications are that designers should consider appropriate feedback, user disembodiment, and asymmetry when designing for parallel experiences.","shortAbstract":"Our research explores the use of mobile video chat in public spaces by","id":"pn1333"},"session":"Social: Connecting over Video","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1333"},"pn1337":{"lastUpdateTime":1389108016696,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525615585,"label":"Visualization"},"Time-series Data":{"dislikes":[],"lastTimeUpdated":1386525860146,"checked":true,"likes":[],"label":"Time-series Data"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"information visualization":{"checked":false,"lastUpdateTime":1386525949140,"dislikes":[],"label":"information visualization","lastTimeUpdated":1386525487187,"likes":[]},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525545621,"checked":true,"likes":["dan@microsoft.com"],"label":"Information Visualization"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644810}},"creationTime":1006,"content":{"authorList":["Danielle Albers, University of Wisconsin - Madison","Michael Correll, University of Wisconsin, Madison","Michael Gleicher, University of Wisconsin, Madison"],"title":"A Task-Driven Framework for Visualizing Time Series Data","paperOrNote":"Paper","fullAbstract":"Visualizations can support a wide range of comparison judgments. Prior research has shown the effectiveness of specific visualizations for particular tasks, but designers have little guidance for understanding how different tasks,or groups of tasks, may be matched with designs. In this paper, we present a framework for understanding the relationship between types of data interpretation tasks and visual encodings for time series data. Our framework combines prior results from perceptual science and graphical perception to suggest what types of visual encodings will be effective for various categories of tasks. The core of the framework is a classification of designs based on visual variables, mapping, and computational variables. We apply the framework to assess how eight different designs support six time series comparison tasks. A crowd-sourced evaluation confirms the predictions of our framework and provides quantitative insight as to which designs are appropriate for various tasks. We discuss how our framework can be useful in the design and evaluation of other visualization designs.","shortAbstract":"Visualizations can support a wide range of comparison judgments. Prior","id":"pn1337"},"session":"Viz: Visual System Design","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1337"},"pn1336":{"lastUpdateTime":1389221773171,"subcommitteeSplit":"","labels":{"Multi-Device User Interfaces":{"dislikes":[],"lastTimeUpdated":1386532282539,"checked":true,"likes":[],"label":"Multi-Device User Interfaces"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["fanny@dgp.toronto.edu","tomer@moscovich.net","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840659}},"creationTime":1005,"content":{"authorList":["Jishuo Yang, University of Toronto","Daniel Wigdor, University of Toronto"],"title":"Panelrama: Enabling Easy Specification of Cross-Device Web Applications","paperOrNote":"Paper","fullAbstract":"We present Panelrama, a web-based framework for the construction of applications using distributed user interfaces (DUIs). Our implementation provides developers with low migration costs through built-in mechanisms for the synchronization of a UI state, requiring minimal changes to existing languages. Additionally, we describe a solution to categorize device characteristics and dynamically change UI allocation to best-fit devices. We illustrate the use of Panelrama through three sample applications which demonstrate its support for known interaction methods, we also present the results of a developer study, which validates our belief that cross-device application experiences can be easily implemented using our framework. ","shortAbstract":"We present Panelrama, a web-based framework for the construction of ap","id":"pn1336"},"session":"Systems: Multi-Device User Interfaces","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1336"},"pn810":{"lastUpdateTime":1389285488228,"subcommitteeSplit":"B","labels":{"crowdfunding":{"dislikes":[],"lastTimeUpdated":1386522570920,"checked":true,"likes":[],"label":"crowdfunding"},"crowd":{"dislikes":[],"lastTimeUpdated":1386522597869,"checked":true,"likes":[],"label":"crowd"},"failure":{"dislikes":[],"lastTimeUpdated":1386522445464,"checked":true,"likes":[],"label":"failure"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755918}},"creationTime":548,"content":{"authorList":["Michael Greenberg, Northwestern University","Liz Gerber, Northwestern University"],"title":"Learning to Fail: Experiencing Public Failure Online Through Crowdfunding","paperOrNote":"Paper","fullAbstract":"Online crowdfunding platforms like Kickstarter are gaining attention among novice creatives as an effective platform for funding their ventures and engaging in creative work with others. However, a focus on financial success of crowdfunding has obscured the fact that over 58% of crowdfunding projects fail to achieve their funding goals. This population of failed creatives however, gives us an audience to study public creative failure in an online environment. We draw inspiration from work in organizational behavior on failure, and work in Human Computer Interaction (HCI) on online behavior, to study online public failure. Using a mixed-methods approach with data scraped from Kickstarter and interview data with failed crowdfunding project creators, we answer the following question: What do project creators on crowdfunding platforms learn and change through the process of failing? We find that creators who relaunch their projects succeed 43% of the time, and that most individuals find failure to be a positive experience. We conclude the paper with a series of design implications for future creative platforms where public failure is part of the creative process.","shortAbstract":"Online crowdfunding platforms like Kickstarter are gaining attention a","id":"pn810"},"session":"CSCW: interactions in the crowd","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn810"},"pn1020":{"lastUpdateTime":1389236648218,"subcommitteeSplit":"","labels":{"E-Learning and Education":{"dislikes":[],"lastTimeUpdated":1386528091687,"checked":true,"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"label":"E-Learning and Education"},"Multimedia UIs":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386531803672,"label":"Multimedia UIs"},"Content Strategy / Content Creation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531806970,"label":"Content Strategy / Content Creation"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165031}},"creationTime":730,"content":{"authorList":["Ben Lafreniere, University of Waterloo","Tovi Grossman, Autodesk Research","Justin Matejka, Autodesk Research","George Fitzmaurice, Autodesk Research"],"title":"Investigating the Feasibility of Extracting Tool Demonstrations from In-Situ Video Content","paperOrNote":"Paper","fullAbstract":"Short video demonstrations are effective resources for helping users to learn tools in feature-rich software. However manually creating demonstrations for the hundreds (or thousands) of individual features in these programs would be impractical. In this paper, we investigate the potential for identifying good tool demonstrations from within screen recordings of users performing real-world tasks. Using an instrumented image-editing application, we collected workflow video content and log data from actual end users. We then developed a heuristic for selecting demonstration clips, and had the quality of a sample set of clips evaluated by both domain experts and end users. This multi-step approach allowed us to characterize the quality of naturally occurring tool demonstrations, and to derive a list of good and bad features of these videos. Finally, we conducted an initial investigation into the potential of using machine learning techniques to identify good and bad video clips.","shortAbstract":"Short video demonstrations are effective resources for helping users t","id":"pn1020"},"session":"Systems: Tutorials","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1020"},"pn796":{"lastUpdateTime":1387315644733,"subcommitteeSplit":"","labels":{"2D Graphical Interfaces":{"dislikes":[],"lastTimeUpdated":1386525746400,"checked":true,"likes":[],"label":"2D Graphical Interfaces"},"Visualization":{"checked":false,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de","j.alexander@lancaster.ac.uk","benko@microsoft.com"],"lastUpdateTime":1386526370957,"label":"Visualization"},"Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525419545,"label":"Visual Design"},"Video Content / Communications":{"dislikes":[],"lastTimeUpdated":1386525404058,"checked":true,"likes":["bulling@mpi-inf.mpg.de","j.alexander@lancaster.ac.uk","forlines@alumni.cmu.edu","wolfgang@cse.yorku.ca"],"label":"Video Content / Communications"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com"],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"youtube":{"dislikes":[],"lastTimeUpdated":1386525767403,"checked":true,"likes":[],"label":"youtube"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525437148,"label":"User Interface Design"},"Video":{"checked":true,"lastUpdateTime":1386525464751,"dislikes":[],"label":"Video","lastTimeUpdated":1386525324449,"likes":[]},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386526384690,"checked":true,"likes":[],"label":"Information Visualization"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644733}},"creationTime":534,"content":{"authorList":["Abir Al-Hajri, University of British Columbia","Gregor Miller, University of British Columbia","Matthew Fong, University of British Columbia","Sidney Fels, University of British Columbia"],"title":"Visualization of Personal History for Video Navigation","paperOrNote":"Paper","fullAbstract":"We compared two different visualizations of video history in a prototype viewer: Video Tiles and Video Timeline. Video Timeline extends the commonly employed list-based visualization for browsing history by applying sizes to indicate heuristics and visualizing more history items to occupy a full screen. Video Tiles visualizes history items in a grid based layout by following predefined templates based on items heuristics and occurrence. It utilizes the screen space effectively by presenting more history items at a time. These visualizations were investigated against the state-of-art method where participants were asked to share their previously seen affective clips. Our studies show that our visualizations outperform the current method and are perceived as intuitive and strongly preferred to current methods. Based on these results, Video Tiles and Video Timeline provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously seen intervals; this leads to applications such as efficient clip sharing, simpler authoring and video summarization. ","shortAbstract":"We compared two different visualizations of video history in a prototy","id":"pn796"},"session":"Navigating Video","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn796"},"pn2417":{"lastUpdateTime":1389285319334,"subcommitteeSplit":"B","labels":{"Instragram":{"checked":false,"lastUpdateTime":1386522833695,"dislikes":[],"label":"Instragram","lastTimeUpdated":1386522828107,"likes":[]},"Instagram":{"dislikes":[],"lastTimeUpdated":1386522853341,"checked":true,"likes":[],"label":"Instagram"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Engagement":{"dislikes":[],"lastTimeUpdated":1386522156955,"checked":true,"likes":[],"label":"Engagement"},"Photo sharing":{"checked":false,"lastUpdateTime":1386530497092,"dislikes":[],"label":"Photo sharing","lastTimeUpdated":1386523206953,"likes":[]},"Affective Communication":{"dislikes":[],"lastTimeUpdated":1386524490412,"checked":true,"likes":[],"label":"Affective Communication"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":["mmassimi@microsoft.com"],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"photo sharing":{"dislikes":[],"lastTimeUpdated":1386523215549,"checked":true,"likes":[],"label":"photo sharing"},"Faces":{"dislikes":[],"lastTimeUpdated":1386538057902,"checked":true,"likes":[],"label":"Faces"},"faces":{"dislikes":[],"lastTimeUpdated":1386524571992,"checked":true,"likes":[],"label":"faces"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032753}},"creationTime":1938,"content":{"authorList":["Saeideh Bakhshi, Georgia Institute of Technology","David Shamma, Yahoo! Research","Eric Gilbert, Georgia Institute of Technology"],"title":"Faces Engage Us: Photos with Faces Attract More Likes and Comments on Instagram","paperOrNote":"Paper","fullAbstract":"Faces are powerful channels of non-verbal communication. Given the ubiquity of photos in online world, we ask: are photos with faces more engaging than those without? Understanding what type of content might influence engagement, can impact both science and design, influencing production and distribution of content. We study the fundamental issue of engagement on a popular photo sharing community, Instagram, using a corpus of 1M images. We organized our study around two important engagement factors, likes and comments. We study how presence of a face, its age and gender might impact engagement on the photo. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. As far as we know, this is one of the first results describing how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.","shortAbstract":"Faces are powerful channels of non-verbal communication. Given the ubi","id":"pn2417"},"session":"Web: Photo sharing","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2417"},"pn1682":{"lastUpdateTime":1389236845002,"subcommitteeSplit":"B","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"make":{"dislikes":[],"lastTimeUpdated":1386523051297,"checked":true,"likes":[],"label":"make"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"making practices":{"dislikes":[],"lastTimeUpdated":1386523385516,"checked":true,"likes":[],"label":"making practices"},"diy":{"dislikes":[],"lastTimeUpdated":1386522188311,"checked":true,"likes":["aantle@sfu.ca","wendyju@stanford.edu","ztoups@nmsu.edu"],"label":"diy"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755968}},"creationTime":1302,"content":{"authorList":["Martin Murer, University of Salzburg","Mattias Jacobsson, Mobile Life @ SICS","Siri Skillgate, Lund University","Petra Sundstrm, Mobile Life @ SICS"],"title":"Taking Things Apart: Reaching Common Ground and Shared Material Understanding","paperOrNote":"Note","fullAbstract":"In this note we discuss and argue about how taking things apart and disassembling can be meaningful practices in explorative design projects. In particular, we report on an explorative design exercise about taking apart an unfamiliar device. Relating to this design situation, we provide accounts for how collaborative hands-on experience can support reaching common ground and acquiring shared material understanding in an interdisciplinary design team. In the end we reflect and discuss how this may complement our practices regarding materiality and interaction design.","shortAbstract":"In this note we discuss and argue about how taking things apart and di","id":"pn1682"},"session":"Making: how things don't work","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1682"},"pn1684":{"lastUpdateTime":1389221215807,"subcommitteeSplit":"A","labels":{"Pain":{"dislikes":[],"lastTimeUpdated":1386523583651,"checked":true,"likes":[],"label":"Pain"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523328386,"label":"Empirical Methods, Quantitative"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523359786,"label":"User-Centered Design / Human-Centered Design"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Physical Therapy":{"dislikes":[],"lastTimeUpdated":1386523394186,"checked":true,"likes":["mentis@umbc.edu"],"label":"Physical Therapy"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523476104,"label":"User Studies"},"Physical Fitness":{"dislikes":[],"lastTimeUpdated":1386523760868,"checked":true,"likes":[],"label":"Physical Fitness"},"rehabilitation":{"checked":false,"lastUpdateTime":1386523386891,"dislikes":[],"label":"rehabilitation","lastTimeUpdated":1386523320405,"likes":[]},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188181}},"creationTime":1304,"content":{"authorList":["Aneesha Singh, University College London","Annina Klapper, University College London","Jinni Jia, University College London","Antonio Rei Fidalgo, University College London","Ana Tajadura-Jimnez, University College London","Nadia Bianchi-Berthouze, University College London","Amanda Williams, University College London"],"title":"Motivating People with Chronic Pain to do Physical Activity: Opportunities for Technology Design","paperOrNote":"Paper","fullAbstract":"Physical activity is important for improving quality of life in people with chronic pain. However, actual or anticipated pain exacerbation, and lack of confidence when doing physical activity make it difficult to maintain and build physical activity towards long-term goals. Research to guide the design of interactive technology to motivate and support physical activity in people with chronic pain is lacking. We conducted studies with: (1) people with chronic pain to understand what strategies they use to maintain and increase physical activity in daily life and what factors deter them; and (2) pain-specialist physiotherapists to understand how they support such people. Building on this understanding, we investigated the use of auditory feedback to address some of the psychological barriers and needs identified and increase self-efficacy, motivation and confidence in physical activity.  We conclude by discussing further design opportunities based on the overall findings.","shortAbstract":"Physical activity is important for improving quality of life in people","id":"pn1684"},"session":"Health: Exergaming for healthcare","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1684"},"pn2303":{"lastUpdateTime":1389238815508,"subcommitteeSplit":"A","labels":{"design in publics":{"checked":false,"lastUpdateTime":1386523627682,"dislikes":[],"label":"design in publics","lastTimeUpdated":1386523621428,"likes":[]},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"New Design Methods":{"dislikes":[],"lastTimeUpdated":1386523786199,"checked":true,"likes":[],"label":"New Design Methods"},"Presentations":{"dislikes":[],"lastTimeUpdated":1386522939231,"checked":true,"likes":[],"label":"Presentations"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Narrative":{"dislikes":[],"lastTimeUpdated":1386523628230,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"Narrative"},"Design Narrative":{"checked":false,"lastUpdateTime":1386523432748,"dislikes":[],"label":"Design Narrative","lastTimeUpdated":1386523320136,"likes":[]},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711764}},"creationTime":1845,"content":{"authorList":["Larissa Pschetz, Microsoft Research Asia","Koji Yatani, Microsoft Research Asia","Darren Edge, Microsoft Research Asia"],"title":"TurningPoint: Narrative-Driven Presentation Planning","paperOrNote":"Note","fullAbstract":"Once upon a time, people told stories unencumbered by slides. What modern presentations gain through visual slide support, however, is often at the expense of storytelling.  We present TurningPoint, a system for narrative-driven presentation planning in slideware. In a formative study with 15 participants, feedback on TurningPoint use highlights the delicate balance between narrative templates focusing author attention in ways that save time, and fixating attention in ways that limit exploration.","shortAbstract":"Once upon a time, people told stories unencumbered by slides. What mod","id":"pn2303"},"session":"Systems: Presentations","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2303"},"pn2242":{"lastUpdateTime":1389107635350,"subcommitteeSplit":"C","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["kash@diku.dk","mtory@cs.uvic.ca","erinacarroll@gmail.com"],"lastUpdateTime":123456789,"label":"Visualization"},"Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527217579,"label":"Visual Design"},"Interaction techniques":{"checked":false,"lastUpdateTime":1386527486804,"dislikes":[],"label":"Interaction techniques","lastTimeUpdated":1386527270087,"likes":[]},"Sports":{"dislikes":[],"lastTimeUpdated":1386527140038,"checked":true,"likes":[],"label":"Sports"},"information visualization":{"checked":false,"lastUpdateTime":1386527691410,"dislikes":[],"label":"information visualization","lastTimeUpdated":1386526360866,"likes":[]},"Visual System Design / Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527493832,"label":"Visual System Design / Visual Design"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386527704243,"checked":true,"likes":["mtory@cs.uvic.ca"],"label":"Information Visualization"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486648}},"creationTime":1794,"content":{"authorList":["Charles Perin, INRIA","Romain Vuillemot, Harvard","Jean-Daniel Fekete, INRIA"],"title":"A Table! Improving Temporal Navigation in Soccer Ranking Tables","paperOrNote":"Paper","fullAbstract":"This article introduces A Table!, an enhanced soccer ranking table to improve temporal navigation, by combining two novel interaction techniques. Ranking tables order soccer teams as rows, and columns contain e. g., their points or number of scored goals. Because they are a snapshot of a championship at a time t, they are constantly updated with new results. Such updates change the rows vertical order, which makes the tracking of a team, over time, difficult. We observed that current tables on the web do not support such changes very well, are generally hard to read, and lack dynamic interactions. This contrasts with the extensive use of temporal trends by soccer analysts in articles. We introduce two interactive techniques to better explore time: DRAG-CELL is based on direct manipulation of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually explore a championship. An on-line evaluation with 143 participants shows that each technique efficiently supports a set of temporal tasks, not supported by current ranking tables, while not breaking the flow of users. This paves the way for efficiently introducing advanced visual exploration techniques to millions of soccer enthusiasts who use tables everyday, as well as other application domains which use ranking tables.","shortAbstract":"This article introduces A Table!, an enhanced soccer ranking table to ","id":"pn2242"},"session":"Viz: Novel Visual Elements","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2242"},"pn2244":{"lastUpdateTime":1389284843631,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386521768371,"checked":true,"likes":["elainemayhuang@gmail.com"],"label":"Field Study"},"sustainability_and_everyday_practice":{"dislikes":[],"lastTimeUpdated":1386522355506,"checked":true,"likes":["hazas@comp.lancs.ac.uk","rob.comber@ncl.ac.uk"],"label":"sustainability_and_everyday_practice"},"Sustainability":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","jonfroehlich@gmail.com","rob.comber@ncl.ac.uk","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Sustainability"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Home":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Home"},"Semi-autonomous systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Semi-autonomous systems"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446312},"Smart Home":{"label":"Smart Home","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1388762574395}},"creationTime":1796,"content":{"authorList":["Rayoung Yang, University of Michigan","Mark Newman, University of Michigan","Jodi Forlizzi, Carnegie Mellon University"],"title":"Making Sustainability Sustainable: Challenges in the Design of Eco-Interaction Technologies","paperOrNote":"Paper","fullAbstract":"The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared peoples interactions with conventional thermostats with interactions with the Nest. One key finding was that the Nest impacted users pattern of HVAC control, but only for a while, and caused new problems unrealized energy savings. Leveraging these findings, we create a set of design implications for Eco-Interaction, the design of features and human-system interactions with the goal of energy consumption.","shortAbstract":"The smart home is here. One area where smart home devices promise to d","id":"pn2244"},"session":"UBI: Smart Homes","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2244"},"pn1549":{"lastUpdateTime":1389236270605,"subcommitteeSplit":"B","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["mmassimi@microsoft.com","l.ciolfi@shu.ac.uk","daverandall2008@gmail.com","david.kirk@ncl.ac.uk"],"lastUpdateTime":1386537086354,"label":"Older Adults"},"China":{"dislikes":[],"lastTimeUpdated":1386522426297,"checked":true,"likes":[],"label":"China"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"Technology use in under-represented populations":{"dislikes":[],"lastTimeUpdated":1386536515058,"checked":true,"likes":[],"label":"Technology use in under-represented populations"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032776}},"creationTime":1200,"content":{"authorList":["Yuling Sun, ","Xianghua Ding, Fudan University","Silvia Lindtner, Fudan University","Tun Lu, Fudan University","Ning Gu, Fudan University"],"title":"Being Senior and ICT: a Study of ICT Use among Seniors in China","paperOrNote":"Paper","fullAbstract":"Work on technology and ageing often focuses on seniors as physically and cognitively declined, and socially disconnected. However, this view is increasingly challenged for being too simplistic to capture what it really means to be a senior. In this paper, drawing on a qualitative study of 17 seniors and their use of ICT in China, we illustrate how seniors are not defined by their limitations, but multifaceted, shaped by their historical, social, physical and cultural context. After uncovering how seniors self-identity, value and situated ecology have shaped the ways in which they adopt, use and interact with ICT, we call for a number of sensitivities when design for them. ","shortAbstract":"Work on technology and ageing often focuses on seniors as physically a","id":"pn1549"},"session":"Social: Connecting through Social Media","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1549"},"to108":{"lastUpdateTime":1389238216391,"subcommitteeSplit":"","labels":{"user experience":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"user experience"},"mobile":{"dislikes":[],"lastTimeUpdated":1386522845764,"checked":true,"likes":["dan@danielashbrook.com"],"label":"mobile"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"personality inferrence":{"checked":false,"lastUpdateTime":1386528608042,"dislikes":[],"label":"personality inferrence","lastTimeUpdated":1386524188265,"likes":[]},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527803811,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2052,"content":{"authorList":["Rodrigo de Oliveira, Telefonica Research","Mauro Cherubini, Telefonica Research","Nuria Oliver, Telefonica Research"],"title":"Influence of Personality on Satisfaction with Mobile Phone Services","paperOrNote":"TOCHI","fullAbstract":"We propose a conceptual model that explains the relationship between the users personality profile and their satisfaction with basic mobile phone services (calls, messages, and simple GPRS/3G services). The model captures direct and indirect effects on satisfaction by means of two variables: actual mobile phone usage and perceived usability of the related services. We empirically validate the model with data gathered from 603 customers of a telecommunication operator, and find that: (1) extroversion, conscientiousness, and intellect \\ have a significant impact on customer satisfactionpositively for the first two traits and negatively for the latter; (2) extroversion positively influences mobile phone usage; and (3) extroversion and conscientiousness positively influence the users perceived usability of mobile services. Interestingly, usability has the strongest positive impact on satisfaction, whereas mobile phone usage has a negative impact on satisfaction. We discuss key findings of this model and propose several implications for the design of mobile phone services.","shortAbstract":"We propose a conceptual model that explains the relationship between t","id":"to108"},"session":"People: Emotions and Mobiles","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to108"},"to105":{"lastUpdateTime":1389592026292,"subcommitteeSplit":"","labels":{"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386523409848,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"public displays":{"dislikes":[],"lastTimeUpdated":1386527920254,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"public displays"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527756258,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2049,"content":{"authorList":["Nemanja Memarovic, University of Lugano (USI)","Marc Langheinrich, University of Lugano","Keith Cheverst, Lancaster University","Nick Taylor, University of Dundee","Florian Alt, University of Munich"],"title":"P-LAYERS  A layered framework addressing the multi-faceted issues facing community-supporting public display deployments","paperOrNote":"TOCHI","fullAbstract":"The proliferation of digital signage systems has prompted a wealth of research that attempts to use public displays for more than just advertisement or transport schedules, such as their use for supporting communities. However, deploying and maintaining display systems in the wild that can support communities is challenging. Based on the authors experiences in designing and fielding a diverse range of community- supporting public display deployments, we identify a large set of challenges and issues that researchers working in this area are likely to encounter. Grouping them into five distinct layers  (1) hardware, (2) system architecture, (3) content, (4) system interaction, and (5) community interaction design  we draw up the P-LAYERS framework to enable a more systematic appreciation of the diverse range of issues associated with the development, the deployment, and the maintenance of such systems. Using three of our own deployments as illustrative examples, we will describe both our experiences within each individual layer, as well as point out interactions between the layers. We believe our framework provides a valuable aid for researchers looking to work in this space, alerting them to the issues they are likely to encounter during their deployments, and help them plan accordingly.","shortAbstract":"The proliferation of digital signage systems has prompted a wealth of ","id":"to105"},"session":"Displays: Interactive Whitebaords and Public Displays","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to105"},"to104":{"lastUpdateTime":1389284883677,"subcommitteeSplit":"","labels":{"Food":{"dislikes":[],"lastTimeUpdated":1386525477578,"checked":true,"likes":[],"label":"Food"},"sustainability":{"checked":false,"dislikes":[],"likes":["jws@microsoft.com"],"lastUpdateTime":1386528741702,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528734086,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Sustainability"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527703417,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2048,"content":{"authorList":["Eva Ganglbauer, Vienna University of Technology","Geraldine Fitzpatrick, Vienna University of Technology","Rob Comber, Newcastle University"],"title":"Negotiating Food Waste: Using a Practice Lens to Inform Design","paperOrNote":"TOCHI","fullAbstract":"Ecological sustainability is becoming of increasing concern to the HCI community, though little focus has been given yet to issues around food waste. Given the environmental impact of food waste, there is potential to make a significant difference. To understand everyday domestic practices around food and waste, we took a practice lens and carried out a study in 14 households that involved interviews, in-home tours and, in five of the households, a FridgeCam technology probe. The analysis highlights that food waste is the unintended result of multiple moments of consumption dispersed in space and time across other integrated practices such as shopping and cooking, which are themselves embedded in broader contextual factors and values. We highlight the importance of respecting the complex negotiations that people make within given structural conditions and competing values and practices, and suggest design strategies to support dispersed as well as integrated food practices, rather than focusing on waste itself.","shortAbstract":"Ecological sustainability is becoming of increasing concern to the HCI","id":"to104"},"session":"HCI4D: Sustainability and Everyday Practices","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to104"},"to107":{"lastUpdateTime":1389285488228,"subcommitteeSplit":"","labels":{"management":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"management"},"crowdfunding":{"dislikes":[],"lastTimeUpdated":1386524752460,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"crowdfunding"},"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"Qualitative":{"dislikes":[],"lastTimeUpdated":1386525390024,"checked":true,"likes":[],"label":"Qualitative"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527723050,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2051,"content":{"authorList":["Liz Gerber, Northwestern University","Julie Hui, Northwestern University"],"title":"Crowdfunding: Motivations and Deterrents for Participation","paperOrNote":"TOCHI","fullAbstract":"Crowdfunding is changing how, why, and which ideas are brought into existence. With the increasing number of crowdfunded projects, it is important to understand what drives people to either create or fund these projects. To shed light on this new social phenomenon, we present a grounded theory of motivation informed by the first cross-platform qualitative study of the crowdfunding community. By performing 83 semi-structured interviews, we uncover creator motivations which include the desire to raise funds, expand awareness of work, connect with others, gain approval, maintain control, and to learn; and supporter motivations which include the desire to collect rewards, help others, support causes and be part of a community. We also explore deterrents to crowdfunding participation, including, among creators, fear of failure, and, for supporters, lack of trust.  Based on these findings, we provide three emergent design principles to inform the design of effective crowdfunding platforms and support tools.","shortAbstract":"Crowdfunding is changing how, why, and which ideas are brought into ex","id":"to107"},"session":"CSCW: interactions in the crowd","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to107"},"to106":{"lastUpdateTime":1389284893302,"subcommitteeSplit":"","labels":{"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528747046,"checked":true,"likes":[],"label":"Sustainability"},"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"Energy":{"dislikes":[],"lastTimeUpdated":1386527836260,"checked":true,"likes":["rcm@mit.edu"],"label":"Energy"},"sustainability":{"checked":false,"dislikes":[],"likes":["jws@microsoft.com"],"lastUpdateTime":1386528751790,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"Home":{"dislikes":[],"lastTimeUpdated":1386527993654,"checked":true,"likes":["rcm@mit.edu"],"label":"Home"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527709003,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2050,"content":{"authorList":["Tobias Schwartz, Fraunhofer Institute for Applied Information Technology FIT","Gunnar Stevens, University of Siegen","Leonardo Ramirez, Fraunhofer Institute for Applied Information Technology (FIT)","Volker Wulf, University of Siegen and Fraunhofer FIT"],"title":"Uncovering practices of making energy consumption accountable: A phenomenological inquiry","paperOrNote":"TOCHI","fullAbstract":"Reacting to the discussion on global warming, the HCI community has started to explore the design of tools to support responsible energy consumption. An important part of this research focuses on motivating energy savings by providing feedback tools which present consumption metrics interactively. In this line of work, the configuration of feedback has been mainly discussed using cognitive or behavioral factors. This narrow focus, however, misses a highly relevant perspective for the design of technology that supports sustainable lifestyles: to investigate the multiplicity of forms in which individuals or collectives actually consume energy. In this article, we broaden this focus, by taking a phenomenological lens to study how people use off-the-shelf eco-feedback systems in private households to make energy consumption accountable and explainable. By reconstructing accounting practices, we delineate several constitutive elements of the phenomenon of energy usage in daily life. We complement these elements with a description of the sophisticated methods used by people to organize their energy practices and to give a meaning to their energy consumption. We describe these elements and methods, providing examples coming from the fieldwork and uncovering observed strategies to account for consumption. Based on our results, we provide a critical perspective on existing eco-feedback mechanisms and describe several elements for a design rationale for designing support for responsible energy consumption. We argue that interactive feedback systems should not simply be an end, but rather a resource for the construction of the artful practice of making energy consumption accountable.","shortAbstract":"Reacting to the discussion on global warming, the HCI community has st","id":"to106"},"session":"HCI4D: Sustainability Perspectives","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to106"},"to101":{"lastUpdateTime":1389238866997,"subcommitteeSplit":"","labels":{"Field Study":{"checked":false,"lastUpdateTime":1386526425047,"dislikes":[],"label":"Field Study","lastTimeUpdated":1386524106912,"likes":[]},"user experience":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526421323,"label":"user experience"},"health and behavior change":{"dislikes":[],"lastTimeUpdated":1386526453042,"checked":true,"likes":[],"label":"health and behavior change"},"Quantified Health":{"dislikes":[],"lastTimeUpdated":1386528861630,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"Quantified Health"},"natural language interface":{"dislikes":[],"lastTimeUpdated":1386524084622,"checked":true,"likes":[],"label":"natural language interface"},"health":{"checked":true,"dislikes":[],"likes":["jeff@jeffreynichols.com"],"lastUpdateTime":123456789,"label":"health"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527773333,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2045,"content":{"authorList":["Frank Bentley, Yahoo! Labs","Konrad Tollmar, KTH","Peter Stephenson, Humana, Inc.","Laura Levy, Georgia Tech","Brian Jones, Georgia Tech","Scott Robertson, Georgia Institute of Technology","Ed Price, Georgia Tech","Richard Catrambone, Georgia Institute of Technology","Jeffrey Wilson, Georgia Institute of Technology"],"title":"Health Mashups: Presenting Statistical Patterns Between Wellbeing Data and Context in Natural Language to Promote Behavior Change","paperOrNote":"TOCHI","fullAbstract":"People now have access to many sources of data about their health and wellbeing. Yet, most people cannot wade through all of this data to answer basic questions about their long-term wellbeing: Do I gain weight when I have busy days? Do I walk more when I work in the city? Do I sleep better on nights after I work out? \\  \\ We built the Health Mashups system to identify connections that are significant over time between weight, sleep, step count, calendar data, location, weather, pain, food intake, and mood. These significant observations are displayed in a mobile application using natural language, e.g. You are happier on days when you sleep more. We performed a pilot study, made improvements to the system, and then conducted a 90-day trial with 60 diverse participants, learning that interactions between wellbeing and context are highly individual and that our system supported an increased self- understanding that lead to focused behavior changes.","shortAbstract":"People now have access to many sources of data about their health and ","id":"to101"},"session":"Health: Quantified Self","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to101"},"to103":{"lastUpdateTime":1389591309860,"subcommitteeSplit":"","labels":{"arts":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"arts"},"longitudinal field study":{"dislikes":[],"lastTimeUpdated":1386523825769,"checked":true,"likes":[],"label":"longitudinal field study"},"public performance":{"dislikes":[],"lastTimeUpdated":1386523809958,"checked":true,"likes":[],"label":"public performance"},"games":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"games"},"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386522973794,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527759322,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2047,"content":{"authorList":["Steve Benford, University of Nottingham","Chris Greenhalgh, The University of Nottingham","Andy Crabtree, The University of Nottingham","Martin Flintham, The University of Nottingham","Brendan Walker, The University of Nottingham","Joe Marshall, University of Nottingham","Boriana Koleva, The University of Nottingham","Stefan Rennick-Egglestone, The University of Nottingham","Gabriella Giannachi, University of Exeter","Matt Adams, Blast Theory"],"title":"Performance-led Research In The Wild","paperOrNote":"TOCHI","fullAbstract":"We explore the approach of performance-led research in the wild in which artists drive the creation of novel performances with the support of HCI researchers that are then deployed and studied at public performance in cultural settings such as galleries, festivals and on the city streets. We motivate the approach and then describe how it consists of three distinct activities  practice, studies and theory  that are interleaved in complex ways through nine different relationships. We present a historical account of how the approach has evolved over a fifteen-year period, charting the evolution of a complex web of projects, papers and relationships between them. We articulate the challenges of pursuing each activity as well as overarching challenges of balancing artistic and research interests, flexible management of relationships, and finally ethics.","shortAbstract":"We explore the approach of performance-led research in the wild in whi","id":"to103"},"session":"Methods and Models: Turn to the Wild","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to103"},"to102":{"lastUpdateTime":1389221814307,"subcommitteeSplit":"","labels":{"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"interactive storytelling":{"dislikes":[],"lastTimeUpdated":1386525577740,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"interactive storytelling"},"mobile":{"dislikes":[],"lastTimeUpdated":1386528900263,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"mobile"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"cci":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528644901,"label":"cci"},"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386523375736,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527739360,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2046,"content":{"authorList":["Elizabeth Bonsignore, University of Maryland","Alexander Quinn, University of Maryland","Allison Druin, HCIL","Benjamin Bederson, Computer Science Department, University of Maryland"],"title":"Sharing Stories in the Wild: A Mobile Storytelling Case Study Using StoryKit","paperOrNote":"TOCHI","fullAbstract":"Todays mobile devices are equipped with a variety of tools that enable users to capture and share their daily experiences. However, designing authoring tools that effectively integrate the discrete media-capture components of mobile devices to enable rich expression  especially by children  remains a challenge. Evaluating such tools authentically, as they are being used in-situ, can be even more challenging. We detail a long-term, multimethod study on the use of StoryKit, a mobile storytelling application. By taking advantage of a public distribution channel, we were able to evaluate StoryKits use on a scale beyond that usually found in lab settings or limited field trials. Our results show that StoryKits simple but well-integrated interface attracted a high number of dedicated users in education contexts at all levels, including children with special learning needs. We include a discussion of the challenges and opportunities that similar in the wild studies hold for HCI research.","shortAbstract":"Todays mobile devices are equipped with a variety of tools that ena","id":"to102"},"session":"Art: Narratives and Storytelling","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to102"},"pn1525":{"lastUpdateTime":1389285319334,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"dislikes":[],"lastTimeUpdated":1386522218149,"checked":true,"likes":[],"label":"Empirical Methods, Quantitative"},"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528959907,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Social Computing and Social Navigation":{"dislikes":[],"lastTimeUpdated":1386521951631,"checked":true,"likes":["egelman@cs.berkeley.edu","elainemayhuang@gmail.com"],"label":"Social Computing and Social Navigation"},"photo sharing":{"dislikes":[],"lastTimeUpdated":1386521751354,"checked":true,"likes":["lorrie@acm.org"],"label":"photo sharing"},"Privacy":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","a.sasse@cs.ucl.ac.uk","elainemayhuang@gmail.com"],"lastUpdateTime":123456789,"label":"Privacy"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446328}},"creationTime":1180,"content":{"authorList":["Auk Kim, KAIST","Gahgene Gweon, KAIST"],"title":"Photo Sharing of the Subject, by the Owner, for the Viewer  Examining the Subjects Preference","paperOrNote":"Note","fullAbstract":"Photo sharing activities on social networking sites concern not only the person sharing the information (owner) and the person receiving the information (viewer) but also the person who is in the photo (subject). In our exploratory lab study, we asked 29 participants about their comfort level in allowing a photo owner to share a picture containing both the participant (subject) and the owner. Our results show that the photo subject feels more comfortable in sharing a photo when i) the subject is younger, ii) the closeness between the subject and the owner (SO closeness) is higher, and iii) the closeness between the subject and the viewer (SV closeness) is higher. In addition, we observed that both SV and SO closeness are important in determining the subjects picture sharing preference level. ","shortAbstract":"Photo sharing activities on social networking sites concern not only t","id":"pn1525"},"session":"Web: Photo sharing","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1525"},"pn1521":{"lastUpdateTime":1389221191523,"subcommitteeSplit":"","labels":{"Pervasive Health":{"checked":false,"lastUpdateTime":1386532709464,"dislikes":[],"label":"Pervasive Health","lastTimeUpdated":1386532505479,"likes":[]},"exertion interfaces":{"dislikes":[],"lastTimeUpdated":1386532403559,"checked":true,"likes":[],"label":"exertion interfaces"},"exergames":{"dislikes":[],"lastTimeUpdated":1386532381601,"checked":true,"likes":[],"label":"exergames"},"Exergames":{"dislikes":[],"lastTimeUpdated":1386526874747,"checked":true,"likes":["wmoncur@dundee.ac.uk","mark.dunlop@strath.ac.uk","marcodesa@gmail.com","e.karapanos@gmail.com","judy.kay@gmail.com"],"label":"Exergames"},"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":["elaw@mcs.le.ac.uk","marcodesa@gmail.com"],"lastUpdateTime":1386532758812,"label":"Ubiquitous Computing / Smart Environments"},"health and behavior change":{"dislikes":[],"lastTimeUpdated":1386532455895,"checked":true,"likes":[],"label":"health and behavior change"},"Exertion games":{"dislikes":[],"lastTimeUpdated":1386532391815,"checked":true,"likes":[],"label":"Exertion games"},"health care":{"checked":false,"lastUpdateTime":1386532575730,"dislikes":[],"label":"health care","lastTimeUpdated":1386532473584,"likes":[]},"Health Care":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":1386532741420,"label":"Health Care"},"gamification":{"dislikes":[],"lastTimeUpdated":1386527198968,"checked":true,"likes":["dominicfurniss@gmail.com","wmoncur@dundee.ac.uk"],"label":"gamification"},"health":{"checked":false,"lastUpdateTime":1386532737676,"dislikes":[],"label":"health","lastTimeUpdated":1386532445821,"likes":[]},"gameplay experience":{"checked":false,"lastUpdateTime":1386532364753,"dislikes":[],"label":"gameplay experience","lastTimeUpdated":1386527516185,"likes":["mark.dunlop@strath.ac.uk","wmoncur@dundee.ac.uk"]},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["elaw@mcs.le.ac.uk","wmoncur@dundee.ac.uk"],"lastUpdateTime":1386532749492,"label":"User Experience Design / Experience Design"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165053}},"creationTime":1176,"content":{"authorList":["Frank Chen, Stanford University","Abby King, Stanford University","Eric Hekler, Arizona State University"],"title":"Healthifying Exergames: Improving Health Outcomes through Intentional Priming","paperOrNote":"Paper","fullAbstract":"Exergames, video game systems that require exertion and interaction, have been rising in popularity in the past years. However, research on popular exergames shows mixed health benefits, potentially due to minimal energy expenditure intensity levels and decreasing use over time. This paper presents a 2x2 experimental study (N = 44), using a popular exergame, where we vary the framing of intention (e.g., Game play or Exercise) and feedback (e.g., Health or No health feedback) to explore their single and interactive impacts on perceived exertion, objectively measured energy expenditure, affect, and duration of usage in a single session.  Our study showed participants primed with exercise used the system significantly longer than those primed with game play (M = 49.2 2.0 min versus M = 39.3 2.0 min). We discuss our results and design implications, particularly related to the potential utility of focusing less on gamifying health behaviors but instead healthifying games by highlighting the dual purpose of exergames to be both a game and exercise. ","shortAbstract":"Exergames, video game systems that require exertion and interaction, h","id":"pn1521"},"session":"Games: Exergames","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1521"},"pn319":{"lastUpdateTime":1389222073366,"subcommitteeSplit":"","labels":{"Multi-modal":{"checked":false,"lastUpdateTime":1386530399961,"dislikes":[],"label":"Multi-modal","lastTimeUpdated":1386527816679,"likes":[]},"User Experience":{"checked":false,"lastUpdateTime":1386531024292,"dislikes":[],"label":"User Experience","lastTimeUpdated":1386527018873,"likes":[]},"Taste":{"dislikes":[],"lastTimeUpdated":1386527798893,"checked":true,"likes":[],"label":"Taste"},"Flavours":{"dislikes":[],"lastTimeUpdated":1386527894734,"checked":true,"likes":["john.vines@ncl.ac.uk","wmoncur@dundee.ac.uk"],"label":"Flavours"},"user experience":{"dislikes":[],"lastTimeUpdated":1386531021559,"checked":true,"likes":[],"label":"user experience"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Multi-modal interfaces":{"dislikes":[],"lastTimeUpdated":1386528770252,"checked":true,"likes":["wmoncur@dundee.ac.uk"],"label":"Multi-modal interfaces"},"Interaction Design":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Interaction Design"},"User Studies":{"checked":true,"dislikes":[],"likes":["wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165026}},"creationTime":158,"content":{"authorList":["Marianna Obrist, Newcastle University","Rob Comber, Newcastle University","Sriram Subramanian, University of Bristol","Betina Piqueras-Fiszman, University of Oxford","Carlos Velasco, University of Oxford","Charles Spence, Oxford University"],"title":"Temporal, Affective, and Embodied Characteristics of Taste Experiences: A Framework for Design","paperOrNote":"Paper","fullAbstract":"We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings from a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes provoke. We discuss our findings on the basis of established psychological and behavioral phenomenon, highlighting the potential for taste-enhanced design.","shortAbstract":"We present rich descriptions of taste experience through an analysis o","id":"pn319"},"session":"UIST: sensible sensory","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn319"},"pn313":{"lastUpdateTime":1389222102553,"subcommitteeSplit":"A","labels":{"design tools":{"dislikes":[],"lastTimeUpdated":1386524535371,"checked":true,"likes":[],"label":"design tools"},"shape changing interfaces":{"dislikes":[],"lastTimeUpdated":1386523728845,"checked":true,"likes":[],"label":"shape changing interfaces"},"Robots":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Robots"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Software architecture and engineering":{"checked":true,"dislikes":[],"likes":["roudauta@gmail.com"],"lastUpdateTime":1386524313865,"label":"Software architecture and engineering"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081887}},"creationTime":155,"content":{"authorList":["Anne Roudaut, University of Bristol","Rebecca Reed, University of Bristol","Tianbo Hao, University of Bristol","Sriram Subramanian, University of Bristol"],"title":"Changibles: Analyzing and Designing Shape Changing Constructive Assembly","paperOrNote":"Note","fullAbstract":"We introduce Changibles, shape-changing units for constructive assembly. Contrary to existing constructive units that change position and rotation to create shapes or motions, Changibles change their form, thus extending the potential of current systems. The benefits of Changibles are: (1) reduce the number of units needed to create a shape as they can take many forms and thus serve as a multi- functional unit; (2) increase the accuracy of the assembly, for example cubical units can change their curvature to create smooth edges; (3) allow the assembly to reshape on- the-fly into a new shapes without changing the position of units, for example, creating a heart pulsing in and out. We contribute the concept of Changibles as well as an analysis tool which helps the designer to choose the right subset of forms for the units to shift in, to create an assembly representing a set of given objects with most accuracy. To validate our tool, we then contribute a first instantiation of Changibles with six wireless units controlled via an interactive surface.","shortAbstract":"We introduce Changibles, shape-changing units for constructive assembl","id":"pn313"},"session":"UIST: Shape-Changers","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn313"},"pn1238":{"lastUpdateTime":1389236125639,"subcommitteeSplit":"A","labels":{"Relationships":{"dislikes":[],"lastTimeUpdated":1386524413206,"checked":true,"likes":[],"label":"Relationships"},"CMC":{"checked":false,"lastUpdateTime":1386525786076,"dislikes":[],"label":"CMC","lastTimeUpdated":1386525363402,"likes":[]},"Conflict Zone":{"dislikes":[],"lastTimeUpdated":1386525404561,"checked":true,"likes":[],"label":"Conflict Zone"},"cmc":{"checked":false,"lastUpdateTime":1386525785103,"dislikes":[],"label":"cmc","lastTimeUpdated":1386525356864,"likes":[]},"remote intimacy":{"dislikes":[],"lastTimeUpdated":1386524627486,"checked":true,"likes":[],"label":"remote intimacy"},"texting keeps up apart":{"checked":false,"lastUpdateTime":1386525797042,"dislikes":[],"label":"texting keeps up apart","lastTimeUpdated":1386525515598,"likes":[]},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["haochuan@cs.nthu.edu.tw","coye.cheshire@gmail.com"],"lastUpdateTime":1386525751424,"label":"Computer-Mediated Communication"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524424221,"label":"Computer Supported Cooperative Work (CSCW)"},"Computer Support Collaborative Romance":{"checked":false,"lastUpdateTime":1386528318967,"dislikes":[],"label":"Computer Support Collaborative Romance","lastTimeUpdated":1386523303663,"likes":[]},"Computer Supported Collaborative Romance":{"dislikes":[],"lastTimeUpdated":1386524330217,"checked":true,"likes":[],"label":"Computer Supported Collaborative Romance"},"Technology and Close Relationships":{"dislikes":[],"lastTimeUpdated":1386523955834,"checked":true,"likes":[],"label":"Technology and Close Relationships"},"self-esteem":{"dislikes":[],"lastTimeUpdated":1386524637792,"checked":true,"likes":[],"label":"self-esteem"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946625}},"creationTime":920,"content":{"authorList":["Lauren Scissors, Northwestern University","Michael E Roloff, Northwestern University","Darren Gergle, Northwestern University"],"title":"Room for Interpretation: The Role of Self-Esteem  and CMC in Romantic Couple Conflict","paperOrNote":"Paper","fullAbstract":"This work explores the role of communication technologies during romantic couple conflict, and the impact that self-esteem has on behavior, preferences for communication channels, and attitudes about mediated communication during conflict. Results revealed that lower levels of self-esteem and communicating via text messaging (vs. face-to-face) were associated with increased distancing and perceived partner distancing behaviors. Lower levels of self-esteem and using mediated communication were also associated with a greater likelihood of thinking that a conflict had a negative impact on the relationship. Yet, there was no evidence to suggest that individuals with lower levels of self-esteem exhibited more negative behaviors and perceptions in text-based communication than in FtF communication. In addition, lower levels of self-esteem were associated with increased use of and preferences for text-based mediated communication over FtF communication during conflict. Overall, this study suggests that both self-esteem and communication channel impact the nature of romantic couple conflict.","shortAbstract":"This work explores the role of communication technologies during roman","id":"pn1238"},"session":"Social: Computer Mediated Romance","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1238"},"pn799":{"lastUpdateTime":1389221094245,"subcommitteeSplit":"A","labels":{"Video Games":{"dislikes":[],"lastTimeUpdated":1386523999490,"checked":true,"likes":["eva@ehornecker.de"],"label":"Video Games"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"whole body interaction":{"dislikes":[],"lastTimeUpdated":1386523971660,"checked":true,"likes":["eva@ehornecker.de"],"label":"whole body interaction"},"gesture elicitation":{"dislikes":[],"lastTimeUpdated":1386524171596,"checked":true,"likes":[],"label":"gesture elicitation"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386523977611,"checked":true,"likes":["eva@ehornecker.de"],"label":"Gestural interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":1386525606467,"label":"User Studies"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946748}},"creationTime":537,"content":{"authorList":["Chaklam Silpasuwanchai, Kochi University of Technology","Xiangshi Ren, School of InformationKochi University of Technology"],"title":"Jump and Shoot! - Prioritizing Primary and Alternative Body Gestures for Intense Gameplay","paperOrNote":"Note","fullAbstract":"Motion gestures enable natural and intuitive input in video games.  However, game gestures designed by developers may not always be the optimal gestures for players. A key challenge in designing appropriate game gestures lies in the interaction-intensive nature of video games, i.e., several actions/commands may need to be executed concurrently using different body parts.  This study analyzes user preferences in game gestures, with the aim of accommodating high interactivity during gameplay.   Two user-elicitation studies were conducted: first, to determine user preferences, we asked participants to define gestures for common game actions/commands; second, to develop effective concurrently executed or combined gestures, participants were asked to define possible game gestures using different body parts (one and two hands, one and two legs, head, eyes, and torso).  Our findings present a set of suitable and alternative body parts for common game actions/commands.  We also present some simultaneously applied game gestures that assist interaction in highly interactive game situations (e.g., selecting a weapon with the feet while shooting with the hand).  Interesting design implications are further discussed, e.g., transferability between hand and leg gestures.","shortAbstract":"Motion gestures enable natural and intuitive input in video games.  Ho","id":"pn799"},"session":"Games: Games","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn799"},"pn1236":{"lastUpdateTime":1389222141946,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386522174628,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"social media"},"hashtag use":{"checked":false,"lastUpdateTime":1386523422245,"dislikes":[],"label":"hashtag use","lastTimeUpdated":1386522201611,"likes":[]},"Twitter":{"dislikes":[],"lastTimeUpdated":1386522671461,"checked":true,"likes":["jacovi@il.ibm.com","gabriela.avram@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"Twitter"},"Q&A":{"dislikes":[],"lastTimeUpdated":1386522143157,"checked":true,"likes":["teevan@gmail.com","gabriela.avram@gmail.com","sadat@us.ibm.com","emilee@gmail.com"],"label":"Q&A"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523433413,"label":"Social Computing and Social Navigation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556765}},"creationTime":918,"content":{"authorList":["Jeffrey Rzeszotarski, Microsoft Research","Emma Spiro, Microsoft Research","Jorge Matias, Microsoft Research","Andres Monroy-Hernandez, Microsoft Research","Meredith Morris, Microsoft Research"],"title":"Is Anyone Out There? Unpacking Q&A Hashtags on Twitter","paperOrNote":"Note","fullAbstract":"In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with Q&A hashtags, such as #lazyweb or #twoogle. We surveyed Twitter users and found they employ these Q&A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&A exchanges reveals that nearly all replies to hashtagged questions come from a users immediate follower network, contradicting users beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.","shortAbstract":"In addition to posting news and status updates, many Twitter users pos","id":"pn1236"},"session":"Social: Do Ask Do Tell","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1236"},"pn1237":{"lastUpdateTime":1389285111611,"subcommitteeSplit":"A","labels":{"Crowd-sourcing actions":{"dislikes":[],"lastTimeUpdated":1386523769399,"checked":true,"likes":[],"label":"Crowd-sourcing actions"},"Video Analysis":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Analysis"},"Human Computation":{"dislikes":[],"lastTimeUpdated":1386524104411,"checked":true,"likes":[],"label":"Human Computation"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386523854341,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Crowd-Powered Systems"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081848}},"creationTime":919,"content":{"authorList":["Walter Lasecki, University of Rochester","Leon Weingard, University of Rochester","George Ferguson, University of Rochester","Jeffrey Bigham, Carnegie Mellon University"],"title":"Finding Dependencies Between Actions Using the Crowd","paperOrNote":"Note","fullAbstract":"Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train such systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.","shortAbstract":"Activity recognition can provide computers with the context underlying","id":"pn1237"},"session":"UBI: Activity Recognition","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1237"},"pn558":{"lastUpdateTime":1389236111891,"subcommitteeSplit":"","labels":{"urban":{"dislikes":[],"lastTimeUpdated":1386522253507,"checked":true,"likes":["gutwin@cs.usask.ca","dmrussell@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk","myriam.lewkowicz@utt.fr","teevan@gmail.com"],"label":"urban"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"gaming":{"dislikes":[],"lastTimeUpdated":1386522297268,"checked":true,"likes":["dmrussell@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"gaming"},"in the city":{"dislikes":[],"lastTimeUpdated":1386523556447,"checked":true,"likes":[],"label":"in the city"},"smart city":{"dislikes":[],"lastTimeUpdated":1386523113868,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk","emailaddress"],"label":"smart city"},"Supporting Participation":{"dislikes":[],"lastTimeUpdated":1386521699988,"checked":true,"likes":[],"label":"Supporting Participation"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523435850,"label":"Social Computing and Social Navigation"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523432877,"label":"Interaction Design"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522280307,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556679}},"creationTime":344,"content":{"authorList":["Thomas Laureyssens, KHLim","Tanguy Coenen, IBBT-SMIT, Vrije Universiteit Brussel","Laurence Claeys, Vrije Universiteit Brussel","Peter Mechant, Universiteit Gent","Johan Criel, Alcatel Lucent","Andrew Vande Moere, KU Leuven "],"title":"ZWERM: a Modular Component Network Approach for an Urban Participation Game","paperOrNote":"Paper","fullAbstract":"As information technology is increasingly embedded in our cities, opportunities arise to design novel applications that benefit urban communities. We describe the design and evaluation of ZWERM (Dutch for the term swarm), a public game that was specifically designed for augmenting community participation in urban neighborhoods. A network of ten components has been designed, some of which had different interfaces and design approaches: from totem-like Trees for gathering around with RFID cards to playful Sparrows that react on whistle sounds. After implementing the urban game in two city neighborhoods, we investigated the impact of each of these components on their communities. Our insights are useful for the public interaction design of future urban, interactive networks that aim to positively influence community participation and social cohesion. ","shortAbstract":"As information technology is increasingly embedded in our cities, oppo","id":"pn558"},"session":"HCI4D: City Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn558"},"pn730":{"lastUpdateTime":1389221756152,"subcommitteeSplit":"","labels":{"bimanual input":{"dislikes":[],"lastTimeUpdated":1386525734545,"checked":true,"likes":["benko@microsoft.com","bulling@mpi-inf.mpg.de"],"label":"bimanual input"},"Multi-modal Interaction":{"dislikes":[],"lastTimeUpdated":1386525486226,"checked":true,"likes":[],"label":"Multi-modal Interaction"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["petra.isenberg@inria.fr"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Multi-modal interfaces":{"checked":false,"lastUpdateTime":1386530448556,"dislikes":[],"label":"Multi-modal interfaces","lastTimeUpdated":1386530427091,"likes":[]},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"sensor fusion":{"dislikes":[],"lastTimeUpdated":1386525922742,"checked":true,"likes":[],"label":"sensor fusion"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644795},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389106391214}},"creationTime":482,"content":{"authorList":["Theophanis Tsandilas, INRIA","Caroline Appert, CNRS","Anastasia Bezerianos, LRI - U. Paris-Sud11","David Bonnet, Univ Paris-Sud & CNRS"],"title":"Coordination of Tilt and Touch in One- and Two-Handed Use","paperOrNote":"Note","fullAbstract":"The addition of motion sensors to mobile devices has opened new possibilities for combining input modalities like drag and tilt, to increase their input vocabulary. To explore the feasibility of such combinations, we study the usability of gestures that combine both a touch drag and a tilt motion. We consider sixteen directional TilTouch gestures that rely on tilt and touch movements along the four main compass directions, and identify the best combinations in terms of performance and user preferences in both single and two-handed use. \\ ","shortAbstract":"The addition of motion sensors to mobile devices has opened new possib","id":"pn730"},"session":"UIST: Motion and Haptics","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn730"},"pn555":{"lastUpdateTime":1388785673817,"subcommitteeSplit":"B","labels":{"Economics & HCI":{"checked":false,"lastUpdateTime":1386522758284,"dislikes":[],"label":"Economics & HCI","lastTimeUpdated":1386522551611,"likes":["wendyju@stanford.edu"]},"Internationalization / Localization":{"checked":false,"lastUpdateTime":1386523248792,"dislikes":[],"label":"Internationalization / Localization","lastTimeUpdated":1386522871927,"likes":["silvia.lindtner@gmail.com","wendyju@stanford.edu"]},"big data":{"dislikes":[],"lastTimeUpdated":1386521879393,"checked":true,"likes":["reinecke@umich.edu"],"label":"big data"},"Localization":{"dislikes":[],"lastTimeUpdated":1386522778087,"checked":true,"likes":[],"label":"Localization"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["silvia.lindtner@gmail.com","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Visual Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visual Design"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755961}},"creationTime":342,"content":{"authorList":["Katharina Reinecke, Harvard University","Krzysztof Gajos, Harvard University"],"title":"Quantifying Visual Preferences Around the World","paperOrNote":"Paper","fullAbstract":"Website aesthetics have been recognized as an influential moderator of people's behavior and perception.  \\ However, what users perceive as ``good design\" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups. ","shortAbstract":"Website aesthetics have been recognized as an influential moderator of","id":"pn555"},"session":"Viz: Visual Aesthetics","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn555"},"pn951":{"lastUpdateTime":1389591419821,"subcommitteeSplit":"A","labels":{"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523613021,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","mark.hancock@uwaterloo.ca","coye.cheshire@gmail.com"],"label":"eye tracking"},"The Eyes Have It":{"dislikes":[],"lastTimeUpdated":1386526262902,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Eyes Have It"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524972289,"label":"Prototyping"},"Health Care":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Health Care"},"health":{"dislikes":[],"lastTimeUpdated":1386524157956,"checked":true,"likes":[],"label":"health"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524970582,"label":"User Studies"},"Vision":{"dislikes":[],"lastTimeUpdated":1386523607900,"checked":true,"likes":[],"label":"Vision"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946630}},"creationTime":670,"content":{"authorList":["Tarik Crnovrsanin, University of California, Davis","Yang Wang, University of California, Davis","Kwan-Liu Ma, University of California at Davis"],"title":"Stimulating a Blink: Reduction of Eye Fatigue With Visual Stimulus","paperOrNote":"Paper","fullAbstract":"Computers make incredible amounts of information available at our fingertips. As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects. One major concern is the increasing number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision. Since encouraging users to blink more often can partially alleviate CVS, we present a prototype system that periodically stimulates a blink response from users. The system uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, triggers a blink stimulus. We investigate four different types of eyeblink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications. Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results from our user studies show that our stimuli are effective in increasing user blink rate, with screen blurring being the best.","shortAbstract":"Computers make incredible amounts of information available at our fing","id":"pn951"},"session":"Methods and Models: The Eyes Have It","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn951"},"pn950":{"lastUpdateTime":1389236747529,"subcommitteeSplit":"A","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523703299,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"eye tracking"},"Children":{"checked":true,"dislikes":[],"likes":["hilary.hutchinson@gmail.com","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Children"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523180063,"label":"Empirical Methods, Qualitative"},"usable security":{"dislikes":[],"lastTimeUpdated":1386526482488,"checked":true,"likes":["lorrie@acm.org"],"label":"usable security"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526652662,"label":"User Studies"},"Security":{"dislikes":[],"lastTimeUpdated":1386523114740,"checked":true,"likes":[],"label":"Security"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188198}},"creationTime":669,"content":{"authorList":["Yasmeen Hashish, University of Manitoba","Andrea Bunt, University of Manitoba","Jim Young, University of Manitoba"],"title":"Kid-in-the-Loop Content Control:  A Collaborative and Education-oriented Content Filtering Approach","paperOrNote":"Paper","fullAbstract":"We present a kid-in-the-loop approach to content control and filtering where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial kid-in-the-loop prototype (for android devices) which allows parents to work with their children to select appropriate applications, providing parents with the opportunity to educate their children on what they consider to be appropriate or inappropriate.  A formal study with 13 sets of parents and children in the six to eight year-old age group revealed an overwhelmingly favorable response to this approach. Our study results suggest that children learned well, and that parents felt that this approach helped facilitate discussions with their children and make the education more enjoyable and approachable. In addition, the approach provided parents with important insights into their childrens interests and understanding of their notions of appropriate and inappropriate content.","shortAbstract":"We present a kid-in-the-loop approach to content control and fil","id":"pn950"},"session":"HCI4D: Engage & Educate Children","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn950"},"pn734":{"lastUpdateTime":1388776604979,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525653815,"label":"Visualization"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["bickmore@ccs.neu.edu","steimle@media.mit.edu"],"lastUpdateTime":1386525733337,"label":"3D Interaction and Graphics"},"Gaze":{"dislikes":[],"lastTimeUpdated":1386525273414,"checked":true,"likes":["dan@microsoft.com","forlines@alumni.cmu.edu","bulling@mpi-inf.mpg.de","pierre.dragice@gmail.com","j.alexander@lancaster.ac.uk","benko@microsoft.com","aquigley@st-andrews.ac.uk"],"label":"Gaze"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644708}},"creationTime":486,"content":{"authorList":["Michael Mauderer, University of St Andrews","Simone Conte, University of St Andrews","Miguel Nacenta, University of St Andrews","Dhanraj Vishwanath, University of St Andrews"],"title":"Depth Perception with Gaze-contingent Depth of Field","paperOrNote":"Paper","fullAbstract":"Blur in images can create the sensation of depth because it emulates an optical property of the eye; namely, the limited depth of field created by the eye's lens. When the human eye looks at an object, this object appears sharp in the retina, but objects at different distances appear blurred. \\ Advances in gaze-tracking technologies enable us to reproduce dynamic depth of field in regular displays, providing an alternative way of conveying depth.  \\ In this paper we investigate gaze-contingent depth of field as a method to produce realistic 3D images, and analyze how effectively people can use it to perceive depth.  \\ We found that GC DOF increases subjective perceived realism and depth and can contribute to the perception of ordinal depth and distance between objects, but it is limited in its accuracy.","shortAbstract":"Blur in images can create the sensation of depth because it emulates a","id":"pn734"},"session":"3D: The third dimension","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn734"},"pn736":{"lastUpdateTime":1389591788886,"subcommitteeSplit":"A","labels":{"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"digital fabrication":{"dislikes":[],"lastTimeUpdated":1386524051852,"checked":true,"likes":["jws@microsoft.com","roudauta@gmail.com","kris.luyten@uhasselt.be"],"label":"digital fabrication"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081819}},"creationTime":488,"content":{"authorList":["Christian Weichel, Lancaster University","Manfred Lau, Lancaster University","David Kim, Microsoft Research","Nicolas Villar, Microsoft Research","Hans Gellersen, Lancaster University"],"title":"MixFab: a Mixed-Reality Environment for Personal Fabrication","paperOrNote":"Paper","fullAbstract":"Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype.","shortAbstract":"Personal fabrication machines, such as 3D printers and laser cutters, ","id":"pn736"},"session":"Displays: Head-Worn Displays (UIST)","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn736"},"pn1014":{"lastUpdateTime":1389590981688,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523585166,"label":"Empirical Methods, Quantitative"},"Emergency response":{"checked":false,"lastUpdateTime":1386522016770,"dislikes":[],"label":"Emergency response","lastTimeUpdated":1386521880638,"likes":[]},"gatekeeping":{"dislikes":[],"lastTimeUpdated":1386523397335,"checked":true,"likes":[],"label":"gatekeeping"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523281030,"label":"Computer-Mediated Communication"},"Emergency Response":{"dislikes":[],"lastTimeUpdated":1386521882347,"checked":true,"likes":["myriam.lewkowicz@utt.fr","dmrussell@gmail.com","sfussell@cornell.edu"],"label":"Emergency Response"},"Crisis computing":{"dislikes":[],"lastTimeUpdated":1386521950151,"checked":true,"likes":[],"label":"Crisis computing"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523721577,"label":"Computer Supported Cooperative Work (CSCW)"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523586041,"label":"Empirical Methods, Qualitative"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556789}},"creationTime":725,"content":{"authorList":["Alex Leavitt, University of Southern California","Joshua Clark, University of Southern California"],"title":"Upvoting Hurricane Sandy: Event-Based News Production Processes on a Social News Site","paperOrNote":"Paper","fullAbstract":"This paper uses the case of Hurricane Sandy and reddits topical community (subreddit) /r/sandy to examine the production and curation of news content around events on a social news site. Through qualitative analysis, we provide a coded topology of produced content and describe how types of networked gatekeeping impact the framing of a crisis situation. This study also examines, through quantitative modeling, what kind of information becomes negotiated and voted as relevant. We suggest that, contrary to the established literature, highly scored content shared in a social news setting focused more on human-interest media and perspective-based citizen journalism than official news reports. We conclude by discussing how the mechanisms of social news sites conflict with the social norms and culture of reddit to produce differing expectations around news.","shortAbstract":"This paper uses the case of Hurricane Sandy and reddits topical com","id":"pn1014"},"session":"HCI4D: Emergency Response","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1014"},"pn1015":{"lastUpdateTime":1389108600672,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Visualization"},"User Studies":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386531293366,"label":"User Studies"},"individual differences":{"dislikes":[],"lastTimeUpdated":1386530080403,"checked":true,"likes":[],"label":"individual differences"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531299206,"label":"User-Centered Design / Human-Centered Design"},"Agents and Intelligent Systems":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531301427,"label":"Agents and Intelligent Systems"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165038}},"creationTime":726,"content":{"authorList":["Dereck Toker, UBC","Cristina Conati, University of British Columbia","Ben Steichen, University of British Columbia","Giuseppe Carenini, University of British Columbia","Enamul Hoque, University of British Columbia"],"title":"Highlighting Interventions and User Differences: Informing Adaptive Information Visualization Support","paperOrNote":"Paper","fullAbstract":"There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each individual user. These results suggest that it is important to investigate information visualization systems that can dynamically adapt the visual information to each users specific needs. In this paper, we address the question of how to adapt to these needs. In particular, we present a study to evaluate a variety of visual prompts, called interventions, that can be performed on a visualization to help users process it. Our results show that some of the tested interventions performed better than a condition in which no intervention was provided, both in terms of task performance as well as subjective user ratings. We also discuss findings indicating how intervention effectiveness is influenced by individual differences and by task complexity.","shortAbstract":"There is increasing evidence that the effectiveness of information vis","id":"pn1015"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1015"},"pn2424":{"lastUpdateTime":1389236301173,"subcommitteeSplit":"","labels":{"multi-display interfaces":{"dislikes":[],"lastTimeUpdated":1386525826546,"checked":true,"likes":[],"label":"multi-display interfaces"},"Information Spaces":{"dislikes":[],"lastTimeUpdated":1386525094282,"checked":true,"likes":[],"label":"Information Spaces"},"Tabletops":{"dislikes":[],"lastTimeUpdated":1386525651389,"checked":true,"likes":[],"label":"Tabletops"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["steimle@media.mit.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["bickmore@ccs.neu.edu","petra.isenberg@inria.fr","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644773}},"creationTime":1944,"content":{"authorList":["Roman Lissermann, Technische Universitt Darmstadt","Jochen Huber, MIT Media Lab","Jrgen Steimle, Max Planck Institute for Informatics","Martin Schmitz, Technische Universitt Darmstadt","Max Mhlhuser, Technische Universitt Darmstadt"],"title":"Permulin: Support of Mixed-Focus Collaboration  on Multi-View Tabletops","paperOrNote":"Paper","fullAbstract":"We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.","shortAbstract":"We contribute Permulin, an integrated set of interaction and visualiza","id":"pn2424"},"session":"CSCW: Coordination & Collaboration","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn2424"},"pn2420":{"lastUpdateTime":1388786174911,"subcommitteeSplit":"A","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Driving":{"dislikes":[],"lastTimeUpdated":1386523098860,"checked":true,"likes":[],"label":"Driving"},"Haptics":{"dislikes":[],"lastTimeUpdated":1386523256280,"checked":true,"likes":[],"label":"Haptics"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["mulderi@acm.org"],"lastUpdateTime":123456789,"label":"User Interface Design"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Navigation":{"dislikes":[],"lastTimeUpdated":1386522930064,"checked":true,"likes":[],"label":"Navigation"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711761}},"creationTime":1940,"content":{"authorList":["Manoj Prasad, Texas A & M University","Tracy Hammond, Texas A&M University","Daniel Goldberg, Texas A & M University"],"title":"HaptiMoto - Turn-by-Turn Haptic Route Guidance Interface for Motorcyclists","paperOrNote":"Paper","fullAbstract":"A national study by the Australian Transport Safety Bureau (ATS) found that motorcycle rider deaths were nearly 30 times more prevalent than drivers of other vehicles. Motorcycle fatalities represent approximately five percent of all highway deaths each year, yet motorcycles represent just two percent of all registered vehicles in the United States. Motorcyclists are highly exposed on the road and maintaining situational awareness at all times is crucial. Route guidance systems, such as the Garmin, allow users to efficiently navigate between two locations using dynamic visual maps and audio directions. These systems have been well tested on automobilists, but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease motorcyclists situational awareness and vehicle control, and thus increase the chances of an accident. To enable motorcyclists to take advantage of route guidance while maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance system. HaptiMoto uses tactile signals to encode the distance and direction of approaching turns, thus avoiding interference with audio/visual awareness. Evaluations show that HaptiMoto is intuitive for motorcyclists, and a safer alternative to existing solutions. ","shortAbstract":"A national study by the Australian Transport Safety Bureau (ATS) found","id":"pn2420"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2420"},"pn1646":{"lastUpdateTime":1389222136220,"subcommitteeSplit":"B","labels":{"citizen science":{"dislikes":[],"lastTimeUpdated":1386522228241,"checked":true,"likes":[],"label":"citizen science"},"User Studies":{"checked":true,"dislikes":[],"likes":["david.kirk@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Social Activism":{"dislikes":[],"lastTimeUpdated":1386525688300,"checked":true,"likes":[],"label":"Social Activism"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032694}},"creationTime":1273,"content":{"authorList":["Alexandra Eveleigh, University College London","Charlene Jennett, University College London","Ann Blandford, University College London","Philip Brohan, Met Office Hadley Centre","Anna Cox, University College London"],"title":"Designing for Dabblers and Deterring Drop-Outs in Citizen Science","paperOrNote":"Paper","fullAbstract":"In most online citizen science projects, a large proportion of participants contribute in small quantities. To investigate how low contributors differ from committed volunteers, we distributed a survey to members of the Old Weather project, followed by interviews with respondents selected according to a range of contribution levels. The studies reveal a complex relationship between motivations and contribution. Whilst high contributors were deeply engaged by social or competitive features, low contributors described a solitary experience of dabbling in projects for short periods. Since the majority of participants exhibit this small-scale contribution pattern, there is great potential value in designing interfaces to tempt lone workers to complete just another page, or to lure early drop-outs back into participation. This includes breaking the work into components which can be tackled without a major commitment of time and effort, and providing feedback on the quality and value of these contributions.","shortAbstract":"In most online citizen science projects, a large proportion of partici","id":"pn1646"},"session":"Social: Social News","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1646"},"pn1834":{"lastUpdateTime":1389221977983,"subcommitteeSplit":"B","labels":{"Pro-Am":{"dislikes":[],"lastTimeUpdated":1386522404057,"checked":true,"likes":["dr.mark.j.perry@googlemail.com","obristmarianna@gmail.com","daverandall2008@gmail.com","m.rouncefield@lancaster.ac.uk","D.StantonFraser@bath.ac.uk","mc+frenzy@ecs.soton.ac.uk"],"label":"Pro-Am"},"Entertainment":{"checked":false,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":1386523032829,"label":"Entertainment"},"Creativity Support Tools":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523029696,"label":"Creativity Support Tools"},"Music":{"dislikes":[],"lastTimeUpdated":1386538856842,"checked":true,"likes":[],"label":"Music"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":1386522304847,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523035974,"label":"Social Computing and Social Navigation"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521838724,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032755}},"creationTime":1437,"content":{"authorList":["Michaela Hoare, University of Nottingham","Steve Benford, University of Nottingham","Rachel Jones, Instrata Ltd","Natasa Milic-Frayling, Microsoft Research Ltd"],"title":"Coming in from the Margins: Amateur Musicians in the Online Age","paperOrNote":"Paper","fullAbstract":"HCI is increasingly interested in amateurism, but the wider literature suggests that the amateur is a complex and distinctive phenomenon. An interview study reveals the nature of the amateur in the digital age. Even though operating non-professionally at a micro-scale, amateur musicians employ a plethora of online services to sustain local fanbases, reach out to new fans, collaborate internationally, and actively promote both digital and material products. Our findings lead to recommendations for event-oriented promotion tools; community-oriented analytics; tangible and embedded products; and limited-edition digital experiences. We conclude that HCI needs to recognise the amateur as an important class of user, one who is serious about their leisure, and who is also distinct from the professional as from the novice and hobbyist.","shortAbstract":"HCI is increasingly interested in amateurism, but the wider literature","id":"pn1834"},"session":"Art: Performance","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1834"},"pn2330":{"lastUpdateTime":1389221135554,"subcommitteeSplit":"B","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Performance Metrics"},"Empirical Methods, Quantitative":{"dislikes":[],"lastTimeUpdated":1386522564698,"checked":true,"likes":["aantle@sfu.ca"],"label":"Empirical Methods, Quantitative"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386522496183,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"games":{"checked":true,"lastUpdateTime":1386522234723,"dislikes":[],"label":"games","lastTimeUpdated":1386522196622,"likes":["ztoups@nmsu.edu","wendyju@stanford.edu"]},"Evaluation methods":{"dislikes":[],"lastTimeUpdated":1386522535040,"checked":true,"likes":[],"label":"Evaluation methods"},"Children":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Children"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755936}},"creationTime":1869,"content":{"authorList":["Erik Harpstead, Carnegie Mellon University","Christopher MacLellan, Carnegie Mellon University","Vincent Aleven, Carnegie Mellon University","Brad Myers, Carnegie Mellon University"],"title":"Using Extracted Features to Inform Alignment-Driven Design Ideas in an Educational Game","paperOrNote":"Paper","fullAbstract":"As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to formatively assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at a fine enough level of detail to inform design decisions. We present a novel methodology that incorporates analytic metrics with structural data mining to examine the alignment in an open-ended educational game. The approach is based on examining how the game reacts to students solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.","shortAbstract":"As educational games have become a larger field of study, there has be","id":"pn2330"},"session":"Games: Education Games","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2330"},"pn426":{"lastUpdateTime":1389106258392,"subcommitteeSplit":"A","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525548979,"label":"Empirical Methods, Quantitative"},"Multitouchy Feely":{"dislikes":[],"lastTimeUpdated":1386526781521,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Multitouchy Feely"},"Touchy Feely":{"dislikes":[],"lastTimeUpdated":1386526791018,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Touchy Feely"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386524395321,"checked":true,"likes":["eva@ehornecker.de","lorrie@acm.org"],"label":"Multitouch"},"tabletop":{"dislikes":[],"lastTimeUpdated":1386524386610,"checked":true,"likes":["eva@ehornecker.de"],"label":"tabletop"},"Input and Interaction Technologies":{"dislikes":[],"lastTimeUpdated":1386524790043,"checked":true,"likes":[],"label":"Input and Interaction Technologies"},"interactive surfaces":{"dislikes":[],"lastTimeUpdated":1386524905099,"checked":true,"likes":["eva@ehornecker.de"],"label":"interactive surfaces"},"motor control":{"dislikes":[],"lastTimeUpdated":1386524432539,"checked":true,"likes":[],"label":"motor control"},"get a grip":{"dislikes":[],"lastTimeUpdated":1386524750572,"checked":true,"likes":[],"label":"get a grip"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946658},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389106250356}},"creationTime":245,"content":{"authorList":["Halla OLAFSDOTTIR, Universit Paris-Sud XI","Theophanis Tsandilas, In Situ, INRIA Saclay, LRI Universit Paris-Sud","Caroline Appert, CNRS, Univ Paris Sud & INRIA"],"title":"Movement Planning: Grip Orientation for Multitouch Interaction on Tabletops","paperOrNote":"Paper","fullAbstract":"Substantial amount of research has focused on how people interact with objects in the physical world. This work has unveiled that when manipulating objects, people show strong signs of prospective motor control, i.e., their initial movements are shaped according to their future intentions for the object. Multitouch tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge no previous work has explored whether movement planning is observed in this context. With this project we want to identify if the principles of movement planning extend to object manipulation within the tabletops 2D space. If found true, this knowledge has potential implications for the design of tabletop interfaces. To test this we ran three experiments on a tabletop. We systematically studied how users place their fingers when asked to translate or/and rotate virtual object in order to reach a target. Our results demonstrate that target position and orientation significantly effect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects.","shortAbstract":"Substantial amount of research has focused on how people interact with","id":"pn426"},"session":"Touch: Multitouchy Feely","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn426"},"pn1586":{"lastUpdateTime":1389590785782,"subcommitteeSplit":"","labels":{"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525642781,"label":"Multimedia UIs"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","aquigley@st-andrews.ac.uk","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Creativity Support Tools":{"checked":false,"dislikes":[],"likes":["dan@microsoft.com"],"lastUpdateTime":1386525636203,"label":"Creativity Support Tools"},"Music":{"dislikes":[],"lastTimeUpdated":1386525473908,"checked":true,"likes":[],"label":"Music"},"Interactive Machine Learning":{"dislikes":[],"lastTimeUpdated":1386525655701,"checked":true,"likes":[],"label":"Interactive Machine Learning"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525634249,"label":"Input and Interaction Technologies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644827}},"creationTime":1228,"content":{"authorList":["Nicholas Bryan, Stanford University","Gautham Mysore, Adobe Systems Inc.","Ge Wang, Stanford University"],"title":"ISSE: An Interactive Source Separation Editor","paperOrNote":"Paper","fullAbstract":"Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.).  Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE--a new interactive source separation editor.  ISSE is an open-source, freely available, and cross-platform audio editing tool which enables a user to perform single-channel source separation by painting on time-frequency visualizations of sound.  The system  leverages a new interaction paradigm and separation algorithm that learns from user-feedback to perform separation, resulting in an interactive machine learning system. For evaluation, we conducted user studies and compared results between inexperienced and expert users.  For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality. ","shortAbstract":"Traditional audio editing tools do not facilitate the task of separati","id":"pn1586"},"session":"UBI: Audio Interaction","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1586"},"pn1642":{"lastUpdateTime":1389236351048,"subcommitteeSplit":"","labels":{"Office and Workplace":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523117164,"label":"Office and Workplace"},"Community Management":{"dislikes":[],"lastTimeUpdated":1386522388290,"checked":true,"likes":[],"label":"Community Management"},"implicit structure and organization":{"dislikes":[],"lastTimeUpdated":1386522803265,"checked":true,"likes":["emailaddress"],"label":"implicit structure and organization"},"Academia":{"dislikes":[],"lastTimeUpdated":1386522737983,"checked":true,"likes":[],"label":"Academia"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522330643,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522325413,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556738}},"creationTime":1270,"content":{"authorList":["Juri Dachtera, Universitt Siegen","David Randall, University of Siegen","Volker Wulf, University of Siegen and Fraunhofer FIT"],"title":"Research on Research: Design Research at the Margins: Academia, Industry and End-Users","paperOrNote":"Paper","fullAbstract":"Design research processes often take place in publicly funded projects. Besides designers and users, public funding increasingly requires industry partners to participate in such projects. We present empirical insights from a joint research project in order to both assess the claims connected with such funding structures and to report on challenges for design research within them. We identify three themes of conflict between academic and industry partners and elaborate on the sources of them. The presentation of our results builds on the distinction between 'academia' and 'industry', which is frequently applied by political funding agencies. The analysis of the respective stakeholders' actual interests, however, will prove such a dichotomy to be misleading and simplistic.","shortAbstract":"Design research processes often take place in publicly funded projects","id":"pn1642"},"session":"Design: Design Theory","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1642"},"pn1587":{"lastUpdateTime":1389238815508,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525298292,"label":"Visualization"},"Information Visualization":{"checked":false,"lastUpdateTime":1386525331792,"dislikes":[],"label":"Information Visualization","lastTimeUpdated":1386525221780,"likes":["elm@purdue.edu"]},"Visual Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525424561,"label":"Visual Design"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":["wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Presentation tool":{"dislikes":[],"lastTimeUpdated":1386525384374,"checked":true,"likes":[],"label":"Presentation tool"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644819}},"creationTime":1229,"content":{"authorList":["Pei-Yu Chi, Microsoft Research","Bongshin Lee, Microsoft Research","Steven Drucker, Microsoft Research"],"title":"DemoWiz: Re-Performing Software Demonstrations for a Live Presentation","paperOrNote":"Paper","fullAbstract":"Showing a live demonstration during a talk can be engaging, but it is often not easy to perform an effective live software demonstration. Presenters may struggle with (or worry about) unexpected software crashes and often face issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present the system with pre-recorded videos. It is, however, difficult to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations as well as better control of timing. A user study shows that DemoWiz significantly improves the presenters perceived ease of narration and timing compared to a system without visualizations, which is similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.","shortAbstract":"Showing a live demonstration during a talk can be engaging, but it is ","id":"pn1587"},"session":"Systems: Presentations","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1587"},"to122":{"lastUpdateTime":1389591294775,"subcommitteeSplit":"","labels":{"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386523363092,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"place-based identity":{"dislikes":[],"lastTimeUpdated":1386524604918,"checked":true,"likes":[],"label":"place-based identity"},"local communities":{"dislikes":[],"lastTimeUpdated":1386524505318,"checked":true,"likes":[],"label":"local communities"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527763095,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2061,"content":{"authorList":["John M. Carroll, School of Information Sciences and Technology","Mary Beth Rosson, http://www.chiplace.org/content/Members/show-profile.jsp?id=213"],"title":"Wild at Home: The Neighborhood as a Living Laboratory for HCI","paperOrNote":"TOCHI","fullAbstract":"HCI can turn to the wild but still stay home. Local community life presents a rich context for understanding challenges and possibilities of information technology. We summarize and reflect upon a program of participatory design research in which we facilitated activities and experiences of our neighbors through developing a series of community-oriented programs and information systems through the past two decades. We organize these reflections around five overlapping themes: visibility of community actors, creation of community information infrastructures, the role of place-based identity and activity in community, the effectiveness of participatory relationships, and the research designs and methods appropriate. We frame these reflections around a conceptual model of community, and the suggestion that the local community can be a living laboratory for HCI in the wild.","shortAbstract":"HCI can turn to the wild but still stay home. Local community li","id":"to122"},"session":"Methods and Models: Turn to the Wild","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to122"},"to127":{"lastUpdateTime":1389284893302,"subcommitteeSplit":"","labels":{"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528769509,"checked":true,"likes":[],"label":"Sustainability"},"sustainability":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528771876,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"special issue - sustainability":{"dislikes":[],"lastTimeUpdated":1386523571643,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - sustainability"},"post-apocalyptic design":{"dislikes":[],"lastTimeUpdated":1386528170229,"checked":true,"likes":[],"label":"post-apocalyptic design"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527765426,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2064,"content":{"authorList":["Bill Tomlinson, University of California, Irvine","Eli Blevis, School of Informatics & Computing, Indiana University","Bonnie Nardi, University of California, Irvine","Donald J. Patterson, University of California, Irvine","M. Six Silberman, University of California, Irvine","Yue Pan, School of Informatics & Computing, Indiana University, Bloomington"],"title":"Collapse Informatics and Practice: Theory, Method, and Design","paperOrNote":"TOCHI","fullAbstract":"What happens if efforts to achieve sustainability fail? Research in many fields argues that contemporary global industrial civilization will not persist indefinitely in its current form, and may, like many past human societies, eventually collapse. Arguments in environmental studies, anthropology, and other fields indicate that this transformation could begin within the next half-century. While imminent collapse is far from certain, it is prudent to consider now how to develop sociotechnical systems for use in these scenarios. We introduce the notion of collapse informatics-the study, design, and development of sociotechnical systems in the abundant present for use in a future of scarcity. We sketch the design space of collapse informatics and a variety of example projects. We ask how notions of practice-theorized as collective activity in the \"here and now\"-can shift to the future since collapse has yet to occur.  ","shortAbstract":"What happens if efforts to achieve sustainability fail? Research in ma","id":"to127"},"session":"HCI4D: Sustainability Perspectives","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to127"},"pn1783":{"lastUpdateTime":1389108184489,"subcommitteeSplit":"","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Visualization":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Visualization"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"input":{"dislikes":[],"lastTimeUpdated":1386532108761,"checked":true,"likes":["tomer@moscovich.net"],"label":"input"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840662}},"creationTime":1393,"content":{"authorList":["Jan Balata, Czech Technical University in Prague","Ladislav Cmolik, Czech Technical University in Prague","Zdenek Mikovec, Czech Technical University in Prague"],"title":"On the Selection of 2D Objects using External Labeling","paperOrNote":"Note","fullAbstract":"We present an external labeling laid over small and/or overlapping 2D objects as an efficient representation for their selection. The approximation of objects with points allows us to transform the labeling problem to graph layout problem, which we solve by means of force-based algorithm. The input parameters allows us to influence the resulting layout of the label boxes (e.g. adapt their distance for imprecise input devices). In a study with 15 participants two implementations of our algorithm were compared against labeling method,where all label boxes share the same offset from corresponding objects. Our implementation that introduce a special functionality (temporary freezing of the label box position recalculation) was 14% faster with a comparable accuracy. The subjective evaluation revealed that our implementation with temporary freezing  is perceived as most comfortable, fastest and most accurate.","shortAbstract":"We present an external labeling laid over small and/or overlapping 2D ","id":"pn1783"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1783"},"to118":{"lastUpdateTime":1389222230397,"subcommitteeSplit":"","labels":{"optimized keyboard layout":{"dislikes":[],"lastTimeUpdated":1386525560161,"checked":true,"likes":[],"label":"optimized keyboard layout"},"text input":{"dislikes":[],"lastTimeUpdated":1386525486328,"checked":true,"likes":[],"label":"text input"},"text entry":{"checked":false,"lastUpdateTime":1386525659200,"dislikes":[],"label":"text entry","lastTimeUpdated":1386525503175,"likes":[]},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386525663001,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"Text Entry"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527706476,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2059,"content":{"authorList":["Will Walmsley, University of Toronto","W. Xavier Snelgrove, University of Toronto","Khai Truong, University of Toronto"],"title":"Disambiguation of Imprecise Input with One-dimensional Rotational Text Entry","paperOrNote":"TOCHI","fullAbstract":"We introduce a distinction between disambiguation supporting continuous vs. discrete ambiguous text entry. With continuous ambiguous text entry methods, letter selections are treated as ambiguous due to expected imprecision rather than due to discretized letter groupings. We investigate the simple case of a one-dimensional character layout to demonstrate the potential of techniques designed for imprecise entry. Our rotation-based sight-free technique, Rotext, maps device orientation to a layout optimized for disambiguation, motor efficiency, and learnability. We also present an audio feedback system for efficient selection of disambiguated word candidates, and explore the role that time spent acknowledging word-level feedback plays in text entry performance. Through a user study, we show that despite missing on average by 2.462.92 character positions, with the aid of a maximum a posteriori (MAP) disambiguation algorithm, users can average sight-free entry speed of 12.6 wpm with 98.9% accuracy within 13 sessions (4.3 hours). In a second study, expert users are found to reach 21 wpm with 99.6% accuracy after session 20 (6.7 hours) and continue to grow in performance, with individual phrases entered at up to 37 wpm. A final study revisits the learnability of the optimized layout. Our modelling of ultimate performance indicates maximum overall sight-free entry speeds of 29.0 wpm with audio feedback, or 40.7 wpm if an expert user could operate without relying on audio feedback.","shortAbstract":"We introduce a distinction between disambiguation supporting continuou","id":"to118"},"session":"UIST: Text Entry and Evaluation","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to118"},"pn1651":{"lastUpdateTime":1389221449828,"subcommitteeSplit":"A","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386524351345,"checked":true,"likes":[],"label":"gestures"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Development Tools / Toolkits / Programming Environments":{"dislikes":[],"lastTimeUpdated":1386523982493,"checked":true,"likes":["dan@danielashbrook.com","nebeling@inf.ethz.ch","fabio.paterno@isti.cnr.it"],"label":"Development Tools / Toolkits / Programming Environments"},"Pen-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen-based UIs"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081890}},"creationTime":1276,"content":{"authorList":["Hao L, University of Washington","James Fogarty, University of Washington","Yang Li, Google Research"],"title":"Gesture Script: Recognizing Gestures and their Structure using Rendering Scripts and Interactively Trained Parts","paperOrNote":"Paper","fullAbstract":"Gesture-based interactions have become an essential part of the modern user interface. However, it remains challenging for developers to create gestures for their applications. In this paper, we study unistroke gestures, an important category of gestures defined by their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke gesture recognizers. Different from existing work, Gesture Script enhances the example-based learning with interactive declarative guidance through rendering scripts and interactively trained parts. The structural information from the rendering scripts allows the system to synthesize gesture variations and generate a more accurate recognizer that also automatically extracts gesture attributes for further UI interactions. The results of our user study show that Gesture Script preserves the threshold of familiar example based gesture tools, while raising the ceiling of the recognizers created in such tools.","shortAbstract":"Gesture-based interactions have become an essential part of the modern","id":"pn1651"},"session":"UIST: Gesture Entry","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1651"},"to117":{"lastUpdateTime":1389284883677,"subcommitteeSplit":"","labels":{"Visualization":{"dislikes":[],"lastTimeUpdated":1386528956542,"checked":true,"likes":[],"label":"Visualization"},"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528776333,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Sustainability"},"user experience":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528777633,"label":"user experience"},"sustainability":{"checked":false,"dislikes":[],"likes":["jws@microsoft.com"],"lastUpdateTime":1386528809301,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"special issue - sustainability":{"checked":false,"lastUpdateTime":1386523490811,"dislikes":[],"label":"special issue - sustainability","lastTimeUpdated":1386523446735,"likes":[]},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527768184,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2058,"content":{"authorList":["Cecilia Katzeff, Energy Design","Loove Broms, Centre for Sustainable Communications","Li Jnsson, The Royal Danish Academy of Fine Arts, School of Design","Ulrika Westholm, Energy Design","Minna Rsenn, School of Natural Science, Technology and Environmental Studies"],"title":"Exploring Sustainable Practices in Workplace Settings through Visualizing Electricity Consumption","paperOrNote":"TOCHI","fullAbstract":"Peoples domestic habits are increasingly being targeted to reduce levels of CO2 emissions. Whereas domestic energy consumption has received a lot of attention with several reported studies on sustainable practices, there are very few studies on workplace practices. Nevertheless, these are considered as having much potential for reducing energy consumption. This paper presents the findings from two field studies where two different types of prototypes for visualizing energy use were designed, implemented and evaluated in different types of workplace settings  factories and offices. The studies used design probes to explore how visual feedback for electricity use was interpreted and acted upon by employees in work settings. A striking observation was that it is very difficult to get people to change to more pro-environmental behavior and practices in a workplace environment. The paper discusses why this might be the case.","shortAbstract":"Peoples domestic habits are increasingly being targeted to reduce l","id":"to117"},"session":"HCI4D: Sustainability and Everyday Practices","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to117"},"to114":{"lastUpdateTime":1389222210195,"subcommitteeSplit":"","labels":{"constructivist":{"dislikes":[],"lastTimeUpdated":1386527057403,"checked":true,"likes":[],"label":"constructivist"},"arts":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"arts"},"peer learning":{"dislikes":[],"lastTimeUpdated":1386527040518,"checked":true,"likes":[],"label":"peer learning"},"Music":{"dislikes":[],"lastTimeUpdated":1386526989731,"checked":true,"likes":[],"label":"Music"},"tabletop":{"dislikes":[],"lastTimeUpdated":1386526985771,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"tabletop"},"Tangible UIs":{"dislikes":[],"lastTimeUpdated":1386528447369,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Tangible UIs"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"Tangibles":{"checked":false,"lastUpdateTime":1386528494874,"dislikes":[],"label":"Tangibles","lastTimeUpdated":1386528491199,"likes":[]},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527712875,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2057,"content":{"authorList":["Anna Xamb, Open University","Eva Hornecker, Bauhaus-Universitt Weimar","Paul Marshall, University College London","Sergi Jord, Universitat Pompeu Fabra","Chris Dobbyn, Open University","Robin Laney, Open University"],"title":"Lets Jam the Reactable: Peer Learning during Musical Improvisation with a Tabletop Tangible Interface","paperOrNote":"TOCHI","fullAbstract":"There has been little research on how interactions with tabletop and tangible user interfaces (TUIs) by groups of users change over time. In this article we investigate the challenges and opportunities of a tabletop tangible interface based on constructive building blocks. We describe a long-term lab study of groups of expert musicians improvising with the Reactable, a commercial tabletop TUI for music performance. We examine interaction, focusing on interface, tangible, musical, and social phenomena. Our findings reveal a practice-based learning between peers in situated contexts, and new forms of participation, all of which is facilitated by the Reactables tangible interface, if compared to traditional musical ensembles. We summarise our findings as a set of design considerations and conclude that construction processes on interactive tabletops support learning by doing and peer learning, which can inform constructivist approaches to learning with technology.","shortAbstract":"There has been little research on how interactions with tabletop and t","id":"to114"},"session":"UIST: Tangibles","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to114"},"to112":{"lastUpdateTime":1389236111891,"subcommitteeSplit":"","labels":{"sustainability":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528739865,"label":"sustainability"},"special issue - sustainability":{"dislikes":[],"lastTimeUpdated":1386523607788,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - sustainability"},"hci4d":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"hci4d"},"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528738038,"checked":true,"likes":[],"label":"Sustainability"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527743187,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2055,"content":{"authorList":["Nicola J Bidwell, University of Pretoria","Masbulele Siya, University of Pretoria","Gary Marsden, Department of Computer Science, University of Cape Town","William D Tucker, University of the Western Cape (UWC)","M Tshemese, University of Pretoria","N Gaven, University of Pretoria","S Ntlango, University of Pretoria","Simon Robinson, FIT Lab, Swansea University, Swansea, W. Glam","Kristen Eglinton, University of Surrey"],"title":"Walking and the Social Life of Solar Charging in Rural Africa","paperOrNote":"TOCHI","fullAbstract":"We consider practices that sustain social and physical environments beyond those dominating sustainable HCI discourse. We describe links between walking, sociality, and using resources in a case study of community-based, solar, cellphone charging in villages in South Africas Eastern Cape. Like 360 million rural Africans, inhabitants of these villages are poor and, like 25% and 92% of the world, respectively, do not have domestic electricity or own motor vehicles. We describe nine practices in using the charging stations we deployed. We recorded 700 people using the stations, over a year, some regularly. We suggest that the way we frame practices limits insights about them, and consider various routines in using and sharing local resources to discover relations that might also feature in charging. Specifically, walking interconnects routines in using, storing, sharing and sustaining resources, and contributes to knowing, feeling, wanting and avoiding as well as to different aspects of sociality, social order and perspectives on sustainability. Along the way, bodies acquire literacies that make certain relationalities legible. Our study shows we cannot assert what sustainable practice means a priori and, further, that detaching practices from bodies and their paths limits solutions, at least in rural Africa. Thus, we advocate a more alongly integrated approach to data about practices.","shortAbstract":"We consider practices that sustain social and physical environments be","id":"to112"},"session":"HCI4D: City Communities","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to112"},"to113":{"lastUpdateTime":1389221887645,"subcommitteeSplit":"","labels":{"aging":{"checked":false,"lastUpdateTime":1386528241916,"dislikes":[],"label":"aging","lastTimeUpdated":1386525117932,"likes":[]},"health":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"health"},"Aging":{"dislikes":[],"lastTimeUpdated":1386528239735,"checked":true,"likes":[],"label":"Aging"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527746090,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2056,"content":{"authorList":["Q. Vera Liao, University of Illinois at Urbana-Champaign","Wai-Tat Fu, University of Illinois at Urbana-Champaign"],"title":"Age Differences in Credibility Judgments of Online Health Information","paperOrNote":"TOCHI","fullAbstract":"Older adults are a notable group among the exponentially growing population of online health information consumers. In order to better support older adults health-related information seeking on the Internet, it is important to understand how they judge the credibility of such information when compared to younger users. We conducted two laboratory studies to explore how the credibility cues in message contents, website features, and user generated comments differentially impact younger (19 to 26 years of age) and older adults (58 to 80 years of age) credibility judgments. Results from the first experiment showed that older adults were less sensitive to the credibility cues in message contents and website features than younger adults. Verbal protocol analysis revealed that these differences could be caused by higher tendency in older adults to passively accept Web information and lack deliberation on its quality, as well as attention towards contextual Web features. In the second experiment, we studied how credibility cues from user reviews might differentially impact older and younger adults credibility judgments of online health information. Results showed that consistent credibility cues in user reviews and message contents could facilitate older adults credibility judgment. Older adults, compared to younger ones, were less swayed by highly appraising user reviews given to low credibility information. These results provide important implications for designing health information technologies to better fit the older population. ","shortAbstract":"Older adults are a notable group among the exponentially growing popul","id":"to113"},"session":"Health: Older Adults","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to113"},"to110":{"lastUpdateTime":1389284893302,"subcommitteeSplit":"","labels":{"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528784381,"checked":true,"likes":[],"label":"Sustainability"},"sustainability":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528786109,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":["Mark.blythe@northumbria.ac.uk"],"lastUpdateTime":123456789,"label":"design"},"practice theory":{"dislikes":[],"lastTimeUpdated":1386526135634,"checked":true,"likes":[],"label":"practice theory"},"special issue - sustainability":{"dislikes":[],"lastTimeUpdated":1386523560743,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - sustainability"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527788865,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2053,"content":{"authorList":["Ron Wakkary, Simon Fraser University","Audrey Desjardins, Simon Fraser University","Sabrina Hauser, Simon Fraser University","Leah Maestri, Simon Fraser University, SFU"],"title":"A Sustainable Design Fiction: Green Practices","paperOrNote":"TOCHI","fullAbstract":"In this paper, we argue that an approach informed by practice theory coupled with design fiction provides useful insights into the role of interaction design with respect to environmental sustainability. We argue that a practice-oriented approach can help interaction designers step away from models of individual behavior and studies of artifacts towards seeing sustainable behaviors as part of multidimensional and interrelated practices and practice elements. We analyze two previously conducted studies. The first study of everyday repair focuses on how people repair their broken objects. The second study of green-DIY examines how green enthusiasts facilitate their practices of making sustainable DIY (do-it-yourself) projects. We describe the practices of everyday repairers and green enthusiasts in terms of materials, competences, and meanings, and the interrelations among those elements, using the framework of Shove et al. (2012). We argue that understanding the dynamics of practice and their unique configurations is a starting point to redefine the roles of sustainable interaction design (SID). We propose that designers design towards resources and tools in ways that reflect on the challenges of intelligibility of their design interventions in practices. In addition to considering SID in the light of practice theories, we reveal how design fictions are readily incorporated into green practices in ways that transform those practices and hold implications for transformations of design as well. We bring forward opportunities for designers to co-design with DIY enthusiasts, targeted as practitioners in their own right, designing toward or within a design fiction. As a result, we conclude with the possibility for sustainable interaction designers to become practice-oriented designers who design with transparent open strategies and accessible materials and competences.","shortAbstract":"In this paper, we argue that an approach informed by practice theory c","id":"to110"},"session":"HCI4D: Sustainability Perspectives","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to110"},"pn1227":{"lastUpdateTime":1387315946646,"subcommitteeSplit":"A","labels":{"Human-Robot Interaction":{"dislikes":[],"lastTimeUpdated":1386524149258,"checked":true,"likes":[],"label":"Human-Robot Interaction"},"scheduling and time":{"dislikes":[],"lastTimeUpdated":1386524778850,"checked":true,"likes":["eva@ehornecker.de"],"label":"scheduling and time"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Performance Metrics"},"time-delay":{"dislikes":[],"lastTimeUpdated":1386524294883,"checked":true,"likes":[],"label":"time-delay"},"Robots":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Robots"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946646}},"creationTime":911,"content":{"authorList":["Jonathan Bidwell, Georgia Institute of Technology","Alexandra Holloway, California Institute of Technology","Scott Davidoff, Jet Propulsion Laboratory"],"title":"Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces","paperOrNote":"Note","fullAbstract":"Many tasks call for efficient user interaction under time delay --- controlling space instruments, piloting remote aircraft and operating search and rescue robots. In this paper we identify an under explored design opportunity for building robotic teleoperation user interfaces following an evaluation of operator performance during a time delayed robotic arm block-stacking task (N=22). More time delay resulted in greater operator hesitation and a decreased ratio of active to inactive input. This ratio can serve as a useful proxy for measuring an operators ability to anticipate the outcome of their control inputs before receiving delayed visual feedback. High anticipatory input ratio (AIR) scores indicate times when robot operators enter commands before waiting for visual feedback. Low AIR scores highlight when operators must wait for visual feedback before continuing. In turn we used this measurement to help us identify particular sub-tasks operators would likely benefit from additional support.","shortAbstract":"Many tasks call for efficient user interaction under time delay --- co","id":"pn1227"},"session":"Human-Robot Interaction","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1227"},"pn1225":{"lastUpdateTime":1389221950963,"subcommitteeSplit":"","labels":{"Printed Electronics":{"dislikes":[],"lastTimeUpdated":1386525982716,"checked":true,"likes":["bulling@mpi-inf.mpg.de"],"label":"Printed Electronics"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386525991982,"checked":true,"likes":[],"label":"Touch Input"},"Multi-modal interfaces":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526641051,"label":"Multi-modal interfaces"},"Prototyping":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","wolfgang@cse.yorku.ca","bickmore@ccs.neu.edu","benko@microsoft.com","bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Prototyping"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["benko@microsoft.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"sensors":{"dislikes":[],"lastTimeUpdated":1386526016713,"checked":true,"likes":[],"label":"sensors"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644730}},"creationTime":909,"content":{"authorList":["Nan-Wei Gong, Massachusetts Institute of Technology ","Jrgen Steimle, Max Planck Institute for Informatics","Simon Olberding, Max Planck Institute for Informatics","Steve Hodges, Microsoft Research","Nicholas Gillian, MIT Media Lab","Yoshihiro Kawahara, The University of Tokyo","Joseph Paradiso, Massachusetts Institute of Technology"],"title":"PrintSense: A Versatile Sensing Technique to Support Multimodal Flexible Surface Interaction","paperOrNote":"Note","fullAbstract":"We present a multimodal on-surface and near-surface sensing technique for planar, curved and flexible surfaces. Our technique leverages temporal multiplexing of signals coming from a universal interdigitated electrode design, which is printed as a single conductive layer on a flexible substrate. It supports sensing of touch and proximity in-put, and moreover is capable of capturing several levels of pressure and flexing. We leverage recent developments in conductive inkjet printing as a practical way to prototype electrode patterns, and combine this with our custom-designed hardware module for supporting the full range of sensing methods. As the technique is relatively easy to implement and inexpensive, it is particularly well-suited for prototyping touch- and hover-based user interfaces, including curved and deformable ones. ","shortAbstract":"We present a multimodal on-surface and near-surface sensing technique ","id":"pn1225"},"session":"UIST: On the surface","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1225"},"pn1222":{"lastUpdateTime":1389591693388,"subcommitteeSplit":"","labels":{"Large displays":{"dislikes":[],"lastTimeUpdated":1386532222140,"checked":true,"likes":[],"label":"Large displays"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Multi-touch":{"dislikes":[],"lastTimeUpdated":1386532251679,"checked":true,"likes":["j.d.hook@ncl.ac.uk"],"label":"Multi-touch"},"Engineering":{"dislikes":[],"lastTimeUpdated":1386532230082,"checked":true,"likes":[],"label":"Engineering"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840654}},"creationTime":906,"content":{"authorList":["Alex Grau, Tactonic Technologies","Charles Hendee, Tactonic Technologies","Ken Perlin, New York University"],"title":"Mechanical Force Redistribution: Enabling Seamless, Large-Format, High-Accuracy Surface Interaction","paperOrNote":"Paper","fullAbstract":"We present Mechanical Force Redistribution (MFR): a method of sensing which creates an anti-aliased image of forces applied to a surface. This technique mechanically focuses the force from a surface onto adjacent discrete forcels (force sensing cells) by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation between adjacent discrete forcels. MFR works with any force transducing technique or material, including force variable resistive inks, piezoelectric materials and capacitive force plates. MFR sensors can be tiled such that the signal is continuous across contiguous tiles. By minimizing active materials and computational complexity, MFR makes large-format interactive walls, collaborative tabletops and high-resolution floor tiles possible and economically feasible.","shortAbstract":"We present Mechanical Force Redistribution (MFR): a method of sensing ","id":"pn1222"},"session":"Displays: Displays (UIST)","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1222"},"pn785":{"lastUpdateTime":1389591606787,"subcommitteeSplit":"A","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528583614,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Privacy":{"checked":true,"dislikes":[],"likes":["sameer.patil@hiit.fi","lorrie@acm.org","haochuan@cs.nthu.edu.tw"],"lastUpdateTime":123456789,"label":"Privacy"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525538815,"label":"Empirical Methods, Quantitative"},"privacy":{"checked":false,"lastUpdateTime":1386525919139,"dislikes":[],"label":"privacy","lastTimeUpdated":1386525906249,"likes":["sameer.patil@hiit.fi"]},"Getting Personal":{"dislikes":[],"lastTimeUpdated":1386526444200,"checked":true,"likes":["sameer.patil@hiit.fi","haochuan@cs.nthu.edu.tw"],"label":"Getting Personal"},"Personalization":{"dislikes":[],"lastTimeUpdated":1386524029956,"checked":true,"likes":[],"label":"Personalization"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525636898,"label":"User Studies"},"Causal Encounters":{"dislikes":[],"lastTimeUpdated":1386525297550,"checked":true,"likes":["paul.marshall@ucl.ac.uk"],"label":"Causal Encounters"},"cloud":{"dislikes":[],"lastTimeUpdated":1386524348898,"checked":true,"likes":[],"label":"cloud"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946726}},"creationTime":527,"content":{"authorList":["Alfred Kobsa, University of California, Irvine","Bart Knijnenburg, University of California, Irvine","Benjamin Livshits, Microsoft Research"],"title":"Lets Rather Do It at My Place?  Attitudinal and Behavioral Study of Privacy in Client-Side Personalization","paperOrNote":"Paper","fullAbstract":"Many users welcome personalized services, but are reluctant to provide the information about themselves that personalization requires. Performing personalization exclusively at the client side (e.g., on ones smartphone) may conceptually increase privacy, because no data is sent to a remote provider. But does client-side personalization (CSP) also increase users _perception_ of privacy?  \\  \\ We developed a causal model of privacy attitudes and behaviors in personalization, and validated it in an experiment that contrasted CSP with personalization at three remote providers: Amazon, a fictitious company, and the cloud. Participants gave roughly the same amount of personal data and tracking permissions in all four conditions. A structural equation modeling analysis shows the reasons: CSP raises the fewest privacy concerns, but does not lead in terms of perceived protection nor in resulting satisfaction and thus behavior. However, we found that adding specific security features in CSP will raise its perceived protection significantly. Our model predicts that CSP will then sharply improve on all other privacy measures as well. \\ ","shortAbstract":"Many users welcome personalized services, but are reluctant to provide","id":"pn785"},"session":"People: Personal Information","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn785"},"pn787":{"lastUpdateTime":1388765570911,"subcommitteeSplit":"A","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386523284477,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Health Care":{"checked":true,"dislikes":[],"likes":["jkientz@uw.edu"],"lastUpdateTime":123456789,"label":"Health Care"},"Mental health":{"dislikes":[],"lastTimeUpdated":1386523273049,"checked":true,"likes":[],"label":"Mental health"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523288019,"label":"User-Centered Design / Human-Centered Design"},"Therapeutic Interfaces":{"checked":false,"lastUpdateTime":1386523834482,"dislikes":[],"label":"Therapeutic Interfaces","lastTimeUpdated":1386523827920,"likes":[]},"Therapy":{"dislikes":[],"lastTimeUpdated":1386523854192,"checked":true,"likes":[],"label":"Therapy"},"Dramatic Research":{"dislikes":[],"lastTimeUpdated":1386536843926,"checked":true,"likes":[],"label":"Dramatic Research"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188208}},"creationTime":528,"content":{"authorList":["Mark Matthews, Cornell University","Geri Gay, Cornell University","Gavin Doherty, Trinity College"],"title":"Taking Part: role-play in the design of therapeutic system","paperOrNote":"Paper","fullAbstract":"Gaining an understanding of user needs is a central component of HCI design approaches such as user-centred design and participatory design. In some settings, such as mental health care, access to end-users is often constrained. This is a particular difficulty given that the experience of those with mental illness can be difficult for researchers to understand, and is further complicated by its associated stigma. In addition, the therapeutic setting is outside the common experience of most people and protected from outside intrusion. Although role-play has been used in varied ways in HCI, rarely has it been defined with sufficient clarity to enable others to deploy it in a nuanced manner. We argue that role-play is particularly suited for use in mental healthcare settings and, when used judiciously, can address some of the difficulties associated with working in this setting. This paper details a range of role-play formats appropriated from therapeutic role-play, drawing upon the HCI and mental health literature, therapist input and our experience (illustrated by 3 case studies) of using role-play for a number of purposes at different stages of the development process. We consider how and why role-play can be used to generate empathy, gain understanding of therapy, provide feedback on designs before clinical use and help train therapists in using technology in the treatment room.  ","shortAbstract":"Gaining an understanding of user needs is a central component of HCI d","id":"pn787"},"session":"Health: Interfaces for Care and Support","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn787"},"pn549":{"lastUpdateTime":1389221479624,"subcommitteeSplit":"","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["no@spam.org","steimle@media.mit.edu","bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca","adf"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Office and Workplace":{"dislikes":[],"lastTimeUpdated":1386525786880,"checked":true,"likes":[],"label":"Office and Workplace"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644807}},"creationTime":337,"content":{"authorList":["Kathrin Probst, University of Applied Sciences Upper Austria","David Lindlbauer, University of Applied Sciences Upper Austria","Michael Haller, University of Applied Sciences Upper Austria","Bernhard Schwartz, University of Applied Sciences Upper Austria","Andreas Schrempf, University of Applied Sciences Upper Austria"],"title":"A Chair as Ubiquitous Input Device: Exploring Semaphoric Chair Gestures for Focused and Peripheral Interaction","paperOrNote":"Paper","fullAbstract":"During everyday office work, we are used to controlling our computers with keyboard and mouse, while the rest of our body remains largely unchallenged, and the workspace that surrounds us remains largely unattended. Addressing this untapped potential, we explore a novel input technique that turns a flexible office chair into a ubiquitous input device. To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities. The evaluation of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as alternative input modality for casual, hands-free interaction.","shortAbstract":"During everyday office work, we are used to controlling our computers ","id":"pn549"},"session":"UIST: Gesture-based interaction","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn549"},"pn547":{"lastUpdateTime":1389221983645,"subcommitteeSplit":"A","labels":{"arts":{"dislikes":[],"lastTimeUpdated":1386522976201,"checked":true,"likes":[],"label":"arts"},"Entertainment":{"checked":true,"dislikes":[],"likes":["lennart.nacke@uoit.ca"],"lastUpdateTime":123456789,"label":"Entertainment"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["rwakkary@sfu.ca","Mark.blythe@northumbria.ac.uk"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"music":{"checked":false,"lastUpdateTime":1386530458768,"dislikes":[],"label":"music","lastTimeUpdated":1386522971275,"likes":[]},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Music":{"dislikes":[],"lastTimeUpdated":1386530456966,"checked":true,"likes":[],"label":"Music"},"Underserved Communities":{"dislikes":[],"lastTimeUpdated":1386523119457,"checked":true,"likes":[],"label":"Underserved Communities"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711752}},"creationTime":335,"content":{"authorList":["Carl Unander-Scharin, CSC/MID","sa Unander-Scharin, Art, communication and education","Kristina Hk, KTH - Royal Institute of Technology"],"title":"The Vocal Chorder Instrument - Empowering the  Disempowered Opera Diva","paperOrNote":"Paper","fullAbstract":"With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on, and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how performances of opera can change with a novel bodily-oriented interface. Through our designerly exploration, we arrived at a device that offered (1) a tool for singers to appropriate and take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage. ","shortAbstract":"With The Vocal Chorder, a large interactive instrument to create accom","id":"pn547"},"session":"Art: Performance 2","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn547"},"pn541":{"lastUpdateTime":1389221983645,"subcommitteeSplit":"C","labels":{"Performing Arts":{"dislikes":[],"lastTimeUpdated":1386526850551,"checked":true,"likes":[],"label":"Performing Arts"},"Video Analysis":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526669101,"label":"Video Analysis"},"Auditory Interface Design":{"checked":false,"lastUpdateTime":1386526853449,"dislikes":[],"label":"Auditory Interface Design","lastTimeUpdated":1386526279619,"likes":[]},"Entertainment":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386526672240,"label":"Entertainment"},"End-user Programming":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526670287,"label":"End-user Programming"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["bpbailey@illinois.edu"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Music":{"dislikes":[],"lastTimeUpdated":1386526815075,"checked":true,"likes":["bpbailey@illinois.edu","christopher.power@york.ac.uk"],"label":"Music"},"Performance":{"checked":false,"lastUpdateTime":1386526852769,"dislikes":[],"label":"Performance","lastTimeUpdated":1386526263361,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486589}},"creationTime":330,"content":{"authorList":["Benjamin Swift, Australian National University","Michael Martin, Australian National University","Henry Gardner, Australian National University"],"title":"Coding Livecoding","paperOrNote":"Note","fullAbstract":"Livecoding is a decade-old artistic programming practice in which an \\ artist's low-level interaction can be observed with sufficiently \\ high fidelity to allow for transcription and analysis. This paper \\ presents the results of the first reported \"coding\" of livecoding \\ videos. From an identified corpus of videos available on the web, we \\ coded performances of two different livecoding artists, recording \\ both the (textual) programming edit events and the musical effect of \\ these edits. Our analysis includes a novel \"transition matrix\" \\ visualisation in the textual and musical dimensions. These matrices \\ revealed similarities between the two artists in terms of their \\ textual editing, but clear differences between them in the musical \\ meaning of their edits, particularly in the later stages of a \\ performance. This suggests that it is the musical dimension \\ of an artist's edits which best captures their individual style. \\ ","shortAbstract":"Livecoding is a decade-old artistic programming practice in which an \\","id":"pn541"},"session":"Art: Performance 2","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn541"},"pn941":{"lastUpdateTime":1389236125639,"subcommitteeSplit":"A","labels":{"game":{"dislikes":[],"lastTimeUpdated":1386523808473,"checked":true,"likes":["lennart.nacke@uoit.ca"],"label":"game"},"Intimacy":{"dislikes":[],"lastTimeUpdated":1386523077623,"checked":true,"likes":[],"label":"Intimacy"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711754}},"creationTime":662,"content":{"authorList":["Jeffrey Bardzell, Indiana University Bloomington","Shaowen Bardzell, Indiana University Bloomington","Guo Zhang, Indiana University Bloomington","Tyler Pace, Indiana University Bloomington"],"title":"The Lonely Raccoon at the Ball:  Designing for Intimacy, Sociability, and Selfhood","paperOrNote":"Paper","fullAbstract":"Designing for sociable systems requires, among other abilities, a sensitivity to the meanings, structures, and nuances of technology-mediated experiences that are simultaneously felt by users to be intimate and also social. Such a sensitivity is not easily acquired, and design researchers have recommended the use of social theories to guide designers readings of technology-mediated social experiences. We use philosopher Michel Foucaults theory of identity (and social power, discourse, sexuality, creativity, and style) known as the care of the self, as a scaffold with which to produce a sensitive interpretation of the intimacy (and expert social creative) practices of adult users of the virtual world Second Life (SL). This reading sheds light on several skilled and creative intimacy practices in SL. It also offers a philosophically grounded hermeneutic strategy for designers interested in analyzing intimate experiences.","shortAbstract":"Designing for sociable systems requires, among other abilities, a sens","id":"pn941"},"session":"Social: Computer Mediated Romance","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn941"},"pn763":{"lastUpdateTime":1389238696698,"subcommitteeSplit":"","labels":{"social impact":{"dislikes":[],"lastTimeUpdated":1386522857432,"checked":true,"likes":[],"label":"social impact"},"activism":{"dislikes":[],"lastTimeUpdated":1386523532026,"checked":true,"likes":[],"label":"activism"},"Emergency Response":{"checked":false,"lastUpdateTime":1386538936177,"dislikes":[],"label":"Emergency Response","lastTimeUpdated":1386522145364,"likes":[]},"Collective action":{"dislikes":[],"lastTimeUpdated":1386521899244,"checked":true,"likes":[],"label":"Collective action"},"Facebook":{"dislikes":[],"lastTimeUpdated":1386522926031,"checked":true,"likes":["sadat@us.ibm.com","jacovi@il.ibm.com"],"label":"Facebook"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523459026,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523515108,"label":"Empirical Methods, Qualitative"},"Social Network Sites":{"dislikes":[],"lastTimeUpdated":1386522100403,"checked":true,"likes":[],"label":"Social Network Sites"},"Politics":{"dislikes":[],"lastTimeUpdated":1386521892843,"checked":true,"likes":["sadat@us.ibm.com"],"label":"Politics"},"social network and social movement":{"checked":false,"lastUpdateTime":1386522971583,"dislikes":[],"label":"social network and social movement","lastTimeUpdated":1386522763059,"likes":[]},"social movement":{"dislikes":[],"lastTimeUpdated":1386522968635,"checked":true,"likes":[],"label":"social movement"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556664}},"creationTime":513,"content":{"authorList":["Clara Crivellaro, Newcastle University","Rob Comber, Newcastle University","John Bowers, Newcastle University ","Peter Wright, Culture Lab, School of Computing Science, Newcastle University","Patrick Olivier, Newcastle University"],"title":"A Pool of Dreams : Facebook, Politics and the Emergence of a Social Movement","paperOrNote":"Paper","fullAbstract":"In this paper, we explore the role of social media in facilitating the emergence of social movements and the \\ potential for an understanding of the political as complex, contingent, contextual existing across everyday life. We situate this work within a discourse analysis of the Facebook page of a local activist group concerned with the redevelopment of a derelict outdoor swimming pool. This paper contributes insights into the evolving political will of the social movement as social media functionalities facilitate the construction of alternative realities and the formation of collectives driving socio-political action for change. The social movement evolves from imagining and re-imagining as a friction of action and memory fosters a political potential. This political potential is finally exposed in the confrontation of the emergent political authority assembled in the Facebook page as a political actor. We conclude by drawing considerations for design in the field of HCI and politics.","shortAbstract":"In this paper, we explore the role of social media in facilitating the","id":"pn763"},"session":"HCI4D: PolitiCHI","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn763"},"pn1316":{"lastUpdateTime":1389108082618,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["mdixon@cs.washington.edu"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"Visualization":{"checked":true,"dislikes":[],"likes":["j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Visualization"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840697}},"creationTime":988,"content":{"authorList":["Michael Glueck, University of Toronto","Azam Khan, Autodesk","Daniel Wigdor, University of Toronto"],"title":"Dive In! Enabling Progressive Loading for Real-Time Navigation of Data Visualizations","paperOrNote":"Paper","fullAbstract":"We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash stream-lines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.","shortAbstract":"We introduce Splash, a framework reducing development overhead for bot","id":"pn1316"},"session":"Viz: Visual System Design","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1316"},"pn164":{"lastUpdateTime":1389591207116,"subcommitteeSplit":"C","labels":{"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526248519,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Virtual Community / Community Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526254266,"label":"Virtual Community / Community Computing"},"History of CHI":{"dislikes":[],"lastTimeUpdated":1386526671527,"checked":true,"likes":[],"label":"History of CHI"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["bpbailey@illinois.edu"],"lastUpdateTime":1386527120166,"label":"Empirical Methods, Quantitative"},"Information Visualization":{"checked":true,"lastUpdateTime":1386526924587,"dislikes":[],"label":"Information Visualization","lastTimeUpdated":1386526442878,"likes":["bpbailey@illinois.edu"]},"Text analysis":{"dislikes":[],"lastTimeUpdated":1386527152011,"checked":true,"likes":[],"label":"Text analysis"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486601}},"creationTime":45,"content":{"authorList":["Yong Liu, University of Oulu","Jorge Goncalves, Department of Computer Science and Engineering, University of Oulu","Denzil Ferreira, University of Oulu","Bei Xiao, bo Akademi University","Simo Hosio, University of Oulu","Vassilis Kostakos, University of Oulu"],"title":"CHI 1994-2013: Mapping two decades of intellectual progress through co-word analysis","paperOrNote":"Paper","fullAbstract":"The study employs hierarchical cluster analysis, strategic diagrams and network analysis to map and visualize the intellectual landscape of the CHI conference on Human Computer Interaction through the use of co-word analysis. The study quantifies and describes the thematic evolution of the field based on a total of 3152 CHI articles and their associated 16035 keywords published between 1994 and 2013. The analysis is conducted for two periods (1994-2003, 2004-2013) and a comparison between them highlights the underlying trends in our community. The study identifies the evolution of major themes in the discipline, and highlights individual topics as popular, core, or backbone research topics within HCI.","shortAbstract":"The study employs hierarchical cluster analysis, strategic diagrams an","id":"pn164"},"session":"Methods and Models: new HCI paradigms","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn164"},"pn166":{"lastUpdateTime":1389592001999,"subcommitteeSplit":"A","labels":{"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"community displays":{"dislikes":[],"lastTimeUpdated":1386523926057,"checked":true,"likes":[],"label":"community displays"},"I'm board":{"dislikes":[],"lastTimeUpdated":1386525683409,"checked":true,"likes":[],"label":"I'm board"},"public displays":{"dislikes":[],"lastTimeUpdated":1386525176053,"checked":true,"likes":[],"label":"public displays"},"communities":{"dislikes":[],"lastTimeUpdated":1386527361694,"checked":true,"likes":[],"label":"communities"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524544299,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526334288,"label":"Empirical Methods, Qualitative"},"ethnography":{"checked":false,"lastUpdateTime":1386531388445,"dislikes":[],"label":"ethnography","lastTimeUpdated":1386523934886,"likes":[]},"Ethnography":{"dislikes":[],"lastTimeUpdated":1386531386628,"checked":true,"likes":[],"label":"Ethnography"},"I'm on board":{"dislikes":[],"lastTimeUpdated":1386525825490,"checked":true,"likes":[],"label":"I'm on board"},"bulletin boards":{"dislikes":[],"lastTimeUpdated":1386523913178,"checked":true,"likes":[],"label":"bulletin boards"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946701}},"creationTime":46,"content":{"authorList":["Claude Fortin, Simon Fraser University","Carman Neustaedter, Simon Fraser University","Kate Hennessy, Simon Fraser University"],"title":"Posting for Community and Culture: Considerations for the Design of Interactive Digital Bulletin Boards","paperOrNote":"Paper","fullAbstract":"The next decade is likely to see a shift in digital public displays moving from non-interactive to interactive content thereby creating forms of digital bulletin boards.  With this shift comes a need to understand how such displays should best be designed to encourage community members to engage and interact with the displays. We examine this by exploring prominent non-digital interactive displays in society, namely community bulletin boards, as cultural artifacts in the wild. Our results highlight the ways in which bulletin boards are used for content of local relevance and how cultures of participation, architecture, location, and personalization affect community members interactions with the boards.  This suggests key design considerations, each intrinsically linked to the users sense of agency within a delineated physical space. We discuss them in relation to geographic relevance, contextual relevance, and entry points for action and participation. ","shortAbstract":"The next decade is likely to see a shift in digital public displays mo","id":"pn166"},"session":"Displays: Interactive Whitebaords and Public Displays","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn166"},"pn1007":{"lastUpdateTime":1389222115080,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532565385,"checked":true,"likes":[],"label":"Touch Input"},"Smartwatches":{"dislikes":[],"lastTimeUpdated":1386531962861,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Smartwatches"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Small Display Interaction":{"dislikes":[],"lastTimeUpdated":1386531985020,"checked":true,"likes":["david.kim@newcastle.ac.uk"],"label":"Small Display Interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840560}},"creationTime":720,"content":{"authorList":["Ian Oakley, Ulsan National Institute of Science and Technology","DoYoung Lee, Ulsan National Institute of Science and Technology"],"title":"Interaction on the Edge: Offset Sensing for Small Devices","paperOrNote":"Paper","fullAbstract":"The touch screen interaction paradigm, currently dominant in mobile devices, begins to fail when very small systems are considered. Specifically, \"fat fingers\", a term referring to the fact that users' extremities physically obstruct their view of screen content and feedback, become particularly problematic. This paper presents a novel solution for this issue based on sensing touches to the perpendicular edges of a device featuring a front-mounted screen. The use of such offset contact points ensures that both a users fingers and the device screen remain clearly in view throughout a targeting operation. The configuration also supports a range of novel interaction scenarios based on the touch, grip and grasp patterns it affords. To explore the viability of this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating this multi-touch functionality. User studies characterizing targeting performance, typical user grasps and exploring input affordances are presented. The results show that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds and with accuracy rates of 3%-18%, promising results considering the small form factor of the device. Furthermore, grasps made with between two and five fingers are robustly identifiable. Finally, we characterize the types of input users envisage performing with EdgeTouch, and report occurrence rates for key interactions such as taps, holds, strokes and multi-touch and compound input. The paper concludes with a discussion of the interaction scenarios enabled by offset sensing.","shortAbstract":"The touch screen interaction paradigm, currently dominant in mobile de","id":"pn1007"},"session":"UIST: Small Devices","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1007"},"pn2432":{"lastUpdateTime":1389222026624,"subcommitteeSplit":"","labels":{"Pointing Techniques":{"dislikes":[],"lastTimeUpdated":1386531937810,"checked":true,"likes":["tomer@moscovich.net"],"label":"Pointing Techniques"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Selection Techniques":{"dislikes":[],"lastTimeUpdated":1386532135345,"checked":true,"likes":["fanny@dgp.toronto.edu","tomer@moscovich.net"],"label":"Selection Techniques"},"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386538655104,"checked":true,"likes":[],"label":"Target Acquisition"},"Target Aquisition":{"checked":false,"lastUpdateTime":1386538660221,"dislikes":[],"label":"Target Aquisition","lastTimeUpdated":1386532425091,"likes":[]},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840682}},"creationTime":1950,"content":{"authorList":["Phillip Pasqual, University of Washington","Jacob Wobbrock, University of Washington"],"title":"Mouse Pointing Endpoint Prediction Using Kinematic Template Matching","paperOrNote":"Paper","fullAbstract":"We present a new method of predicting the endpoints of mouse movements. While prior approaches to endpoint prediction have relied upon normative kinematic laws, regression, or control theory, our approach is straightforward but kinematically rich. Our key insight is to regard the unfolding velocity profile of a pointing movement as a 2-D stroke gesture and to use template matching to predict the endpoint based on prior observed movements. We call our technique kinematic template matching (KTM), which is simple to implement, user-adaptable, and kinematically expressive. In a study of 17 able-bodied participants evaluated over movement amplitudes ranging from 100-800 pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels at 90%, using 1000 templates per participant. These accuracies make KTM as successful an approach to endpoint prediction as any prior technique, while being easier to implement and understand than most.","shortAbstract":"We present a new method of predicting the endpoints of mouse movements","id":"pn2432"},"session":"UIST: Pointing","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2432"},"pn1821":{"lastUpdateTime":1388765570911,"subcommitteeSplit":"A","labels":{"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Health Care":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523218700,"label":"Health Care"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526546423,"label":"User Experience Design / Experience Design"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Health and social media":{"dislikes":[],"lastTimeUpdated":1386523275367,"checked":true,"likes":["Jina.huh@gmail.com","wilcox@cc.gatech.edu"],"label":"Health and social media"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188189}},"creationTime":1426,"content":{"authorList":["Phil Adams, Cornell University","Eric Baumer, Cornell University","Geri Gay, Cornell University"],"title":"Staccato Social Support in Mobile Health Applications","paperOrNote":"Paper","fullAbstract":"Social support plays an important role in health systems. While significant work has explored the role of social support in CMC environments, less attention has been devoted to social support in mobile health systems. This paper describes socially supportive messages in VERA, a mobile application for sharing health decisions and behaviors. The short and bursty interactions in social awareness streams [36] afford a particular style of social support, for which we offer the label staccato social support. Results indicate that in comparison to previous work, staccato social support is characterized by a greater prevalence of esteem support, which builds respect and confidence. We further note the presence of following up, a positive behavior that contributes to supportive interactions, likely via social pressure and accountability [7, 38]. These findings suggest design recommendations to developers of mobile social support systems, and contribute to understanding technologically mediated social support for health.","shortAbstract":"Social support plays an important role in health systems. While signif","id":"pn1821"},"session":"Health: Interfaces for Care and Support","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1821"},"pn1820":{"lastUpdateTime":1389221814307,"subcommitteeSplit":"B","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Visualization"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"E-Learning and Education":{"dislikes":[],"lastTimeUpdated":1386522913468,"checked":true,"likes":[],"label":"E-Learning and Education"},"comics":{"dislikes":[],"lastTimeUpdated":1386523060172,"checked":true,"likes":[],"label":"comics"},"interactive narrative":{"dislikes":[],"lastTimeUpdated":1386523071148,"checked":true,"likes":[],"label":"interactive narrative"},"interactive storytelling":{"dislikes":[],"lastTimeUpdated":1386523066685,"checked":true,"likes":[],"label":"interactive storytelling"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Children":{"dislikes":[],"lastTimeUpdated":1386522899152,"checked":true,"likes":[],"label":"Children"},"Literacy":{"dislikes":[],"lastTimeUpdated":1386536978474,"checked":true,"likes":[],"label":"Literacy"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755951}},"creationTime":1425,"content":{"authorList":["Daniel Andrews, University of Birmingham","Chris Baber, University of Birmingham"],"title":"Visualizing Interactive Narratives: Employing a Branching Comic to Tell a Story and Show its Readings","paperOrNote":"Paper","fullAbstract":"In this paper, the question of how readers respond to visual narrative when presented on screen or on paper is considered, and how the same visual structure can be employed to present this data. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. This informs the design, development and testing of a branching comic, presented on both paper in linear form and on computer in interactive form. In an experiment testing the comic with 11-12 year old school children, we found that the summaries of stories recalled from the paper version of the comic were highly varied, whereas those of the computer version seem to have been guided by the points at which users can interact. We also saw evidence that supports existing research on the phenomenological difference between texts presented on paper and on screen, and that which suggests that interactive branching stories are goal-oriented.","shortAbstract":"In this paper, the question of how readers respond to visual narrative","id":"pn1820"},"session":"Art: Narratives and Storytelling","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1820"},"pn2328":{"lastUpdateTime":1389236747529,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"E-Learning and Education":{"checked":true,"dislikes":[],"likes":["mmassimi@microsoft.com"],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032731}},"creationTime":1867,"content":{"authorList":["Yun-En Liu, University of Washington","Travis Mandel, University of Washington","Emma Brunskill, Carnegie Mellon University","Zoran Popovic, University of Washington"],"title":"Towards Automatic Experimentation of Educational Knowledge","paperOrNote":"Paper","fullAbstract":"We present a general automatic experimentation and hypothesis generation framework that relies on a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. \\ We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. \\ To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. \\ Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. \\ We briefly discuss our results in the context of the greater educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.","shortAbstract":"We present a general automatic experimentation and hypothesis generati","id":"pn2328"},"session":"HCI4D: Engage & Educate Children","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2328"},"pn2327":{"lastUpdateTime":1389236836254,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Workshops":{"dislikes":[],"lastTimeUpdated":1386523318994,"checked":true,"likes":[],"label":"Workshops"},"Prototyping":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"Prototyping"},"Physical Computing":{"dislikes":[],"lastTimeUpdated":1386523323634,"checked":true,"likes":[],"label":"Physical Computing"},"Physical interaction":{"dislikes":[],"lastTimeUpdated":1386523294480,"checked":true,"likes":[],"label":"Physical interaction"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711744}},"creationTime":1866,"content":{"authorList":["Leah Buechley, Massachusetts Institute of Technology"],"title":"Sketching in Circuits:  Designing and building electronics on paper","paperOrNote":"Paper","fullAbstract":"The field of new methods and techniques for building electronics is quickly growingfrom research in new materials for circuit building, to modular toolkits, and more recently to untoolkits which aim to incorporate more off-the-shelf parts.  However, the standard mediums for circuit design and construction remain the breadboard, protoboard, and printed circuit board (PCB).   As an alternative, we introduce a method in which circuits are hand-made on ordinary paper substrates, connected with conductive foil tape and off-the-shelf circuit components with the aim of supporting the durability, scalability, and accessibility needs of novice and expert circuit builders alike.   We also used electrified notebooks to investigate how the circuit design and build process would be affected by the constraints and affordances of the bound book.  Our ideas and techniques were evaluated through a series of workshops, through which we found our methods supported a wide variety of approaches and resultsboth technical and expressive to electronics design and construction.","shortAbstract":"The field of new methods and techniques for building electronics is qu","id":"pn2327"},"session":"Making: Hacking","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2327"},"pn1796":{"lastUpdateTime":1388786174911,"subcommitteeSplit":"","labels":{"Video Analysis":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Analysis"},"cycling":{"dislikes":[],"lastTimeUpdated":1386525915012,"checked":true,"likes":[],"label":"cycling"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Sports":{"dislikes":[],"lastTimeUpdated":1386525497138,"checked":true,"likes":["petra.isenberg@inria.fr"],"label":"Sports"},"Handheld Projection":{"dislikes":[],"lastTimeUpdated":1386525909165,"checked":true,"likes":[],"label":"Handheld Projection"},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["elm@purdue.edu","j.alexander@lancaster.ac.uk","dan@microsoft.com","adf"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Navigation":{"dislikes":[],"lastTimeUpdated":1386525926357,"checked":true,"likes":[],"label":"Navigation"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644829}},"creationTime":1405,"content":{"authorList":["Alexandru Dancu, Chalmers University of Technology","Zlatko Franjcic, Chalmers University of Technology","Morten Fjeld, Chalmers University of Technology"],"title":"Smart Flashlight: Map Navigation Using a Bike-Mounted Projector","paperOrNote":"Note","fullAbstract":"Mobile phones change our behavior and separate us from the physical environment, which could instead become a responsive part of the information domain. Navigating an urban map by bicycle, we compared a smartphone display and a projection on the road. This paper firstly proposes the concept of GPS-based map navigation using a bike-mounted projector. Secondly, it implements a prototype using both a projector and a smartphone mounted on a bike, comparing them for use in a navigation system for nighttime cycling. Thirdly, it examines how visuo-spatial factors influence navigation. We believe that our findings will be useful for designing navigation systems for bikes and even for cars, helping cyclists  and drivers be more attentive to their environment during navigation and providing necessary information while moving.","shortAbstract":"Mobile phones change our behavior and separate us from the physical en","id":"pn1796"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1796"},"pn2220":{"lastUpdateTime":1389238884539,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Design and responsibility":{"dislikes":[],"lastTimeUpdated":1386523102890,"checked":true,"likes":[],"label":"Design and responsibility"},"Internationalization / Localization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523300289,"label":"Internationalization / Localization"},"reflective ethnography":{"checked":false,"lastUpdateTime":1386523279953,"dislikes":[],"label":"reflective ethnography","lastTimeUpdated":1386523040826,"likes":[]},"Designing With People":{"dislikes":[],"lastTimeUpdated":1386523317099,"checked":true,"likes":[],"label":"Designing With People"},"Located accountabilities in design":{"dislikes":[],"lastTimeUpdated":1386523112422,"checked":true,"likes":[],"label":"Located accountabilities in design"},"Ethnography":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu","wendyju@stanford.edu","silvia.lindtner@gmail.com"],"lastUpdateTime":123456789,"label":"Ethnography"},"Postcolonial Designing":{"dislikes":[],"lastTimeUpdated":1386523352083,"checked":true,"likes":[],"label":"Postcolonial Designing"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["silvia.lindtner@gmail.com","fuzhiyong@tsinghua.edu.cn","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"collaborative ethnography":{"checked":true,"lastUpdateTime":1386522496483,"dislikes":[],"label":"collaborative ethnography","lastTimeUpdated":1386522337298,"likes":[]},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755926}},"creationTime":1776,"content":{"authorList":["Margot Brereton, Queensland University of Technology","Paul Roe, Queensland University of Technology","Ronald Schroeter, Queensland University of Technology","Anita Lee Hong, Queensland University of Technology"],"title":"Beyond Ethnography: Engagement and Reciprocity as Foundations for Design Research Out Here","paperOrNote":"Note","fullAbstract":"This paper explores a new paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover ethnographic research often does not seem the best or most appropriate course of action. \\  \\ We draw upon a project working with a remote Australian Aboriginal community to contribute an alternative approach. It is founded on the principles of reciprocal engagement in which we first make together, learn, teach and translate together. These are practical forms of action in which both parties benefit together. We argue that this can lead to sustainable designs, valid research and profound innovation. \\ ","shortAbstract":"This paper explores a new paradigm for HCI design research based prima","id":"pn2220"},"session":"Design: Research through Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2220"},"pn2226":{"lastUpdateTime":1389235997798,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386522862733,"checked":true,"likes":[],"label":"Field Study"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":["jonfroehlich@gmail.com","jfc@cs.berkeley.edu","rob.comber@ncl.ac.uk","a.sasse@cs.ucl.ac.uk","nithyas@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"Sexual harassment":{"dislikes":[],"lastTimeUpdated":1386521836397,"checked":true,"likes":[],"label":"Sexual harassment"},"ICTD":{"dislikes":[],"lastTimeUpdated":1386521831347,"checked":true,"likes":["jonfroehlich@gmail.com","nithyas@gmail.com","egelman@cs.berkeley.edu"],"label":"ICTD"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"User Studies":{"checked":true,"lastUpdateTime":1386522888893,"dislikes":[],"label":"User Studies","lastTimeUpdated":1386522806278,"likes":[]},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446300}},"creationTime":1780,"content":{"authorList":["Syed Ishtiaque Ahmed, Cornell University","Steven Jackson, Cornell University","Nova Ahmed, North South University","Hasan Ferdous, Bangladesh University of Engineering and Technology","Md. Rashidujjaman Rifat, Bangladesh University of Engineering and Technology","Abu Saleh Rizvi, Bangladesh University of Engineering and Technology","Shamir Ahmed, Bangladesh University of Engineering and Technology","Rifat Sabbir Mansur, Bangladesh University of Engineering and Technology"],"title":"Protibadi: A Platform for Fighting Sexual Harassment in Urban Bangladesh","paperOrNote":"Paper","fullAbstract":"Public sexual harassment has emerged as a large and growing concern in urban Bangladesh, with deep and damaging implications for gender security, justice, and rights of public participation. In this paper we describe an integrated program of ethnographic and design work meant to understand and address such problems. For one year we conducted surveys, interviews, and focus groups around sexual harassment with women at three different universities in Dhaka. Based on this input, we developed Protibadi, a web and mobile phone based application designed to report, map, and share womens stories around sexual harassment in public places. In August 2013 the system launched, user studies were conducted, and public responses were monitored to gauge reactions, strengths, and limits of the system. This paper describes the findings of our ethnographic and design-based work, and suggests lessons relevant to other HCI efforts to understand and design around difficult and culturally sensitive problems.","shortAbstract":"Public sexual harassment has emerged as a large and growing concern in","id":"pn2226"},"session":"HCI4D: CHI for Social Development","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2226"},"pn2227":{"lastUpdateTime":1389238496089,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528666225,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Passwords":{"dislikes":[],"lastTimeUpdated":1386521783525,"checked":true,"likes":["me@patrickgage.com","alexander.de.luca@ifi.lmu.de","rob.comber@ncl.ac.uk","rcm@mit.edu","egelman@cs.berkeley.edu","lorrie@acm.org"],"label":"Passwords"},"Mturk":{"dislikes":[],"lastTimeUpdated":1386521842845,"checked":true,"likes":[],"label":"Mturk"},"User Studies":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"Authentication":{"dislikes":[],"lastTimeUpdated":1386522280170,"checked":true,"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","lorrie@acm.org"],"label":"Authentication"},"Usability Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526338914,"label":"Usability Research"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386522055825,"checked":true,"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","nithyas@gmail.com","lorrie@acm.org"],"label":"Usable Security"},"Security":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Security"},"Password Policies":{"dislikes":[],"lastTimeUpdated":1386521836910,"checked":true,"likes":[],"label":"Password Policies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446255}},"creationTime":1781,"content":{"authorList":["Richard Shay, Carnegie Mellon","Saranga Komanduri, Carnegie Mellon University","Adam Durity, Carnegie Mellon University","Phillip Huh, Carnegie Mellon University","Michelle Mazurek, Carnegie Mellon University","Sean Segreti, Carnegie Mellon University","Blase Ur, Carnegie Mellon University","Lujo Bauer, Carnegie Mellon University","Lorrie Cranor, Carnegie Mellon University","Nicolas Christin, Carnegie Mellon University"],"title":"Can Long Passwords be Secure and Usable?","paperOrNote":"Paper","fullAbstract":"A recommended password-composition policy designed to encourage strong passwords requires passwords to have at least 8 characters from 4 character classes and pass a dictionary check.  Recent research has suggested, however, that policies requiring longer passwords with fewer additional requirements can be more usable and in some cases more secure. To explore this in more detail, we conducted an online experiment with 8,143 participants. Using a cracking algorithm modified for longer passwords, we evaluate eight policies across a variety of metrics for strength and usability. Among the longer policies, we discover new evidence for a security/usability tradeoff, with none being strictly better than another on both dimensions. Compared with the recommended policy, however, we find several policies that are both more usable and more secure. Our analyses additionally reveal commonalities in passwords that suggest ways password policies might be enhanced.","shortAbstract":"A recommended password-composition policy designed to encourage strong","id":"pn2227"},"session":"Security: Passwords","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2227"},"pn2225":{"lastUpdateTime":1389236481152,"subcommitteeSplit":"","labels":{"document managment":{"checked":false,"lastUpdateTime":1386523116325,"dislikes":[],"label":"document managment","lastTimeUpdated":1386523110857,"likes":[]},"tags":{"checked":false,"lastUpdateTime":1386532005462,"dislikes":[],"label":"tags","lastTimeUpdated":1386522599317,"likes":[]},"conference organization":{"dislikes":[],"lastTimeUpdated":1386521934746,"checked":true,"likes":[],"label":"conference organization"},"Academia":{"dislikes":[],"lastTimeUpdated":1386523305283,"checked":true,"likes":[],"label":"Academia"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521944435,"checked":true,"likes":["jacovi@il.ibm.com","gabriela.avram@gmail.com","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"crowdsourcing"},"data organizing":{"dislikes":[],"lastTimeUpdated":1386522839660,"checked":true,"likes":[],"label":"data organizing"},"Document management":{"dislikes":[],"lastTimeUpdated":1386523119532,"checked":true,"likes":["smunson@uw.edu"],"label":"Document management"},"Tagging":{"dislikes":[],"lastTimeUpdated":1386532003241,"checked":true,"likes":[],"label":"Tagging"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522106897,"label":"Social Computing and Social Navigation"},"ontologies":{"dislikes":[],"lastTimeUpdated":1386522590303,"checked":true,"likes":[],"label":"ontologies"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522103941,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556721}},"creationTime":1779,"content":{"authorList":["Lydia Chilton, University of Washington","Juho Kim, Massachusetts Institute of Technology","Paul Andr, Carnegie Mellon University","Felicia Cordeiro, ","James Landay, University of Washington","Dan Weld, University of Washington","Steven Dow, Carnegie Mellon University","Rob Miller, MIT CSAIL","Haoqi Zhang, MIT CSAIL"],"title":"Frenzy: Collaborative Data Organization for  Creating Conference Sessions","paperOrNote":"Paper","fullAbstract":"Organizing conference sessions around themes improves the experience for attendees. However, the session creation process can be difficult and time-consuming due to the amount of expertise and effort required to consider alternative paper groupings. We designed collaborative software called Frenzy to draw on the efforts and knowledge of an entire program committee. Frenzy comprises (a) interfaces to support large numbers of experts working collectively to craft sessions, and (b) a \"micro-task\" workflow that decom-poses the session-creation problem into meta-data elicitation and global constraint satisfaction. Meta-data elicitation involves a large group of experts working simultaneously, while global constraint satisfaction involves a smaller group that uses the meta-data to form sessions.  \\  \\ We evaluated Frenzy with over 50 people during a deployment at a large conference program committee meeting. The session making process was much faster than the traditional process, taking 88 minutes instead of a full day. We found that meta-data elicitation was useful for session creation, and that participants found Frenzy to be more fun and efficient than the traditional process.  \\ ","shortAbstract":"Organizing conference sessions around themes improves the experience f","id":"pn2225"},"session":"CSCW: Document and Intertextuality","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2225"},"to129":{"lastUpdateTime":1387316225848,"subcommitteeSplit":"","labels":{"information needs":{"dislikes":[],"lastTimeUpdated":1386525709233,"checked":true,"likes":[],"label":"information needs"},"Field Study":{"dislikes":[],"lastTimeUpdated":1386525736117,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Field Study"},"Experience Sampling":{"dislikes":[],"lastTimeUpdated":1386525770820,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Experience Sampling"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527748503,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2066,"content":{"authorList":["Karen Church, Yahoo Labs","Mauro Cherubini, Google, Inc.","Nuria Oliver, Telefonica Research"],"title":"A Large Scale Study of Daily Information Needs Captured In-Situ","paperOrNote":"TOCHI","fullAbstract":"The goal of this work is to provide a fundamental understanding of the daily information needs of people through a large-scale, in-depth, quantitative investigation. To this end, we have conducted one of the most comprehensive studies of information needs to date, spanning a 3-month period and involving over 100 users. The study employed a contextual experience sampling method (ESM); a snippet-based diary technique using SMS technology and an on-line Web diary to gather in-situ insights into the types of needs that occur from day to day, how those needs are addressed and how contextual, technological and demographic factors impact on those needs. Our results not only complement earlier studies but also provide a new understanding of the intricacies of peoples daily information needs.","shortAbstract":"The goal of this work is to provide a fundamental understanding of the","id":"to129"},"session":"Information in Use","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to129"},"to128":{"lastUpdateTime":1389107800193,"subcommitteeSplit":"","labels":{"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"Accessibility":{"checked":false,"lastUpdateTime":1386536598369,"dislikes":[],"label":"Accessibility","lastTimeUpdated":1386525193528,"likes":["dan@danielashbrook.com"]},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527716547,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2065,"content":{"authorList":["Leonardo Ferres, Universidad de Concepcion","Gitte Lindgaard, Carleton University","Livia Sumegi, ","Bruce Tsuji, "],"title":"Evaluating a tool for improving accessibility to charts and graphs","paperOrNote":"TOCHI","fullAbstract":"This paper reports a case study of the iterative design and evaluation of a natural language- driven assistive technology, iGraph-Lite, providing people who are blind access to line graphs. Two laboratory-based usability studies involving blind and sighted people are presented with a discussion of the ensuing implementation of changes. Blind participants were found to adopt different graph interrogation strategies than sighted participants. A small field study is then reported in which a blind user who works with graphs took part to determine the degree to which the iGraph-Lite commands would meet the needs of blind graph experts. The final study invited sighted graph experts and novices to visually inspect and explain a set of line graphs comparable to those used in the usability studies. It aimed to highlight the concepts and the range of words sighted people use, to ascertain the appropriateness of the iGraph-Lite lexicon. A set of preliminary guidelines is presented.","shortAbstract":"This paper reports a case study of the iterative design and evaluation","id":"to128"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to128"},"to123":{"lastUpdateTime":1389591306521,"subcommitteeSplit":"","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386523914876,"checked":true,"likes":[],"label":"Field Study"},"technology development":{"dislikes":[],"lastTimeUpdated":1386528518186,"checked":true,"likes":[],"label":"technology development"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"hci4d":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"hci4d"},"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386523352077,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527719571,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2062,"content":{"authorList":["Anne Adams, Open Univeristy IET","Elizabeth FitzGerald, The Open University","Gary Priestnall, The University of Nottingham"],"title":"Of Catwalk Technologies and Boundary Creatures","paperOrNote":"TOCHI","fullAbstract":"Researchers designing and deploying technologies in the wild can find it difficult to balance pure innovation with scalable solutions. Tensions often relate to expectations around current and future roles of the technology development. We propose a catwalk technology metaphor where researchers as boundary creatures focus on innovation whilst providing links to prt--porter (ready to wear) developments. Evidence from 140 participants, within three in-the-wild field-based learning case studies (for mobile, distributed, sensor and augmented reality systems), conceptualise the researchers boundary creature role in managing design process tensions. Stakeholders, including participants, expected the research projects to produce ready to wear (prt--porter) boundary objects for current practices even when researchers sought to take catwalk approaches by innovating technologies and changing practices. The researcher design role (RDR) model articulates researchers narratives with the design team, stakeholders and users around what is innovated (e.g. technology, activities) and how the intervention changes or sustains current practices.","shortAbstract":"Researchers designing and deploying technologies in the wild can find ","id":"to123"},"session":"Methods and Models: Turn to the Wild","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to123"},"pn2134":{"lastUpdateTime":1389236966690,"subcommitteeSplit":"B","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386521826004,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Handheld Devices and Mobile Computing"},"Big data":{"checked":false,"lastUpdateTime":1386528259607,"dislikes":[],"label":"Big data","lastTimeUpdated":1386522715634,"likes":[]},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","a.sasse@cs.ucl.ac.uk","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"ICTD":{"dislikes":[],"lastTimeUpdated":1386522187310,"checked":true,"likes":["nithyas@gmail.com"],"label":"ICTD"},"big data":{"dislikes":[],"lastTimeUpdated":1386528257791,"checked":true,"likes":[],"label":"big data"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446290}},"creationTime":1697,"content":{"authorList":["Christopher Smith, University College London","Afra Mashhadi, Alcatel-Lucent","Licia Capra, "],"title":"Poverty on the Cheap: Estimating Poverty Maps Using Aggregated Mobile Communication Networks","paperOrNote":"Paper","fullAbstract":"Governments and other organisations often rely on data collected by national household surveys and censuses to identity areas in most need of regeneration and development projects. However, due to the high cost associated with the data collection process, many developing countries conduct such surveys very infrequently and include only a rather small sample of the population, thus failing to accurately capture the current socio-economic status of the country's population. In this paper, we address this challenge by means of a methodology that relies on an alternative source of data from which to derive up to date poverty indicators, at a very fine level of spatio-temporal granularity. Taking two developing countries as examples, we show how to analyse the aggregated call detail records of their mobile subscribers and extract features that are strongly correlated with poverty indexes currently derived from census data. ","shortAbstract":"Governments and other organisations often rely on data collected by na","id":"pn2134"},"session":"HCI4D: Finances","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2134"},"to120":{"lastUpdateTime":1389285684614,"subcommitteeSplit":"","labels":{"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"web":{"dislikes":[],"lastTimeUpdated":1386525075939,"checked":true,"likes":[],"label":"web"},"Web 2.0":{"dislikes":[],"lastTimeUpdated":1386525080661,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"Web 2.0"},"Accessibility":{"checked":false,"lastUpdateTime":1386536594879,"dislikes":[],"label":"Accessibility","lastTimeUpdated":1386525141893,"likes":["jeff@jeffreynichols.com"]},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527731378,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2060,"content":{"authorList":["Caroline Jay, University of Manchester","Andy Brown, University of Manchester","Simon Harper, University of Manchester"],"title":"Predicting Whether Users View Dynamic Content on the World Wide Web","paperOrNote":"TOCHI","fullAbstract":"Dynamic micro-contentinteractive or updating widgets and featuresis now widely used on the Web, but there is little understanding of how people allocate attention to it. In this article we present the results of an eye-tracking investigation examining how the nature of dynamic micro-content influences whether or not the user views it. We propose and validate the Dynamic Update Viewing-likelihood (DUV) model, a Chi-squared Automatic Interaction Detector (CHAID) model that predicts with around 80% accuracy whether users view dynamic updates as a function of how they are initiated, their size, and their duration. The model is constructed with data from live Web sites and does not rely on knowledge of the user's task to make its predictions, giving it a high level of external validity. We discuss one example of its application: informing how dynamic content should be presented in audio via assistive technology for people with visual impairments.","shortAbstract":"Dynamic micro-contentinteractive or updating widgets and features","id":"to120"},"session":"Web: Web","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to120"},"pn1558":{"lastUpdateTime":1387315556689,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"search":{"dislikes":[],"lastTimeUpdated":1386523552776,"checked":true,"likes":[],"label":"search"},"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"information search":{"dislikes":[],"lastTimeUpdated":1386524258213,"checked":true,"likes":[],"label":"information search"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"Video search":{"dislikes":[],"lastTimeUpdated":1386523948519,"checked":true,"likes":[],"label":"Video search"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386522025940,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"crowdsourcing"},"Video Analysis":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Analysis"},"Video":{"dislikes":[],"lastTimeUpdated":1386522370085,"checked":true,"likes":[],"label":"Video"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556689}},"creationTime":1208,"content":{"authorList":["Barnaby Craggs, Lancaster University","Myles Kilgallon Scott, Lancaster University","Jason Alexander, Lancaster University"],"title":"ThumbReels: Query Sensitive Web Video Previews Based on Temporal, Crowdsourced, Semantic Tagging","paperOrNote":"Note","fullAbstract":"During online search, the user's expectations often differ from those of the  author. This is known as the `intention gap' and is particularly problematic when searching for and discriminating between online video content. An author uses description and meta-data tags to label their content, but often cannot predict alternate interpretations or appropriations of their work. To address this intention gap, we present ThumbReels, a concept for query-sensitive video previews generated from crowdsourced, temporally defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly temporal tagging of videos, whose output can be used for later search queries. A first user study validates the tool and concept. We then present a second study that shows user preference for ThumbReels over contemporary preview techniques. ","shortAbstract":"During online search, the user's expectations often differ from those ","id":"pn1558"},"session":"Navigating Video","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1558"},"pn1635":{"lastUpdateTime":1389221416620,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386525671391,"checked":true,"likes":["benko@microsoft.com","no@spam.org"],"label":"Touch Input"},"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":["benko@microsoft.com","aquigley@st-andrews.ac.uk"],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"pressure interaction":{"dislikes":[],"lastTimeUpdated":1386525340075,"checked":true,"likes":[],"label":"pressure interaction"},"bimanual input":{"dislikes":[],"lastTimeUpdated":1386525725202,"checked":true,"likes":["davidmcgookin@gmail.com"],"label":"bimanual input"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":["davidmcgookin@gmail.com"],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525882016,"label":"User Studies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644721}},"creationTime":1263,"content":{"authorList":["Ross McLachlan, University of Glasgow","Daniel Boland, University of Glasgow","Stephen Brewster, University of Glasgow"],"title":"Transient and Transitional States: Pressure as an Auxiliary Input Modality for Bimanual Interaction","paperOrNote":"Paper","fullAbstract":"In this paper, a novel investigation of pressure input is presented where it is characterised as a transient modality - a modality that has a natural inverse, bounce-back and a state that only persists during interaction. Three empirical studies are described that evaluate these properties for use as a non-dominant hand input modality in the context bimanual tablet interaction, where the ability to target and maintain pressure while simultaneously performing a dominant hand targeting task is investigated. The aim is to to inform the design of interaction techniques that enable simultaneous two-handed input while users are still holding a device. Across all conditions, pressure accuracy was high (93%) and the impact on dominant hand targeting was low. Mean pressure accuracy when selecting targets by releasing pressure was also high (89%) as was selecting targets by applying pressure from a non-zero starting point (94.4%). The ability to accurately maintain pressure over time was better with larger target pressures.  Example applications and design guidelines are presented that enable designers to exploit the transient properties of pressure input in interaction design.","shortAbstract":"In this paper, a novel investigation of pressure input is presented wh","id":"pn1635"},"session":"UIST: Force Input","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1635"},"pn1252":{"lastUpdateTime":1387315711779,"subcommitteeSplit":"A","labels":{"Human-robot interaction":{"dislikes":[],"lastTimeUpdated":1386523178197,"checked":true,"likes":[],"label":"Human-robot interaction"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se","lennart.nacke@uoit.ca"],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se"],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"Robots":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se"],"lastUpdateTime":123456789,"label":"Robots"},"Social Presence":{"dislikes":[],"lastTimeUpdated":1386523034354,"checked":true,"likes":["mulderi@acm.org","lennart.nacke@uoit.ca"],"label":"Social Presence"},"Augmented Reality and Tangible UI":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523007952,"label":"Augmented Reality and Tangible UI"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711779}},"creationTime":932,"content":{"authorList":["Andr Pereira, Instituto Superior Tcnico - University of Lisbon","Rui Prada, Instituto Superior Tcnico - University of Lisbon","Ana Paiva, Instituto Superior Tcnico - Technical University of Lisbon"],"title":"Improving Social Presence in Human-Agent Interaction","paperOrNote":"Paper","fullAbstract":"Humans have a tendency to consider many media devices as social beings. Social agents and artificial opponents can be examined as one instance of this effect and today's technology can already be used to make artificial agents perceived as more socially present. In this paper, we start by identifying the factors that influence perceptions of social presence in human-agent interaction. By taking into account these factors and by following previously defined guidelines for building socially present artificial opponents, a case study was created where a social robot plays the Risk board game against three human players. To demonstrate whether the agent created in this case study is perceived as socially present, an experiment was performed. The experiment suggested that by following guidelines for creating socially present artificial board game opponents, the user's perceived social presence towards the artificial agent improves.","shortAbstract":"Humans have a tendency to consider many media devices as social beings","id":"pn1252"},"session":"Human-Robot Interaction","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1252"},"pn1257":{"lastUpdateTime":1389238216391,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386527952854,"checked":true,"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"],"label":"Handheld Devices and Mobile Computing"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","mark.dunlop@strath.ac.uk"],"lastUpdateTime":1386527282383,"label":"Office and Workplace"},"mobile":{"checked":false,"lastUpdateTime":1386527288596,"dislikes":[],"label":"mobile","lastTimeUpdated":1386527262258,"likes":[]},"email overload":{"dislikes":[],"lastTimeUpdated":1386530315705,"checked":true,"likes":[],"label":"email overload"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com","mark.dunlop@strath.ac.uk","wmoncur@dundee.ac.uk"],"lastUpdateTime":1386530356486,"label":"Computer-Mediated Communication"},"email":{"dislikes":[],"lastTimeUpdated":1386530341326,"checked":true,"likes":[],"label":"email"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386530359941,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165021}},"creationTime":937,"content":{"authorList":["Kyle Rector, University of Washington","Joshua Hailpern, Hewlet Packard"],"title":"MinEMail: SMS Alert System for Managing Critical Emails","paperOrNote":"Paper","fullAbstract":"Email is the primary method of digital communication for most people, but the overwhelming quantity has led to a poverty of attention. Existing manual and automatic solutions that aim to save important emails from falling through the cracks have begun to address this problem, but may increase user workload, sacrifice efficiency, or fail to identify high value communications. In response, we developed MinEMail, an alert system that uses a text message (SMS) to remind and notify users of critical emails that may have been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately labeling and predicting which emails are critical, and when and how they need to be addressed. To motivate our system, we also present an up-front study with 777 participants that aims to understand the state and limitations of email and SMS in enterprise. We conduct an experience sampling study of over 3000 emails in order to construct MinEMails predictive models. Finally, we present the results from a 15 user ecologically valid real-world deployment of MinEMail in enterprise.","shortAbstract":"Email is the primary method of digital communication for most people, ","id":"pn1257"},"session":"People: Emotions and Mobiles","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1257"},"pn1255":{"lastUpdateTime":1389222141946,"subcommitteeSplit":"","labels":{"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386522187621,"checked":true,"likes":["yardi@umich.edu","emilee@gmail.com"],"label":"crowdsourcing"},"Twitter":{"dislikes":[],"lastTimeUpdated":1386522479661,"checked":true,"likes":["yardi@umich.edu"],"label":"Twitter"},"social capital":{"dislikes":[],"lastTimeUpdated":1386523991894,"checked":true,"likes":[],"label":"social capital"},"Friendsourcing":{"checked":true,"lastUpdateTime":1386522641153,"dislikes":[],"label":"Friendsourcing","lastTimeUpdated":1386521680286,"likes":[]},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523471873,"label":"Social Computing and Social Navigation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556746}},"creationTime":935,"content":{"authorList":["Jeffrey Rzeszotarski, Microsoft Research","Meredith Morris, Microsoft Research"],"title":"Estimating the Social Costs of Friendsourcing","paperOrNote":"Paper","fullAbstract":"Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.","shortAbstract":"Every day users of social networking services ask their followers and ","id":"pn1255"},"session":"Social: Do Ask Do Tell","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1255"},"pn1490":{"lastUpdateTime":1389222141946,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["mc+frenzy@ecs.soton.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032713}},"creationTime":1148,"content":{"authorList":["Q. Vera Liao, University of Illinois at Urbana-Champaign","Wai-Tat Fu, University of Illinois at Urbana-Champaign"],"title":"Expert Voices in Echo Chambers: Effects of Source Expertise Indicators on Exposure to Diverse Opinions","paperOrNote":"Paper","fullAbstract":"We studied how a source expertise indicator impacted users consumption of information in an opinion-diverse online environment, and how it interacted with a source position indicator to shape users selectivity of information. We found that, while the expertise indicator alone did not significantly affect participants selective exposure tendency, defined as the preferential selection of attitude consistent sources over attitude inconsistent ones, the expertise and position indicators together decreased such tendency among expert sources, but increased it among non-expert ones. We also found that the expertise indicator increased selection of expert sources but decreased that of non-expert sources. This tendency was more persistent for selecting attitude inconsistent sources than consistent ones, suggesting that source expertise plays a more critical role in selecting dissonant information. Moreover, we found that the source expertise indicator increased participants agreement with the information from, and the perceived expertise of the sources indicated as experts. Interestingly, even with same expertise indicators, attitude consistent sources were perceived to have higher expertise than attitude inconsistent ones. Implications for designing systems that present diverse information were discussed.","shortAbstract":"We studied how a source expertise indicator impacted users consumpt","id":"pn1490"},"session":"Social: Do Ask Do Tell","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1490"},"pn576":{"lastUpdateTime":1389222136220,"subcommitteeSplit":"A","labels":{"design in publics":{"dislikes":[],"lastTimeUpdated":1386523635099,"checked":true,"likes":["lennart.nacke@uoit.ca"],"label":"design in publics"},"Citizen Journalism":{"dislikes":[],"lastTimeUpdated":1386523212082,"checked":true,"likes":[],"label":"Citizen Journalism"},"Social Activism":{"dislikes":[],"lastTimeUpdated":1386523256613,"checked":true,"likes":[],"label":"Social Activism"},"Computational Journalism":{"dislikes":[],"lastTimeUpdated":1386523491669,"checked":true,"likes":[],"label":"Computational Journalism"},"Journalism":{"dislikes":[],"lastTimeUpdated":1386523599764,"checked":true,"likes":[],"label":"Journalism"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"New Design Methods":{"dislikes":[],"lastTimeUpdated":1386523556066,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"New Design Methods"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["younlim.cixd@gmail.com"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711795}},"creationTime":359,"content":{"authorList":["Nick Taylor, University of Dundee","David Frohlich, University of Surrey","Paul Egglestone, University of Central Lancashire","Justin Marshall, University College Falmouth","Jon Rogers, University of Dundee","Alicia Blum-Ross, London School of Economics and Political Science","John Mills, University of Central Lancashire","Michael Shorter, University of Dundee","Patrick Olivier, Newcastle University"],"title":"Utilising Insight Journalism for Community Technology Design","paperOrNote":"Paper","fullAbstract":"We describe the process of insight journalism, in which local amateur journalists were used to generate unique insights into the digital needs of a community. We position this as a means for communities to represent themselves to designers, both as a method of designing community technologies and ultimately as a first step towards supporting innovation at a local level. To demonstrate insight journalism, we present two case studies of community technologies that were directly inspired, informed and evaluated by journalistic content. Based on this experience, we evaluate the role that insight journalism can play in designing for communities, the particular characteristics that it lends to the design process and how it might be utilised to support sustainable community innovation.","shortAbstract":"We describe the process of insight journalism, in which local amateur ","id":"pn576"},"session":"Social: Social News","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn576"},"pn751":{"lastUpdateTime":1389236916221,"subcommitteeSplit":"","labels":{"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523486556,"label":"Social Computing and Social Navigation"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":["yardi@umich.edu"],"lastUpdateTime":1386523485394,"label":"Computer-Mediated Communication"},"tie strength":{"dislikes":[],"lastTimeUpdated":1386522737071,"checked":true,"likes":[],"label":"tie strength"},"Social Network Sites":{"dislikes":[],"lastTimeUpdated":1386521484254,"checked":true,"likes":["yardi@umich.edu"],"label":"Social Network Sites"},"Facebook":{"dislikes":[],"lastTimeUpdated":1386522711690,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"Facebook"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522300284,"label":"Computer Supported Cooperative Work (CSCW)"},"social networks":{"checked":false,"lastUpdateTime":1386522725901,"dislikes":[],"label":"social networks","lastTimeUpdated":1386522386421,"likes":[]},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556778}},"creationTime":503,"content":{"authorList":["Moira Burke, Facebook, Inc.","Robert Kraut, Carnegie Mellon University"],"title":"Growing Closer on Facebook: Changes in Tie Strength Through Social Network Site Use","paperOrNote":"Paper","fullAbstract":"Scientists debate whether people grow closer to their friends through social networking sites like Facebook, whether those sites displace more meaningful interaction, or whether they simply reflect existing ties. Combining server log analysis and longitudinal surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we find that communication on the site is associated with changes in reported relationship closeness, over and above effects attributable to their face-to-face, phone, and email contact. Tie strength increases with both one-on-one communication, such as posts, comments, and messages, and through reading friends broadcasted content, such as status updates and photos. The effect is greater for composed pieces, such as comments, posts, and messages than for one-click actions such as Likes and Pokes. Facebook has a greater impact on non-family relationships and ties who do not frequently communicate via other channels.","shortAbstract":"Scientists debate whether people grow closer to their friends through ","id":"pn751"},"session":"HCI4D: Family 2.0","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn751"},"pn750":{"lastUpdateTime":1389591349787,"subcommitteeSplit":"A","labels":{"search":{"dislikes":[],"lastTimeUpdated":1386523891231,"checked":true,"likes":["lorrie@acm.org"],"label":"search"},"interaction science":{"dislikes":[],"lastTimeUpdated":1386524217521,"checked":true,"likes":[],"label":"interaction science"},"replication":{"dislikes":[],"lastTimeUpdated":1386524909708,"checked":false,"likes":["Brumby@cs.ucl.ac.uk"],"label":"replication","lastUpdateTime":1388783456876},"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523863054,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"eye tracking"},"The Eyes Have It":{"dislikes":[],"lastTimeUpdated":1386526299650,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Eyes Have It"},"predictive model":{"dislikes":[],"lastTimeUpdated":1386523912450,"checked":true,"likes":[],"label":"predictive model"},"menus":{"dislikes":[],"lastTimeUpdated":1386523927067,"checked":true,"likes":["lorrie@acm.org"],"label":"menus"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946672},"Models":{"label":"Models","checked":false,"likes":[],"dislikes":[],"lastTimeUpdated":1388783440605,"lastUpdateTime":1388783554682},"Fitts's Law":{"label":"Fitts's Law","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389104904628},"sorta fitz law":{"label":"sorta fitz law","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389104913518}},"creationTime":502,"content":{"authorList":["Gilles Bailly, Max-Planck-Institut fuer Informatik","Antti Oulasvirta, Max Planck Institute for Informatics","Duncan Brumby, University College London","Andrew Howes, University of Birmingham","Xiuli Chen, University of Birmingham"],"title":"Model of Visual Search and Selection Time in Linear Menus","paperOrNote":"Paper","fullAbstract":"This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five factors: 1) menu length, 2) menu organization, 3) target position, 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.","shortAbstract":"This paper presents a novel mathematical model for visual search and s","id":"pn750"},"session":"Methods and Models: User Model 1","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn750"},"pn208":{"lastUpdateTime":1389220864045,"subcommitteeSplit":"","labels":{"Tangible UIs":{"checked":false,"lastUpdateTime":1386526022309,"dislikes":[],"label":"Tangible UIs","lastTimeUpdated":1386525731650,"likes":["S.fairclough@ljmu.ac.uk"]},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"tongue":{"dislikes":[],"lastTimeUpdated":1386525333653,"checked":true,"likes":[],"label":"tongue"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"multimodal interfaces":{"dislikes":[],"lastTimeUpdated":1386525313980,"checked":true,"likes":[],"label":"multimodal interfaces"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644792}},"creationTime":78,"content":{"authorList":["Qiao Zhang, University of Washington","Shyamnath Gollakota, University of Washington","Ben Taskar, University of Washington","Raj Rao, University of Washington"],"title":"Non-Intrusive Tongue Machine Interface","paperOrNote":"Note","fullAbstract":"There has been recent interest in designing systems that use the tongue as an input interface. Prior work however either require surgical procedures or in-mouth sensor placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine interface that can recognize a rich set of tongue gestures using electromyography (EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness of TongueSee with experimental studies to classify six tongue gestures across eight participants. TongueSee achieves a classification accuracy of 94.44% and a false positive probability of 0.0056 per second. Finally, we design a proof-of-concept tongue-based passphrase system that can guard against shoulder surfing attacks","shortAbstract":"There has been recent interest in designing systems that use the tongu","id":"pn208"},"session":"Health: Accessibility","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn208"},"pn205":{"lastUpdateTime":1389221773171,"subcommitteeSplit":"B","labels":{"Multi-channel Applications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-channel Applications"},"User Interface Engineering":{"checked":false,"lastUpdateTime":1386524131690,"dislikes":[],"label":"User Interface Engineering","lastTimeUpdated":1386523712423,"likes":[]},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Multi-Device User Interfaces":{"dislikes":[],"lastTimeUpdated":1386524525541,"checked":true,"likes":[],"label":"Multi-Device User Interfaces"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["nebeling@inf.ethz.ch","xiangcao@acm.org","roudauta@gmail.com"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081883}},"creationTime":75,"content":{"authorList":["Michael Nebeling, ETH Zurich","Theano Mintsi, ETH Zurich","Maria Husmann, ETH Zurich","Moira Norrie, ETH Zurich"],"title":"Interactive Development of Cross-Device User Interfaces","paperOrNote":"Paper","fullAbstract":"Current GUI builders provide a design environment for user interfaces that target either a single type or fixed set of devices, and provide little support for scenarios in which the user interface, or parts of it, are distributed over multiple devices. Distributed user interfaces have received increasing attention over the past years. There are different, often model-based, approaches that focus on technical issues. This paper presents XDStudio--a new GUI builder designed to support interactive development of cross-device user interfaces. XDStudio implements two complementary authoring modes with a focus on the design process of distributed user interfaces. First, simulated authoring allows designing for a multi-device environment on a single device by simulating other target devices. Second, distributed authoring allows the design process itself to be distributed over multiple devices, as design and development take place on the target devices themselves. To support interactive development for multi-device environments, where not all devices may be present at design and run-time, XDStudio supports switching between the two authoring modes, as well as between design and use modes, as required. This paper focuses on the design of XDStudio, and evaluates its support for two distribution scenarios.","shortAbstract":"Current GUI builders provide a design environment for user interfaces ","id":"pn205"},"session":"Systems: Multi-Device User Interfaces","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn205"},"pn683":{"lastUpdateTime":1389221094245,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"User Experience":{"checked":false,"lastUpdateTime":1386531016693,"dislikes":[],"label":"User Experience","lastTimeUpdated":1386528841222,"likes":[]},"gameplay experience":{"dislikes":[],"lastTimeUpdated":1386527853461,"checked":true,"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"label":"gameplay experience"},"user experience":{"dislikes":[],"lastTimeUpdated":1386531014708,"checked":true,"likes":[],"label":"user experience"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165073}},"creationTime":448,"content":{"authorList":["Elisa Mekler, University of Basel","Julia Bopp, University of Basel","Alexandre Tuch, University of Basel","Klaus Opwis, University of Basel"],"title":"Conceptualizations, Determinants and Measures of Game Enjoyment -- A Systematic Review","paperOrNote":"Paper","fullAbstract":"Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop a common understanding of what constitutes an enjoyable game experience. We conducted a systematic review of 87 studies, analyzing different measures and conceptualizations of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes not only players' positive response towards the game itself, but also a positive disposition towards themselves, thanks to several beneficial psychological outcomes of gameplay. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.","shortAbstract":"Enjoyment has been identified as a central component of the player exp","id":"pn683"},"session":"Games: Games","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn683"},"pn687":{"lastUpdateTime":1389236270605,"subcommitteeSplit":"A","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":["mulderi@acm.org"],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Practitioners":{"dislikes":[],"lastTimeUpdated":1386523461438,"checked":true,"likes":[],"label":"Practitioners"},"Personas":{"dislikes":[],"lastTimeUpdated":1386523776608,"checked":true,"likes":[],"label":"Personas"},"Real-world study":{"dislikes":[],"lastTimeUpdated":1386523225644,"checked":true,"likes":[],"label":"Real-world study"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"personas":{"checked":false,"lastUpdateTime":1386530485146,"dislikes":[],"label":"personas","lastTimeUpdated":1386522977043,"likes":[]},"Understanding Design":{"dislikes":[],"lastTimeUpdated":1386523728144,"checked":true,"likes":["scott.davidoff@jpl.nasa.gov"],"label":"Understanding Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711741}},"creationTime":451,"content":{"authorList":["Lene Nielsen, IT University Copenhagen","Kira Storgaard Nielsen, Games and Interaction Design"],"title":"Personas is Applicable  A Study On the Use of Personas In Denmark","paperOrNote":"Paper","fullAbstract":"The persona method is gaining widespread use and support. Many researchers have reported from single cases of how they have used the method, others have reported from use in novel domains. Few have conducted literature studies in order to identify and discuss the different understandings of the method. Fewer still report from ethnographic studies of practice. This paper falls within the last category, it reports from a study on how practitioners in Denmark use the method, and their perceptions of benefits and difficulties when using the method. Finally it analyses different casts of personas obtained from the involved companies. The findings are compared to findings in reported studies of practice. Contrary to the existing findings the study reports that the method is well integrated into existing practices.","shortAbstract":"The persona method is gaining widespread use and support. Many researc","id":"pn687"},"session":"Social: Connecting through Social Media","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn687"},"pn686":{"lastUpdateTime":1388766320872,"subcommitteeSplit":"A","labels":{"Medication":{"dislikes":[],"lastTimeUpdated":1386523070295,"checked":true,"likes":["hilary.hutchinson@gmail.com","weibel@ucsd.edu"],"label":"Medication"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Mobile health":{"dislikes":[],"lastTimeUpdated":1386523740697,"checked":true,"likes":["Jina.huh@gmail.com","Mark.blythe@northumbria"],"label":"Mobile health"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526686170,"label":"User-Centered Design / Human-Centered Design"},"Adherence":{"dislikes":[],"lastTimeUpdated":1386523476341,"checked":true,"likes":[],"label":"Adherence"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188212}},"creationTime":450,"content":{"authorList":["Katarzyna Stawarz, University College London","Anna Cox, University College London","Ann Blandford, University College London"],"title":"Don't Forget Your Pill! Designing Effective Medication Reminder Apps That Support Users' Daily Routines","paperOrNote":"Paper","fullAbstract":"Despite the fact that a third of all cases of unintentional medication non-adherence are caused by simple forgetfulness, the majority of interventions neglect this issue. Even though patients have access to smartphone applications (\"apps\") designed to help them remember medication, neither their quality nor effectiveness has been evaluated yet. We report the findings of a functionality review of 229 medication reminder apps and a thematic analysis of their 1,012 user reviews. Our research highlights the gap between the theory and practice: while the literature shows that many medication regimens are habitual in nature and the presence of daily routines supports remembering, existing apps rely on timer-based reminders. To address this disparity, we present design requirements for building medication reminders that support the routine aspect of medication-taking and its individual nature, and demonstrate how they could be implemented to move from passive alerts to a smarter memory and routine assistant.","shortAbstract":"Despite the fact that a third of all cases of unintentional medication","id":"pn686"},"session":"Health: Health and Everyday Life","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn686"},"pn371":{"lastUpdateTime":1389222210195,"subcommitteeSplit":"","labels":{"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526067571,"label":"Ubiquitous Computing / Smart Environments"},"On your Feet":{"dislikes":[],"lastTimeUpdated":1386525425171,"checked":true,"likes":[],"label":"On your Feet"},"Foot Interaction":{"dislikes":[],"lastTimeUpdated":1386525424446,"checked":true,"likes":[],"label":"Foot Interaction"},"Footsie":{"dislikes":[],"lastTimeUpdated":1386525698886,"checked":true,"likes":[],"label":"Footsie"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["davidmcgookin@gmail.com","bulling@mpi-inf.mpg.de","dan@microsoft.com","S.fairclough@ljmu.ac.uk","no@spam.org","jonfroehlich@gmail.com"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526069325,"label":"Input and Interaction Technologies"},"far-out interaction styles":{"dislikes":[],"lastTimeUpdated":1386525602825,"checked":true,"likes":["no@spam.org","bickmore@ccs.neu.edu"],"label":"far-out interaction styles"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644767}},"creationTime":198,"content":{"authorList":["Dominik Schmidt, Hasso Plattner Institute","Raf Ramakers, Hasselt University - tUL - iMinds","Esben Warming Pedersen, University of Copenhagen","Johannes Jasper, Hasso Plattner Institute","Sven Khler, Hasso Plattner Institute","Aileen Pohl, Hasso Plattner Institute","Hannes Rantzsch, Hasso Plattner Institute","Andreas Rau, Hasso Plattner Institute","Patrick Schmidt, Hasso Plattner Institute","Christoph Sterz, Hasso Plattner Institute","Yanina Yurchenko, Hasso Plattner Institute","Patrick Baudisch, Hasso Plattner Institute"],"title":"Kickables: Tangibles for Feet","paperOrNote":"Paper","fullAbstract":"We introduce the concept of tangibles that users can manipulate with their feet. We call them kickables. Unlike traditional tangibles, kickables allow for very large interaction surfaces as kickables reside on the ground. The main benefit of kickables over other foot-based modalities, such as foot touch, is their strong affordance, which we validate in two user studies. This affordance makes kickables well-suited for walk-up installations, such as tradeshows or museum exhibits.  \\  \\ We present a custom design as well as five families of standard kickables to help application designers create kickable applications faster. Each family supports multiple standard controls, such as push buttons, switches, dials, and sliders. Each type explores a different design principle, in particular different mechanical constraints. We demonstrate an implementation on our pressure-sensing floor. \\ ","shortAbstract":"We introduce the concept of tangibles that users can manipulate with t","id":"pn371"},"session":"UIST: Tangibles","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn371"},"pn372":{"lastUpdateTime":1389222115080,"subcommitteeSplit":"","labels":{"Smartwatches":{"dislikes":[],"lastTimeUpdated":1386531709241,"checked":true,"likes":["eve.hoggan@hiit.fi"],"label":"Smartwatches"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386536971135,"checked":true,"likes":[],"label":"Wearables"},"wearable":{"checked":false,"lastUpdateTime":1386532141330,"dislikes":[],"label":"wearable","lastTimeUpdated":1386532068928,"likes":[]},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Wearable":{"checked":false,"lastUpdateTime":1386536981602,"dislikes":[],"label":"Wearable","lastTimeUpdated":1386532137742,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840639}},"creationTime":199,"content":{"authorList":["Robert Xiao, Carnegie Mellon University","Gierad Laput, Carnegie Mellon University","Chris Harrison, Carnegie Mellon University"],"title":"Expanding the Input Expressivity of Smartwatches with Physical Pan, Twist, Tilt and Click","paperOrNote":"Note","fullAbstract":"Smartwatches promise to bring enhanced convenience to common communication, creation and information retrieval tasks. Due to their prominent placement on the wrist, they must be small and otherwise unobtrusive. This dramatically impacts their usability, and in turn limits the sophistication of interactions we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen for input, as the display is small and our fingers are relatively large. In this work, we propose a complementary input approach: using the watch face as a multi-degree-of-freedom, mechanical interface. We developed a proof of concept smartwatch that supports continuous 2D panning and twist, as well as binary tilt and click. To illustrate the potential of our approach, we developed a series of example applications, many of which are cumbersome  or even impossible  on todays smartwatch devices.","shortAbstract":"Smartwatches promise to bring enhanced convenience to common communica","id":"pn372"},"session":"UIST: Small Devices","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn372"},"pn757":{"lastUpdateTime":1389238496089,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528636658,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Back of Device Interaction":{"checked":false,"lastUpdateTime":1386522070957,"dislikes":[],"label":"Back of Device Interaction","lastTimeUpdated":1386521663268,"likes":[]},"Authentication":{"dislikes":[],"lastTimeUpdated":1386521643597,"checked":true,"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","lorrie@acm.org"],"label":"Authentication"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526502145,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Security":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","me@patrickgage.com","a.sasse@cs.ucl.ac.uk","egelman@cs.berkeley.edu","rob.comber@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Security"},"User Studies":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446320}},"creationTime":507,"content":{"authorList":["Alexander De Luca, University of Munich (LMU)","Marian Harbach, Leibniz University Hannover","Emanuel von Zezschwitz, University of Munich (LMU)","Max-Emanuel Maurer, Netlight Consulting","Bernhard Slawik, University of Munich (LMU)","Heinrich Hussmann, University of Munich (LMU)","Matthew Smith, Leibniz Universitt Hannover"],"title":"Now You See Me, Now You Don't - Protecting Smartphone Authentication from Shoulder Surfers","paperOrNote":"Paper","fullAbstract":"In this paper, we present XSide, an authentication mechanism that uses the front and the back of smartphones to enter stroke-based passwords. Users can switch sides during input to minimize the risk of shoulder surfing. We performed a user study (n = 32) to explore how switching sides during authentication affects usability and security of the system. The results indicate that switching the sides significantly increases security while authentication speed stays relatively fast (<= 4 seconds). The paper furthermore shows how 3D printed prototype cases can improve the back-of-device interaction experience and we provide insights on accuracy of eyes-free input as used in XSide.","shortAbstract":"In this paper, we present XSide, an authentication mechanism that uses","id":"pn757"},"session":"Security: Passwords","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn757"},"pn756":{"lastUpdateTime":1388776467635,"subcommitteeSplit":"","labels":{"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386532451700,"checked":true,"likes":["j.d.hook@ncl.ac.uk","olwal@mit.edu"],"label":"Target Acquisition"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","olwal@mit.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532142269,"checked":true,"likes":["mdixon@cs.washington.edu","tomer@moscovich.net","olwal@mit.edu"],"label":"Touch Input"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Pointing Techniques":{"dislikes":[],"lastTimeUpdated":1386532517348,"checked":true,"likes":[],"label":"Pointing Techniques"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840711}},"creationTime":506,"content":{"authorList":["Oscar Kin-Chung Au, City University of Hong Kong (CityUHK)","Xiaojun Su, City University of Hong Kong","Rynson Lau, City University of Hong Kong"],"title":"LinearDragger: Local Linear Selector for Target Acquisition on Touch Screens","paperOrNote":"Paper","fullAbstract":"Touch input is increasingly popular nowadays, especially for mobile devices such as smartphones and tablet computers. However the human finger has considerably large fingertip size and finger input is imprecise. As such, acquiring small targets on a touch screen is still a challenging task. In this paper, we present the \\\\emph{LinearDragger}, a new and integrated one-finger target acquisition technique for small and clustered targets. The proposed method has two advantages. First, it allows users to select targets in dense clustered groups easily with a single touch-drag-release operation. Second, it maps the 2D selection problem into a more precise 1D selection problem, which is independent of the target distribution. Besides, it also avoids finger occlusion and does not create visual distraction. As a result, it is particularly suitable for applications with dense targets and rich visual elements. Results of our controlled experiments show that when selecting small targets, \\\\emph{LinearDragger} performs better than some popular techniques, while having similar error rates.","shortAbstract":"Touch input is increasingly popular nowadays, especially for mobile de","id":"pn756"},"session":"Touch: Touch","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn756"},"pn755":{"lastUpdateTime":1389222026624,"subcommitteeSplit":"","labels":{"Pointing Techniques":{"dislikes":[],"lastTimeUpdated":1386532365829,"checked":true,"likes":[],"label":"Pointing Techniques"},"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386538639956,"checked":true,"likes":[],"label":"Target Acquisition"},"Selection Techniques":{"dislikes":[],"lastTimeUpdated":1386532358885,"checked":true,"likes":[],"label":"Selection Techniques"},"Target Aquisition":{"checked":false,"lastUpdateTime":1386538643544,"dislikes":[],"label":"Target Aquisition","lastTimeUpdated":1386531793388,"likes":["tomer@moscovich.net"]},"input":{"dislikes":[],"lastTimeUpdated":1386532063591,"checked":true,"likes":["tomer@moscovich.net"],"label":"input"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Mice":{"dislikes":[],"lastTimeUpdated":1386531806979,"checked":true,"likes":[],"label":"Mice"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840605}},"creationTime":505,"content":{"authorList":["Oscar Kin-Chung Au, City University of Hong Kong (CityUHK)","Xiaojun Su, City University of Hong Kong","Rynson Lau, City University of Hong Kong"],"title":"The Implicit Fan Cursor: A Velocity Dependent Area Cursor","paperOrNote":"Paper","fullAbstract":"We present the Implicit Fan Cursor (IFC) -- a novel target pointing technique using a cursor with a fan-shape activation area. \\ The IFC couples the cursor's activation area with its velocity, i.e., the speed and direction of the mouse motion, behaving like a 2D spotlight cursor at low speed and a circular area cursor at high speed. Thus, it enables the user to precisely acquire distant targets at low speed and easily acquire nearest targets at high speed, without explicit mode switching. This technique minimizes cursor movement, while taking into consideration of the precision of cursor movement at different speeds. It also ensures that only one target is captured at any time. The results of our controlled experiments show that the IFC outperforms the point cursor and the area cursor techniques, particularly in terms of cursor moving distance, and that its performance can be accurately modeled using the Fitts' law.","shortAbstract":"We present the Implicit Fan Cursor (IFC) -- a novel target pointing te","id":"pn755"},"session":"UIST: Pointing","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn755"},"pn977":{"lastUpdateTime":1388776604979,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":["eve.hoggan@hiit.fi","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["olwal@mit.edu"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Stereoscopic 3D (S3D)":{"dislikes":[],"lastTimeUpdated":1386532630420,"checked":true,"likes":[],"label":"Stereoscopic 3D (S3D)"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840612}},"creationTime":694,"content":{"authorList":["Dimitar Valkov, University of Muenster","Alexander Giesler, University of Mnster","Klaus Hinrichs, University of Mnster"],"title":"Imperceptible Depth Shifts for Touch Interaction with Stereoscopic Objects","paperOrNote":"Paper","fullAbstract":"While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. \\ Therefore we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object and propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. \\ In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.","shortAbstract":"While touch technology has proven its usability for 2D interaction and","id":"pn977"},"session":"3D: The third dimension","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn977"},"pn198":{"lastUpdateTime":1389237026654,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386532254421,"checked":true,"likes":[],"label":"Multitouch"},"input":{"dislikes":[],"lastTimeUpdated":1386531454147,"checked":true,"likes":[],"label":"input"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532262794,"checked":true,"likes":[],"label":"Touch Input"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840636}},"creationTime":70,"content":{"authorList":["Morgan Dixon, University of Washington","Gierad Laput, Carnegie Mellon University","James Fogarty, University of Washington"],"title":"Examining Sliding Widgets in Existing Interfaces for Hybrid Touch and Mouse-Based Devices","paperOrNote":"Paper","fullAbstract":"There is an emerging class of devices that provide both touch and mouse capabilities, potentially offering the advantages of each device as a way to support mobile and desktop tasks. Unfortunately, graphical interfaces for these devices are either difficult to use or expensive to produce. This is because developers either provide standard mouse-based interfaces, which are difficult to use with touch because targets are small and densely arranged, or developers implement an entire second interface that is optimized for touch. To address this problem, we explore a solution that uses pixel-based reverse engineering to modify existing interfaces in order to better accommodate touch. Specifically, we scale Moscovich et al.s implementation of Sliding Widgets to dynamically replace mouse-based elements throughout Microsoft Windows 8. In our exploration we present novel strategies for defining the behavior and appearance of Sliding Widgets in the context of real-world applications, and we unearth important implications for the design of both Sliding Widgets and pixel-based runtime modifications in general.","shortAbstract":"There is an emerging class of devices that provide both touch and mous","id":"pn198"},"session":"Systems: GUIs","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn198"},"pn975":{"lastUpdateTime":1389221922387,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527149429,"label":"Older Adults"},"social media":{"dislikes":[],"lastTimeUpdated":1386527476150,"checked":true,"likes":[],"label":"social media"},"Computer-Mediated Communication":{"dislikes":[],"lastTimeUpdated":1386526472372,"checked":true,"likes":["maria.wolters@ed.ac.uk"],"label":"Computer-Mediated Communication"},"connectedness":{"dislikes":[],"lastTimeUpdated":1386526445404,"checked":true,"likes":[],"label":"connectedness"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527093980,"label":"Empirical Methods, Qualitative"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486630}},"creationTime":692,"content":{"authorList":["Alexis Hope, MIT","Ted Schwaba, Northwestern University","Anne Marie Piper, Northwestern University"],"title":"Understanding Digital and Material Social Communications for Older Adults","paperOrNote":"Paper","fullAbstract":"Online technologies are promising for helping older adults maintain social connectedness, particularly with younger people, yet many older adults resist or participate minimally in the mainstream technologies used by younger members of their social network. We present results from an interview study involving 22 older adults (age 71-92) to understand communication preferences and values related to social media. Seniors articulate many concerns with online social media, including the time required for legitimate participation, the loss of deeper communication, content irrelevance, and privacy. Additionally, older adults engage in social practices that could be supported by online social technologies, but they rarely use such tools. The theme of material social communications emerges from our data, and we introduce ongoing research involving cultural probes to explore this theme. We conclude with a discussion of older adults values and preferences related to digital and material social communications, and as part of this describe research on bridging technologies to close communication gaps between generations.","shortAbstract":"Online technologies are promising for helping older adults maintain so","id":"pn975"},"session":"Health: Older Adults 2","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn975"},"pn999":{"lastUpdateTime":1389236332031,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"critical design":{"dislikes":[],"lastTimeUpdated":1386521940408,"checked":true,"likes":["wendyju@stanford.edu","silvia.lindtner@gmail.com","aantle@sfu.ca","adf"],"label":"critical design"},"pragmatic design":{"dislikes":[],"lastTimeUpdated":1386522672003,"checked":true,"likes":[],"label":"pragmatic design"},"design research evaluation":{"dislikes":[],"lastTimeUpdated":1386522651776,"checked":true,"likes":[],"label":"design research evaluation"},"constructive design research":{"dislikes":[],"lastTimeUpdated":1386522632597,"checked":true,"likes":["silvia.lindtner@gmail.com"],"label":"constructive design research"},"design theory":{"dislikes":[],"lastTimeUpdated":1386522622647,"checked":true,"likes":["silvia.lindtner@gmail.com","wendyju@stanford.edu"],"label":"design theory"},"research through design":{"dislikes":[],"lastTimeUpdated":1386522637199,"checked":true,"likes":[],"label":"research through design"},"Product Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Product Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"design process":{"dislikes":[],"lastTimeUpdated":1386522627219,"checked":true,"likes":[],"label":"design process"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"Hermeneutics":{"dislikes":[],"lastTimeUpdated":1386522599934,"checked":true,"likes":[],"label":"Hermeneutics"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755964}},"creationTime":715,"content":{"authorList":["Jeffrey Bardzell, Indiana University Bloomington","Shaowen Bardzell, Indiana University Bloomington","Erik Stolterman, Indiana University Bloomington"],"title":"Assessing Critical Designs:  Supporting Reasoned Debates about Critical Design","paperOrNote":"Paper","fullAbstract":"Critical Design has emerged as an important concept in HCI research and practice. It is an intriguing concept and a source of controversies. We propose to shift the conversation away from definitional (or territorial) issues towards the more practical problem of assessment. Inasmuch as they deal at all with critical design, designers, design educators, curators, and researchers alike all make assessments about critical designswhether they count as critical designs, how they are critical, whether they are any good, how they can be made more critical, how critical design processes differ from other design processes, etc. In the hope of supporting reasoned critical design practices, we propose a structured approach to assessing critical designs. This approach brings clarity to analytical units of analysis, the relevance of sociocultural norms, the contingency of the analytical situation, and the analytical isolation and contemplation of critical aspects of a design. ","shortAbstract":"Critical Design has emerged as an important concept in HCI research an","id":"pn999"},"session":"Design: Critical Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn999"},"pn1103":{"lastUpdateTime":1389285494405,"subcommitteeSplit":"","labels":{"Crowdsourcing":{"checked":false,"lastUpdateTime":1386529951365,"dislikes":[],"label":"Crowdsourcing","lastTimeUpdated":1386529919672,"likes":[]},"crowdwork":{"checked":false,"lastUpdateTime":1386529959255,"dislikes":[],"label":"crowdwork","lastTimeUpdated":1386526939019,"likes":[]},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527593688,"label":"Empirical Methods, Quantitative"},"cognition":{"checked":true,"lastUpdateTime":1386527655156,"dislikes":[],"label":"cognition","lastTimeUpdated":1386526986581,"likes":[]},"crowdsourcing":{"checked":false,"lastUpdateTime":1386527555405,"dislikes":[],"label":"crowdsourcing","lastTimeUpdated":1386526960430,"likes":[]},"Flavours":{"checked":false,"lastUpdateTime":1386528935925,"dislikes":[],"label":"Flavours","lastTimeUpdated":1386527907117,"likes":[]},"Usability Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527592096,"label":"Usability Research"},"Boring":{"dislikes":[],"lastTimeUpdated":1386528925628,"checked":true,"likes":["john.vines@ncl.ac.uk"],"label":"Boring"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386529941274,"checked":true,"likes":["judy.kay@gmail.com"],"label":"Crowd-Powered Systems"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527589832,"label":"User Experience Design / Experience Design"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165055}},"creationTime":799,"content":{"authorList":["Harini Alagarai Sampath, International Institute of Information Technology, Hyderabad","Rajeev Rajeshuni, International Institute of Information Technology, Hyderabad","Bipin Indurkhya, International Institute of Information Technology, Hyderabad"],"title":"Cognitively-Inspired Task Design to Improve User Performance on Crowdsourcing Platforms","paperOrNote":"Paper","fullAbstract":"Recent research in human computation has focused on improving the quality of work done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted like filtering crowd workers through qualification tasks, and aggregating responses from multiple crowd workers to obtain consensus. In this paper, we investigate how improving the presentation of the task itself by using cognitively-inspired features affects the performance of crowd workers. We illustrate this with a case-study for the task of extracting text from scanned images. We generated six task-presentation designs by modifying two parameters - visual saliency of the target fields and working memory requirements, and conducted experiments on Amazon Mechanical Turk (AMT) and with an eye-tracker in the lab setting. Our results identify which task-design parameters (e.g. highlighting target fields) result in improved performance, and which ones do not (e.g. reducing number of distractors) do not. In conclusion, we claim that the use of cognitively-inspired features for task design is a powerful technique for maximizing the performance of crowd workers. \\ ","shortAbstract":"Recent research in human computation has focused on improving the qual","id":"pn1103"},"session":"CSCW: Crowdsourcing","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1103"},"pn1818":{"lastUpdateTime":1389238216391,"subcommitteeSplit":"","labels":{"Emotion":{"checked":false,"lastUpdateTime":1386528139884,"dislikes":[],"label":"Emotion","lastTimeUpdated":1386527816074,"likes":[]},"emotion":{"checked":false,"lastUpdateTime":1386527851921,"dislikes":[],"label":"emotion","lastTimeUpdated":1386527838407,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["manfred.tscheligi@sbg.ac.at","marcodesa@gmail.com","wmoncur@dundee.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Emotion and Affective User Interface":{"dislikes":[],"lastTimeUpdated":1386528111595,"checked":true,"likes":["judy.kay@gmail.com","wmoncur@dundee.ac.uk"],"label":"Emotion and Affective User Interface"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":1386531097952,"label":"User Experience Design / Experience Design"},"usability-aestheic relationship":{"checked":false,"lastUpdateTime":1386531078823,"dislikes":[],"label":"usability-aestheic relationship","lastTimeUpdated":1386528370229,"likes":["wmoncur@dundee.ac.uk"]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165075}},"creationTime":1423,"content":{"authorList":["Alexander Meschtscherjakov, University of Salzburg","David Wilfinger, University of Salzburg","Manfred Tscheligi, University of Salzburg"],"title":"Mobile Attachment - Causes and Consequences for Emotional Bonding with Mobile Phones","paperOrNote":"Paper","fullAbstract":"This paper addresses the phenomenon of emotional attachments to mobile phones. We introduce the term \"mobile attachment\" and define it as a bond between a person's self and a mobile phone that varies in strength. Based on a critical reflection of interdisciplinary literature, a conceptual mobile attachment model is developed. Within this model causes, consequences and influencing factors of mobile attachment are exposed and elaborated. We argue that mobile attachment emerges when the mobile phone becomes part of the user's self concept. The link between the user and their mobile phone may be fostered when it empowers, enriches, or gratifies the user's self. Attachment causes lead to \"design space determinants\" that enable user experience designers to design for mobile attachment. Attachment consequences may be operationalized for user experience (UX) evaluation.","shortAbstract":"This paper addresses the phenomenon of emotional attachments to mobile","id":"pn1818"},"session":"People: Emotions and Mobiles","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1818"},"pn1811":{"lastUpdateTime":1389238893968,"subcommitteeSplit":"B","labels":{"warnings":{"dislikes":[],"lastTimeUpdated":1386526425008,"checked":true,"likes":["lorrie@acm.org"],"label":"warnings"},"SSL":{"dislikes":[],"lastTimeUpdated":1386521735159,"checked":true,"likes":[],"label":"SSL"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526434471,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"Security":{"checked":true,"dislikes":[],"likes":["ajbrush@microsoft.com","alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","rob.comber@ncl.ac.uk","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Security"},"User Experience Design / Experience Design":{"dislikes":[],"lastTimeUpdated":1386522237104,"checked":true,"likes":[],"label":"User Experience Design / Experience Design"},"User Studies":{"checked":false,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":1386527212093,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446288}},"creationTime":1416,"content":{"authorList":["Adrienne Felt, Google","Robert Reeder, Google","Hazim Almuhimedi, Carnegie Mellon University","Sunny Consolvo, Google"],"title":"Experimenting At Scale With Google Chrome's SSL Warning","paperOrNote":"Note","fullAbstract":"Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and collected user reactions to 130,754 impressions.","shortAbstract":"Web browsers show HTTPS authentication warnings (i.e., SSL warnings) w","id":"pn1811"},"session":"Security: Security","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1811"},"pn1814":{"lastUpdateTime":1388765615245,"subcommitteeSplit":"A","labels":{"Health and social media":{"dislikes":[],"lastTimeUpdated":1386523162666,"checked":true,"likes":["Jina.huh@gmail.com"],"label":"Health and social media"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523545994,"label":"Empirical Methods, Qualitative"},"network of care":{"dislikes":[],"lastTimeUpdated":1386539099816,"checked":true,"likes":[],"label":"network of care"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188241}},"creationTime":1419,"content":{"authorList":["Jina Huh, Michigan State University","Wanda Pratt, University of Washington"],"title":"Weaving Clinical Expertise in Online Health Communities","paperOrNote":"Paper","fullAbstract":"Many patients visit online health communities to receive support. In face-to-face support groups, health professionals facilitate peer-patients exchanging experience while adding their clinical expertise when necessary. However, the large scale of online health communities makes it challenging for such health professional moderators involvement to happen. To address this challenge of delivering clinical expertise to where patients need them, we explore the idea of semi-automatically providing clinical expertise in online health communities. We interviewed 14 clinicians showing them example peer-patient conversation threads. From the interviews, we learned how the clinicians applied their clinical experience to provide expertise in online health communities. The clinicians continuously assessed when peer-patients were providing appropriate support, what kinds of clinical help they could give online, and when to defer to patients healthcare providers. Using the findings, we present implications for how clinical expertise can be semi-automatically weaved into online health communities.","shortAbstract":"Many patients visit online health communities to receive support. In f","id":"pn1814"},"session":"Health: Social Media and Health","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1814"},"pn1817":{"lastUpdateTime":1389286103691,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523457019,"label":"E-Learning and Education"},"In School":{"dislikes":[],"lastTimeUpdated":1386523534786,"checked":true,"likes":[],"label":"In School"},"classroom learning & teaching":{"dislikes":[],"lastTimeUpdated":1386523734295,"checked":true,"likes":["moher@uic.edu"],"label":"classroom learning & teaching"},"claa":{"checked":false,"lastUpdateTime":1386523716249,"dislikes":[],"label":"claa","lastTimeUpdated":1386523703063,"likes":[]},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526312751,"label":"User Interface Design"},"inquiry learning":{"dislikes":[],"lastTimeUpdated":1386523398086,"checked":true,"likes":[],"label":"inquiry learning"},"Children":{"checked":true,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":123456789,"label":"Children"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188238}},"creationTime":1422,"content":{"authorList":["Tia Shelley, University of Illinois Chicago (UIC)","Leilah Lyons, University of Illinois at Chicago","Tom Moher, University of Illinois at Chicago","Chandan Dasgupta, University of Illinois at Chicago","Brenda Lopez Silva, University of Illinois at Chicago","Alexandra Silva, University of Illinois, Chicago"],"title":"Information-Building Applications: Designing for Data Exploration and Analysis by Elementary School Students","paperOrNote":"Paper","fullAbstract":"The propagation of Inquiry Based Learning has lead to many more elementary students interacting with authentic scientific tools and practices. However, the more problematic realities of scientific data collection, such as noise and large data sets, are often deliberately hidden from students. Students will need to confront these realities and be able to make skillful data scoping decisions in order to make sense of ever more prevalent large datasets. In this paper we introduce the design principles that support Information-Building Applications (IBAs). We also present the design decisions that went into building an exemplar of this class, PhotoMAT (Photo Management and Analysis Tool) and a brief user study to show how the solutions enacted by following these principles are taken up by actual students. ","shortAbstract":"The propagation of Inquiry Based Learning has lead to many more elemen","id":"pn1817"},"session":"HCI4D: Learning and Education","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1817"},"pn2358":{"lastUpdateTime":1387315711746,"subcommitteeSplit":"A","labels":{"Robots":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se","Mark.blythe@northumbria.ac.uk","carmster@gmail.com","lennart.nacke@uoit.ca","joonhwan@snu.ac.kr","adf"],"lastUpdateTime":123456789,"label":"Robots"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523436210,"label":"User-Centered Design / Human-Centered Design"},"Understanding Design":{"dislikes":[],"lastTimeUpdated":1386523393934,"checked":true,"likes":["scott.davidoff@jpl.nasa.gov"],"label":"Understanding Design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"Participatory Design / Cooperative Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522869244,"label":"Participatory Design / Cooperative Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711746}},"creationTime":1893,"content":{"authorList":["HEE RIN LEE, Indiana University","Selma Sabanovic, Indiana University","Erik Stolterman, Indiana University Bloomington"],"title":"Stay on the Boundary: A Critique of the Epistemic Hierarchy in Robot Design Using Artifact Analysis Method","paperOrNote":"Note","fullAbstract":"In recent years, HCI researchers have increased their focus on the power relationships between researchers and users, as well as their interest in developing appropriate methodologies sensitive to politics in design. The differential value applied to expert versus lay knowledge is one of the central factors in these debates. We employed an analytical method called artifact analysis, originally designed to help designers handle the complexity of digital artifacts, to explore expert and non-expert participants knowledge about robotics, a technological field characterized by significant complexity. Our results show that both non-expert users and expert researchers have significant knowledge about robotics, but with different specialtiesusers are more adept at addressing mediated and interaction complexity while researchers are more knowledgeable about internal and external complexity. From our interviews with participants during the artifact analysis exercise, we found that digital artifacts such as robots function as boundary objects between experts and users. Considering this positioning of digital artifacts as boundary objects, we claim designers need to be on the boundary and mediate between the ways in which users and researchers frame technology.","shortAbstract":"In recent years, HCI researchers have increased their focus on the pow","id":"pn2358"},"session":"Human-Robot Interaction","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2358"},"pn2235":{"lastUpdateTime":1389285480381,"subcommitteeSplit":"","labels":{"search":{"checked":false,"lastUpdateTime":1386522044361,"dislikes":[],"label":"search","lastTimeUpdated":1386521943824,"likes":[]},"information search":{"dislikes":[],"lastTimeUpdated":1386524277401,"checked":true,"likes":[],"label":"information search"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523606612,"label":"Empirical Methods, Quantitative"},"creativity":{"dislikes":[],"lastTimeUpdated":1386524063458,"checked":true,"likes":[],"label":"creativity"},"ideation":{"dislikes":[],"lastTimeUpdated":1386521630640,"checked":true,"likes":["teevan@gmail.com"],"label":"ideation"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521545770,"checked":true,"likes":["dmrussell@gmail.com","myriam.lewkowicz@utt.fr","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"crowdsourcing"},"Creativity Support Tools":{"dislikes":[],"lastTimeUpdated":1386524052991,"checked":true,"likes":["teevan@gmail.com"],"label":"Creativity Support Tools"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556704}},"creationTime":1787,"content":{"authorList":["Lixiu Yu, Carnegie Mellon University","Aniket Kittur, Carnegie Mellon University","Robert Kraut, Carnegie Mellon University"],"title":"Searching for Analogical Ideas with Crowds","paperOrNote":"Paper","fullAbstract":"Seeking solutions from one domain to solve problems in another is an effective process of innovation. This process of analogy searching is difficult for both humans and machines. In this paper, we present a novel approach for re-presenting a problem in terms of its abstract structure, and then allowing people to use this structural representation to find analogies. We propose a crowdsourcing process that helps people navigate a large dataset to find analogies. Through two experiments, we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem, and that these ideas result in better solutions than alternative approaches for both the source problem and a structurally similar problem in a different domain. This work provides a useful method for finding analogies, and can streamline innovation for both novices and professional designers.","shortAbstract":"Seeking solutions from one domain to solve problems in another is an e","id":"pn2235"},"session":"CSCW: Crowds and Creativity","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2235"},"to134":{"lastUpdateTime":1389285111611,"subcommitteeSplit":"","labels":{"Sustainability":{"checked":false,"lastUpdateTime":1386528819337,"dislikes":[],"label":"Sustainability","lastTimeUpdated":1386528798693,"likes":[]},"activity recognition":{"checked":false,"lastUpdateTime":1386528217968,"dislikes":[],"label":"activity recognition","lastTimeUpdated":1386525138773,"likes":[]},"sustainability":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528800949,"label":"sustainability"},"engineering":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"engineering"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"health":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"health"},"Activity recognition":{"dislikes":[],"lastTimeUpdated":1386528214710,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Activity recognition"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527775554,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2070,"content":{"authorList":["Saguna Saguna, Monash University","Arkady Zaslavsky, CSIRO","Dipanjan Chakraborty, IBM Research"],"title":"Complex Activity Recognition using Context Driven Activity Theory and Activity Signatures","paperOrNote":"TOCHI","fullAbstract":"In pervasive and ubiquitous computing systems, human activity recognition has immense potential in a large number of application domains. Current activity recognition techniques (i) do not handle variations in sequence, concurrency and interleaving of complex activities; (ii) do not incorporate context; and (iii) require large amounts of training data. There is a lack of a unifying theoretical framework which exploits both domain knowledge and data-driven observations to infer complex activities. In this paper, we propose, develop and validate a novel context-driven activity theory (CDAT) for recognizing complex activities. We develop a mechanism using probabilistic and Markov chain analysis to discover complex activity signatures and generate complex activity definitions. We also develop a complex activity recognition algorithm (CAR). It achieves an overall accuracy of 95.73% using extensive experimentation with real-life test data. CDAT utilizes context and links complex activities to situations which reduces inference time by 32.5% and also reduces training data by 66%.","shortAbstract":"In pervasive and ubiquitous computing systems, human activity recognit","id":"to134"},"session":"UBI: Activity Recognition","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to134"},"to135":{"lastUpdateTime":1389222230397,"subcommitteeSplit":"","labels":{"crowdsourced experiments":{"dislikes":[],"lastTimeUpdated":1386525999438,"checked":true,"likes":[],"label":"crowdsourced experiments"},"input":{"dislikes":[],"lastTimeUpdated":1386525153526,"checked":true,"likes":[],"label":"input"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386525160836,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"Text Entry"},"Input and Interaction Technologies":{"dislikes":[],"lastTimeUpdated":1386525156578,"checked":true,"likes":[],"label":"Input and Interaction Technologies"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527807225,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2071,"content":{"authorList":["Keith Vertanen, Montana Tech","Per Ola Kristensson, University of St Andrews"],"title":"Complementing Text Entry Evaluations with a Composition Task","paperOrNote":"TOCHI","fullAbstract":"A common methodology for evaluating text entry methods is to ask participants to transcribe a predefined set of memorable sentences or phrases. In this paper we explore if we can complement the conventional transcription task with a more externally valid composition task. In a series of large-scale crowdsourced experiments, we found that participants could consistently and rapidly invent high quality and creative compositions with only modest reductions in entry rates. Based on our series of experiments, we provide a best-practice procedure for using composition tasks in text entry evaluations.  This includes a judging protocol which can be performed either by the experimenters or by workers on a crowdsourcing microtask market. We evaluated our composition task procedure using a text entry method unfamiliar to participants. Our empirical results show that the composition task can serve as a valid and complementary text entry evaluation method.","shortAbstract":"A common methodology for evaluating text entry methods is to ask parti","id":"to135"},"session":"UIST: Text Entry and Evaluation","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to135"},"to136":{"lastUpdateTime":1389284893302,"subcommitteeSplit":"","labels":{"Sustainability":{"dislikes":[],"lastTimeUpdated":1386528791389,"checked":true,"likes":[],"label":"Sustainability"},"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"sustainability":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386528793285,"label":"sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"Ethnography":{"dislikes":[],"lastTimeUpdated":1386526272440,"checked":true,"likes":[],"label":"Ethnography"},"sensory ethnography":{"dislikes":[],"lastTimeUpdated":1386526282469,"checked":true,"likes":[],"label":"sensory ethnography"},"special issue - sustainability":{"dislikes":[],"lastTimeUpdated":1386523626906,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - sustainability"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527795113,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2072,"content":{"authorList":["Sarah Pink, RMIT","Kerstin Leder Mackley, Loughborough University","Val Mitchell, Loughborough University","Marcus Hanratty, Loughborough University","Carolina Escobar-Tello, Loughborough University","Tracy Bhamra, Loughborough University","Roxana Morosanu, Loughborough University"],"title":"Applying the Lens of Sensory Ethnography to Sustainable HCI","paperOrNote":"TOCHI","fullAbstract":"Sociological appropriations of practice theory as applied to sustainable design have successfully problematized overly simplistic and individualistic models of consumer choice and behavior change. By taking everyday practices as the principal units of analysis, they move towards acknowledging the socially and materially structured nature of human activity. However, to inform sustainable HCI we also need to understand how practices are part of wider experiential environments and flows of practical activity. In this article, we develop an approach rooted in phenomenological anthropology and sensory ethnography. This approach builds on theories of place, perception and movement and enables us to situate practices, and understand practical activity, as emplaced within complex and shifting ecologies of things. Drawing on an interdisciplinary study of domestic energy consumption and digital media use, we discuss ethnographic and design practice examples. We demonstrate how this theoretical and methodological framework can be aligned with the 3rd paradigm of HCI.","shortAbstract":"Sociological appropriations of practice theory as applied to sustainab","id":"to136"},"session":"HCI4D: Sustainability Perspectives","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to136"},"to137":{"lastUpdateTime":1389285494405,"subcommitteeSplit":"","labels":{"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386525020373,"checked":true,"likes":["dan@danielashbrook.com"],"label":"crowdsourcing"},"planning":{"dislikes":[],"lastTimeUpdated":1386524848745,"checked":true,"likes":[],"label":"planning"},"Tasks and Plans":{"dislikes":[],"lastTimeUpdated":1386536981939,"checked":true,"likes":[],"label":"Tasks and Plans"},"natural language processing":{"dislikes":[],"lastTimeUpdated":1386525049254,"checked":true,"likes":[],"label":"natural language processing"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527800562,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2073,"content":{"authorList":["Nicolas Kokkalis, Stanford University","Thomas Khn, Stanford University","Johannes Huebner, Stanford University","Moontae Lee, Stanford University","Florian Schulze, Stanford University","Scott Klemmer, UC San Diego"],"title":"TaskGenies: Automatically Providing Action Plans Helps People Complete Tasks","paperOrNote":"TOCHI","fullAbstract":"People complete tasks more quickly when they have concrete plans. However, they often fail to create such action plans. (How) can systems provide these concrete steps automatically? This article demonstrates that these benefits can also be realized when these plans are created by others or reused from similar tasks. Four experiments test these approaches, finding that people indeed complete more tasks when they receive externally-created action plans. To automatically provide plans, we introduce the Genies workflow that combines benefits of crowd wisdom, collaborative refinement, and automation. We demonstrate and evaluate this approach through the TaskGenies system, and introduce an NLP similarity algorithm for reusing plans. We demonstrate that it is possible for people to create action plans for others, and we show that it can be cost effective.","shortAbstract":"People complete tasks more quickly when they have concrete plans. Howe","id":"to137"},"session":"CSCW: Crowdsourcing","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to137"},"to131":{"lastUpdateTime":1388776832811,"subcommitteeSplit":"","labels":{"management":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"management"},"user experience":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"user experience"},"Vehicular":{"dislikes":[],"lastTimeUpdated":1386525859322,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Vehicular"},"engineering":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"engineering"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"text to speech":{"dislikes":[],"lastTimeUpdated":1386525653596,"checked":true,"likes":[],"label":"text to speech"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527783242,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2067,"content":{"authorList":["Sergej Truschin, Technische Universitt Mnchen","Michael Schermann, Technische Universitt Mnchen","Suparna Goswami, Technische Universitt Mnchen","Helmut Krcmar, Technische Universitt Mnchen"],"title":"Designing Interfaces for Multiple-Goal Environments: Experimental Insights from In-Vehicle Speech Interfaces","paperOrNote":"TOCHI","fullAbstract":"Designing computer-human interfaces for multiple-goal environments is challenging because people pursue multiple goals with conflicting priorities. Safety-critical environments, such as driving, aggravate the need for a more nuanced understanding of interfaces that may reconcile conflicting tasks. Speech interfaces are prime examples of such interfaces. In this paper, we investigate how design variations of an in-vehicle speech interface influence performance of a primary task (driving safely) and a secondary task (e-mailing). In a controlled experiment, we test the performance implications of using single computer-generated text-to-speech (TTS) voice and multiple matching TTS voices while users respond to e-mails with varying levels of complexity during driving. Our results indicate that the number of voices used has a significant effect on both driving performance and handling e-mail related activities. We discuss potentially unintended consequences of making the interface too naturalistic and too engaging for the driver and conclude with theoretical and practical implications. ","shortAbstract":"Designing computer-human interfaces for multiple-goal environments is ","id":"to131"},"session":"Transportation: Driving Me Mental","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to131"},"to132":{"lastUpdateTime":1389591298737,"subcommitteeSplit":"","labels":{"special issue - turn to wild":{"dislikes":[],"lastTimeUpdated":1386523229888,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - turn to wild"},"research methods":{"dislikes":[],"lastTimeUpdated":1386524153455,"checked":true,"likes":[],"label":"research methods"},"ethnography":{"checked":false,"lastUpdateTime":1386531377220,"dislikes":[],"label":"ethnography","lastTimeUpdated":1386524135063,"likes":[]},"Ethnography":{"dislikes":[],"lastTimeUpdated":1386531375284,"checked":true,"likes":[],"label":"Ethnography"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527780001,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2068,"content":{"authorList":["John Rooksby, University of Glasgow"],"title":"Wild in the Laboratory: A Discussion of Plans and Situated Actions","paperOrNote":"TOCHI","fullAbstract":"Suchmans book Plans and Situated Actions has been influential in HCI (Human Computer Interaction).  The book is often discussed with reference to ethnographic fieldwork, sometimes being cited as if it were a field study.  However, the book uses examples from a laboratory study and contains criticisms of ethnography.  This paper explores how and why Suchman carried out a laboratory study.  Based upon this exploration, it argues that social analysis in HCI does not necessitate fieldwork outside the laboratory.  More broadly, the paper argues that an appreciation of Plans and Situated Actions can help in moving towards forms of social analysis that span both the laboratory and the world outside.  If there is to be a turn to the wild in HCI, this should not be a turn away from the laboratory but a turn away from research methods that ignore human practice.  This is not to defend laboratory experiments, but lab-based studies that explicate technology in practice.   ","shortAbstract":"Suchmans book Plans and Situated Actions has been influential in HC","id":"to132"},"session":"Methods and Models: Turn to the Wild","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to132"},"to133":{"lastUpdateTime":1389284883677,"subcommitteeSplit":"","labels":{"special issue - sustainability":{"dislikes":[],"lastTimeUpdated":1386523546600,"checked":true,"likes":["jeff@jeffreynichols.com"],"label":"special issue - sustainability"},"design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"design"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527728682,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2069,"content":{"authorList":["Lenneke Kuijer, Delft University of Technology","Annelise de Jong, Interactive Institute, Design research Unit","Daan Van Eijk, Delft University of Technology"],"title":"Practices as a Unit of Design: An Exploration of Theoretical Guidelines in a Study on Bathing","paperOrNote":"TOCHI","fullAbstract":"The sustainability challenges facing society today require approaches that look beyond single product-user interactions. Focusing on socially shared practicese.g. cooking, launderinghas been identified as a promising direction. Building on a growing body of research in sustainable HCI that takes practices as unit of analysis, this article explores what it means to take practices as a unit of design. Drawing on theories of practice, it proposes that practice-oriented design approaches should: involve bodily performance, create crises of routine and generate a variety of performances. These guidelines were integrated into a Generative Improv Performances (GIP) approach, entailing a series of performances by improvisation actors with low-fidelity prototypes in a lab environment. The approach was implemented in an empirical study on bathing. Although the empirical example does not deal with common types of interactive technologies, the guidelines and GIP approach offer sustainable HCI a way to think beyond immediate interactions and to conceptualize change on a practice level.","shortAbstract":"The sustainability challenges facing society today require approaches ","id":"to133"},"session":"HCI4D: Sustainability and Everyday Practices","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to133"},"pn1704":{"lastUpdateTime":1389238262241,"subcommitteeSplit":"C","labels":{"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526882004,"label":"Usability Testing and Evaluation"},"Camera-based UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526879833,"label":"Camera-based UIs"},"Museum experience":{"dislikes":[],"lastTimeUpdated":1386526241003,"checked":true,"likes":["karyn.moffatt@mcgill.ca","f.hwang@reading.ac.uk","kgajos@eecs.harvard.edu","bpbailey@illinois.edu"],"label":"Museum experience"},"heritage":{"dislikes":[],"lastTimeUpdated":1386526547015,"checked":true,"likes":[],"label":"heritage"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526887367,"label":"Interaction Design"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526888942,"label":"User Experience Design / Experience Design"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486605}},"creationTime":1323,"content":{"authorList":["Leonard Wein, University of Amsterdam"],"title":"Visual Recognition in Museum Guide Apps: Do Visitors Want It?","paperOrNote":"Note","fullAbstract":"In this paper, visual recognition (VR) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VR. A prototype featuring VR, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VR. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for visual recognition among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of visual recognition to improve visitors museum experiences.","shortAbstract":"In this paper, visual recognition (VR) is evaluated as a method to acc","id":"pn1704"},"session":"Art: Museum Experience","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1704"},"pn1670":{"lastUpdateTime":1389285684614,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Boring":{"checked":false,"lastUpdateTime":1386531460661,"dislikes":[],"label":"Boring","lastTimeUpdated":1386527694343,"likes":[]},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Performance Metrics":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531471037,"label":"Performance Metrics"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165096}},"creationTime":1292,"content":{"authorList":["Mirjam Seckler, University of Basel","Silvia Heinz, University of Basel","Javier Bargas-Avila, Google, Inc.","Klaus Opwis, University of Basel","Alexandre Tuch, University of Copenhagen"],"title":"Designing Usable Web Forms  Empirical Evaluation of Web Form Optimization Guidelines","paperOrNote":"Paper","fullAbstract":"This study reports a controlled eye tracking experiment (N = 63) that shows the combined effectiveness of 20 guidelines to optimize interactive online forms when applied to forms found on real company websites. Results indicate that optimized web forms lead to faster completion times, less form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to optimize their web forms using UX guidelines.","shortAbstract":"This study reports a controlled eye tracking experiment (N = 63) that ","id":"pn1670"},"session":"Web: Web","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1670"},"pn1675":{"lastUpdateTime":1389238017883,"subcommitteeSplit":"","labels":{"urban":{"dislikes":[],"lastTimeUpdated":1386523050731,"checked":true,"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk","myriam.lewkowicz@utt.fr","teevan@gmail.com","emilee@gmail.com"],"label":"urban"},"Smartphones":{"dislikes":[],"lastTimeUpdated":1386524146307,"checked":true,"likes":[],"label":"Smartphones"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"in the city":{"dislikes":[],"lastTimeUpdated":1386523643109,"checked":true,"likes":[],"label":"in the city"},"Ubiquitous Computing / Smart Environments":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523739955,"label":"Ubiquitous Computing / Smart Environments"},"geo-social media":{"dislikes":[],"lastTimeUpdated":1386526555161,"checked":true,"likes":[],"label":"geo-social media"},"smart city":{"dislikes":[],"lastTimeUpdated":1386523079466,"checked":true,"likes":["emailaddress"],"label":"smart city"},"heck frickin' yeah":{"dislikes":[],"lastTimeUpdated":1386526478640,"checked":true,"likes":[],"label":"heck frickin' yeah"},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523533325,"label":"Prototyping"},"Location based technologies":{"dislikes":[],"lastTimeUpdated":1386523054415,"checked":true,"likes":[],"label":"Location based technologies"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523531838,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386526532363,"label":"Social Computing and Social Navigation"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522078221,"label":"User Studies"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522076734,"label":"Computer Supported Cooperative Work (CSCW)"},"Location":{"dislikes":[],"lastTimeUpdated":1386522554092,"checked":true,"likes":["sadat@us.ibm.com","emilee@gmail.com"],"label":"Location"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556661}},"creationTime":1297,"content":{"authorList":["David McGookin, University of Glasgow","Stephen Brewster, University of Glasgow","Georgi Christov, University of Glasgow"],"title":"DigiGraff: Investigating Graffiti for Location-Based Social Networks","paperOrNote":"Paper","fullAbstract":"The recent rise in geo-tagged social media has led to interest in how that  media can be  re-integrated into the physical environment, and the services this offers. However, as location is automatically appended to such media without direct user involvement, we do not know how users consider  the location where they create social media when they create it, or what links to location can be inferred by other viewers of that media. To investigate this  we developed and evaluated DigiGraff: a novel social media service, strongly based on the affordances of graffiti, that allows the unconstrained digital annotation of the physical environment.  A two week field study was conducted to investigate how users relate media to the environment, the roles this fulfils and how best to view that media in relation to the environment. We found that DigiGraff fulfilled multiple concurrent roles, ranging from utilitarian to artistic. Whilst users often intended media they created to relate to the environment, the nature of that relationship was complex and  often not understood by viewers of that media. In cases were there was a strong relationship, deeply embedding the media into the environment through projection was preferred.  We outline implications of our work for services that seek to repurpose existing geo-tagged social media in the design of novel services. ","shortAbstract":"The recent rise in geo-tagged social media has led to interest in how ","id":"pn1675"},"session":"People: Location Location Location","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1675"},"pn1709":{"lastUpdateTime":1389221181945,"subcommitteeSplit":"B","labels":{"design tools":{"dislikes":[],"lastTimeUpdated":1386522385537,"checked":true,"likes":[],"label":"design tools"},"Exergames":{"dislikes":[],"lastTimeUpdated":1386538758108,"checked":true,"likes":[],"label":"Exergames"},"Entertainment":{"checked":false,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":1386522942112,"label":"Entertainment"},"exertion interfaces":{"dislikes":[],"lastTimeUpdated":1386522614417,"checked":true,"likes":[],"label":"exertion interfaces"},"dance/movement":{"dislikes":[],"lastTimeUpdated":1386522241682,"checked":true,"likes":["wendyju@stanford.edu","ztoups@nmsu.edu"],"label":"dance/movement"},"Creativity Support Tools":{"dislikes":[],"lastTimeUpdated":1386522596566,"checked":true,"likes":["ztoups@nmsu.edu"],"label":"Creativity Support Tools"},"whole body interaction":{"dislikes":[],"lastTimeUpdated":1386522394892,"checked":true,"likes":["aantle@sfu.ca"],"label":"whole body interaction"},"Exergame":{"checked":false,"lastUpdateTime":1386538754095,"dislikes":[],"label":"Exergame","lastTimeUpdated":1386538750213,"likes":[]},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755974}},"creationTime":1328,"content":{"authorList":["Florian Mueller, RMIT University","Martin Gibbs, The University of Melbourne","Frank Vetere, The University of Melbourne","Darren Edge, Microsoft Research Asia"],"title":"Supporting the creative game design process with Exertion Cards","paperOrNote":"Paper","fullAbstract":"Advances in sensing technologies have led to a focus on exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are still no tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the Exertion Framework, grounded in our experience of creating exertion games for over a decade. We studied the use of these Exertion Cards in three workshops held over seven sessions with 134 design students and experts, and present results that suggest the utility of the cards. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.","shortAbstract":"Advances in sensing technologies have led to a focus on exertion games","id":"pn1709"},"session":"Games: Exergame Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1709"},"pn1241":{"lastUpdateTime":1389285319334,"subcommitteeSplit":"A","labels":{"anticipation":{"dislikes":[],"lastTimeUpdated":1386523451513,"checked":true,"likes":[],"label":"anticipation"},"slow design":{"dislikes":[],"lastTimeUpdated":1386522828949,"checked":true,"likes":[],"label":"slow design"},"Reflection":{"dislikes":[],"lastTimeUpdated":1386523346236,"checked":true,"likes":[],"label":"Reflection"},"Flickr":{"dislikes":[],"lastTimeUpdated":1386523475730,"checked":true,"likes":[],"label":"Flickr"},"non-interactive artifact":{"dislikes":[],"lastTimeUpdated":1386523432518,"checked":true,"likes":[],"label":"non-interactive artifact"},"Photo sharing":{"dislikes":[],"lastTimeUpdated":1386537365378,"checked":false,"likes":[],"label":"Photo sharing","lastUpdateTime":1387553062247},"Interaction Design":{"checked":false,"dislikes":[],"likes":["rwakkary@sfu.ca"],"lastUpdateTime":1386523430198,"label":"Interaction Design"},"Home":{"dislikes":[],"lastTimeUpdated":1386522935782,"checked":true,"likes":[],"label":"Home"},"longitudinal field study":{"dislikes":[],"lastTimeUpdated":1386523151262,"checked":true,"likes":[],"label":"longitudinal field study"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["Mark.blythe@northumbria.ac.uk"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"photo sharing":{"checked":true,"lastUpdateTime":1387553060898,"dislikes":[],"label":"photo sharing","lastTimeUpdated":1386523082740,"likes":[]},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711782},"Tangible UIs":{"label":"Tangible UIs","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389224410964},"Tangibles":{"label":"Tangibles","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389224419296}},"creationTime":923,"content":{"authorList":["William Odom, Carnegie Mellon University","Abigail Sellen, Microsoft Research","Richard Banks, Microsoft Research","David Kirk, Newcastle University","Tim Regan, Microsoft","Mark Selby, The University of Nottingham","Jodi Forlizzi, Carnegie Mellon University","John Zimmerman, Carnegie Mellon University"],"title":"Designing for Slowness, Anticipation and Re-visitation: A Long Term Field Study of the Photobox","paperOrNote":"Paper","fullAbstract":"We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owners Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months, to explore how its slowness might grow anticipation and create an interaction pace that supports re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and outside of the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community.","shortAbstract":"We describe the design, implementation and deployment of Photobox, a d","id":"pn1241"},"session":"Web: Photo sharing","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1241"},"pn1242":{"lastUpdateTime":1389221709637,"subcommitteeSplit":"A","labels":{"User studies of medical devices":{"dislikes":[],"lastTimeUpdated":1386523793878,"checked":true,"likes":[],"label":"User studies of medical devices"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527330711,"label":"Usability Testing and Evaluation"},"Health Care":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":["beverly_harrison@yahoo.com"],"lastUpdateTime":1386524410844,"label":"Empirical Methods, Qualitative"},"User Studies":{"dislikes":[],"lastTimeUpdated":1386523587646,"checked":true,"likes":[],"label":"User Studies"},"autoethnography":{"dislikes":[],"lastTimeUpdated":1386524372286,"checked":true,"likes":[],"label":"autoethnography"},"self studies":{"dislikes":[],"lastTimeUpdated":1386523754925,"checked":true,"likes":[],"label":"self studies"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946679}},"creationTime":924,"content":{"authorList":["Aisling Ann O'Kane, ","Ann Blandford, University College London"],"title":"Im in the washroom trying to be silent but also quick: Evaluating Non-Routine Mobile Device Use with Self-Study","paperOrNote":"Note","fullAbstract":"In this paper, we report on autoethnography as a method to access non-routine usage of mobile devices, such as during business trips, vacations, etc. Autoethnography, a self-study method with the researcher as participant, was employed for the evaluation of a wrist blood pressure monitor usually used by patients. Surprising insights into the impact that environmental and social contexts had on the use and adoption of the technology were gained in these non-routine times. It was found that, although the method can be very disruptive to a researchers life, it is a relatively easy to implement, lightweight method to access empathy for the experiences users of mobile devices might face in context. This method allows HCI researchers to better understand user experiences with mobile devices, especially during non-routine times that can be difficult to study in-situ with traditional user studies.","shortAbstract":"In this paper, we report on autoethnography as a method to access non-","id":"pn1242"},"session":"Social: Lonely, Sad and Awful","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1242"},"pn1482":{"lastUpdateTime":1389220864045,"subcommitteeSplit":"C","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk","tjvg@di.fc.ul.pt","mtory@cs.uvic.ca"],"lastUpdateTime":1386527026745,"label":"Input and Interaction Technologies"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk","kgajos@eecs.harvard.edu","vlh@acm.org"],"lastUpdateTime":1386527058422,"label":"Universal (or Disability)  Access"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386526559752,"checked":true,"likes":["kash@diku.dk","awaller@computing.dundee.ac.uk","mtory@cs.uvic.ca"],"label":"Wearables"},"Participatory Design / Cooperative Design":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk","andrew.sears@rit.edu"],"lastUpdateTime":1386527010047,"label":"Participatory Design / Cooperative Design"},"motor control":{"checked":false,"lastUpdateTime":1386526974389,"dislikes":[],"label":"motor control","lastTimeUpdated":1386526710523,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486621}},"creationTime":1140,"content":{"authorList":["Patrick Carrington, UMBC","Amy Hurst, ","Shaun Kane, UMBC"],"title":"Wearables and Chairables: Inclusive Design of Mobile Input and Output Techniques for Power Wheelchair Users","paperOrNote":"Paper","fullAbstract":"Power wheelchair users often use and carry multiple mobile computing devices. Many power wheelchair users have some upper body motor impairment that can make using these devices difficult. We believe that mobile device accessibility could be improved through designs that take into account users functional abilities and take advantage of available space around the wheelchair itself. In this paper we present findings from multiple design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring the placement and form factor possibilities for input and output on a power wheelchair. We found that many power wheelchair users could benefit from chairable technology that is designed to work within the workspace of the wheelchair, whether worn on the body or mounted on he wheelchair frame. We present participants preferences for chairable input and output devices, and identify possible design configurations for wearable and chairable devices. ","shortAbstract":"Power wheelchair users often use and carry multiple mobile computing d","id":"pn1482"},"session":"Health: Accessibility","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1482"},"pn1485":{"lastUpdateTime":1389221780441,"subcommitteeSplit":"","labels":{"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Interactive Machine Learning":{"dislikes":[],"lastTimeUpdated":1386523750156,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Interactive Machine Learning"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081843}},"creationTime":1143,"content":{"authorList":["Todd Kulesza, Oregon State University","Saleema Amershi, Microsoft Research","Rich Caruana, Microsoft Research","Danyel Fisher, Microsoft Research","Denis Charles, Microsoft Research"],"title":"Structured Labeling for Facilitating Concept Evolution in Machine Learning","paperOrNote":"Paper","fullAbstract":"Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution, the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than a traditional method.","shortAbstract":"Labeling data is a seemingly simple task required for training many ma","id":"pn1485"},"session":"Systems: Machines Interactively Learning","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1485"},"pn1488":{"lastUpdateTime":1389222115080,"subcommitteeSplit":"","labels":{"On-Body Interfaces":{"checked":true,"lastUpdateTime":1386525779580,"dislikes":[],"label":"On-Body Interfaces","lastTimeUpdated":1386525339606,"likes":[]},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386525384145,"checked":true,"likes":["elm@purdue.edu","bickmore@ccs.neu.edu","no@spam.org","benko@microsoft.com","aquigley@st-andrews.ac.uk"],"label":"Touch Input"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644842}},"creationTime":1146,"content":{"authorList":["Martin Weigel, Max Planck Institute for Informatics","Vikram Mehta, Max Planck Institute for Informatics","Jrgen Steimle, Max Planck Institute for Informatics"],"title":"More Than Touch: Understanding How People Use Skin as an Input Surface for Mobile Computing","paperOrNote":"Paper","fullAbstract":"This paper contributes results from an empirical study of on-skin input, an emerging technique for controlling mobile devices. Skin is fundamentally different from off-body touch surfaces, opening up a new and largely unexplored interaction space. We investigate characteristics of the various skin-specific input modalities, analyze what kinds of gestures are performed on skin, and study what are preferred input locations. Our main results show that (1) users intuitively leverage the properties of skin for a wide range of more expressive commands than on conventional touch surfaces; (2) established multi-touch gestures can be transferred to on-skin input; (3) physically uncomfortable modalities are deliberately used for irreversible commands and expressing negative emotions; and (4) the forearm and the hand are most preferred locations for on-skin input. We detail on users mental models and contribute a first consolidated set of on-skin gestures. Our results provide guidance for developers of future sensors as well as for designers of future applications of on-skin input.","shortAbstract":"This paper contributes results from an empirical study of on-skin inpu","id":"pn1488"},"session":"UIST: Small Devices","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1488"},"pn219":{"lastUpdateTime":1389238200057,"subcommitteeSplit":"A","labels":{"Social Media":{"checked":false,"lastUpdateTime":1386528859468,"dislikes":[],"label":"Social Media","lastTimeUpdated":1386524827478,"likes":["asellen@microsoft.com"]},"Virtual Community / Community Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525110546,"label":"Virtual Community / Community Computing"},"Health and social media":{"dislikes":[],"lastTimeUpdated":1386525099439,"checked":true,"likes":[],"label":"Health and social media"},"Social Media and Habits":{"dislikes":[],"lastTimeUpdated":1386525484594,"checked":true,"likes":["dgergle@northwestern.edu"],"label":"Social Media and Habits"},"Social and Legal issues":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525030789,"label":"Social and Legal issues"},"social media":{"dislikes":[],"lastTimeUpdated":1386528858189,"checked":true,"likes":[],"label":"social media"},"breaking the addiction of social media":{"dislikes":[],"lastTimeUpdated":1386524772528,"checked":true,"likes":[],"label":"breaking the addiction of social media"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524672722,"label":"Computer-Mediated Communication"},"social media addiction":{"dislikes":[],"lastTimeUpdated":1386525348439,"checked":true,"likes":[],"label":"social media addiction"},"Behavior Modification":{"dislikes":[],"lastTimeUpdated":1386525093276,"checked":true,"likes":[],"label":"Behavior Modification"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946690}},"creationTime":87,"content":{"authorList":["Sarita Yardi Schoenebeck, University of Michigan"],"title":"Giving up Twitter for Lent: How and Why We Take Breaks from Social Media","paperOrNote":"Paper","fullAbstract":"Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31%  acknowledge their failure; the other 69% simply return. We observe hedging patterns (e.g. I thought about giving up Twitter for Lent but) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in real life. We discuss gaps in related theory that might help reduce users anxieties and open design problems related to designing systems and services that can help users manage their own social media use. ","shortAbstract":"Social media use is widespread, but many people worry about overuse. T","id":"pn219"},"session":"People: constant connectivity","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn219"},"pn216":{"lastUpdateTime":1389285580072,"subcommitteeSplit":"B","labels":{"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522115593,"label":"Prototyping"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Internationalization / Localization":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu","wendyju@stanford.edu","aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"Internationalization / Localization"},"Exertion games":{"checked":false,"lastUpdateTime":1386522758589,"dislikes":[],"label":"Exertion games","lastTimeUpdated":1386522750664,"likes":[]},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755949}},"creationTime":85,"content":{"authorList":["Luis A. Leiva, ITI/DSIC, Universitat Politcnica de Valncia","Vicent Alabau, Universidad Politcnica de Valencia (UPV)"],"title":"The Impact of Visual Contextualization on UI Localization","paperOrNote":"Note","fullAbstract":"Translating the text in an interface is a challenging task. Besides the jargon and technical terms, many of the strings are often very short, such as those shown in buttons and pull-down menus. Then, as a result of the lack of visual context in the traditional localization process, an important ambiguity problem arises. We study three approaches to solve this problem: using plain gettext (baseline condition), using gettext plus being able to operate the UI, and translating the UI in-place. We found that translators are substantially faster with plain gettext but commit a significantly higher number of errors in comparison to the other approaches. Unexpectedly, the mixed condition was slower and more error-prone than in-place translation. The latter was found to be comparable to plain gettext in terms of time, although some strings passed unnoticed as the UI was operated. Based on our results, we arrive at a set of recommendations to augment localization tools to improve translator's productivity.","shortAbstract":"Translating the text in an interface is a challenging task. Besides th","id":"pn216"},"session":"HCI4D: Lost and Found in Translation","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn216"},"pn692":{"lastUpdateTime":1388761461342,"subcommitteeSplit":"","labels":{"E-Learning and Education":{"dislikes":[],"lastTimeUpdated":1386527087710,"checked":true,"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"label":"E-Learning and Education"},"User Studies":{"checked":false,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":1386531838256,"label":"User Studies"},"Usability Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527108604,"label":"Usability Research"},"Video":{"checked":false,"lastUpdateTime":1386531826404,"dislikes":[],"label":"Video","lastTimeUpdated":1386527788393,"likes":[]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165029}},"creationTime":455,"content":{"authorList":["James Nicholson, Newcastle University","Mark Huber, University ","Daniel Jackson, Newcastle University","Patrick Olivier, Newcastle University"],"title":"Panopticon as an eLearning Support Search Tool","paperOrNote":"Note","fullAbstract":"We present an evaluation of Panopticon, a video surrogate system, as an online eLearning support search tool for finding information within video lectures. A comparison was made with a standard video player (YouTube) in two scenarios with two classes of users: revision students and independent learners. Results showed that users of Panopticon were significantly faster at finding information within the lecture videos than users of the YouTube player. It was also found that videos predominantly featuring a talking lecturer took longest to navigate, presenting design implications for lectures to be uploaded to open eLearning platforms.","shortAbstract":"We present an evaluation of Panopticon, a video surrogate system, as a","id":"pn692"},"session":"Navigating Video","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn692"},"pn691":{"lastUpdateTime":1389222141946,"subcommitteeSplit":"A","labels":{"reviews":{"dislikes":[],"lastTimeUpdated":1386524267872,"checked":true,"likes":[],"label":"reviews"},"Do Ask Do Tell":{"dislikes":[],"lastTimeUpdated":1386525082566,"checked":true,"likes":[],"label":"Do Ask Do Tell"},"collaborative filtering":{"dislikes":[],"lastTimeUpdated":1386524744048,"checked":true,"likes":[],"label":"collaborative filtering"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525128571,"label":"Empirical Methods, Quantitative"},"is this product any good? (ratings)":{"dislikes":[],"lastTimeUpdated":1386525317835,"checked":true,"likes":[],"label":"is this product any good? (ratings)"},"social inference":{"dislikes":[],"lastTimeUpdated":1386523955763,"checked":true,"likes":[],"label":"social inference"},"product ratings":{"dislikes":[],"lastTimeUpdated":1386523940423,"checked":true,"likes":[],"label":"product ratings"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":["dabbish@cmu.edu"],"lastUpdateTime":1386526700463,"label":"Social Computing and Social Navigation"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524653162,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946737}},"creationTime":454,"content":{"authorList":["Eric Gilbert, Georgia Institute of Technology"],"title":"What If We Ask A Different Question?: Social Inferences Create the Same Product Rating Faster","paperOrNote":"Note","fullAbstract":"Consumer product reviews are the backbone of commerce online. Most commonly, sites ask users for their personal opinions on a product or service. We conjecture, however, that this traditional method of eliciting reviews often invites idiosyncratic viewpoints. In this paper, we present a statistical study examining the differences between traditionally elicited product ratings (i.e., How do you rate this product?) and social inference ratings (i.e., How do you think other people will rate this product?). We find that social inference ratings produce the same aggregate product rating as the one produced via traditionally elicited ratings, but with less variance. This is significant because using social inference ratings 1) therefore converges on the true aggregate product rating faster, and 2) is a cheap design intervention on the part of existing sites.","shortAbstract":"Consumer product reviews are the backbone of commerce online. Most com","id":"pn691"},"session":"Social: Do Ask Do Tell","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn691"},"pn361":{"lastUpdateTime":1389286027763,"subcommitteeSplit":"A","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386524493908,"checked":true,"likes":[],"label":"Field Study"},"search":{"dislikes":[],"lastTimeUpdated":1386524536712,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"search"},"Desktop interactions":{"dislikes":[],"lastTimeUpdated":1386523930842,"checked":true,"likes":[],"label":"Desktop interactions"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525024391,"label":"Empirical Methods, Quantitative"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["eadar@mit.edu"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"file browser":{"dislikes":[],"lastTimeUpdated":1386524544465,"checked":true,"likes":[],"label":"file browser"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["eadar@mit.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946667}},"creationTime":189,"content":{"authorList":["Stephen Fitchett, University of Canterbury","Andy Cockburn, University of Canterbury","Carl Gutwin, University of Saskatchewan"],"title":"Finder Highlights: Field Evaluation and Design of an Augmented File Browser","paperOrNote":"Paper","fullAbstract":"Navigating to files through a hierarchy is often a slow, laborious, and repetitive task. Recent lab studies showed that file browser interface augmentations, such as Icon Highlights and Search Directed Navigation, have the potential to reduce file retrieval times. However, for this potential to be realised in actual systems, further study is necessary to address two important issues. First, there are important design and implementation challenges in advancing the research prototypes previously evaluated into complete interactive systems that can be used for real work. Second, it is unknown how real users would employ these systems while engaged in actual work; would the potential performance improvements suggested by the earlier lab studies be realised? We therefore describe the design, implementation,  and longitudinal field study evaluation of Finder Highlights, a file browser plugin for the OS X `Finder' that adds support for Icon Highlights and Search Directed Navigation. Study results confirm that the augmentations are effective in reducing real-world file retrieval times, with retrieval times 13% faster when using Finder Highlights compared to the standard tool (10.6s versus 12.2s). The results also suggest directions for iterative refinement. In summary, the paper strongly suggests that large-scale deployment of interface augmentations to file browser systems, particularly Icon Highlights, will have a marked effect in improving users' real-world file retrieval. ","shortAbstract":"Navigating to files through a hierarchy is often a slow, laborious, an","id":"pn361"},"session":"Systems: Desktop Search and History","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn361"},"pn366":{"lastUpdateTime":1389222059201,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"EEG-based HCI":{"dislikes":[],"lastTimeUpdated":1386525473338,"checked":true,"likes":["pierre.dragice@gmail.com"],"label":"EEG-based HCI"},"(passive) BCI":{"dislikes":[],"lastTimeUpdated":1386525334333,"checked":true,"likes":["sriramable@gmail.com","dan@microsoft.com","j.alexander@lancaster.ac.uk"],"label":"(passive) BCI"},"passive BCI":{"dislikes":[],"lastTimeUpdated":1386525411236,"checked":true,"likes":["tzander@gmail.com","bulling@mpi-inf.mpg.de"],"label":"passive BCI"},"(passive) Brain-Computer Interfaces":{"dislikes":[],"lastTimeUpdated":1386525338626,"checked":true,"likes":["abe.karnik@gmail.com"],"label":"(passive) Brain-Computer Interfaces"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644754}},"creationTime":193,"content":{"authorList":["Chi Thanh Vi, University of Bristol","Izdihar Jamil, University of Bristol","Sriram Subramanian, University of Bristol"],"title":"Error Related Negativity in Observing Interactive Tasks","paperOrNote":"Paper","fullAbstract":"Error Related Negativity is triggered when a user either makes a mistake or the application behaves differently from their expectation. It can also appear while observing another user making a mistake. This paper investigates ERN in collaborative settings where observing another user (the executer) perform a task is typical and then explores its applicability to HCI. We first show that ERN can be detected on signals captured by commodity EEG headsets like an Emotiv headset when observing another person perform a typical multiple-choice reaction time task. We then investigate the anticipation effects by detecting ERN in the time interval when an executer is reaching towards an answer. We show that we can detect this signal with both a clinical EEG device and with an Emotiv headset. Our results show that online single trial detection is possible using both headsets during tasks that are typical of collaborative interactive applications. However there is a trade-off between the detection speed and the quality/prices of the headsets. Based on the results, we discuss and present several HCI scenarios for use of ERN in observing tasks and collaborative settings. ","shortAbstract":"Error Related Negativity is triggered when a user either makes a mista","id":"pn366"},"session":"UIST: Read My Mind: Passive BCI","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn366"},"pn189":{"lastUpdateTime":1389237026654,"subcommitteeSplit":"B","labels":{"2D Graphical Interfaces":{"dislikes":[],"lastTimeUpdated":1386522576425,"checked":true,"likes":[],"label":"2D Graphical Interfaces"},"menus":{"dislikes":[],"lastTimeUpdated":1386531905108,"checked":true,"likes":[],"label":"menus"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Real-world applications":{"checked":false,"lastUpdateTime":1386522555351,"dislikes":[],"label":"Real-world applications","lastTimeUpdated":1386522456934,"likes":[]},"Menus":{"checked":false,"lastUpdateTime":1386531907002,"dislikes":[],"label":"Menus","lastTimeUpdated":1386522588462,"likes":[]},"User Interface Design":{"checked":true,"dislikes":[],"likes":["stuart@tropic.org.uk"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Usability testing":{"dislikes":[],"lastTimeUpdated":1386522741055,"checked":true,"likes":[],"label":"Usability testing"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755934}},"creationTime":63,"content":{"authorList":["Joey Scarr, University of Canterbury","Carl Gutwin, University of Saskatchewan","Andy Cockburn, University of Canterbury","Andrea Bunt, University of Manitoba","Jared Cechanowicz, University of Saskatchewan"],"title":"The Usability of CommandMaps in Realistic Tasks","paperOrNote":"Paper","fullAbstract":"CommandMaps are a promising interface technique that flattens command hierarchies and exploits human spatial memory to provide rapid access to commands. CommandMaps have performed favorably in constrained cued-selection studies, but have not yet been tested in the context of real tasks. In this paper we present two real-world implementations of CommandMaps: one for Microsoft Word and one for an image editing program called Pinta. We use these as our experimental platforms in two experiments. In the first, we show that CommandMaps demonstrate performance and subjective advantages in a realistic task. In the second, we observe naturalistic use of CommandMaps over the course of a week, and gather qualitative data from interviews, questionnaires, and conversations. Our results provide substantial insight into users reactions to CommandMaps, showing that they are positively received by users and allowing us to provide concrete recommendations to designers regarding when and how they should be implemented in real applications.","shortAbstract":"CommandMaps are a promising interface technique that flattens command ","id":"pn189"},"session":"Systems: GUIs","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn189"},"pn186":{"lastUpdateTime":1389236966690,"subcommitteeSplit":"B","labels":{"finance":{"checked":false,"lastUpdateTime":1386523086985,"dislikes":[],"label":"finance","lastTimeUpdated":1386523066734,"likes":[]},"money":{"dislikes":[],"lastTimeUpdated":1386527603422,"checked":true,"likes":["lorrie@acm.org"],"label":"money"},"Empirical Methods, Qualitative":{"checked":false,"lastUpdateTime":1386526694861,"dislikes":[],"label":"Empirical Methods, Qualitative","lastTimeUpdated":1386523626203,"likes":[]},"Ethnography":{"checked":false,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","m.rouncefield@lancaster.ac.uk","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":1386526691930,"label":"Ethnography"},"Home":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk","dr.mark.j.perry@googlemail.com","com@psychology.nottingham.ac.uk","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":1386522350391,"label":"Home"},"HCI and finance":{"dislikes":[],"lastTimeUpdated":1386526552628,"checked":true,"likes":["lorrie@acm.org"],"label":"HCI and finance"},"Show Me the Money":{"dislikes":[],"lastTimeUpdated":1386526563371,"checked":true,"likes":[],"label":"Show Me the Money"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032750}},"creationTime":61,"content":{"authorList":["Joseph 'Jofish' Kaye, Yahoo! Research","Mary McCuistion, Essential Anthropology","Rebecca Gulotta, Carnegie Mellon University","David Shamma, Yahoo! Research"],"title":"Money Talks: Tracking Personal Finances","paperOrNote":"Paper","fullAbstract":"How do people keep track of their money? In this paper we study how 14 individuals procure, save, spend and understand their personal and family finances. We describe best practices for exploring the sensitive topic of money in qualitative interviews, and then discuss three sets of findings. The first is the complex relationship between finances and self-identity, relationships, and family. Second, we discuss the tools and processes people used to keep track of their financial situation. Finally we discuss how people account for the unknown and unpredictable nature of the future through their financial decisions. We conclude by discussing the future of studies of money and finance in HCI, and reflect on the opportunities for improving tools to aid people in managing and planning their finances.","shortAbstract":"How do people keep track of their money? In this paper we study how 14","id":"pn186"},"session":"HCI4D: Finances","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn186"},"pn180":{"lastUpdateTime":1389238200057,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523198558,"label":"Handheld Devices and Mobile Computing"},"Video Content / Communications":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523196321,"label":"Video Content / Communications"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":1386523194065,"label":"Empirical Methods, Quantitative"},"mobile instant messaging":{"dislikes":[],"lastTimeUpdated":1386523161893,"checked":true,"likes":[],"label":"mobile instant messaging"},"prediction":{"dislikes":[],"lastTimeUpdated":1386523549474,"checked":true,"likes":["teevan@gmail.com"],"label":"prediction"},"social transparency":{"dislikes":[],"lastTimeUpdated":1386523239807,"checked":true,"likes":[],"label":"social transparency"},"awareness":{"dislikes":[],"lastTimeUpdated":1386523174212,"checked":true,"likes":[],"label":"awareness"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556674}},"creationTime":56,"content":{"authorList":["Martin Pielot, Telefonica Research","Rodrigo de Oliveira, Telefonica Research","Haewoon Kwak, Telefonica Research","Nuria Oliver, Telefonica Research"],"title":"Didn't You See my Message? Predicting Reactiveness in Mobile Instant Messaging","paperOrNote":"Paper","fullAbstract":"Mobile instant messages (e.g., SMS, WhatsApp, etc...) often go along with an expectation of high reactiveness, i.e., that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. In a survey with 84 participants, we found that this makes users feel observed and creates social pressure. As remedy, we propose to share a machine-computed prediction of whether the user will see the message within the next few minutes (fast) or not (slow). For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. From the log data and by means of machine learning techniques, we automatically identified six variables which are strong predictors of reactiveness: (1) the time since the screen was last turned off, (2) the time that the user last uncovered the screen, (3) whether the screen is covered, (4) the ringer mode, (5) the hour of the day, and (6) the day of the week. In our experiments, we show that these features predict whether a phone user will view a message within 5 minutes or not with 76.0% accuracy.","shortAbstract":"Mobile instant messages (e.g., SMS, WhatsApp, etc...) often go along w","id":"pn180"},"session":"People: constant connectivity","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn180"},"pn983":{"lastUpdateTime":1389590870612,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Software architecture and engineering":{"checked":true,"dislikes":[],"likes":["xiangcao@acm.org","dan@danielashbrook.com","roudauta@gmail.com"],"lastUpdateTime":123456789,"label":"Software architecture and engineering"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081840}},"creationTime":699,"content":{"authorList":["Jaeyeon Kihm, Cornell University","Franois Guimbretire, Cornell University"],"title":"Low Power User Interface System for Asymmetric Cores","paperOrNote":"Note","fullAbstract":"Low power helper cores have been increasingly included on application processors to accomplish low intensity tasks such as music playing and motion sensing with minimum energy consumption. Recently, Guimbretire et al. [1] demonstrated that such helper cores can also be used to execute simple user interface tasks. We revisit their approach by implementing a similar system on an off-the-shelf application processor (TI OMAP4). Our study shows that in the case of high event rate interactions (pen inking and virtual keyboard), significant battery life gains (1.7 and 2.3 respectively) can be achieved with the helper core executing the interface. Having the helper core only dis-patch input events incurs a 18% penalty relative to the maximum savings rate, but allows for simplified deployment since it merely requires a change in toolkit infrastructure.","shortAbstract":"Low power helper cores have been increasingly included on applic","id":"pn983"},"session":"UBI: Battery Life","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn983"},"pn988":{"lastUpdateTime":1388776467635,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["mdixon@cs.washington.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Pen and Tactile Input":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen and Tactile Input"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Menus":{"dislikes":[],"lastTimeUpdated":1386532550696,"checked":false,"likes":[],"label":"Menus","lastUpdateTime":1387552908925},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386532543897,"checked":true,"likes":[],"label":"Multitouch"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840721},"menus":{"label":"menus","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387552906825}},"creationTime":704,"content":{"authorList":["Carl Gutwin, University of Saskatchewan","Andy Cockburn, University of Canterbury","Joey Scarr, University of Canterbury","Sylvain Malacria, University of Canterbury"],"title":"Faster Command Selection on Tablets with FastTap","paperOrNote":"Paper","fullAbstract":"Touch-based tablet UIs provide few mechanisms for rapid command selection such as toolbars or keyboard shortcuts; as a result, command selection on tablets often requires slow traversal of menus. We developed a new selection technique for multi-touch tablets  called FastTap  that uses thumb-and-finger touches to show and choose from a spatially-stable grid-based overlay interface. FastTap allows novices to view and inspect the full interface, but once item locations are known, FastTap also allows people to select commands with a single quick thumb-and-finger tap. The interface helps users develop expertise, since the motor actions carried out in novice mode rehearse the expert behavior. A controlled study with 16 participants showed that FastTap was significantly faster (by 33% per selection overall) than marking menus, both for novices and experts, and without reduction in accuracy or subjective preference. Our work introduces a new and efficient selection mechanism that supports rapid command execution on touch tablets, for both novices and experts.","shortAbstract":"Touch-based tablet UIs provide few mechanisms for rapid command select","id":"pn988"},"session":"Touch: Touch","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn988"},"pn1110":{"lastUpdateTime":1389238017883,"subcommitteeSplit":"A","labels":{"Location Location Location":{"dislikes":[],"lastTimeUpdated":1386523236479,"checked":true,"likes":["eva@ehornecker.de","sameer.patil@hiit.fi","dabbish@cmu.edu"],"label":"Location Location Location"},"scheduling and time":{"dislikes":[],"lastTimeUpdated":1386523699348,"checked":true,"likes":["eva@ehornecker.de"],"label":"scheduling and time"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"urban informatics":{"dislikes":[],"lastTimeUpdated":1386523707650,"checked":true,"likes":[],"label":"urban informatics"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":1386525078766,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":["eva@ehornecker.de"],"lastUpdateTime":123456789,"label":"Ethnography"},"Transport":{"checked":true,"dislikes":[],"likes":["adf"],"lastUpdateTime":123456789,"label":"Transport"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946675}},"creationTime":806,"content":{"authorList":["Gary Pritchard, Newcastle University","John Vines, Newcastle University","Pam Briggs, Northumbria University","Lisa Thomas, Northumbria University","Patrick Olivier, Newcastle University"],"title":"Digitally Driven: How Location Based Services Impact the Work Practices of London Bus Drivers","paperOrNote":"Paper","fullAbstract":"This paper examines how an occupational group has adapted to the demands of working with a Location Based Service (LBS). Instead of following a rigid timetable, Londons bus drivers are now required to maintain an equal distance between the bus in front and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth semi-structured interviews to elicit drivers perspectives of the new system and how it has modified their driving and general work conditions. In this we explore how passengers influence the movement of the bus and how the technology frames bus drivers relationships to their managers commuters. This work contributes to our understanding of the impact of LBS in the workplace and shows how technological imperatives can be established that cause unanticipated consequences and gradually undermine human relationships.","shortAbstract":"This paper examines how an occupational group has adapted to the deman","id":"pn1110"},"session":"People: Location Location Location","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1110"},"pn1071":{"lastUpdateTime":1389285684614,"subcommitteeSplit":"A","labels":{"search":{"dislikes":[],"lastTimeUpdated":1386524023872,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"search"},"information search":{"dislikes":[],"lastTimeUpdated":1386524038618,"checked":true,"likes":[],"label":"information search"},"interaction science":{"dislikes":[],"lastTimeUpdated":1386524318898,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"interaction science"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524670977,"label":"Empirical Methods, Quantitative"},"choice overload":{"dislikes":[],"lastTimeUpdated":1386524045529,"checked":true,"likes":[],"label":"choice overload"},"replication":{"dislikes":[],"lastTimeUpdated":1386524895529,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"replication"},"repliCHI":{"dislikes":[],"lastTimeUpdated":1386524888055,"checked":true,"likes":["Brumby@cs.ucl.ac.uk"],"label":"repliCHI"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946718}},"creationTime":770,"content":{"authorList":["Pawitra Chiravirakul, University of Bath","Stephen Payne, University of Bath"],"title":"Choice Overload in Search Engine Use?","paperOrNote":"Paper","fullAbstract":"Search engines typically return so many results that choosing from the list might be predicted to suffer from the effects of choice overload.  Preliminary work has reported just such an effect [12]. In this paper a series of three experiments were conducted to investigate the choice overload effect in search engine use. Participants were given search tasks and presented with either six options or twenty-four returns to choose from. The results revealed that the choice behaviour was strongly influenced by the ranking of returns, and that choice satisfaction was affected by the number of options and the decision time. Large sets of options yielded positive effect on participants satisfaction when they made a decision without time limit. When time was more strongly constrained, choices from small sets led to relatively higher satisfaction. Our studies show how user satisfaction with found information can be affected by processing strategies that are influenced by search engine design features.","shortAbstract":"Search engines typically return so many results that choosing from the","id":"pn1071"},"session":"Web: Web","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1071"},"pn191":{"lastUpdateTime":1389238893968,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528592975,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Privacy":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Privacy"},"warnings":{"dislikes":[],"lastTimeUpdated":1386526016890,"checked":true,"likes":["lorrie@acm.org"],"label":"warnings"},"Risk management":{"dislikes":[],"lastTimeUpdated":1386521873850,"checked":true,"likes":[],"label":"Risk management"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"usable security":{"dislikes":[],"lastTimeUpdated":1386525977109,"checked":true,"likes":[],"label":"usable security"},"Security":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de"],"lastUpdateTime":123456789,"label":"Security"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386525984363,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446325}},"creationTime":65,"content":{"authorList":["Marian Harbach, Leibniz University Hannover","Markus Hettig, Leibniz University Hannover","Susanne Weber, Leibniz University Hannover","Matthew Smith, Leibniz Universitt Hannover"],"title":"Personalized Warnings: Using Examples to Improve Risk Communication","paperOrNote":"Paper","fullAbstract":"Warning messages have been used to communicate risks in IT security systems for a long time. However, their lack of efficacy as well as problems with habituation are also well known. In this paper, we propose to communicate risks using personalized examples in warning messages. Examples of private information that may be at risk can draw the users attention to the warning and also improve their response. Changing examples also diminish habituation. We present two experiments that validate this approach in the context of Android app permissions. Private information accessible to apps given certain permissions is displayed when a user wants to install an app in order to demonstrate the consequences this installation might have. We find that participants made more privacy-conscious choices when deciding which apps to install. Additionally, our results show that using personalized examples in warnings causes a negative affect in participants, which makes them pay more attention.","shortAbstract":"Warning messages have been used to communicate risks in IT security sy","id":"pn191"},"session":"Security: Security","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn191"},"pn190":{"lastUpdateTime":1389236270605,"subcommitteeSplit":"A","labels":{"Social Media":{"checked":false,"lastUpdateTime":1386528878398,"dislikes":[],"label":"Social Media","lastTimeUpdated":1386525022995,"likes":["mark.hancock@uwaterloo.ca"]},"social media":{"dislikes":[],"lastTimeUpdated":1386528876731,"checked":true,"likes":[],"label":"social media"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525534154,"label":"Empirical Methods, Quantitative"},"cognition":{"dislikes":[],"lastTimeUpdated":1386524553181,"checked":true,"likes":[],"label":"cognition"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"User and Cognitive models":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524587085,"label":"User and Cognitive models"},"epistemic":{"dislikes":[],"lastTimeUpdated":1386524546991,"checked":true,"likes":[],"label":"epistemic"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946707}},"creationTime":64,"content":{"authorList":["Rosanna Yuen-Yan Chan, The Chinese University of Hong Kong","Silu Li, The Chinese University of Hong Kong","Diane Hui, Lingnan University"],"title":"Social Epistemic Cognition in Online Interactions","paperOrNote":"Paper","fullAbstract":"Social media and online social networks dramatically change the way in which knowledge is acquired and disseminated. How do we re-understand about knowledge and knowing in the socio-technical world? This work aims at extending the current understanding of human epistemic cognition in online social environments, where epistemic cognition refers to cognitions and cognitive processes related to epistemic matters such as knowledge and beliefs justification. We approach our inquiry with mixed methods: (1) quantitative survey to test whether epistemic cognition might differs in individual and social contexts, and whether online interactions might mediate the social dimension of epistemic cognition; and (2) cognitive task analysis with structured interviews to manifest the intricate interplay of dynamics between epistemic cognition and online interactions. We contribute to the field of HCI with an evolved theory which states that human epistemic cognition can be promoted in online social environments as mediated by online interactions.","shortAbstract":"Social media and online social networks dramatically change the way in","id":"pn190"},"session":"Social: Connecting through Social Media","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn190"},"pn1806":{"lastUpdateTime":1389222127656,"subcommitteeSplit":"B","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386528863771,"checked":true,"likes":[],"label":"social media"},"Social Media":{"checked":false,"lastUpdateTime":1386528865701,"dislikes":[],"label":"Social Media","lastTimeUpdated":1386522215718,"likes":[]},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"User Studies":{"checked":true,"dislikes":[],"likes":["l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032736}},"creationTime":1412,"content":{"authorList":["Xuan Zhao, University of Michigan","Sin Lindley, Microsoft Research"],"title":"Curation through Use: Understanding the Personal Value of Social Media","paperOrNote":"Paper","fullAbstract":"Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become more meaningful for the self over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with keepable social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, is a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.","shortAbstract":"Content generation on social network sites has been considered mainly ","id":"pn1806"},"session":"Social: Social Media Applied","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1806"},"pn1800":{"lastUpdateTime":1389236916221,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["awaller@computing.dundee.ac.uk"],"lastUpdateTime":1386527071072,"label":"Older Adults"},"formal caregivers":{"checked":false,"lastUpdateTime":1386527062914,"dislikes":[],"label":"formal caregivers","lastTimeUpdated":1386526569042,"likes":[]},"health care":{"checked":false,"lastUpdateTime":1386526601458,"dislikes":[],"label":"health care","lastTimeUpdated":1386526531757,"likes":[]},"Health Care":{"checked":false,"lastUpdateTime":1386527083786,"dislikes":[],"label":"Health Care","lastTimeUpdated":1386526525105,"likes":["maria.wolters@ed.ac.uk"]},"social care":{"checked":false,"lastUpdateTime":1386527064988,"dislikes":[],"label":"social care","lastTimeUpdated":1386526512514,"likes":[]},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk","awaller@computing.dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Social Computing and Social Navigation":{"dislikes":[],"lastTimeUpdated":1386527285758,"checked":true,"likes":["karyn.moffatt@mcgill.ca"],"label":"Social Computing and Social Navigation"},"photo work":{"checked":false,"lastUpdateTime":1386527067063,"dislikes":[],"label":"photo work","lastTimeUpdated":1386526502453,"likes":[]},"Photo sharing":{"checked":false,"lastUpdateTime":1386527068358,"dislikes":[],"label":"Photo sharing","lastTimeUpdated":1386526329233,"likes":[]},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527077687,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486597}},"creationTime":1409,"content":{"authorList":["Jenny Waycott, The University of Melbourne","Hilary Davis, The University of Melbourne","Frank Vetere, The University of Melbourne","Amee Morgans, Benetas Aged Care Services","Alan Gruner, Benetas Aged Care Services","Elizabeth Ozanne, The University of Melbourne","Lars Kulik, The University of Melbourne"],"title":"Supporting Psychosocial Aged Care with Photo-Sharing: Relationship Building and Boundary Work","paperOrNote":"Paper","fullAbstract":"Social technologies offer enormous potential for enhancing aged care, but technologies designed to support aging in place typically focus on monitoring and security, rather than supporting the social aspects of aged care. Research on the use of social technologies in aged care has largely focused on institutional or informal care settings. In this paper we examine the use of social technologies to support the provision of formal aged care services to clients who live in their own homes. We conducted a field study in which aged care managers used a novel photo and message-sharing tool to communicate with their clients. Our findings demonstrate that visual and social forms of communication are valuable for addressing aged care clients social and emotional needs and enhancing the client-carer relationship. The study also highlights the challenges involved in implementing social technologies in this context, where caregivers must carefully negotiate boundaries between personal and professional lives.  ","shortAbstract":"Social technologies offer enormous potential for enhancing aged care, ","id":"pn1800"},"session":"HCI4D: Family 2.0","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1800"},"pn1904":{"lastUpdateTime":1389236836254,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"make":{"dislikes":[],"lastTimeUpdated":1386522297454,"checked":true,"likes":[],"label":"make"},"making practices":{"dislikes":[],"lastTimeUpdated":1386522741402,"checked":true,"likes":[],"label":"making practices"},"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Product Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Product Design"},"diy":{"dislikes":[],"lastTimeUpdated":1386521864783,"checked":true,"likes":["silvia.lindtner@gmail.com","wendyju@stanford.edu","reinecke@umich.edu","aantle@sfu.ca"],"label":"diy"},"mobile phone":{"dislikes":[],"lastTimeUpdated":1386523094646,"checked":true,"likes":[],"label":"mobile phone"},"cell phone":{"dislikes":[],"lastTimeUpdated":1386523099125,"checked":true,"likes":[],"label":"cell phone"},"mobiles":{"dislikes":[],"lastTimeUpdated":1386523092197,"checked":false,"likes":[],"label":"mobiles","lastUpdateTime":1387552953005},"digital fabrication":{"dislikes":[],"lastTimeUpdated":1386522277371,"checked":true,"likes":[],"label":"digital fabrication"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755946},"mobile":{"label":"mobile","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387552948720}},"creationTime":1495,"content":{"authorList":["David Mellis, Massachusetts Institute of Technology","Leah Buechley, Massachusetts Institute of Technology"],"title":"Do-It-Yourself Cellphones: Applying Digital Fabrication and DIY Electronics to Everyday Devices","paperOrNote":"Paper","fullAbstract":"We describe the application of the increasingly accessible technologies of digital fabrication and embedded computation to the production of a device for use in daily life. The DIY cellphone cellphone consists of a custom circuit board and digitally-fabricated enclosure that can be individually assembled. We discuss our experience in making and using the device and describe two workshops in which designers and members of the general public assembled the devices for themselves. Three major themes emerge: assembling their own devices helps people to understand and question the assumptions and design of commercial devices, DIY electronics participates in a complex ecosystem that enables and limits its possibilities, and there is an opportunity and need to improve the bridge between electronics prototyping and production. This suggests future work in electronics toolkits and DIY circuit design, as well as further investigations of the use of DIY devices in daily life.","shortAbstract":"We describe the application of the increasingly accessible technologie","id":"pn1904"},"session":"Making: Hacking","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1904"},"pn2343":{"lastUpdateTime":1389285480381,"subcommitteeSplit":"","labels":{"World Wide Web and Hypermedia":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523579513,"label":"World Wide Web and Hypermedia"},"Sketching":{"dislikes":[],"lastTimeUpdated":1386521862719,"checked":true,"likes":[],"label":"Sketching"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["yardi@umich.edu","antonella.deangeli@disi.unitn.it","teevan@gmail.com"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Collaborative editing":{"dislikes":[],"lastTimeUpdated":1386524190194,"checked":true,"likes":[],"label":"Collaborative editing"},"Drawing":{"dislikes":[],"lastTimeUpdated":1386522201607,"checked":true,"likes":[],"label":"Drawing"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523580500,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556649}},"creationTime":1881,"content":{"authorList":["Zhenpeng Zhao, Purdue University","Sriram Karthik Badam, Purdue University","Deok Gun Park, Purdue University","Senthil Chandrasegaran, Purdue University","Niklas Elmqvist, Purdue University","Lorraine Kisselburgh, Purdue University","Karthik Ramani, Purdue University"],"title":"skWiki: A Multimedia Sketching System for Collaborative Creativity","paperOrNote":"Paper","fullAbstract":"We present skWiki, a web application framework for collaborative creativity in digital multimedia projects, including text, hand-drawn sketches, and photographs. skWiki overcomes common drawbacks of existing wiki software by providing a rich viewer/editor architecture for all media types that is integrated into the web browser itself, thereby eliminating the dependency on client-side media editors. Rather than operating on files, skWiki uses the concept of paths as trajectories of persistent state over time. This data model has intrinsic support for collaborative editing, including cloning, branching, and merging paths edited by multiple contributors. We present our skWiki prototype and demonstrate its utility using a qualitative, sketching-based user study.   \\ ","shortAbstract":"We present skWiki, a web application framework for collaborative creat","id":"pn2343"},"session":"CSCW: Crowds and Creativity","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2343"},"pn1901":{"lastUpdateTime":1389221094245,"subcommitteeSplit":"B","labels":{"3D Interaction and Graphics":{"dislikes":[],"lastTimeUpdated":1386522220729,"checked":true,"likes":[],"label":"3D Interaction and Graphics"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["daverandall2008@gmail.com"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Video Games":{"dislikes":[],"lastTimeUpdated":1386523023579,"checked":true,"likes":["jantin@gmail.com"],"label":"Video Games"},"Target Acquisition":{"dislikes":[],"lastTimeUpdated":1386538624271,"checked":true,"likes":[],"label":"Target Acquisition"},"Target Aquisition":{"checked":false,"lastUpdateTime":1386538680127,"dislikes":[],"label":"Target Aquisition","lastTimeUpdated":1386522226371,"likes":[]},"3D Interaction":{"dislikes":[],"lastTimeUpdated":1386522212472,"checked":true,"likes":[],"label":"3D Interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032726}},"creationTime":1492,"content":{"authorList":["Rodrigo Vicencio-Moreira, University of Saskatchewan","Regan Mandryk, University of Saskatchewan","Carl Gutwin, University of Saskatchewan","Scott Bateman, University of Prince Edward Island"],"title":"The Effectiveness (or Lack Thereof) of Aim-Assist Techniques in First-Person Shooter Games","paperOrNote":"Paper","fullAbstract":"Aim-assistance techniques have been shown to work for player balancing in 2D environments, but little information exists about how well these techniques will work in a 3D FPS game. We carried out three studies of the performance of five different aim assists in an Unreal-based game world. The assists worked well in a target-range scenario (study 1), but their performance was reduced when game elements were introduced in a walkthrough map (study 2). We systematically examined the relationships between realistic game elements and assist performance (study 3). These studies show that two techniques  bullet magnetism and area cursor  worked well in a wide variety of situations. Other techniques that worked well were too perceptible, and some previously-successful techniques did not work well in any game-like scenario. Our studies are the first to provide empirical evidence of the performance of aim assist techniques in 3D environments, and the first to identify the complexities in using these techniques in real FPS games.","shortAbstract":"Aim-assistance techniques have been shown to work for player balancing","id":"pn1901"},"session":"Games: Games","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1901"},"pn2208":{"lastUpdateTime":1389285480381,"subcommitteeSplit":"","labels":{"crowdwork":{"dislikes":[],"lastTimeUpdated":1386522219301,"checked":true,"likes":[],"label":"crowdwork"},"idea generation":{"dislikes":[],"lastTimeUpdated":1386523257577,"checked":true,"likes":[],"label":"idea generation"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523237310,"label":"Empirical Methods, Quantitative"},"Ideation":{"checked":false,"lastUpdateTime":1386531712817,"dislikes":[],"label":"Ideation","lastTimeUpdated":1386522214488,"likes":[]},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386522222820,"checked":true,"likes":[],"label":"crowdsourcing"},"crowd innovation":{"checked":false,"lastUpdateTime":1386523649808,"dislikes":[],"label":"crowd innovation","lastTimeUpdated":1386523271570,"likes":[]},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["teevan@gmail.com","emilee@gmail.com"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Product Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Product Design"},"innovation":{"dislikes":[],"lastTimeUpdated":1386523647649,"checked":true,"likes":[],"label":"innovation"},"ideation":{"dislikes":[],"lastTimeUpdated":1386531710426,"checked":true,"likes":[],"label":"ideation"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523238684,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556692}},"creationTime":1767,"content":{"authorList":["Lixiu Yu, Carnegie Mellon University","Aniket Kittur, Carnegie Mellon University","Robert Kraut, Carnegie Mellon University"],"title":"Distributed Analogical Idea Generation: Innovating with Crowds","paperOrNote":"Paper","fullAbstract":"Harnessing crowds can be a powerful mechanism for increasing innovation. However, current approaches to crowd innovation rely on large numbers of contributors working independently with no structured process. We introduce a new approach called distributed analogical idea generation, which aims to make idea generation more effective and less reliant on chance without stifling creativity. Drawing from the literature in cognitive science on analogy and schema induction, our approach decomposes the creative process in a structured way amenable to using crowds, even of novices. In three experiments we show that distributed analogical idea generation leads to better ideas than an example-based approach, and investigate the conditions under which crowds generate good analogical schemas and ideas. Our results have implications for improving creativity and building systems for distributed crowd innovation.","shortAbstract":"Harnessing crowds can be a powerful mechanism for increasing innovatio","id":"pn2208"},"session":"CSCW: Crowds and Creativity","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2208"},"pn2200":{"lastUpdateTime":1389286103691,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":1386530795214,"label":"E-Learning and Education"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188243}},"creationTime":1759,"content":{"authorList":["Toni-Jan Keith Monserrat, National University of Singapore","Yawen Li, National University of Singapore","Shengdong Zhao, National University of Singapore","Xiang Cao, Lenovo Research & Technology"],"title":"L.IVE: An Integrated Interactive Video-based Learning Environment","paperOrNote":"Note","fullAbstract":"In this paper, we introduce L.IVE: an online interactive video-based learning environment with an alternative design and architecture that integrates three major interface components: video, comment threads, and assessments. Existing interfaces visually separate these components, which may hinder effective learning by requiring users to collect and piece-together information from different sources. Alternatively, L.IVE embeds comment threads and assessments in the video, so different sources of information are tightly linked in context. This study, which compares L.IVE with existing popular video-based learning environments, shows that L.IVE demonstrates a significant advantage in learning.","shortAbstract":"In this paper, we introduce L.IVE: an online interactive video-based l","id":"pn2200"},"session":"HCI4D: Learning and Education","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2200"},"pn2202":{"lastUpdateTime":1389221977983,"subcommitteeSplit":"B","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Entertainment":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk","l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Entertainment"},"audience interaction":{"dislikes":[],"lastTimeUpdated":1386523059212,"checked":true,"likes":[],"label":"audience interaction"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk","l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Performance":{"dislikes":[],"lastTimeUpdated":1386522147563,"checked":true,"likes":[],"label":"Performance"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["m.rouncefield@lancaster.ac.uk"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032734}},"creationTime":1761,"content":{"authorList":["Louise Barkhuus, Stockholm University","Arvid Engstrm, Mobile Life @ Stockholm University","Goranka Zoric, Interactive Institute, Stockholm"],"title":"Watching the Footwork: Second Screen Interaction at a Dance and Music Performance","paperOrNote":"Paper","fullAbstract":"Interactive mobile technologies have become part of audience experiences of live performances in terms of both general media sharing and specific (sometimes official) extra content. At the same time, high bandwidth affords streaming of live events to mobile devices. We take advantage of these technologies in our high resolution, panoramic image video stream and study a scenario of audience members viewing the very same live event they are watching on a tablet. The video stream on the tablet is navigational and enables audience members to pan and zoom in the real-time video feed. We studied audience interaction and impressions in three performances of a dance and music show and found distinct uses of the second screen video stream. We emphasize that despite initial reluctance, the observed utilization of the technology opened up for new potential practices. Our study shows how working with perceived conflict in technology can still open up design space for interactive technologies.","shortAbstract":"Interactive mobile technologies have become part of audience experienc","id":"pn2202"},"session":"Art: Performance","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2202"},"pn2203":{"lastUpdateTime":1388786174911,"subcommitteeSplit":"B","labels":{"Intelligent transport":{"dislikes":[],"lastTimeUpdated":1386522396784,"checked":true,"likes":[],"label":"Intelligent transport"},"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521974372,"label":"Multimedia UIs"},"in car technology":{"dislikes":[],"lastTimeUpdated":1386523016706,"checked":true,"likes":[],"label":"in car technology"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521973114,"label":"Usability Testing and Evaluation"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521969766,"label":"User-Centered Design / Human-Centered Design"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521975752,"label":"User Interface Design"},"Transport":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522995879,"label":"Transport"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521957546,"label":"Interaction Design"},"User and Cognitive models":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521956452,"label":"User and Cognitive models"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522992339,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de","david.kirk@ncl.ac.uk"],"lastUpdateTime":1386522990038,"label":"User Experience Design / Experience Design"},"Semi-autonomous systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Semi-autonomous systems"},"Usability Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386521958760,"label":"Usability Research"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032689}},"creationTime":1762,"content":{"authorList":["Key Jung Lee, Stanford University","Yeon Kyoung Joo, Stanford University"],"title":"Partially Intelligent Automobiles and Driver Experience in the Moment of System Transition","paperOrNote":"Note","fullAbstract":"The current study explored the impact of different levels of automation and modality to control automated driving on drivers attitudes and behavior. A 2 X 3 ANOVA between-subject design (N= 42) found that the full or latitude automation car was perceived significantly intelligent than the longitudinally automated car. In addition, drivers in the longitudinal automation condition were significantly more nervous when using the touch interface than the voice interface. However, drivers in full and latitudinal automation conditions did not reported such difference. Drivers who used voice interface to control automated driving were able to engage in safer driving than those in the touch interface condition. Our findings have important psychological and practical implications for building driverless cars and driver assistant interfaces in such vehicles.  ","shortAbstract":"The current study explored the impact of different levels of automatio","id":"pn2203"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2203"},"pn2119":{"lastUpdateTime":1389591499037,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"user modelling":{"dislikes":[],"lastTimeUpdated":1386522350610,"checked":true,"likes":[],"label":"user modelling"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"user performance":{"dislikes":[],"lastTimeUpdated":1386524357843,"checked":true,"likes":[],"label":"user performance"},"User and Cognitive models":{"dislikes":[],"lastTimeUpdated":1386522362986,"checked":true,"likes":["oantti@mpi-inf.mpg.de"],"label":"User and Cognitive models"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032739}},"creationTime":1685,"content":{"authorList":["Max Nicosia, University of St Andrews","Antti Oulasvirta, Max Planck Institute for Informatics","Per Ola Kristensson, University of St Andrews"],"title":"Modeling the Perception of User Performance","paperOrNote":"Paper","fullAbstract":"This paper studies how users perceive their own performance \\ in two alternative user interfaces. We extend methodology \\ from psychophysics to the study of interactive performance, \\ and conduct two experiments in order to create a model of \\ users perception of their own performance. In our studies, \\ two interfaces are sequentially used in a pointing task, and \\ users are asked to rate in which interface their performance \\ was higher. We first differentiate the effects of objective performance \\ (speed, accuracy) versus interface qualities (distance, \\ width of elements) on perceived performance. We then \\ derive a model that predicts the amount of change required \\ in an interface for users to reliably detect a difference. The \\ model is useful as a heuristic for predicting if a new interface \\ design is better enough for users to reliably appreciate the obtained \\ gain in user performance. We validate the model via a \\ separate user study, and conclude by discussing how to apply \\ our findings to design problems.","shortAbstract":"This paper studies how users perceive their own performance \\ in two a","id":"pn2119"},"session":"Methods and Models: User Model 2","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2119"},"pn2112":{"lastUpdateTime":1389238827699,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528493983,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386528596467,"checked":true,"likes":[],"label":"Wearables"},"Privacy":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","a.sasse@cs.ucl.ac.uk","egelman@cs.berkeley.edu","nithyas@gmail.com","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Privacy"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"User Studies":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"User Studies"},"Google Glass":{"dislikes":[],"lastTimeUpdated":1386521755230,"checked":true,"likes":[],"label":"Google Glass"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386521765251,"label":"Augmented Reality and Tangible UI"},"Wearable":{"checked":false,"lastUpdateTime":1386528598636,"dislikes":[],"label":"Wearable","lastTimeUpdated":1386522061350,"likes":[]},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446335}},"creationTime":1678,"content":{"authorList":["Tamara Denning, University of Washington","Zakariya Dehlawi, University of Washington","Tadayoshi Kohno, University of Washington"],"title":"In-Situ Bystander Privacy Perspectives on Augmented Reality Glasses","paperOrNote":"Paper","fullAbstract":"Augmented reality (AR) devices are poised to enter the mainstream market and offer the ability to record more subtly and more pervasively than current common recording technologies; consequently, they have the potential to have an effect on the privacy of individuals in publicly accessible locations. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafs, during which we interviewed 31 participants regarding their responses to a researcher wearing a mock AR device. We present results from the interviews, including: participants reactions to the presence of the AR device; factors that contribute to making the AR recording experience either similar to or different from the bystander experience with other technologies; reasons behind participants reactions and factors that affect the acceptability of being recorded; and participants thoughts regarding asking permission before recording and the possibility of blocking technologies. These topics are of potential use to technologists and system developers, as they suggest action points around which system mitigations or design decisions may be made. In this way, by frequently investigating and adjusting for peoples perspectives, the adoption of AR technologies may be both smoother and more respectful to a larger group of stakeholders.","shortAbstract":"Augmented reality (AR) devices are poised to enter the mainstream mark","id":"pn2112"},"session":"Security: Privacy","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2112"},"pn2115":{"lastUpdateTime":1389221215807,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["christopher.power@york.ac.uk"],"lastUpdateTime":1386527242207,"label":"Older Adults"},"Health Care":{"checked":true,"dislikes":[],"likes":["mtory@cs.uvic.ca"],"lastUpdateTime":123456789,"label":"Health Care"},"Technology adoption":{"dislikes":[],"lastTimeUpdated":1386527346638,"checked":true,"likes":["kgajos@eecs.harvard.edu"],"label":"Technology adoption"},"Home":{"checked":true,"dislikes":[],"likes":["erinacarroll@gmail.com"],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":false,"dislikes":[],"likes":["christopher.power@york.ac.uk"],"lastUpdateTime":1386526678755,"label":"User Studies"},"Rehabilitation":{"dislikes":[],"lastTimeUpdated":1386526466569,"checked":true,"likes":["christopher.power@york.ac.uk","joanna@cs.ub.ca","kgajos@eecs.harvard.edu","erinacarroll@gmail.com"],"label":"Rehabilitation"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486642}},"creationTime":1681,"content":{"authorList":["Mobolaji Ayoade, GCU","Lynne Baillie, Glasgow Caledonian University"],"title":"A Novel Knee Rehabilitation System for the Home","paperOrNote":"Paper","fullAbstract":"In this paper, we describe the design and evaluation of an interactive home-based rehabilitation system used by seniors to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that seniors were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation. ","shortAbstract":"In this paper, we describe the design and evaluation of an interactive","id":"pn2115"},"session":"Health: Exergaming for healthcare","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2115"},"pn2117":{"lastUpdateTime":1388776489997,"subcommitteeSplit":"B","labels":{"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["mmassimi@microsoft.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032763}},"creationTime":1683,"content":{"authorList":["Joanna Bergstrom-Lehtovirta, Helsinki Institute for Information Technology HIIT, Aalto University and University of Helsinki","Antti Oulasvirta, Max Planck Institute for Informatics"],"title":"Modeling the Functional Area of the Thumb on Mobile Touchscreen Surfaces","paperOrNote":"Paper","fullAbstract":"We present a novel mathematical model that predicts the functional area of the thumb: the area of a touchscreen surface reachable by the users thumb. We derive a quadratic formula by analyzing the anatomy of a hand gripping a surface. Model fit was high for the thumb-motion trajectories of 20 participants. The model predicts the functional area for a given 1) surface size, 2) hand size, and 3) position of the index finger on the back. Designers can use this information to ensure that their user interface layout is suited to one-handed interaction. The model can also be used inversely; that is, to infer the grips that will be necessitated by a given user interface layout.","shortAbstract":"We present a novel mathematical model that predicts the functional are","id":"pn2117"},"session":"Touch: Multitouchy Feely","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2117"},"pn1275":{"lastUpdateTime":1389221977983,"subcommitteeSplit":"","labels":{"Emotion":{"checked":false,"lastUpdateTime":1386528142168,"dislikes":[],"label":"Emotion","lastTimeUpdated":1386527910271,"likes":[]},"User Studies":{"checked":false,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk"],"lastUpdateTime":1386531219584,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","marcodesa@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Entertainment":{"checked":true,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165050}},"creationTime":954,"content":{"authorList":["Jonna Hkkil, University of Oulu","Maaret Posti, University of Oulu","Stefan Schneegass, University of Stuttgart","Florian Alt, University of Munich","Kunter Gultekin, University of Oulu","Albrecht Schmidt, University of Stuttgart"],"title":"Let me catch this! Experiencing Interactive 3D Cinema through Collecting Content with a Mobile Phone","paperOrNote":"Paper","fullAbstract":"Entertainment industry is going through a transformation, and technology development is affecting how we enjoy and interact with the entertainment media content. When looking at the current trends in watching movies in cinemas and home environments, we see two prominent emerging trends  3D content is becoming increasingly popular and watching movies is not a passive observation task anymore. In our work, we explore how to enable interaction with content in the context of 3D cinemas. This would enable viewers to use their mobile phone and to retrieve, e.g., information on the artist of the soundtrack currently playing, or a discount coupon on the watch the main actor is wearing. We are particularly interested in the user experience side of the interactive 3D cinema concept, and how different interactive elements and interaction techniques and concepts were perceived. We report on the development of a prototype application utilizing smart phones and on an evaluation in a cinema context with 20 participants. Results emphasize that designing for interactive cinema experiences should drive for holistic and positive user experiences. Interactive content should be tight together with the actual video content, but integrated into contexts where it does not intrude with the immersive experience with the movie.","shortAbstract":"Entertainment industry is going through a transformation, and technolo","id":"pn1275"},"session":"Art: Performance","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1275"},"pn514":{"lastUpdateTime":1389236481152,"subcommitteeSplit":"","labels":{"social media at work":{"checked":false,"lastUpdateTime":1386523141634,"dislikes":[],"label":"social media at work","lastTimeUpdated":1386523077900,"likes":["jacovi@il.ibm.com"]},"Document management":{"dislikes":[],"lastTimeUpdated":1386523156123,"checked":true,"likes":["smunson@uw.edu","emilee@gmail.com"],"label":"Document management"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523596304,"label":"Empirical Methods, Qualitative"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522300688,"label":"Computer Supported Cooperative Work (CSCW)"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["myriam.lewkowicz@utt.fr"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556713}},"creationTime":311,"content":{"authorList":["Charlotte Massey, University of California ","Thomas Lennig, University of California","Steve Whittaker, University of California at Santa Cruz"],"title":"Cloudy Forecast: An Exploration of the Factors Underlying Shared Repository Use","paperOrNote":"Paper","fullAbstract":"Many teams are now adopting shared repositories for their work. Such adoption is paradoxical, however, as past research has repeatedly shown major co-organizational barriers; teams cannot agree a common organizational scheme, making it difficult to retrieve information organized by others. Another barrier is email competition; email provides a reliable alternative for distributing files that are then personally organized. To address this paradox, we explored how 27 participants actively using shared repositories overcome these barriers in a qualitative study. We found teams addressed co-organization using 4 strategies. First they created ContentMaps that provided explicit structure to organize shared information. Participants also co-organized using implicit strategies based on task structure, expertise, and tool affordances. Greater shared repository use also led to a changed role for email. Versioning problems meant email was not used for distributing attachments, instead for task management. We present technical implications suggesting how new tools might be better integrated with email facilitating these continued email uses. ","shortAbstract":"Many teams are now adopting shared repositories for their work. Such a","id":"pn514"},"session":"CSCW: Document and Intertextuality","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn514"},"pn1475":{"lastUpdateTime":1388766330700,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386522873374,"checked":true,"likes":[],"label":"Field Study"},"HIV":{"dislikes":[],"lastTimeUpdated":1386522083749,"checked":true,"likes":[],"label":"HIV"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"ICTD":{"dislikes":[],"lastTimeUpdated":1386522015678,"checked":true,"likes":["jonfroehlich@gmail.com","rob.comber@ncl.ac.uk","egelman@cs.berkeley.edu","nithyas@gmail.com"],"label":"ICTD"},"User Studies":{"checked":false,"lastUpdateTime":1386522880477,"dislikes":[],"label":"User Studies","lastTimeUpdated":1386522789864,"likes":[]},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446279}},"creationTime":1134,"content":{"authorList":["Anirudha Joshi, Indian Institute of Technology, Bombay","Mandar Rane, Indian Institute of Technology, Bombay","Debjani Roy, Indian Institute of Technology, Bombay","Nagraj Emmadi, Indian Institute of Technology, Bombay","Padma Srinivasan, Indian Institute of Technology, Bombay","N Kumarasamy, YRG Care","Sanjay Pujari, Institute of Infectious Diseases","Davidson Solomon, Shadows","Rashmi Rodrigues, St. John's Hospital","DG Saple, HHRF","Kamalika Sen, Grameen Foundation","Els Veldeman, Johnson and Johnson","Romain Rutten, Johnson and Johnson"],"title":"Supporting Treatment of People Living with HIV / AIDS in Resource Limited Settings with IVRs","paperOrNote":"Paper","fullAbstract":"We developed an interactive voice response (IVR) system called TAMA (Treatment Advice by Mobile Alerts) that provides treatment support to people living with HIV / AIDS (PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study, we gathered feedback about TAMAs design and usage. Additionally, we conducted detailed qualitative in-terviews and analysed usage logs. We found that TAMA was usable and viable in the real life settings of PLHA and it had many desirable effects on their treatment adherence. We developed insights that inform the design of TAMA and some of these can be generalised to design of other long-term, frequent-use IVR applications for users in developing countries in the healthcare domain and beyond.","shortAbstract":"We developed an interactive voice response (IVR) system called TAMA (T","id":"pn1475"},"session":"Health: HealthyCHI","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1475"},"pn1472":{"lastUpdateTime":1389107707576,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de","dan@microsoft.com"],"lastUpdateTime":1386525565333,"label":"Visualization"},"Reality-Based Interfaces":{"checked":false,"lastUpdateTime":1386525764819,"dislikes":[],"label":"Reality-Based Interfaces","lastTimeUpdated":1386525688429,"likes":[]},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525558725,"checked":true,"likes":["petra.isenberg@inria.fr"],"label":"Information Visualization"},"fabrication":{"checked":false,"lastUpdateTime":1386525117446,"dislikes":[],"label":"fabrication","lastTimeUpdated":1386525048027,"likes":[]},"informaion visualization":{"checked":false,"lastUpdateTime":1386525561640,"dislikes":[],"label":"informaion visualization","lastTimeUpdated":1386525128786,"likes":[]},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644834}},"creationTime":1131,"content":{"authorList":["Jeffrey Rzeszotarski, Carnegie Mellon University","Aniket Kittur, Carnegie Mellon University"],"title":"Naturalistic Physics-Based Affordances for Data Visualization","paperOrNote":"Paper","fullAbstract":"Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.","shortAbstract":"Over the last several years there has been an explosion of powerful, a","id":"pn1472"},"session":"Viz: Novel Visual Elements","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1472"},"pn1473":{"lastUpdateTime":1389221449828,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531674011,"checked":true,"likes":["dvogel@uwaterloo.ca","j.d.hook@ncl.ac.uk","olwal@mit.edu"],"label":"Touch Input"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386531758711,"checked":true,"likes":[],"label":"Handheld Devices and Mobile Computing"},"menus":{"dislikes":[],"lastTimeUpdated":1386531911435,"checked":true,"likes":[],"label":"menus"},"Menus":{"checked":false,"lastUpdateTime":1386531913362,"dislikes":[],"label":"Menus","lastTimeUpdated":1386531776661,"likes":[]},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386531742037,"checked":true,"likes":["olwal@mit.edu"],"label":"Multitouch"},"User Interface Design":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531728877,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840552}},"creationTime":1132,"content":{"authorList":["Seongkook Heo, KAIST (Korea Advanced Institute of Science and Technology)","Jiseong Gu, KAIST (Korea Advanced Institute of Science and Technology)","Geehyuk Lee, KAIST (Korea Advanced Institute of Science and Technology)"],"title":"Expanding Touch Input Vocabulary  by Using Consecutive Distant Taps","paperOrNote":"Paper","fullAbstract":"In recent years, touch screens have emerged as the main input interface for mobile and tablet computers. In this paper, we explore a new possibility of using consecutive distant taps to expand touch screen input vocabulary. We analyzed time intervals and distances between consecutive taps while using common applications on a tablet and verified that consecutive distant taps can be used with existing touch gestures without conflicts. We designed two interaction techniques utilizing consecutive distant taps. The first one, that we call Ta-tap, uses two consecutive distant taps to define two control points for a zooming or rotation operation. The second interaction technique, that we call Ta-ta-tap, is a spatial gesture defined by a series of consecutive distant taps. We verified the feasibility of the two interaction techniques through a series of experiments and a user study. The high recognition rate of Ta-tap and Ta-ta-tap gestures, few conflicts with existing gestures, and positive feedback from the participants assert the potential of consecutive distant taps as a new design space to enrich touch screen interaction.","shortAbstract":"In recent years, touch screens have emerged as the main input interfac","id":"pn1473"},"session":"UIST: Gesture Entry","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1473"},"pn1470":{"lastUpdateTime":1389236301173,"subcommitteeSplit":"","labels":{"Collaborative analysis":{"checked":true,"lastUpdateTime":1386523290154,"dislikes":[],"label":"Collaborative analysis","lastTimeUpdated":1386522262161,"likes":[]},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523298294,"label":"Empirical Methods, Quantitative"},"collaboration":{"dislikes":[],"lastTimeUpdated":1386523148884,"checked":true,"likes":["dmrussell@gmail.com"],"label":"collaboration"},"Surveillance":{"dislikes":[],"lastTimeUpdated":1386522188216,"checked":true,"likes":[],"label":"Surveillance"},"implicit structure and organization":{"dislikes":[],"lastTimeUpdated":1386522968562,"checked":true,"likes":[],"label":"implicit structure and organization"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523395250,"label":"Computer-Mediated Communication"},"sensemaking":{"dislikes":[],"lastTimeUpdated":1386523363425,"checked":true,"likes":[],"label":"sensemaking"},"external representations":{"dislikes":[],"lastTimeUpdated":1386523378521,"checked":true,"likes":[],"label":"external representations"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":1386523348614,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556743}},"creationTime":1129,"content":{"authorList":["Nitesh Goyal, Cornell University, Ithaca","Gilly Leshed, Cornell University","Dan Cosley, Cornell University","Susan Fussell, Cornell University"],"title":"Effects of Implicit Sharing in Collaborative Analysis","paperOrNote":"Paper","fullAbstract":"When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit. In this study, we explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other. In a controlled experiment with 68 participants, 2-member teams played the role of crime analysts, solving a set of serial killer crimes as distributed pairs with both partners having some, but not all, clues relevant to the crimes. When implicit sharing of notes was available in the collaborative analysis tool, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.","shortAbstract":"When crime analysts collaborate to solve crime cases, they need to sha","id":"pn1470"},"session":"CSCW: Coordination & Collaboration","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1470"},"pn1471":{"lastUpdateTime":1389222059201,"subcommitteeSplit":"","labels":{"On-Body Interfaces":{"dislikes":[],"lastTimeUpdated":1386532389298,"checked":true,"likes":[],"label":"On-Body Interfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"(passive) Brain-Computer Interfaces":{"dislikes":[],"lastTimeUpdated":1386532257542,"checked":true,"likes":[],"label":"(passive) Brain-Computer Interfaces"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"BCI":{"dislikes":[],"lastTimeUpdated":1386532112981,"checked":true,"likes":["Nchen@microsoft.com","yangli@acm.org"],"label":"BCI"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840727}},"creationTime":1130,"content":{"authorList":["Daniel Afergan, Tufts University","Evan Peck, Tufts University","Erin Solovey, Drexel University","Andrew Jenkins, Tufts University","Samuel Hincks, Tufts University","Remco Chang, Tufts University","Robert Jacob, Tufts University"],"title":"Dynamic Difficulty Using Brain Metrics of Workload","paperOrNote":"Paper","fullAbstract":"Dynamic difficulty adjustments can be used in human-computer systems in order to improve user engagement and performance. In this paper, we use functional near-infrared spectroscopy (fNIRS) to obtain passive brain sensing data and differentiate between periods of boredom, optimal workload, and overload in real-time. By using these physiological signals, we find that we can more accurately model user state than by processing behavioral metrics alone. This state information allows the system to better fit the task to the user from moment to moment. To demonstrate this idea, we ran a laboratory study in which participants were asked to remotely pilot multiple unmanned aerial vehicles (UAVs) in a simulation. Based on their state, we varied the difficulty of the task by adding or removing UAVs and found that we were able to decrease errors by 35% over a baseline condition. Our results show that we can use fNIRS brain sensing to detect task difficulty in real-time and construct an interface that improves user performance through dynamic difficulty adjustment.","shortAbstract":"Dynamic difficulty adjustments can be used in human-computer systems i","id":"pn1471"},"session":"UIST: Read My Mind: Passive BCI","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1471"},"pn739":{"lastUpdateTime":1389220864045,"subcommitteeSplit":"C","labels":{"Wearables":{"dislikes":[],"lastTimeUpdated":1386526529337,"checked":true,"likes":["tjvg@di.fc.ul.pt","erinacarroll@gmail.com","awaller@computing.dundee.ac.uk"],"label":"Wearables"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Google Glass":{"dislikes":[],"lastTimeUpdated":1386526891723,"checked":true,"likes":[],"label":"Google Glass"},"google glass":{"checked":false,"lastUpdateTime":1386526894565,"dislikes":[],"label":"google glass","lastTimeUpdated":1386526887188,"likes":[]},"Health Care":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":123456789,"label":"Health Care"},"Augmented Reality":{"checked":false,"lastUpdateTime":1386539176450,"dislikes":[],"label":"Augmented Reality","lastTimeUpdated":1386526263668,"likes":[]},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527466513,"label":"Empirical Methods, Qualitative"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527468922,"label":"User Studies"},"Rehabilitation":{"checked":false,"lastUpdateTime":1386527376669,"dislikes":[],"label":"Rehabilitation","lastTimeUpdated":1386526520198,"likes":["awaller@computing.dundee.ac.uk"]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486608}},"creationTime":491,"content":{"authorList":["Roisin McNaney, Newcastle University","John Vines, Newcastle University","Daniel Roggen, Newcastle University","Madeline Balaam, Newcastle University","Pengfei Zhang, Newcastle University","Ivan Poliakov, Newcastle University","Patrick Olivier, Newcastle University"],"title":"Exploring the Acceptability of Google Glass as an Everyday Assistive Device for People with Parkinsons","paperOrNote":"Note","fullAbstract":"We describe a qualitative study investigating the acceptability of the Google Glass eyewear computer to people with Parkinsons disease (PD). We held a workshop with 5 PD patients and 2 carers exploring initial perceptions of Glass. This was followed by 5-day field trials of Glass with 4 PD patients, where participants wore the device during everyday activities at home and in public. We report hugely positive responses to Glass as a device to instil confidence and safety for this potentially vulnerable group. We also raise concerns related to the potential for Glass to reaffirm dependency on others and stigmatise wearers. ","shortAbstract":"We describe a qualitative study investigating the acceptability of the","id":"pn739"},"session":"Health: Accessibility","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn739"},"pn228":{"lastUpdateTime":1389221625522,"subcommitteeSplit":"","labels":{"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Animation":{"dislikes":[],"lastTimeUpdated":1386532234333,"checked":true,"likes":[],"label":"Animation"},"Pen and Tactile Input":{"dislikes":[],"lastTimeUpdated":1386532075136,"checked":true,"likes":["mdixon@cs.washington.edu","j.d.hook@ncl.ac.uk"],"label":"Pen and Tactile Input"},"Sketch-based":{"dislikes":[],"lastTimeUpdated":1386532452533,"checked":true,"likes":[],"label":"Sketch-based"},"Pen-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Pen-based UIs"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840713}},"creationTime":94,"content":{"authorList":["Rubaiat Habib Kazi, Autodesk Research","Fanny Chevalier, University of Toronto","Tovi Grossman, Autodesk Research","Shengdong Zhao, National University of Singapore","George Fitzmaurice, Autodesk Research"],"title":"Draco: Bringing Life to Illustrations with Kinetic Textures","paperOrNote":"Paper","fullAbstract":"We present Draco, a sketch-based interface that allows artists and casual users alike to add a rich set of animation effects to their drawings, seemingly bringing illustrations to life. While previous systems have introduced sketch-based animations for individual objects, our contribution is a unified framework of motion controls that allows users to seamlessly add coordinated motions to object collections. We propose a framework built around kinetic textures, which provide continuous animation effects while preserving the unique timeless nature of still illustrations. This enables many dynamic effects difficult or not possible with previous sketch-based tools, such as a school of fish swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe our implementation and illustrate the repertoire of animation effects it supports. A user study with professional animators and casual users demonstrates the variety of animations, applications and creative possibilities our tool provides.","shortAbstract":"We present Draco, a sketch-based interface that allows artists and cas","id":"pn228"},"session":"Art: Image and Animation Authoring","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn228"},"pn223":{"lastUpdateTime":1389285580072,"subcommitteeSplit":"A","labels":{"tools for learning":{"dislikes":[],"lastTimeUpdated":1386523293523,"checked":true,"likes":["Jina.huh@gmail.com","weibel@ucsd.edu"],"label":"tools for learning"},"E-Learning and Education":{"checked":false,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":1386523435539,"label":"E-Learning and Education"},"second language learning":{"checked":false,"lastUpdateTime":1386523636379,"dislikes":[],"label":"second language learning","lastTimeUpdated":1386523604255,"likes":["jkientz@uw.edu"]},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188236}},"creationTime":91,"content":{"authorList":["Manolis Savva, Stanford University","Angel Chang, Stanford University","Christopher Manning, Stanford University","Pat Hanrahan, Stanford University"],"title":"TransPhoner: Phonetic Keywords for Learning Languages","paperOrNote":"Paper","fullAbstract":"Learning foreign languages is challenging, yet critically important as internationalization brings the world together.  In this work, we present TransPhoner: a system that generates mnemonic keywords for assisting in vocabulary learning.  We select effective keywords by considering phonetic, orthographic and semantic word similarity, and word concept imageability.  We show that keywords provided by TransPhoner improve language learning performance in an on-line vocabulary learning study, with the improvement being more pronounced for harder words.  Participants rated TransPhoner keywords as more helpful than a random keyword baseline, and almost as helpful as manually selected keywords.  Comments also indicated higher engagement in the learning task, and more desire to continue learning.  We demonstrate additional applications to tasks such as pure phonetic transliteration and generating mnemonics for complex vocabulary.","shortAbstract":"Learning foreign languages is challenging, yet critically important as","id":"pn223"},"session":"HCI4D: Lost and Found in Translation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn223"},"pn222":{"lastUpdateTime":1389591780431,"subcommitteeSplit":"","labels":{"Wearable computing":{"dislikes":[],"lastTimeUpdated":1386532593882,"checked":true,"likes":[],"label":"Wearable computing"},"Head-Worn Displays":{"dislikes":[],"lastTimeUpdated":1386536868501,"checked":true,"likes":[],"label":"Head-Worn Displays"},"Faces":{"dislikes":[],"lastTimeUpdated":1386536904210,"checked":true,"likes":[],"label":"Faces"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"On-Body Interfaces":{"dislikes":[],"lastTimeUpdated":1386532271711,"checked":true,"likes":["olwal@mit.edu"],"label":"On-Body Interfaces"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386532261507,"checked":true,"likes":[],"label":"Wearables"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","olwal@mit.edu","j.d.hook@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840555}},"creationTime":90,"content":{"authorList":["Marcos Serrano, University of Manitoba","Barrett Ens, University of Manitoba","Pourang Irani, University of Manitoba"],"title":"Exploring the Use of Hand-To-Face Input for Interacting with Head-Worn Displays","paperOrNote":"Paper","fullAbstract":"We propose the use of Hand-to-Face input, a method to \\ interact with head-worn displays (HWDs) that involves \\ contact with the face. We explore Hand-to-Face interaction \\ to find suitable techniques for common mobile tasks. We \\ evaluate this novel form of interaction with document \\ navigation tasks and examine the social acceptability \\ barriers for its adoption. In an elicitation study, users \\ identify the cheek and forehead as predominant areas for \\ interaction and agree on gestures for tasks involving \\ continuous input, such as document navigation. These \\ results guide the design of several Hand-to-Face navigation \\ techniques. A study evaluating the effectiveness and \\ physical effort reveals that gestures performed on the cheek \\ are more efficient and less tiring than interactions directly \\ on the HWD. Results on the social acceptability of Hand-to- \\ Face input allow us to further refine our design choices, \\ and reveal unforeseen results: some gestures are considered \\ culturally inappropriate and gender plays a role in selection \\ of specific Hand-to-Face interactions. From our overall \\ results, we provide a set of guidelines for developing \\ effective Hand-to-Face interaction techniques.","shortAbstract":"We propose the use of Hand-to-Face input, a method to \\ interact with ","id":"pn222"},"session":"Displays: Head-Worn Displays (UIST)","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn222"},"pn737":{"lastUpdateTime":1389221191523,"subcommitteeSplit":"B","labels":{"Fitts's Law":{"dislikes":[],"lastTimeUpdated":1386521986563,"checked":true,"likes":[],"label":"Fitts's Law"},"Exergames":{"dislikes":[],"lastTimeUpdated":1386521852744,"checked":true,"likes":[],"label":"Exergames"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","rob.comber@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"games":{"dislikes":[],"lastTimeUpdated":1386522032703,"checked":true,"likes":[],"label":"games"},"Input and Interaction Technologies":{"dislikes":[],"lastTimeUpdated":1386522061248,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Input and Interaction Technologies"},"Exergame":{"checked":false,"lastUpdateTime":1386531416714,"dislikes":[],"label":"Exergame","lastTimeUpdated":1386521715934,"likes":[]},"Exercise":{"dislikes":[],"lastTimeUpdated":1386521748208,"checked":true,"likes":[],"label":"Exercise"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446267}},"creationTime":489,"content":{"authorList":["Taiwoo Park, KAIST","Uichin Lee, KAIST","Miri Moon, KAIST","Inseok Hwang, KAIST","Scott MacKenzie, York University","Junehwa Song, KAIST"],"title":"Human Factors of Speed-based Exergame Controllers","paperOrNote":"Paper","fullAbstract":"Exergame controllers are intended to add fun to monotonous exercise. However, studies on exergame controllers mostly focus on designing new controllers and exploring specific application domains without analyzing human factors, such as performance, comfort, and effort. In this paper, we examine characteristics of a speed-based exergame controller that bear on human factors related to body movement and exercise. Users performed tasks such as changing and maintaining exercise speed for avatar control while their performance was measured. The controllers follow Fitts law, but require longer movement time than a gamepad and Wiimote. As well, resistance force and target speed affect performance. Our user experience data confirm that the comfort and mental effort are adequate as practical game controllers. The paper concludes with discussion on applying our findings to practical exergame design.","shortAbstract":"Exergame controllers are intended to add fun to monotonous exercise. H","id":"pn737"},"session":"Games: Exergames","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn737"},"pn224":{"lastUpdateTime":1389236648218,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Tutorials":{"dislikes":[],"lastTimeUpdated":1386537201370,"checked":true,"likes":[],"label":"Tutorials"},"Crowd-Powered Systems":{"dislikes":[],"lastTimeUpdated":1386523895229,"checked":true,"likes":["nebeling@inf.ethz.ch"],"label":"Crowd-Powered Systems"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081846}},"creationTime":92,"content":{"authorList":["Juho Kim, Massachusetts Institute of Technology","Phu Nguyen, Massachusetts Institute of Technology","Sarah Weir, Massachusetts Institute of Technology","Philip Guo, University of Rochester","Rob Miller, Massachusetts Institute of Technology","Krzysztof Gajos, Harvard University"],"title":"Crowdsourcing Step-by-Step Information Extraction to Enhance Existing How-to Videos","paperOrNote":"Paper","fullAbstract":"Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of watching existing how-to videos with step-by-step annotations. \\  \\ We first performed a formative study to verify that annotations are actually useful to learners. For this study, we created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player. \\  \\ To add the necessary step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all domains with 77% precision and 81% recall. ","shortAbstract":"Millions of learners today use how-to videos to master new skills in a","id":"pn224"},"session":"Systems: Tutorials","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn224"},"pn428":{"lastUpdateTime":1389221840890,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Keyboards":{"dislikes":[],"lastTimeUpdated":1386531678450,"checked":true,"likes":["tomer@moscovich.net","eve.hoggan@hiit.fi"],"label":"Keyboards"},"Gesture Recognition":{"dislikes":[],"lastTimeUpdated":1386532134399,"checked":true,"likes":[],"label":"Gesture Recognition"},"Gestural Interaction":{"dislikes":[],"lastTimeUpdated":1386532040045,"checked":true,"likes":["david.kim@newcastle.ac.uk","otmar.hilliges@inf.ethz.ch"],"label":"Gestural Interaction"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840574}},"creationTime":247,"content":{"authorList":["Stuart Taylor, Microsoft Research","Cem Keskin, Microsoft Research","Otmar Hilliges, ETH Zurich","Shahram Izadi, Microsoft Research"],"title":"Type-Hover-Swipe in 96 Bytes: A Motion Sensing Mechanical Keyboard","paperOrNote":"Paper","fullAbstract":"We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work. ","shortAbstract":"We present a new type of augmented mechanical keyboard, capable of sen","id":"pn428"},"session":"UIST: novel keyboards","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn428"},"pn425":{"lastUpdateTime":1388776475848,"subcommitteeSplit":"","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386531871957,"checked":true,"likes":["fanny@dgp.toronto.edu","eve.hoggan@hiit.fi","j.d.hook@ncl.ac.uk"],"label":"Gestural interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Mobile Spatial Input":{"dislikes":[],"lastTimeUpdated":1386531918221,"checked":true,"likes":[],"label":"Mobile Spatial Input"},"pan and zoom":{"dislikes":[],"lastTimeUpdated":1386531583456,"checked":true,"likes":[],"label":"pan and zoom"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840578}},"creationTime":244,"content":{"authorList":["Martin Spindler, University of Magdeburg","Martin Schuessler, Telekom Innovation Laboratories TU Berlin","Marcel Martsch, University of Magdeburg","Raimund Dachselt, Technische Universitt Dresden"],"title":"Pinch-Drag-Flick vs. Spatial Input: Rethinking Zoom & Pan on Mobile Displays","paperOrNote":"Paper","fullAbstract":"The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide popularity on mobile displays, where it is the paradigm of choice for navigating 2D documents. But is finger-based navigation really the gold standard? In this paper, we present a comprehensive user study with 40 participants. We systematically compared the Pinch-Drag-Flick approach with a technique that relies entirely on spatial manipulation, such as lifting a display up/down to zoom. While we solely considered established techniques, we put considerable effort in implementing both input strategies on popular consumer hardware (iPhone and iPad). We gathered over 12 hours of performance data as well as detailed self-assessments of participants. Results show that spatial manipulation significantly outperforms conventional multi-touch-based navigation. Given the care-fully optimized prototypes, we are confident to have found strong arguments that future generations of mobile devices should rely much more on spatial interaction principles. ","shortAbstract":"The multi-touch-based pinch to zoom, drag and flick to pan metaphor ha","id":"pn425"},"session":"Touch: Touch-me Mobile Interaction","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn425"},"pn794":{"lastUpdateTime":1389222210195,"subcommitteeSplit":"","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Prototyping"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["olwal@mit.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk","eve.hoggan@hiit.fi","olwal@mit.edu"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840567}},"creationTime":533,"content":{"authorList":["Rong-Hao Liang, National Taiwan University","Liwei Chan, ","Da-Yuan Huang, National Taiwan University","Bing-Yu Chen, National Taiwan University","De-Nian Yang, Academia Sinica"],"title":"GaussBricks: Magnetic Building Blocks for Constructive Tangible Interactions on Portable Displays","paperOrNote":"Paper","fullAbstract":"This paper presents a novel material of tangible interaction design, GaussBricks, which is a system of magnetic building blocks that enables real-time constructive tangible interactions on portable displays. The mechanical design of the magnetic building blocks is simple, and thus effective to enable configurable form construction. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback. With an analog Hall-sensor grid mounted to the back, the portable display resolves the geometry of the constructions and detects various user interactions in real time. We also introduce several advanced uses of the block design, such as enabling near-surface and multi-touch interactions, shape change, and display capabilities. This building block system enriches the way we interact with the portable displays physically.","shortAbstract":"This paper presents a novel material of tangible interaction design, G","id":"pn794"},"session":"UIST: Tangibles","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn794"},"pn641":{"lastUpdateTime":1389592121047,"subcommitteeSplit":"","labels":{"Smartphones":{"dislikes":[],"lastTimeUpdated":1386523573508,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"Smartphones"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"notifications":{"dislikes":[],"lastTimeUpdated":1386523486509,"checked":true,"likes":[],"label":"notifications"},"Phone":{"checked":false,"lastUpdateTime":1386523576984,"dislikes":[],"label":"Phone","lastTimeUpdated":1386522812991,"likes":[]},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Interruption management":{"dislikes":[],"lastTimeUpdated":1386523561121,"checked":true,"likes":[],"label":"Interruption management"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523731739,"label":"Interaction Design"},"Visual System Design / Visual Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visual System Design / Visual Design"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556781}},"creationTime":410,"content":{"authorList":["Matthias Bhmer, German Research Center for Artificial Intelligence (DFKI)","Christian Lander, German Research Center for Artificial Intelligence (DFKI)","Sven Gehring, German Research Center for Artificial Intelligence (DFKI)","Duncan Brumby, University College London","Antonio Krger, German Research Center for Artificial Intelligence (DFKI)"],"title":"Interrupted by a Phone Call: Exploring Designs for Lowering the Impact of Call Notifications for Smartphone Users","paperOrNote":"Paper","fullAbstract":"Mobile phones have evolved significantly in recent years from single-purpose communication devices to multi-purpose computing devices. Despite this evolution, the interaction model for how incoming calls are handled has barely changed. Current-generation smartphones still use abrupt full-screen notifications to alert users to incoming calls, demanding a decision to either accept or decline the call. These full-screen notifications forcibly interrupt whatever activity the user was already engaged in. This might be undesirable when the users primary task was more important than the incoming call. This paper explores the design space for how smartphones can alert users to incoming calls. We consider designs that allow users to postpone calls and also to multiplex by way of a smaller partial-screen notification. These design alternatives were evaluated in both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild study. Results show that a multiplex design solution works best because it allows people to continue working in their primary task while being made aware of that there is a caller on the line. The contribution of this work is an enhanced interaction design for handling phone calls, and an understanding of how people use it for handling incoming calls.","shortAbstract":"Mobile phones have evolved significantly in recent years from single-p","id":"pn641"},"session":"CSCW: Interruptions and Distractions","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn641"},"pn643":{"lastUpdateTime":1389236845002,"subcommitteeSplit":"","labels":{"repair":{"dislikes":[],"lastTimeUpdated":1386528481097,"checked":true,"likes":[],"label":"repair"},"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386527628471,"checked":true,"likes":["judy.kay@gmail.com","marcodesa@gmail.com","mark.dunlop@strath.ac.uk","wmoncur@dundee.ac.uk"],"label":"Handheld Devices and Mobile Computing"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","wmoncur@dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"usability-aestheic relationship":{"dislikes":[],"lastTimeUpdated":1386528455004,"checked":true,"likes":["wmoncur@dundee.ac.uk"],"label":"usability-aestheic relationship"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165036}},"creationTime":412,"content":{"authorList":["Florian Schaub, Ulm University","Julian Seifert, Ulm University","Frank Honold, Ulm University","Michael Mller, Ulm University","Enrico Rukzio, Ulm University","Michael Weber, Ulm University"],"title":"Broken Display = Broken Interface? The Impact of Display Damage on Smartphone Interaction","paperOrNote":"Paper","fullAbstract":"This paper is the first to assess the impact of touchscreen damage on smartphone interaction. We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive information about a device's usage history, damage severity, and impact on use. 88% of our participants continued to use their damaged smartphone for at least three months; 32% plan to use it for another year or more, mainly due to high repair and replacement costs. From the dataset, we identified three categories of damaged smartphone displays. Reading and text input were most affected. Further interviews (n=11) revealed that users adapt to damage with diverse coping strategies, closely tailored to specific interaction issues. In total, we identified 23 different strategies. Based on our results, we proposed guidelines for interaction design in order to provide a positive user experience when display damage occurs.","shortAbstract":"This paper is the first to assess the impact of touchscreen damage on ","id":"pn643"},"session":"Making: how things don't work","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn643"},"pn648":{"lastUpdateTime":1388776832811,"subcommitteeSplit":"","labels":{"EEG-based HCI":{"dislikes":[],"lastTimeUpdated":1386525355373,"checked":true,"likes":["bickmore@ccs.neu.edu","benko@microsoft.com"],"label":"EEG-based HCI"},"Driving":{"dislikes":[],"lastTimeUpdated":1386525730635,"checked":true,"likes":["davidmcgookin@gmail.com","pierre.dragice@gmail.com"],"label":"Driving"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Performance Metrics"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Automotive":{"dislikes":[],"lastTimeUpdated":1386525936672,"checked":true,"likes":["abe.karnik@gmail.com","bulling@mpi-inf.mpg.de"],"label":"Automotive"},"(passive) BCI":{"dislikes":[],"lastTimeUpdated":1386525351044,"checked":true,"likes":["aquigley@st-andrews.ac.uk"],"label":"(passive) BCI"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"passive BCI":{"dislikes":[],"lastTimeUpdated":1386525422877,"checked":true,"likes":["tzander@gmail.com"],"label":"passive BCI"},"(passive) Brain-Computer Interfaces":{"dislikes":[],"lastTimeUpdated":1386525346732,"checked":true,"likes":["forlines@alumni.cmu.edu","dan@microsoft.com","bickmore@ccs.neu.edu"],"label":"(passive) Brain-Computer Interfaces"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Transport":{"checked":true,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de","bickmore@ccs.neu.edu"],"lastUpdateTime":123456789,"label":"Transport"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644765}},"creationTime":417,"content":{"authorList":["Erin Solovey, Drexel University","Marin Zec, Technische Universitt Mnchen","Enrique Abdon Garcia Perez, MIT","Bryan Reimer, MIT","Bruce Mehler, Massachusetts Institute of Technology"],"title":"Classifying Driver Workload Using Physiological and  Driving Performance Data: Two Field Studies","paperOrNote":"Paper","fullAbstract":"Understanding the drivers cognitive load is important for evaluating in-vehicle user interfaces. This paper describes experiments to assess machine learning classification algorithms on their ability to automatically identify elevated cognitive workload levels in drivers, leading towards the development of robust tools for automobile user interface evaluation. We look at using both driver performance data as well as physiological sensors. These measures can be collected in real-time and do not interfere with the primary task of driving the vehicle. We report classification accuracies of up to 90% for detecting elevated levels of cognitive load, and show that physiological data is valuable and leads to higher classification accuracy than vehicle sensor data evaluated alone. Finally, we show results suggesting that models can be built to classify cognitive load across individuals, instead of building individual models for each person. By collecting data from 119 drivers in two field studies on the highway, this work extends prior work and demonstrates feasibility and potential of such measures for HCI research in vehicles","shortAbstract":"Understanding the drivers cognitive load is important for evaluatin","id":"pn648"},"session":"Transportation: Driving Me Mental","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn648"},"pn791":{"lastUpdateTime":1389221083200,"subcommitteeSplit":"","labels":{"E-Learning and Education":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Learning and Education"},"multi-display interfaces":{"dislikes":[],"lastTimeUpdated":1386525594474,"checked":true,"likes":["elm@purdue.edu"],"label":"multi-display interfaces"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"play":{"dislikes":[],"lastTimeUpdated":1386536695054,"checked":true,"likes":[],"label":"play"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Children":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Children"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644816}},"creationTime":531,"content":{"authorList":["Wooi Boon Goh, Nanyang Technological University","MING CHEN, Nanyang Technology University","Cuong Trinh, Nanyang Technology University","Jacquelyn Tan, Nanyang Technological University","Wei Shou, Nanyang Technological University"],"title":"The MOY Framework for Collaborative Play Design in Integrated Shared and Private Interactive Spaces","paperOrNote":"Paper","fullAbstract":"A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combines both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.","shortAbstract":"A novel Mine-Ours-Yours (MOY) interaction design framework is proposed","id":"pn791"},"session":"Games: Fun N Play","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn791"},"pn1055":{"lastUpdateTime":1389285111611,"subcommitteeSplit":"C","labels":{"Mental health":{"dislikes":[],"lastTimeUpdated":1386527441243,"checked":true,"likes":[],"label":"Mental health"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526902896,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["bpbailey@illinois.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486644}},"creationTime":757,"content":{"authorList":["Onur Yrten, Swiss Federal Institue of Technology","Jiyong Zhang, EPFL","Pearl Pu, EPFL"],"title":"Predictors of Life Satisfaction based on Daily Activities from Mobile Sensor Data","paperOrNote":"Note","fullAbstract":"In recent years much research work has been dedicated to \\ detecting user activity patterns from sensor data such as location, \\ movement and proximity. However, how daily activities \\ are correlated to peoples happiness (such as their satisfaction \\ from work and social lives) is not well explored. In \\ this work, we propose an approach to investigate the relationship \\ between users daily activity patterns and their life satisfaction \\ level. From a well-known longitudinal dataset collected \\ by mobile devices, we extract various activity features \\ through location and proximity information, and compute the \\ entropies of these data to capture the regularities of the behavioral \\ patterns of the participants. We then perform component \\ analysis and structural equation modeling to identify key behavior \\ contributors to self-reported satisfaction scores. Our \\ results show that our analytical procedure can identify meaningful \\ assumptions of causality between activities and satisfaction. \\ Particularly, keeping regularity in daily activities can \\ significantly improve the life satisfaction.","shortAbstract":"In recent years much research work has been dedicated to \\ detecting u","id":"pn1055"},"session":"UBI: Activity Recognition","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1055"},"pn1057":{"lastUpdateTime":1389591341091,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["roudauta@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Activity recognition":{"dislikes":[],"lastTimeUpdated":1386524699355,"checked":true,"likes":[],"label":"Activity recognition"},"Mobile UI":{"dislikes":[],"lastTimeUpdated":1386524090612,"checked":true,"likes":[],"label":"Mobile UI"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081892},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389105985548}},"creationTime":758,"content":{"authorList":["Mohammad Faizuddin Mohd Noor, University of Glasgow","Simon Rogers, University of Glasgow","Williamson John, University of Glasgow","Stephen Hughes, SAMH Engineering","Andrew Ramsay, University of Glasgow"],"title":"28 Frames Later: Predicting Screen Touches From Back-of-Device Grip Changes","paperOrNote":"Note","fullAbstract":"We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.","shortAbstract":"We demonstrate that front-of-screen targeting on mobile phones can be ","id":"pn1057"},"session":"Methods and Models: User Model 1","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1057"},"pn1296":{"lastUpdateTime":1389221709637,"subcommitteeSplit":"","labels":{"forums":{"dislikes":[],"lastTimeUpdated":1386521919082,"checked":true,"likes":["myriam.lewkowicz@utt.fr"],"label":"forums"},"community structures":{"dislikes":[],"lastTimeUpdated":1386523041637,"checked":true,"likes":[],"label":"community structures"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522204558,"label":"Computer-Mediated Communication"},"Dysfunctional Communities":{"dislikes":[],"lastTimeUpdated":1386522110980,"checked":true,"likes":[],"label":"Dysfunctional Communities"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523497045,"label":"Social Computing and Social Navigation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556775}},"creationTime":971,"content":{"authorList":["Jessica Pater, Georgia Institute of Technology","Yacin Nadji, Georgia Institute of Technology","Elizabeth Mynatt, Georgia Institute of Technology","Amy Bruckman, Georgia Institute of Technology"],"title":"Just Awful Enough  The Functional Dysfunction of the Something Awful Forums","paperOrNote":"Note","fullAbstract":"The Something Awful Forums is an online community comprised of a loosely connected federation of forums, united in a distinctive brand of humor with a focus on the quality of member contributions. In this case study we find that the site has sustained success while deviating from common conventions and norms of online communities. Humor and the quality of content contributed by Forum members foster practices that seem counterintuitive to the development of a stable and thriving community. In this case study we show how design decisions are contextual and inter-dependent and together these heuristics create a different kind of online third place.","shortAbstract":"The Something Awful Forums is an online community comprised of a loose","id":"pn1296"},"session":"Social: Lonely, Sad and Awful","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1296"},"pn1295":{"lastUpdateTime":1389285319334,"subcommitteeSplit":"A","labels":{"information needs":{"dislikes":[],"lastTimeUpdated":1386525131876,"checked":true,"likes":[],"label":"information needs"},"photography":{"dislikes":[],"lastTimeUpdated":1386525125444,"checked":true,"likes":["lorrie@acm.org"],"label":"photography"},"Experience Sampling":{"dislikes":[],"lastTimeUpdated":1386525113146,"checked":true,"likes":["asellen@microsoft.com","lorrie@acm.org"],"label":"Experience Sampling"},"Photosharing":{"checked":false,"lastUpdateTime":1386530519006,"dislikes":[],"label":"Photosharing","lastTimeUpdated":1386524395408,"likes":[]},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525641773,"label":"User Studies"},"photo sharing":{"dislikes":[],"lastTimeUpdated":1386530516290,"checked":true,"likes":[],"label":"photo sharing"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946653}},"creationTime":970,"content":{"authorList":["Zhen Yue, University of Pittsburgh","Eden Litt, Northwestern University","Carrie Cai, Massachusetts Institute of Technology","Jeff Stern, Elon University","Kathy Baxter, Google, Inc.","Zhiwei Guan, Google","Nikhil Sharma, Google","Guangqiang (George) Zhang, Google Inc"],"title":"Photographing Information Needs: The Role of Photos in Experience Sampling Method-Style Research","paperOrNote":"Paper","fullAbstract":"Experience Sampling Method (ESM) enables researchers to capture information about participants experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photographs in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphone with more than 1000 US participants, and analyzed participants photo submissions, including how photo use correlated with participants data quality and what if any value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.","shortAbstract":"Experience Sampling Method (ESM) enables researchers to capture inform","id":"pn1295"},"session":"Web: Photo sharing","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1295"},"pn1293":{"lastUpdateTime":1389591385901,"subcommitteeSplit":"B","labels":{"user modelling":{"dislikes":[],"lastTimeUpdated":1386525499546,"checked":true,"likes":["david.kirk@ncl.ac.uk"],"label":"user modelling"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["david.kirk@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Software Engineering Methods and Processes - Mathematical/Formal":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Software Engineering Methods and Processes - Mathematical/Formal"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032792}},"creationTime":969,"content":{"authorList":["Himanshu Zade, IIIT-H (International Institute of Information Technology - Hyderabad)","Santosh Arvind Adimoolam, IIIT-H (International Institute of Information Technology - Hyderabad)","Sai Gollapudi, IIIT-H (International Institute of Information Technology - Hyderabad)","Anind Dey, Carnegie Mellon University","Venkatesh Choppella, IIIT-H (International Institute of Information Technology - Hyderabad)"],"title":"Edit Distance: A Quantitative Measure to Study Evolution of User Models","paperOrNote":"Paper","fullAbstract":"When a user learns to use a new device, her understanding of the device evolves. A progressive comparison of the evolving user models towards the device target model, for analyzing learning, involves determining the behavioral proximity be- tween them. To quantify the gap between a user model and a target model, we introduce an edit distance metric for measuring behavioral proximity between them using a bisimulation-based equivalence relation. We define edit distance to be the minimum number of edges and states with incident edges required to be deleted from and/or added to a user model to make it bisimilar to the target model. We propose an algorithm to compute edit distance for models and support its integrity with formal proofs. We employ this heuristic procedure on our experimental data for computing edit distance between user and target models. We collected this data in two separate experiments, where users interacted with two different devices: (a) a hypothetical device and (b) a close to real- world vehicle transmission model. The results validate our proposed metric as edit distance converges with progressive user learning, increases for erroneous learning, and remains unchanged indicating no learning.","shortAbstract":"When a user learns to use a new device, her understanding of the devic","id":"pn1293"},"session":"Methods and Models: User Model 1","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1293"},"pn1290":{"lastUpdateTime":1389221215807,"subcommitteeSplit":"A","labels":{"Health and social media":{"dislikes":[],"lastTimeUpdated":1386523249867,"checked":true,"likes":["Jina.huh@gmail.com","a.parker@neu.edu"],"label":"Health and social media"},"In School":{"dislikes":[],"lastTimeUpdated":1386523426500,"checked":true,"likes":[],"label":"In School"},"Physical Fitness":{"dislikes":[],"lastTimeUpdated":1386523159077,"checked":true,"likes":["jkientz@uw.edu","a.parker@neu.edu","weibel@ucsd.edu"],"label":"Physical Fitness"},"Health Care":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523442663,"label":"Health Care"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Get Up! Technology for Physical Fitness":{"checked":false,"lastUpdateTime":1386523573425,"dislikes":[],"label":"Get Up! Technology for Physical Fitness","lastTimeUpdated":1386523330949,"likes":["weibel@ucsd.edu"]},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523389374,"label":"User Studies"},"Children":{"checked":true,"dislikes":[],"likes":["lana@research.att.com","hilary.hutchinson@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188215}},"creationTime":967,"content":{"authorList":["Andrew Miller, Georgia Institute of Technology","Elizabeth Mynatt, Georgia Institute of Technology"],"title":"StepStream: A School-based Pervasive Social Fitness System for Everyday Adolescent Health","paperOrNote":"Paper","fullAbstract":"Computer-supported fitness interventions for adolescents have the potential to improve adolescents attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings. ","shortAbstract":"Computer-supported fitness interventions for adolescents have the pote","id":"pn1290"},"session":"Health: Exergaming for healthcare","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1290"},"pn1298":{"lastUpdateTime":1388765570911,"subcommitteeSplit":"A","labels":{"Health Information Management":{"dislikes":[],"lastTimeUpdated":1386523746598,"checked":true,"likes":["mentis@umbc.edu"],"label":"Health Information Management"},"cancer":{"checked":true,"lastUpdateTime":1386526041432,"dislikes":[],"label":"cancer","lastTimeUpdated":1386522921132,"likes":[]},"Mobile health":{"dislikes":[],"lastTimeUpdated":1386523694465,"checked":true,"likes":["Mark.blythe@northumbria"],"label":"Mobile health"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526501974,"label":"User-Centered Design / Human-Centered Design"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526708335,"label":"Empirical Methods, Qualitative"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526673242,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188217}},"creationTime":973,"content":{"authorList":["Maia Jacobs, Georgia Institute of Technology","James Clawson, Georgia Institute of Technology","Elizabeth Mynatt, Georgia Institute of Technology"],"title":"MJC: A Preliminary Investigation of a Mobile Tool for Cancer Patients","paperOrNote":"Paper","fullAbstract":"Health information management for cancer care is a challenging and personal process that changes over time based on ones needs, goals, and health status. Technologies to support health information management appear promising, but we do not fully understand how health information tools fit into peoples daily lives. To better understand the opportunities and usage barriers of integrated health management tools and whether such tools could improve the cancer care experience, we provided breast cancer patients with a mobile, tablet-based health management aid: MJC. We used a qualitative analysis to investigate participants initial patterns of adoption, adaptation, use and non-use one month after deployment. We found that developing a tool that was customizable, mobile, and integrated into the participants healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks, demonstrating the potential health management tools possess for improving the cancer care experience. ","shortAbstract":"Health information management for cancer care is a challenging and per","id":"pn1298"},"session":"Health: Interfaces for Care and Support","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1298"},"pn2268":{"lastUpdateTime":1388717982850,"subcommitteeSplit":"A","labels":{"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"Play":{"dislikes":[],"lastTimeUpdated":1386523303683,"checked":true,"likes":["Mark.blythe@northumbria"],"label":"Play"},"Children":{"checked":true,"dislikes":[],"likes":["lana@research.att.com"],"lastUpdateTime":123456789,"label":"Children"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":["lana@research.att.com"],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188210}},"creationTime":1815,"content":{"authorList":["Seth Hunter, MIT Media Lab","Pattie Maes, MIT Media Lab","Anthony Tang, University of Calgary","Kori Inkpen, Microsoft Research"],"title":"WaaZam! Supporting Creative Play at a Distance in Customized Video Environments","paperOrNote":"Paper","fullAbstract":"We present the design, implementation and evaluation of WaaZam, a video mediated communication system designed to support creative play in customized environments. Users can interact together in virtual environments composed of digital assets layered in 3D space. The goal of the project is to support creative play and increase social engagement during video sessions of geographically separated families. We try to understand the value of customization for individual families with children ages 6-12. We present interviews with creativity experts, a pilot study and a formal evaluation of families playing together in four conditions: separate windows, merged windows, digital play sets, and customized digital environments. We found that playing in the same video space enables new activities and increases social engagement for families. Customization allows families to modify scenes for their needs and support more creative play activities that embody the imagination of the child.","shortAbstract":"We present the design, implementation and evaluation of WaaZam, a vide","id":"pn2268"},"session":"Navigating Video","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2268"},"pn1120":{"lastUpdateTime":1389221135554,"subcommitteeSplit":"A","labels":{"E-Learning and Education":{"checked":false,"lastUpdateTime":1386523470685,"dislikes":[],"label":"E-Learning and Education","lastTimeUpdated":1386523447697,"likes":[]},"User Studies":{"checked":false,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":1386526656845,"label":"User Studies"},"Education":{"dislikes":[],"lastTimeUpdated":1386523445611,"checked":true,"likes":[],"label":"Education"},"games":{"dislikes":[],"lastTimeUpdated":1386523437539,"checked":true,"likes":[],"label":"games"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188168}},"creationTime":816,"content":{"authorList":["Eleanor O'Rourke, University of Washington","Kyla Haimovitz, Stanford University","Christy Ballweber, University of Washington","Carol Dweck, Stanford University","Zoran Popovic, University of Washington"],"title":"Brain Points: A Growth Mindset Incentive Structure Boosts Persistence in an Educational Game","paperOrNote":"Paper","fullAbstract":"There is a growing interest in leveraging video games to inspire children to achieve educational goals. Games have many features that make them well-suited for learning: they can adapt to meet individual needs, provide continual feedback as students learn, and offer rich and engaging reward structures. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's ideas about intelligence and success. In this work, we argue that the effectiveness of educational games can be increased by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present results from a study of 15,000 children showing that our ``brain points'' reward system increases student persistence and use of strategy, even after a short period of time. Unlike existing mindset interventions, this incentive structure shows children how growth mindset behaviors can be practiced and achieved.","shortAbstract":"There is a growing interest in leveraging video games to inspire child","id":"pn1120"},"session":"Games: Education Games","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1120"},"pn1123":{"lastUpdateTime":1389236301173,"subcommitteeSplit":"","labels":{"crowdwork":{"dislikes":[],"lastTimeUpdated":1386521270680,"checked":true,"likes":["sadat@us.ibm.com"],"label":"crowdwork"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523554127,"label":"Empirical Methods, Quantitative"},"ideation":{"dislikes":[],"lastTimeUpdated":1386521271998,"checked":true,"likes":[],"label":"ideation"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386521276805,"checked":true,"likes":[],"label":"crowdsourcing"},"implicit structure and organization":{"dislikes":[],"lastTimeUpdated":1386523085160,"checked":true,"likes":[],"label":"implicit structure and organization"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523558455,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556677}},"creationTime":819,"content":{"authorList":["Paul Andr, Carnegie Mellon University","Robert Kraut, Carnegie Mellon University","Aniket Kittur, Carnegie Mellon University"],"title":"Effects of Simultaneous and Sequential Work Structures on Collaborative Interdependent Tasks","paperOrNote":"Paper","fullAbstract":"Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design. However, coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge. We conducted an experiment comparing the effectiveness of two coordination strategies (simultaneous vs. sequential work) on a complex creative task as the number of group members increased. Our results indicate that, contrary to prior work, a sequential work structure was more effective than a simultaneous work structure as the size of the group increased. A mediation analysis suggests that social processes such as territoriality partially accounts for these results. A follow up experiment giving workers specific roles mitigated the detrimental effects of the simultaneous work structure. These results have implications for small group theory and crowdsourcing research.","shortAbstract":"Distributed online groups have great potential for generating interdep","id":"pn1123"},"session":"CSCW: Coordination & Collaboration","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1123"},"pn775":{"lastUpdateTime":1389221191523,"subcommitteeSplit":"","labels":{"Crowdsourcing":{"checked":false,"lastUpdateTime":1386528368324,"dislikes":[],"label":"Crowdsourcing","lastTimeUpdated":1386525790979,"likes":[]},"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com","bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Alternate Reality Games":{"dislikes":[],"lastTimeUpdated":1386525541689,"checked":true,"likes":[],"label":"Alternate Reality Games"},"Virtual Reality":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Reality"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386528366945,"checked":true,"likes":[],"label":"crowdsourcing"},"Prototyping":{"dislikes":[],"lastTimeUpdated":1386525520913,"checked":true,"likes":["davidmcgookin@gmail.com"],"label":"Prototyping"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":["wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"far-out interaction styles":{"dislikes":[],"lastTimeUpdated":1386525672344,"checked":true,"likes":["no@spam.org","benko@microsoft.com","elm@purdue.edu"],"label":"far-out interaction styles"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644832}},"creationTime":521,"content":{"authorList":["Lung-Pan Cheng, Hasso Plattner Institute","Patrick Lhne, Hasso Plattner Institute","Pedro Lopes, Hasso Plattner Institute","Christoph Sterz, Hasso Plattner Institute","Patrick Baudisch, Hasso Plattner Institute"],"title":"Haptic Turk: A Motion Platform Based on People","paperOrNote":"Paper","fullAbstract":"Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more turkers. The player enjoys an interactive experience, such as a flight simulation. The motion in the players experience is generated by the turkers who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on turkers mobile devices, which they attach to the players body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays, and that leverage swings, chairs, etc. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by experimentally deploying at an art festival in the Nevada desert.","shortAbstract":"Motion platforms are used to increase the realism of virtual interacti","id":"pn775"},"session":"Games: Exergames","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn775"},"pn1872":{"lastUpdateTime":1387315840694,"subcommitteeSplit":"","labels":{"Multimedia UIs":{"checked":true,"dislikes":[],"likes":["fanny@dgp.toronto.edu"],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"Video":{"dislikes":[],"lastTimeUpdated":1386531633242,"checked":true,"likes":["fanny@dgp.toronto.edu","yangli@acm.org","j.d.hook@ncl.ac.uk"],"label":"Video"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840694}},"creationTime":1467,"content":{"authorList":["Dustin Freeman, University of Toronto","Stephanie Santosa, University of Toronto","Fanny Chevalier, University of Toronto","Karan Singh, University of Toronto","Ravin Balakrishnan, University of Toronto"],"title":"LACES: Live Authoring through Compositing and Editing of Streaming Video","paperOrNote":"Paper","fullAbstract":"The task of video authoring typically consists of three main phases: pre-production planning, production video capture and post-production processing. The status quo is that these phases occur separately, and the latter two have a large amount of \"slack time\", where the camera operator is watching the scene unfold during capture, and the editor is re-watching and navigating through recorded footage during post-production. While this process is well suited to many forms of video, others such as casual videos of the sort often seen in online forums could benefit from some authoring or \"cleanup\" without the overhead or post-processing of current authoring tools. We introduce LACES, a tablet-based system that allows for simple video manipulations while filming a scene. Seamless in-situ integration of video capture and manipulation forms a novel workflow, enabling greater spontaneity and exploration in more casual forms of video creation.","shortAbstract":"The task of video authoring typically consists of three main phases: p","id":"pn1872"},"session":"Navigating Video","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1872"},"pn896":{"lastUpdateTime":1388780491676,"subcommitteeSplit":"","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Auditory I/O and Sound in the UI":{"dislikes":[],"lastTimeUpdated":1386531961483,"checked":true,"likes":[],"label":"Auditory I/O and Sound in the UI"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840691}},"creationTime":623,"content":{"authorList":["Mayank Goel, University of Washington","Brendan Lee, University of Washington","Md. Tanvir Islam Aumi, University of Washington","Lilian de Greef, University of Washington","Shwetak Patel, University of Washington","Gaetano Borriello, University of Washington","Stacie Hibino, Samsung Research America","Bo Begole, Samsun Research America"],"title":"SurfaceLink: Using Inertial and Acoustic Sensing to Enable Multi-Device Interaction on a Surface","paperOrNote":"Paper","fullAbstract":"We present SurfaceLink, a system where users can make natural surface gestures to control association and information transfer among a set of devices that are placed on a mutually shared surface (e.g., a table). SurfaceLink uses a combination of on-device accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device contact microphone for greater sensitivity) to sense gestures performed on the shared surface. In a controlled evaluation with 10 participants, SurfaceLink detected the presence of devices on the same surface with 97.7% accuracy, their placement and orientation with 89.4% accuracy, and various single- and multi-touch surface gestures with an average accuracy of 90.3%. A usability analysis of SurfaceLink-powered multi-device interaction techniques shows that SurfaceLink has advantages over current multi-device interaction techniques in a number of situations.","shortAbstract":"We present SurfaceLink, a system where users can make natural surface ","id":"pn896"},"session":"Touch: Multitouchy Feely","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn896"},"pn2372":{"lastUpdateTime":1388776467635,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531531674,"checked":true,"likes":["tomer@moscovich.net","olwal@mit.edu"],"label":"Touch Input"},"Pointing Techniques":{"dislikes":[],"lastTimeUpdated":1386532419443,"checked":true,"likes":[],"label":"Pointing Techniques"},"Selection Techniques":{"dislikes":[],"lastTimeUpdated":1386532413581,"checked":true,"likes":[],"label":"Selection Techniques"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"input":{"dislikes":[],"lastTimeUpdated":1386531929795,"checked":true,"likes":["tomer@moscovich.net"],"label":"input"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tangible UIs"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840724}},"creationTime":1902,"content":{"authorList":["Yuexing Luo, Department of Computer Science","Daniel Vogel, University of Waterloo"],"title":"Crossing-Based Selection with Direct Touch Input","paperOrNote":"Paper","fullAbstract":"Fundamental performance results for crossing-based selection tasks with direct touch input are presented. A close adaptation of Accot and Zhais indirect stylus crossing experiment reveals similar trends for direct touch input: touch crossing task time is faster or equivalent to touch pointing; continuous selection of large orthogonal crossing targets is most effective; and continuous selection of small collinear targets is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct touch pointing performance is modeled accurately with standard Fitts law. Instead, FFitts law, used previously for touch pointing with small targets, is used to more accurately model discrete touch crossing with a directional target. In addition, visual touch feedback is shown to have a strong effect on absolute accuracy. Our work serves to validate crossing performance for touch and demonstrates a new application of FFitts law to crossing. This new empirical evidence and theoretical results provide necessary support for crossing-based interaction techniques in direct touch interfaces.","shortAbstract":"Fundamental performance results for crossing-based selection tasks wit","id":"pn2372"},"session":"Touch: Touch","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2372"},"pn897":{"lastUpdateTime":1389238017883,"subcommitteeSplit":"A","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528477183,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Location Location Location":{"dislikes":[],"lastTimeUpdated":1386523324614,"checked":true,"likes":["sameer.patil@hiit.fi","lorrie@acm.org","paul.marshall@ucl.ac.uk","coye.cheshire@gmail.com","beverly_harrison@yahoo.com","dabbish@cmu.edu"],"label":"Location Location Location"},"Context-Aware Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525954782,"label":"Context-Aware Computing"},"Privacy":{"dislikes":[],"lastTimeUpdated":1386525947759,"checked":true,"likes":["sameer.patil@hiit.fi","lorrie@acm.org"],"label":"Privacy"},"privacy":{"checked":false,"lastUpdateTime":1386525942818,"dislikes":[],"label":"privacy","lastTimeUpdated":1386524675510,"likes":[]},"Experience Sampling":{"dislikes":[],"lastTimeUpdated":1386524146948,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Experience Sampling"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526669463,"label":"Social Computing and Social Navigation"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525953485,"label":"Computer Supported Cooperative Work (CSCW)"},"feedback":{"dislikes":[],"lastTimeUpdated":1386524684021,"checked":true,"likes":[],"label":"feedback"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946662}},"creationTime":624,"content":{"authorList":["Sameer Patil, ","Roman Schlegel, City University of Hong Kong","Apu Kapadia, Indiana University","Adam Lee, University of Pittsburgh"],"title":"Reflection or Action?: How Feedback and Control Affect Location Sharing Decisions","paperOrNote":"Paper","fullAbstract":"Owing to the ever expanding size of social and professional networks, it is becoming cumbersome for individuals to configure information disclosure settings. We use location sharing systems as a vehicle to unpack the nature of discrepancies between a person's disclosure settings and contextual desires. Specifically, we conducted an experience sampling study (N = 35) to examine various contextual factors that contribute to such divergence. We found that immediate feedback without any ability to control disclosure outcome can evoke feelings of oversharing. Moreover, deviation from specified settings does not always signal privacy violation; it is just as likely that settings prevent information disclosure that is considered permissible in situ. Our findings further motivate selective control when sharing location with socially distant recipients and when visiting atypical locations.","shortAbstract":"Owing to the ever expanding size of social and professional networks, ","id":"pn897"},"session":"People: Location Location Location","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn897"},"to126":{"lastUpdateTime":1389107824425,"subcommitteeSplit":"","labels":{"visualization":{"dislikes":[],"lastTimeUpdated":1386524267499,"checked":true,"likes":[],"label":"visualization"},"visualization composition":{"dislikes":[],"lastTimeUpdated":1386524469207,"checked":true,"likes":[],"label":"visualization composition"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386524454724,"checked":true,"likes":["dan@danielashbrook.com"],"label":"crowdsourcing"},"information visualization":{"dislikes":[],"lastTimeUpdated":1386524444027,"checked":true,"likes":[],"label":"information visualization"},"visual perception":{"dislikes":[],"lastTimeUpdated":1386524447288,"checked":true,"likes":[],"label":"visual perception"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527735978,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2063,"content":{"authorList":["Huahai Yang, IBM Almaden Research Center","Yunyao Li, IBM Almaden Research Center","Michelle Zhou, IBM Almaden Research Center"],"title":"Understand Users Comprehension and Preferences for Composing Information Visualizations","paperOrNote":"TOCHI","fullAbstract":"We are developing an automated visualization system that helps users combine two or more existing information graphics to form an integrated view. To establish empirical foundations for building such a system, we designed and conducted two studies on Amazon Mechanical Turk to understand users comprehension and preferences of composite visualization under different conditions (e.g., data and tasks). In Study 1, we collected over 1500 textual descriptions capturing about 500 participants insights of given information graphics, which resulted in a task-oriented taxonomy of visual insights. In Study 2, we asked 240 participants to rank composite visualizations by their suitability for acquiring a given visual insight identified in Study 1, which resulted in ranked user preferences of visual compositions for acquiring each type of insight. In this article, we report the details of our two studies, and discuss the broader implications of our crowdsourced research methodology and results to HCI-driven visualization research.","shortAbstract":"We are developing an automated visualization system that helps users c","id":"to126"},"session":"Viz: Studying Visualization","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to126"},"pn2216":{"lastUpdateTime":1389221479624,"subcommitteeSplit":"A","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386522788784,"checked":true,"likes":[],"label":"gestures"},"tabletop":{"dislikes":[],"lastTimeUpdated":1386523224271,"checked":true,"likes":[],"label":"tabletop"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386522780974,"checked":true,"likes":[],"label":"Gestural interaction"},"interactive surfaces":{"dislikes":[],"lastTimeUpdated":1386523244235,"checked":true,"likes":[],"label":"interactive surfaces"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711785}},"creationTime":1772,"content":{"authorList":["Consuelo Valdes, Wellesley College","Diana Eastman, Wellesley College","Casey Grote, Wellesley College","Shantanu Thatte, Louisiana State University","Orit Shaer, Wellesley College","Ali Mazalek, Georgia Institute of Technology","Brygg Ullmer, Louisiana State University","Miriam Konkel, Louisiana State University"],"title":"Exploring the Design Space of Gestural Interaction with Active Tokens through User-Defined Gestures","paperOrNote":"Paper","fullAbstract":"Multi-touch and tangible interfaces provide unique opportunities for enhancing learning and discovery with big data. However, existing interaction techniques have limitations when manipulating big data sets. Our goal is to define novel interaction techniques for multi-touch and tangible interfaces, which support the construction of complex queries for big data. In this paper, we present results from a study which investigates the use of gestural interaction with active tokens for manipulating large data sets. In particular, we studied user expectations of a hybrid tangible and gestural language engaging this space. Our main results include: a vocabulary of user-defined gestures for interaction with active tokens, which extends beyond familiar multitouch gestures; 2) characterization of the design space of gestural interaction with active tokens; and 3) insight into participants mental models including common metaphors. We also present implications for the design of multi-touch and tangible interfaces with active tokens. ","shortAbstract":"Multi-touch and tangible interfaces provide unique opportunities for e","id":"pn2216"},"session":"UIST: Gesture-based interaction","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2216"},"pn2214":{"lastUpdateTime":1389238866997,"subcommitteeSplit":"A","labels":{"Health Information Management":{"dislikes":[],"lastTimeUpdated":1386523755767,"checked":true,"likes":["mentis@umbc.edu"],"label":"Health Information Management"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Personal Informatics":{"dislikes":[],"lastTimeUpdated":1386523633230,"checked":true,"likes":[],"label":"Personal Informatics"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526705402,"label":"Empirical Methods, Qualitative"},"Quantified Health":{"dislikes":[],"lastTimeUpdated":1386523441314,"checked":true,"likes":[],"label":"Quantified Health"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188205}},"creationTime":1771,"content":{"authorList":["Eun Kyoung Choe, University of Washington","Nicole B. Lee, Microsoft","Bongshin Lee, Microsoft Research","Wanda Pratt, University of Washington","Julie A. Kientz, University of Washington"],"title":"Understanding Quantified-Selfers Practices in  Collecting and Exploring Personal Data","paperOrNote":"Paper","fullAbstract":"Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. However, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these extreme users, who have used existing technologies and built their own workarounds to overcome different types of barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand their practices in terms of what they did, how they did it, and what they learned. We high-light several common pitfalls, including tracking too many things, not tracking triggers and context, and lack of scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.","shortAbstract":"Researchers have studied how people use self-tracking technologies and","id":"pn2214"},"session":"Health: Quantified Self","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2214"},"pn2105":{"lastUpdateTime":1389591484139,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"dislikes":[],"lastTimeUpdated":1386522653527,"checked":true,"likes":[],"label":"Empirical Methods, Quantitative"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de","daverandall2008@gmail.com","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"eye tracking":{"checked":false,"lastUpdateTime":1386522686736,"dislikes":[],"label":"eye tracking","lastTimeUpdated":1386522597533,"likes":[]},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032773},"Tasks and Plans":{"label":"Tasks and Plans","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389105082440}},"creationTime":1672,"content":{"authorList":["Yunfeng Zhang, University of Oregon","Anthony Hornof, University of Oregon"],"title":"Understanding Multitasking Performance Through Strategy Exploration and Individualized Cognitive Modeling","paperOrNote":"Paper","fullAbstract":"Human multitasking often involves complex task interactions and subtle tradeoffs which may only be understood by detailed computational cognitive modeling. But traditional cognitive modeling studies often do not explore enough task strategies to reveal why people behave the way they do. This study proposes an automated, large- scale strategy exploration approach and presents a parallel modeling system to support the exploration. This study also dives into the realm of modeling individual performance. The results show that the traditional approach of modeling average human performance can lead to problematic conclusions and that the individualized modeling can help understand why certain task strategies are adopted by the participants.","shortAbstract":"Human multitasking often involves complex task interactions and subtle","id":"pn2105"},"session":"Methods and Models: User Model 2","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2105"},"pn2103":{"lastUpdateTime":1389236450714,"subcommitteeSplit":"B","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","jonfroehlich@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Software Engineering":{"dislikes":[],"lastTimeUpdated":1386521703752,"checked":true,"likes":[],"label":"Software Engineering"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446306}},"creationTime":1670,"content":{"authorList":["Roman Atachiants, Trinity College Dublin","David Gregg, Trinity College Dublin","Gavin Doherty, Trinity College Dublin"],"title":"Design Considerations for Parallel Performance Tools","paperOrNote":"Paper","fullAbstract":"In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the \\ design of software tools to support developers in the endeavour \\ of parallel programming.","shortAbstract":"In recent years there has been a shift in microprocessor manufacture f","id":"pn2103"},"session":"Systems: Development Tools","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2103"},"pn183":{"lastUpdateTime":1389222059201,"subcommitteeSplit":"","labels":{"EEG-based HCI":{"dislikes":[],"lastTimeUpdated":1386525586268,"checked":true,"likes":[],"label":"EEG-based HCI"},"NIRS":{"dislikes":[],"lastTimeUpdated":1386525605180,"checked":true,"likes":[],"label":"NIRS"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"passive BCI":{"dislikes":[],"lastTimeUpdated":1386525440720,"checked":true,"likes":["tzander@gmail.com","wolfgang@cse.yorku.ca","bulling@mpi-inf.mpg.de"],"label":"passive BCI"},"(passive) Brain-Computer Interfaces":{"dislikes":[],"lastTimeUpdated":1386525399334,"checked":true,"likes":["bickmore@ccs.neu.edu"],"label":"(passive) Brain-Computer Interfaces"},"fNIRS":{"dislikes":[],"lastTimeUpdated":1386525487153,"checked":true,"likes":[],"label":"fNIRS"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644717}},"creationTime":58,"content":{"authorList":["Matthew Pike, Nottingham University","Horia Maior, University of Nottingham","Martin Porcheron, University of Nottingham","Sarah Sharples, University of Nottingham","Max Wilson, University of Nottingham"],"title":"TAPping into Cognition: Measuring the Effects of Think Aloud Protocols on Human Cognition using fNIRS","paperOrNote":"Paper","fullAbstract":"Functional Near-Infrared Spectroscopy (fNIRS) offers the potential to provide continuous, detailed insight into brain activity, enabling an objective view of the cognitive processes during complex tasks, whilst in more natural HCI conditions compared to other brain sensing techniques like fMRI and EEG. Little work has been done, however, to identify the effect that participant verbalisations (including verbal protocols) or increasing task complexity has on fNIRS data. Such work is essential if fNIRS is to be applied to ecologically valid tasks. For these reasons, we have investigated the effects on fNIRS data produced by: nonsense verbalisations, passive concurrent think aloud protocol, and invasive concurrent think aloud protocol, in the context of both subjective \\ responses and performance measures during a complex task. Our results provide novel insights into the effect that different forms of verbalisation have on mental workload during tasks, and show that fNIRS, as an objective measure, is more sensitive to demonstrating these differences than subjective and reflective measures often used in studies. Our findings are a step towards our goal of proactively involving fNIRS analysis in ecologically valid user studies of Human-Computer Interaction.","shortAbstract":"Functional Near-Infrared Spectroscopy (fNIRS) offers the potential to ","id":"pn183"},"session":"UIST: Read My Mind: Passive BCI","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn183"},"pn1617":{"lastUpdateTime":1389236916221,"subcommitteeSplit":"B","labels":{"Family":{"dislikes":[],"lastTimeUpdated":1386522238257,"checked":true,"likes":[],"label":"Family"},"Intergenerational Communication":{"dislikes":[],"lastTimeUpdated":1386521927562,"checked":true,"likes":[],"label":"Intergenerational Communication"},"ExtendedFamily":{"dislikes":[],"lastTimeUpdated":1386521713907,"checked":true,"likes":[],"label":"ExtendedFamily"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["rob.comber@ncl.ac.uk","egelman@cs.berkeley.edu","jonfroehlich@gmail.com","hazas@comp.lancs.ac.uk"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Home":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","a.sasse@cs.ucl.ac.uk","jonfroehlich@gmail.com"],"lastUpdateTime":123456789,"label":"Home"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446274}},"creationTime":1248,"content":{"authorList":["Azadeh Forghani, Simon Fraser University","Carman Neustaedter, Simon Fraser University"],"title":"The Routines and Needs of Grandparents and Parents for Grandparent-Grandchild Conversations Over Distance","paperOrNote":"Paper","fullAbstract":"A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet despite this, there are few studies of the actual conversational routines and needs of these groups. To address this, we have conducted an interview and diary study that explores the conversational practices and needs of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe how grandparent-grandchild conversations tend to focus on learning, unexpected stuff, storytelling, sharing experiences, and cultural exchanges. We also show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildrens lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.","shortAbstract":"A variety of systems have been designed to support communication betwe","id":"pn1617"},"session":"HCI4D: Family 2.0","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1617"},"pn1727":{"lastUpdateTime":1389221950963,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"social computing":{"dislikes":[],"lastTimeUpdated":1386524065372,"checked":true,"likes":["emailaddress"],"label":"social computing"},"communication":{"dislikes":[],"lastTimeUpdated":1386523887183,"checked":true,"likes":[],"label":"communication"},"Virtual Reality":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Reality"},"avatars":{"dislikes":[],"lastTimeUpdated":1386523100974,"checked":true,"likes":[],"label":"avatars"},"Models of trust":{"dislikes":[],"lastTimeUpdated":1386523456118,"checked":true,"likes":[],"label":"Models of trust"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522456993,"label":"Computer-Mediated Communication"},"spherical displays":{"dislikes":[],"lastTimeUpdated":1386523098679,"checked":true,"likes":[],"label":"spherical displays"},"Trust":{"dislikes":[],"lastTimeUpdated":1386523089100,"checked":true,"likes":[],"label":"Trust"},"display technology":{"dislikes":[],"lastTimeUpdated":1386523961461,"checked":true,"likes":[],"label":"display technology"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522451464,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556768}},"creationTime":1344,"content":{"authorList":["Ye Pan, University College London","William Steptoe, University College London","Anthony Steed, University College London"],"title":"Comparing Flat and Spherical Displays in a Trust Scenario in Avatar-Mediated Interaction","paperOrNote":"Paper","fullAbstract":"We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. Our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between trustworthy and un-trustworthy advice than if they observe the avatar face on. We then introduce a novel spherical display and a ray-traced rendering that can display an avatar that can be seen correctly for any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non- verbal cues, particularly gaze and deixis, because it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate trustworthy advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiment demonstrate how trust can be altered depending on how one views the avatar.","shortAbstract":"We report on two experiments that investigate the influence of display","id":"pn1727"},"session":"UIST: On the surface","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1727"},"pn1724":{"lastUpdateTime":1389238893968,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528681213,"checked":true,"likes":[],"label":"usable privacy and security"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526581577,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"Home":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Home"},"Security":{"checked":true,"dislikes":[],"likes":["ajbrush@microsoft.com","a.sasse@cs.ucl.ac.uk","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Security"},"User Studies":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446285}},"creationTime":1342,"content":{"authorList":["Kami Vaniea, Michigan State University","Emilee Rader, Michigan State University","Rick Wash, Michigan State University"],"title":"Betrayed By Updates: How Negative Experiences Affect Future Security","paperOrNote":"Note","fullAbstract":"Installing security-relevant software updates is one of the best computer protection mechanisms. However, users do not always choose to install updates. Through interviewing non-expert Windows users, we found that users frequently decide not to install future updates, regardless of whether they are important for security, after negative experiences with past updates. This means that even non-security updates (such as user interface changes) can impact the security of a computer.  This update behavior is becoming increasingly important as devices move toward an ``app'' model for software distribution and updates. \\  \\  ","shortAbstract":"Installing security-relevant software updates is one of the best compu","id":"pn1724"},"session":"Security: Security","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1724"},"pn1722":{"lastUpdateTime":1387316165041,"subcommitteeSplit":"","labels":{"Human-robot interaction":{"dislikes":[],"lastTimeUpdated":1386532036400,"checked":true,"likes":[],"label":"Human-robot interaction"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532065767,"label":"Empirical Methods, Quantitative"},"Multi-modal interfaces":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532020684,"label":"Multi-modal interfaces"},"Robots":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Robots"},"gestures":{"dislikes":[],"lastTimeUpdated":1386526973871,"checked":true,"likes":["judy.kay@gmail.com"],"label":"gestures"},"Animation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386532073617,"label":"Animation"},"Human-Robot Interaction":{"dislikes":[],"lastTimeUpdated":1386532047653,"checked":true,"likes":[],"label":"Human-Robot Interaction"},"Gestural Interaction":{"checked":false,"lastUpdateTime":1386530321237,"dislikes":[],"label":"Gestural Interaction","lastTimeUpdated":1386528424342,"likes":[]},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386528414901,"checked":true,"likes":["judy.kay@gmail.com"],"label":"Gestural interaction"},"Gesture":{"checked":false,"lastUpdateTime":1386531521939,"dislikes":[],"label":"Gesture","lastTimeUpdated":1386528900590,"likes":["marcodesa@gmail.com","judy.kay@gmail.com"]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165041}},"creationTime":1340,"content":{"authorList":["Manja Lohse, Human Media Interaction, University of Twente","Reinier Rothuis, Human Media Interaction, University of Twente","Jorge Gallego-Perez, University of Twente","Daphne Karreman, University of Twente.","Vanessa Evers, University of Twente"],"title":"Robot Gestures Make Difficult Tasks Easier: the Impact of Gestures on Perceived Workload and Task Performance","paperOrNote":"Paper","fullAbstract":"Gestures are important non-verbal signals in human communication. With the development of virtual agents and robots that are able to produce gestures, they have also entered the field of human-computer interaction. This paper investigates the influence of robot gestures on the users' task performance and perceived workload in a direction-giving task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult task) experiment.  \\ The results indicate that robot gestures increased user performance and decreased perceived workload in the difficult task but not in the easy task. Thus, robot gestures are a promising means to improve human-robot interaction particularly in challenging tasks.","shortAbstract":"Gestures are important non-verbal signals in human communication. With","id":"pn1722"},"session":"Human-Robot Interaction","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1722"},"pn1269":{"lastUpdateTime":1389592013048,"subcommitteeSplit":"","labels":{"Multimedia UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531926217,"label":"Multimedia UIs"},"User Generated Content":{"dislikes":[],"lastTimeUpdated":1386526826861,"checked":true,"likes":[],"label":"User Generated Content"},"User Studies":{"checked":false,"lastUpdateTime":1386531921147,"dislikes":[],"label":"User Studies","lastTimeUpdated":1386528647047,"likes":["marcodesa@gmail.com"]},"public displays":{"dislikes":[],"lastTimeUpdated":1386529116969,"checked":true,"likes":[],"label":"public displays"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165015}},"creationTime":949,"content":{"authorList":["Miriam Greis, University of Stuttgart","Florian Alt, University of Munich","Niels Henze, University of Stuttgart","Nemanja Memarovic, Universita della Svizzera Italiana"],"title":"I Can Wait a Minute: Uncovering the Optimal Delay Time for Pre-Moderated User-Generated Content on Public Displays","paperOrNote":"Note","fullAbstract":"In recent years public displays have been advanced from isolated and non interactive ``ad'' displays which show Powerpoint slides and images to displays that are networked, interactive and open to a wide variety of content and applications. Prior work has shown large potential of user-generated content on public displays. However, one of the problems with user-generated content on public displays is moderation. Content may be explicit or troublesome for a particular location or may not comply with the display owners' ideas of what should be displayed. In this work we explore the expectations of users with regard to content moderation on public displays. An online survey shows that people consider a delay of up to 10 minutes acceptable if they know that content gets moderated. In a subsequent in the wild deployment we compared different moderation delays. We found that a moderation delay significantly decreases the number of user-generated posts while at the same time there is no significant effect on users' decision to repeatedly post on the display. \\ ","shortAbstract":"In recent years public displays have been advanced from isolated and n","id":"pn1269"},"session":"Displays: Interactive Whitebaords and Public Displays","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1269"},"pn1268":{"lastUpdateTime":1389236351048,"subcommitteeSplit":"B","labels":{"Internationalization / Localization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522866883,"label":"Internationalization / Localization"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755924}},"creationTime":948,"content":{"authorList":["Huatong Sun, University of Washington Tacoma","William F. Hart-Davidson, Michigan State University"],"title":"Text-only web versions put me sitting in the back of the bus: Binding the material and the discursive with a relational approach of affordances","paperOrNote":"Paper","fullAbstract":"As Normans vision of affordances developed 25 years ago is unable to address complex challenges faced by todays designers, we outline a view of affordances as discursive relations in HCI design. This argument is framed in the discussion of a larger trend of work beyond the HCI field, the scholarship on relational affordances from the fields of communication and organization studies. Through comparison and interrogation, we maintain a relational approach of affordances that bind the material and the discursive will help us to address design issues such as discursive power, cultural values, performed identities, mediated agency, and articulated voices in this increasingly globalized world and design culturally sensitive technology for transformation and emancipation.  With a few cases, this paper deciphers the hidden power relationship of interaction design and suggests ways of we should design for social affordances.","shortAbstract":"As Normans vision of affordances developed 25 years ago is unable t","id":"pn1268"},"session":"Design: Design Theory","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1268"},"pn1262":{"lastUpdateTime":1388776618754,"subcommitteeSplit":"A","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr","scott.davidoff@jpl.nasa.gov"],"lastUpdateTime":123456789,"label":"Prototyping"},"New Prototyping Methods":{"dislikes":[],"lastTimeUpdated":1386523664307,"checked":true,"likes":[],"label":"New Prototyping Methods"},"Stereoscopic 3D (S3D)":{"dislikes":[],"lastTimeUpdated":1386523160130,"checked":true,"likes":[],"label":"Stereoscopic 3D (S3D)"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Stereoscopic":{"dislikes":[],"lastTimeUpdated":1386523172305,"checked":true,"likes":[],"label":"Stereoscopic"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711803}},"creationTime":942,"content":{"authorList":["Nora Broy, BMW Research and Technology","Stefan Schneegass, University of Stuttgart","Florian Alt, University of Munich","Albrecht Schmidt, University of Stuttgart"],"title":"FrameBox and MirrorBox: Tools for Prototyping User Interfaces for 3D Displays","paperOrNote":"Paper","fullAbstract":"In this paper, we describe the design and development of MirrorBox and FrameBox  two user interface (UI) prototyping tools for stereoscopic 3D (S3D) displays. As auto-stereoscopy (glasses-free 3D) becomes available for the mass market we believe the design of 3D UIs for devices, such as mobile phones, public displays, or car dashboards will gain importance at a rapidly accelerating pace. A benefit of such interfaces is that they can group and structure information in a way that makes them easily perceivable for the user, for example, by showing important information further to the front then currently less important information. This paper first explores core requirements for designing S3D UIs. Based on these requirements we then built two prototyping tools with the aim to overcome limitations of traditional paper prototyping when it comes to sketching the S3D UI. We evaluated the prototypes with usability experts from different fields and compared them to traditional paper prototyping.","shortAbstract":"In this paper, we describe the design and development of MirrorBox and","id":"pn1262"},"session":"3D: 3D modeling","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1262"},"pn1264":{"lastUpdateTime":1389221922387,"subcommitteeSplit":"C","labels":{"Older adults":{"checked":false,"lastUpdateTime":1386526616745,"dislikes":[],"label":"Older adults","lastTimeUpdated":1386526208935,"likes":[]},"social impact":{"checked":true,"lastUpdateTime":1386527533262,"dislikes":[],"label":"social impact","lastTimeUpdated":1386526808577,"likes":[]},"Older Adults":{"checked":false,"lastUpdateTime":1386527131854,"dislikes":[],"label":"Older Adults","lastTimeUpdated":1386526529907,"likes":["kgajos@eecs.harvard.edu","mtory@cs.uvic.ca"]},"Participatory Design":{"checked":false,"lastUpdateTime":1386527469862,"dislikes":[],"label":"Participatory Design","lastTimeUpdated":1386527271480,"likes":[]},"Elderly":{"checked":false,"lastUpdateTime":1386526625222,"dislikes":[],"label":"Elderly","lastTimeUpdated":1386526266908,"likes":[]},"Technology use in under-represented populations":{"dislikes":[],"lastTimeUpdated":1386536571244,"checked":true,"likes":["vlh@acm.org"],"label":"Technology use in under-represented populations"},"Creativity Support Tools":{"dislikes":[],"lastTimeUpdated":1386526655975,"checked":true,"likes":["maria.wolters@ed.ac.uk"],"label":"Creativity Support Tools"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527138359,"label":"Empirical Methods, Qualitative"},"innovation":{"checked":false,"lastUpdateTime":1386527333508,"dislikes":[],"label":"innovation","lastTimeUpdated":1386526502918,"likes":[]},"stigma":{"checked":false,"lastUpdateTime":1386527688911,"dislikes":[],"label":"stigma","lastTimeUpdated":1386526730872,"likes":[]},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527210083,"label":"User Experience Design / Experience Design"},"Participatory Design / Cooperative Design":{"checked":false,"dislikes":[],"likes":["bpbailey@illinois.edu","kash@diku.dk"],"lastUpdateTime":1386527436645,"label":"Participatory Design / Cooperative Design"},"diy":{"dislikes":[],"lastTimeUpdated":1386527874347,"checked":true,"likes":[],"label":"diy"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486615}},"creationTime":944,"content":{"authorList":["Yvonne Rogers, University College London","Jeni Paay, Aalborg University","Margot Brereton, Queensland University of Technology","Kate Vaisutis, Queensland University of Technology","Gary Marsden, Department of Computer Science, University of Cape Town","Frank Vetere, The University of Melbourne"],"title":"Never Too Old: Engaging Retired People Inventing The Future With MaKey MaKey","paperOrNote":"Paper","fullAbstract":"Within HCI, aging is often viewed in terms of designing assistive technologies to improve the lives of older people, such as those who are suffering from frailty or memory loss. Our research adopts a very different approach, reframing the relationship in terms of wisdom, creativity and invention. We ran a series of workshops where groups of retirees, aged from 60-90, used the MaKey MaKey inventors toolkit. We asked them to think about inventing the future and suggest ideas for new technologies. Our findings showed that they not only rose to the challenge but also mastered the technology, collaborated intensely together whilst using it and freely and at length discussed their own, their familys and others relationship with technology. We discuss the value of empowering people in this way and consider what else could be invented to enable more people to be involved in the design and use of creative technologies.","shortAbstract":"Within HCI, aging is often viewed in terms of designing assistive tech","id":"pn1264"},"session":"Health: Older Adults 2","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1264"},"pn505":{"lastUpdateTime":1389590860045,"subcommitteeSplit":"A","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":["jws@microsoft.com"],"lastUpdateTime":123456789,"label":"Prototyping"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081853},"Energy":{"label":"Energy","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389103649885},"Wearable computing":{"label":"Wearable computing","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389103719566}},"creationTime":305,"content":{"authorList":["Jussi Mikkonen, Aalto University","Ramyah Gowrishankar, Aalto University","Miia Oksanen, Aalto University","Harri Raittinen, iCraft Oy","Arto Kolinummi, iCraft Oy"],"title":"OJAS - Open Source Bi-Directional Inductive Power Link","paperOrNote":"Paper","fullAbstract":"We present the design, development and evaluation of a bi-directional inductive power transfer circuit for prototyping purposes in the watt-range. Our device doesn't require any configuration and is intended for the development of wearable and tangible systems. Currently all small-scale watt-range inductive links are directed, supplying the power from the transmitter to the receiver. Our approach allows a bi-directional power flow without any change in the circuit, such that the same circuit can be used for charging and discharging a battery. The contribution of this work is an enabling technology for researchers and practitioners in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction interested in exploring new interactions powered by watt-range inductive links. It enables smaller battery sizes, and therefore lighter devices, as the power can be distributed in a way that has not been feasible before. We discuss the motivations, technical details, and the workshop evaluating our inductive approach.","shortAbstract":"We present the design, development and evaluation of a bi-directional ","id":"pn505"},"session":"UBI: Battery Life","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn505"},"pn1460":{"lastUpdateTime":1389222136220,"subcommitteeSplit":"A","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Visualization"},"Crowd-Powered Systems":{"checked":false,"lastUpdateTime":1386524169211,"dislikes":[],"label":"Crowd-Powered Systems","lastTimeUpdated":1386524066998,"likes":[]},"HCI and Journalism":{"dislikes":[],"lastTimeUpdated":1386523673148,"checked":true,"likes":[],"label":"HCI and Journalism"},"maps":{"dislikes":[],"lastTimeUpdated":1386524890360,"checked":true,"likes":[],"label":"maps"},"User Interface Engineering":{"checked":false,"lastUpdateTime":1386524022954,"dislikes":[],"label":"User Interface Engineering","lastTimeUpdated":1386523835271,"likes":[]},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"geography":{"dislikes":[],"lastTimeUpdated":1386524845952,"checked":true,"likes":[],"label":"geography"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081826}},"creationTime":1119,"content":{"authorList":["Tong Gao, University of Michigan","Jessica Hullman, University of Michigan School of Information","Eytan Adar, University of Michigan","Brent Hecht, University of Minnesota","Nicholas Diakopoulos, Columbia University"],"title":"NewsViews: An Automated Pipeline for Creating Custom Geovisualizations for News","paperOrNote":"Paper","fullAbstract":"Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. When based on data and annotated with text explanations, maps support a deeper understanding of local and regional trends relevant to an article. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of found databases, and techniques adapted from cartography to identify and create visually interesting thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, interestingness of representation and annotation quality). ","shortAbstract":"Interactive visualizations add rich, data-based context to online news","id":"pn1460"},"session":"Social: Social News","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn1460"},"pn1583":{"lastUpdateTime":1389221416620,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532162111,"checked":true,"likes":[],"label":"Touch Input"},"Tactile and Haptic UIs":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531713950,"label":"Tactile and Haptic UIs"},"Haptics":{"dislikes":[],"lastTimeUpdated":1386531708840,"checked":true,"likes":["eve.hoggan@hiit.fi","tomer@moscovich.net"],"label":"Haptics"},"Virtual Reality":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Reality"},"Selection Techniques":{"dislikes":[],"lastTimeUpdated":1386532148094,"checked":true,"likes":[],"label":"Selection Techniques"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840704}},"creationTime":1225,"content":{"authorList":["Taku Hachisu, University of Electro-Communications","masaaki fukumoto, Microsoft Research"],"title":"VacuumTouch: Attractive Force Feedback Interface for Haptic Interactive Surface using Air Suction","paperOrNote":"Paper","fullAbstract":"We present VacuumTouch, a novel haptic interface architecture for the touch screens that provides attractive force feedback to the users finger. VacuumTouch consists of an air pump and solenoid air valves that connect to the surface of the touch screen and suck the air above the surface where the users finger makes contact. VacuumTouch does not require the user to hold or attach additional devices to provide the attractive force, which allows for easy interaction with the surface. This work introduces the implementation of the VacuumTouch architecture and some applications for enhancement of the graphical user interface, namely a suction button, a suction slider, and a suction dial. The quantitative evaluation was conducted with the suction dial and showed that the attractive force provided by VacuumTouch improved the performance of the dial menu interface and its potential effects. At the end of the paper, we discuss the current prototypes advantages and limitations with possible improvements and potential capabilities.","shortAbstract":"We present VacuumTouch, a novel haptic interface architecture for the ","id":"pn1583"},"session":"UIST: Force Input","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1583"},"pn728":{"lastUpdateTime":1389222073366,"subcommitteeSplit":"","labels":{"far-out interaction styles":{"dislikes":[],"lastTimeUpdated":1386525334408,"checked":true,"likes":["no@spam.org","benko@microsoft.com","elm@purdue.edu","bickmore@ccs.neu.edu"],"label":"far-out interaction styles"},"Smell":{"dislikes":[],"lastTimeUpdated":1386525418266,"checked":true,"likes":[],"label":"Smell"},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["sriramable@gmail.com"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"multisensory interaction":{"dislikes":[],"lastTimeUpdated":1386525799337,"checked":true,"likes":[],"label":"multisensory interaction"},"heck frickin' yeah":{"dislikes":[],"lastTimeUpdated":1386525385180,"checked":true,"likes":["davidmcgookin@gmail.com","no@spam.org","benko@microsoft.com","elm@purdue.edu","aquigley@st-andrews.ac.uk"],"label":"heck frickin' yeah"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644761}},"creationTime":480,"content":{"authorList":["Sue Ann Seah, University of Bristol","Diego Martinez Plasencia, University of Bristol","Peter Bennett, University of Bristol","Abhijit Karnik, University of Bristol","Vlad Otrocol, University of Bristol","Jarrod Knibbe, University of Bristol","Andy Cockburn, University of Canterbury","Sriram Subramanian, University of Bristol"],"title":"SensaBubble: A Chrono-Sensory Mid-Air Display of Sight and Smell","paperOrNote":"Paper","fullAbstract":"We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until the bubble bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubbles design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts  from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.","shortAbstract":"We present SensaBubble, a chrono-sensory mid-air display system ","id":"pn728"},"session":"UIST: sensible sensory","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn728"},"pn438":{"lastUpdateTime":1389221756152,"subcommitteeSplit":"","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":["wolfgang@cse.yorku.ca","steimle@media.mit.edu","petra.isenberg@inria.fr","S.fairclough@ljmu.ac.uk","bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"ultrasonic haptics":{"dislikes":[],"lastTimeUpdated":1386525877472,"checked":true,"likes":[],"label":"ultrasonic haptics"},"heck frickin' yeah":{"dislikes":[],"lastTimeUpdated":1386526323967,"checked":true,"likes":["davidmcgookin@gmail.com"],"label":"heck frickin' yeah"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525813470,"label":"User Interface Design"},"Multi-modal interfaces":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526346871,"label":"Multi-modal interfaces"},"Interaction Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526343805,"label":"Interaction Design"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644757}},"creationTime":256,"content":{"authorList":["Graham Wilson, University of Glasgow","Thomas Carter, University of Bristol","Sriram Subramanian, University of Bristol","Stephen Brewster, University of Glasgow"],"title":"Perception of Ultrasonic Haptic Feedback on the Hand: Localisation and Apparent Motion","paperOrNote":"Paper","fullAbstract":"Ultrasonic haptic feedback is a promising means of providing tactile sensations in mid-air, without encumbering the user with an actuator. However, controlled and rigorous HCI research is needed to understand the basic characteristics of perception of this new feedback medium, and so how best to utilize ultrasonic haptics in an interface. This paper describes two experiments conducted into two fundamental aspects of tactile perception: 1) localisation of a static point and 2) the perception of motion. Understanding these would provide insight into 1) the spatial resolution for an interface and 2) what forms of feedback are needed to give the most convincing illusion of movement. The results showed that detection rates were good with an average localisation error of 8.5mm. Convincing sensations of movement were reliably produced when travelling longer distances, using longer stimulus durations and stimulating multiple points along the trajectory. Guidelines for feedback design are given.","shortAbstract":"Ultrasonic haptic feedback is a promising means of providing tactile s","id":"pn438"},"session":"UIST: Motion and Haptics","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn438"},"pn345":{"lastUpdateTime":1389238200057,"subcommitteeSplit":"A","labels":{"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Personal Informatics":{"dislikes":[],"lastTimeUpdated":1386523728203,"checked":true,"likes":[],"label":"Personal Informatics"},"email overload":{"dislikes":[],"lastTimeUpdated":1386524652965,"checked":true,"likes":[],"label":"email overload"},"replication":{"dislikes":[],"lastTimeUpdated":1386523700328,"checked":true,"likes":["dabbish@cmu.edu"],"label":"replication"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524538893,"label":"Empirical Methods, Qualitative"},"repliCHI":{"dislikes":[],"lastTimeUpdated":1386525654366,"checked":true,"likes":["dabbish@cmu.edu","dgergle@northwestern.edu"],"label":"repliCHI"},"information overload":{"dislikes":[],"lastTimeUpdated":1386523713601,"checked":true,"likes":[],"label":"information overload"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"email":{"dislikes":[],"lastTimeUpdated":1386531277118,"checked":true,"likes":[],"label":"email"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946636}},"creationTime":175,"content":{"authorList":["Catherine Grevet, Georgia Institute of Technology","David Choi, Google, Inc.","Debra Lauterbach, Google","Eric Gilbert, Georgia Institute of Technology"],"title":"Overload is Overloaded: Email in the Age of Gmail","paperOrNote":"Paper","fullAbstract":"The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Googles Gmail. We found that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) an update of the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research. ","shortAbstract":"The term email overload has two definitions: receiving a large volume ","id":"pn345"},"session":"People: constant connectivity","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn345"},"pn657":{"lastUpdateTime":1389238696698,"subcommitteeSplit":"A","labels":{"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Wikipedia":{"dislikes":[],"lastTimeUpdated":1386523789073,"checked":true,"likes":[],"label":"Wikipedia"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"The Road Ahead":{"dislikes":[],"lastTimeUpdated":1386526085154,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Road Ahead"},"assessability":{"dislikes":[],"lastTimeUpdated":1386523782813,"checked":true,"likes":[],"label":"assessability"},"information literacy":{"dislikes":[],"lastTimeUpdated":1386523809022,"checked":true,"likes":[],"label":"information literacy"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524565002,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946731}},"creationTime":426,"content":{"authorList":["Andrea Forte, Drexel University","Nazanin Andalibi, Drexel University","Thomas Park, Drexel University","Heather Willever-Farr, Drexel University"],"title":"Designing Information Savvy Societies: An Introduction to Assessability","paperOrNote":"Paper","fullAbstract":"This paper establishes an empirically grounded design vocabulary for assessable design as an HCI response to the global need for better information literacy skills. We present a framework for synthesizing literatures called the Interdisciplinary Literacy Framework and use it to highlight gaps in our understanding of information literacy that HCI as a field is particularly well suited to fill. We then report on two studies that lay a foundation for developing guidelines for assessable information system design. The first is an interview study of Wikipedians, librarians, and laypersons information assessment practices from which we derive two important features of assessable designs: information provenance and stewardship. The second is an experimental study in which we operationalize these concepts in designs and test them using Amazon Mechanical Turk.","shortAbstract":"This paper establishes an empirically grounded design vocabulary for a","id":"pn657"},"session":"HCI4D: PolitiCHI","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn657"},"pn654":{"lastUpdateTime":1389591844450,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":["j.d.hook@ncl.ac.uk","tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"User Studies"},"Augmented Reality":{"dislikes":[],"lastTimeUpdated":1386532398846,"checked":true,"likes":[],"label":"Augmented Reality"},"Peepholes":{"dislikes":[],"lastTimeUpdated":1386531794188,"checked":true,"likes":[],"label":"Peepholes"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840543}},"creationTime":423,"content":{"authorList":["Roman Rdle, University of Konstanz","Hans-Christian Jetter, University College London","Jens Mller, University of Konstanz","Harald Reiterer, University of Konstanz"],"title":"Bigger is not always better: Display Size, Performance, and Task Load during Peephole Map Navigation","paperOrNote":"Paper","fullAbstract":"Dynamic peephole navigation is an increasingly popular technique for navigating large information spaces such as maps. Thereby users can view the map through handheld, spatially aware displays that serve as peepholes and they can navigate it by moving the displays in physical space. We conducted a controlled experiment of peephole map navigation with 16 participants to understand what effect the peephole size has on users navigation performance and task load. Using four different sizes from 4 (smartphone) up to 120 (control condition), we found that greater peepholes significantly improve learning speed, navigation speed, and reduce task load. However, this added benefit diminishes with growing sizes which lets us recommend a tablet-sized peephole of 10.6 as the best tradeoff between performance, task load, size, and constraints of real-world scenarios.","shortAbstract":"Dynamic peephole navigation is an increasingly popular technique for n","id":"pn654"},"session":"Displays: Novel Mobile Displays (UIST)","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn654"},"pn653":{"lastUpdateTime":1389221709637,"subcommitteeSplit":"","labels":{"social media":{"dislikes":[],"lastTimeUpdated":1386521637711,"checked":true,"likes":[],"label":"social media"},"television":{"dislikes":[],"lastTimeUpdated":1386522158397,"checked":true,"likes":[],"label":"television"},"Video Content / Communications":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523518855,"label":"Video Content / Communications"},"Twitter":{"dislikes":[],"lastTimeUpdated":1386523387832,"checked":true,"likes":["jacovi@il.ibm.com"],"label":"Twitter"},"live casting":{"dislikes":[],"lastTimeUpdated":1386523080427,"checked":true,"likes":[],"label":"live casting"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523515463,"label":"Computer-Mediated Communication"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523517337,"label":"Social Computing and Social Navigation"},"Social TV":{"dislikes":[],"lastTimeUpdated":1386522182832,"checked":true,"likes":[],"label":"Social TV"},"User Studies":{"checked":false,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":1386523514436,"label":"User Studies"},"events":{"dislikes":[],"lastTimeUpdated":1386521758076,"checked":true,"likes":[],"label":"events"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556700}},"creationTime":422,"content":{"authorList":["Steven Schirra, Massachusetts Institute of Technology","Huan Sun, MIT","Frank Bentley, Massachusetts Institute of Technology"],"title":"Together Alone: Motivations for Live-Tweeting a Television Series","paperOrNote":"Paper","fullAbstract":"In this paper, we explore motivations for live-tweeting across a season of a television show. Using the third season of Downton Abbey as a case study, we followed 2,234 live- tweeters from the show's premiere episode to its finale, finding that nearly a third of users returned each week to tweet. Semi-structured interviews with 11 diverse live- tweeters revealed that the decision to live-tweet is dependent upon a variety of personal considerations and social conventions forming around this emerging TV viewing practice. This includes the desire to feel connected to a larger community that is interested in the show. Participants actively sought to protect the user experience of others by following good live-tweeting etiquette, including limiting their number of posts and censoring content that might spoil the show for others. Over time, live-tweeting helped users build and maintain a network of fellow Downton Abbey viewers with shared interests.","shortAbstract":"In this paper, we explore motivations for live-tweeting across a seaso","id":"pn653"},"session":"Social: Lonely, Sad and Awful","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn653"},"pn650":{"lastUpdateTime":1389221780441,"subcommitteeSplit":"","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"E-Commerce":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"E-Commerce"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Interactive Machine Learning":{"dislikes":[],"lastTimeUpdated":1386524386634,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Interactive Machine Learning"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081895}},"creationTime":419,"content":{"authorList":["Benedikt Loepp, University of Duisburg-Essen","Tim Hussein, University of Duisburg-Essen","Juergen Ziegler, University of Duisburg-Essen"],"title":"Choice-Based Preference Elicitation for Collaborative Filtering Recommender Systems","paperOrNote":"Paper","fullAbstract":"We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations. \\  \\ In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems. ","shortAbstract":"We present an approach to interactive recommending that combines the a","id":"pn650"},"session":"Systems: Machines Interactively Learning","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn650"},"pn1046":{"lastUpdateTime":1389221416620,"subcommitteeSplit":"","labels":{"Touch input":{"checked":false,"lastUpdateTime":1386532073942,"dislikes":[],"label":"Touch input","lastTimeUpdated":1386531829685,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Haptics":{"dislikes":[],"lastTimeUpdated":1386531522604,"checked":true,"likes":["eve.hoggan@hiit.fi"],"label":"Haptics"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386531749449,"checked":true,"likes":["yangli@acm.org"],"label":"Gestural interaction"},"pressure interaction":{"dislikes":[],"lastTimeUpdated":1386531837118,"checked":true,"likes":[],"label":"pressure interaction"},"Multi-touch":{"dislikes":[],"lastTimeUpdated":1386532494457,"checked":true,"likes":[],"label":"Multi-touch"},"Pressure":{"checked":false,"lastUpdateTime":1386531840555,"dislikes":[],"label":"Pressure","lastTimeUpdated":1386531834750,"likes":[]},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532071951,"checked":true,"likes":[],"label":"Touch Input"},"Gestural Interaction":{"checked":false,"lastUpdateTime":1386531752033,"dislikes":[],"label":"Gestural Interaction","lastTimeUpdated":1386531607205,"likes":[]},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531582830,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840668}},"creationTime":748,"content":{"authorList":["Christian Rendl, University of Applied Sciences Upper Austria","Patrick Greindl, University of Applied Sciences Upper Austria","Martin Behrens, University of Applied Sciences Upper Austria","Michael Haller, University of Applied Sciences Upper Austria"],"title":"Presstures: Exploring Pressure-Sensitive Multi-Touch Gestures on Trackpads","paperOrNote":"Note","fullAbstract":"In this paper, we present Presstures, a concept that introduces pressure-sensitive multi-touch gestures for trackpads that use the initial pressure of the gesture for implicit mode switching. Our approach does not require any visual feedback and can be globally embedded on an operating system level. To evaluate the feasibility of our concept, we conducted an experiment, which proves that users are able to distinguish up to three pressure levels without feedback. Moreover, our results show that users are able to initiate multi-touch gestures with a specific pressure level. Based on that, we give recommendations for the design of pressure-sensitive multi-touch gestures and propose application scenarios that make optimal use of our concept.","shortAbstract":"In this paper, we present Presstures, a concept that introduces pressu","id":"pn1046"},"session":"UIST: Force Input","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1046"},"pn235":{"lastUpdateTime":1389221756152,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Gaze":{"dislikes":[],"lastTimeUpdated":1386525265226,"checked":true,"likes":["dan@microsoft.com","steimle@media.mit.edu","S.fairclough@ljmu.ac.uk","j.alexander@lancaster.ac.uk","bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca"],"label":"Gaze"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":["bickmore@ccs.neu.edu","benko@microsoft.com"],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Computer  Vision":{"dislikes":[],"lastTimeUpdated":1386538219152,"checked":true,"likes":[],"label":"Computer  Vision"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644776}},"creationTime":101,"content":{"authorList":["Julia Schwarz, Carnegie Mellon University","Charles Marais, Microsoft","Tommer Leyvand, Microsoft ","Scott Hudson, Carnegie Mellon University","Jennifer Mankoff, Carnegie Mellon University"],"title":"Combining Body Pose, Gaze, and Gesture to Determine Intention to Interact in Vision-Based Interfaces","paperOrNote":"Paper","fullAbstract":"Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a users intention to interact with the system. We show how this can be used to determine when to pay attention to a users actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a raise an open hand in front of you gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline wave to engage gesture currently shipping on Xbox 360.","shortAbstract":"Vision-based interfaces, such as those made popular by the Microsoft K","id":"pn235"},"session":"UIST: Motion and Haptics","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn235"},"pn233":{"lastUpdateTime":1388776832811,"subcommitteeSplit":"","labels":{"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":["S.fairclough@ljmu.ac.uk","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Driving":{"dislikes":[],"lastTimeUpdated":1386525771632,"checked":true,"likes":["benko@microsoft.com","pierre.dragice@gmail.com","no@spam.org"],"label":"Driving"},"Automotive":{"dislikes":[],"lastTimeUpdated":1386525668836,"checked":true,"likes":["no@spam.org"],"label":"Automotive"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["no@spam.org"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"situational awareness":{"dislikes":[],"lastTimeUpdated":1386525672529,"checked":true,"likes":[],"label":"situational awareness"},"Multi-modal interfaces":{"checked":false,"dislikes":[],"likes":["no@spam.org"],"lastUpdateTime":1386525877057,"label":"Multi-modal interfaces"},"in car technology":{"dislikes":[],"lastTimeUpdated":1386525655048,"checked":true,"likes":[],"label":"in car technology"},"Transport":{"checked":true,"dislikes":[],"likes":["S.fairclough@ljmu.ac.uk","davidmcgookin@gmail.com","bulling@mpi-inf.mpg.de","no@spam.org"],"lastUpdateTime":123456789,"label":"Transport"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644781}},"creationTime":99,"content":{"authorList":["Ioannis Politis, University of Glasgow","Stephen Brewster, University of Glasgow","Frank Pollick, University of Glasgow"],"title":"Evaluating Multimodal Driver Displays under Varying Situational Urgency","paperOrNote":"Paper","fullAbstract":"Previous studies have investigated audio, visual and tactile driver warnings, indicating the importance of communicating the appropriate level of urgency to the drivers. However, these modalities have never been combined exhaustively and tested under conditions of varying situational urgency, to assess their effectiveness both in the presence and absence of critical driving events. This paper describes an experiment evaluating all multimodal combinations of such warnings under two contexts of situational urgency: a lead car braking and not braking. The results showed that participants responded quicker to more urgent warnings, especially in the presence of a car braking. They also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour improved in the presence of the warnings and the absence of a car braking. These results highlight the utility of multimodal displays to rapidly and effectively alert drivers and demonstrate how driving behaviour can be affected by such signals.","shortAbstract":"Previous studies have investigated audio, visual and tactile driver wa","id":"pn233"},"session":"Transportation: Driving Me Mental","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn233"},"pn239":{"lastUpdateTime":1389286027763,"subcommitteeSplit":"","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Software Engineering Methods and Processes - Mathematical/Formal":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Software Engineering Methods and Processes - Mathematical/Formal"},"Software architecture and engineering":{"checked":true,"dislikes":[],"likes":["kris.luyten@uhasselt.be"],"lastUpdateTime":123456789,"label":"Software architecture and engineering"},"Model-based design and evaluation":{"dislikes":[],"lastTimeUpdated":1386524270157,"checked":true,"likes":[],"label":"Model-based design and evaluation"},"Information Architecture":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Information Architecture"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081824}},"creationTime":103,"content":{"authorList":["Mathieu Nancel, University of Canterbury","Andy Cockburn, University of Canterbury"],"title":"Causality  A Conceptual Model of Interaction History","paperOrNote":"Paper","fullAbstract":"Simple history systems such as Undo and Redo permit retrieval of earlier or later interaction states,  but advanced systems allow powerful capabilities to reuse or reapply combinations of commands, states, or data across interaction contexts.  Whether simple or powerful, designing interaction history mechanisms is challenging. In particular, there is a lack of tools to assist designers and researchers in specifying, contemplating, combining, and communicating the behaviour of history systems. To resolve this problem, we present Causality, a conceptual model of interaction history that clarifies the possibilities for temporal interactions. The model includes components for the work artifact (such as the text and formatting of a Word document), the system context (such as the settings and parameters of the user interface), the linear timeline (the commands executed in real time), and the branching chronology (a structure of executed commands and their impact on the artifact and/or context, which may be navigable by the user). We describe and exemplify how this model can be used to encapsulate existing user interfaces and reveal limitations in their behaviour, and we also show how the model stimulates the design of new and innovative opportunities for interacting in time. ","shortAbstract":"Simple history systems such as Undo and Redo permit retrieval of earli","id":"pn239"},"session":"Systems: Desktop Search and History","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn239"},"pn1865":{"lastUpdateTime":1388776475848,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Annotation":{"dislikes":[],"lastTimeUpdated":1386525680619,"checked":true,"likes":[],"label":"Annotation"},"it is NOT pen input":{"dislikes":[],"lastTimeUpdated":1386525916116,"checked":true,"likes":[],"label":"it is NOT pen input"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Pen and Tactile Input":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525899455,"label":"Pen and Tactile Input"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644821}},"creationTime":1462,"content":{"authorList":["Yi Ren, University of Waterloo","Yang Li, Google Research","Edward Lank, University of Waterloo"],"title":"InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones","paperOrNote":"Paper","fullAbstract":"Although touchscreen mobile phones are widely used for recording informal text notes (grocery lists, reminders, directions, etc.), the lack of efficient mechanisms for combining informal graphical content with text is a persistent challenge. In this paper, we present InkAnchor, a digital ink editor that allows users to easily create ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor incorporates flexible anchoring, focus-plus-context input, content chunking, and simple editing to support the capture of informal notes and annotations. We describe the design and evaluation of InkAnchor on a range of mobile note-taking tasks in a first-use study and show that the overall application is a significant improvement over current informal mobile note taking applications.","shortAbstract":"Although touchscreen mobile phones are widely used for recording infor","id":"pn1865"},"session":"Touch: Touch-me Mobile Interaction","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1865"},"pn1867":{"lastUpdateTime":1389285590040,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523545972,"label":"Empirical Methods, Quantitative"},"Multilingual communication":{"dislikes":[],"lastTimeUpdated":1386522095105,"checked":true,"likes":["jacovi@il.ibm.com","emilee@gmail.com","myriam.lewkowicz@utt.fr","sfussell@cornell.edu","teevan@gmail.com","haochuan@cs.nthu.edu.tw"],"label":"Multilingual communication"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":1386523547132,"label":"Computer-Mediated Communication"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523548202,"label":"Computer Supported Cooperative Work (CSCW)"},"Speech recognition":{"checked":false,"lastUpdateTime":1386523163989,"dislikes":[],"label":"Speech recognition","lastTimeUpdated":1386523035510,"likes":[]},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556760}},"creationTime":1464,"content":{"authorList":["Ge Gao, NTT Communication Science Labs.","Naomi Yamashita, NTT Communication Science Labs","Ari Hautasaari, NTT Communication Science Labs","Andy Echenique, NTT Communication Science Lab","Susan Fussell, Cornell University"],"title":"Effects of Public vs. Private Automated Transcripts on Multiparty Communication between Native and Non-Native English Speakers","paperOrNote":"Paper","fullAbstract":"Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS).  Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.","shortAbstract":"Real-time transcripts generated by automated speech recognition (ASR) ","id":"pn1867"},"session":"HCI4D: Multilingual Communication","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1867"},"pn2368":{"lastUpdateTime":1389238477951,"subcommitteeSplit":"A","labels":{"Animals":{"dislikes":[],"lastTimeUpdated":1386523051939,"checked":true,"likes":[],"label":"Animals"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Dogs":{"dislikes":[],"lastTimeUpdated":1386523058850,"checked":true,"likes":[],"label":"Dogs"},"Post-humanist Design":{"dislikes":[],"lastTimeUpdated":1386523061309,"checked":true,"likes":[],"label":"Post-humanist Design"},"Animal-computer interaction":{"dislikes":[],"lastTimeUpdated":1386523419720,"checked":true,"likes":[],"label":"Animal-computer interaction"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"health":{"dislikes":[],"lastTimeUpdated":1386522735555,"checked":true,"likes":[],"label":"health"},"Ethnography":{"dislikes":[],"lastTimeUpdated":1386522760561,"checked":true,"likes":[],"label":"Ethnography"},"Participatory Design":{"checked":false,"lastUpdateTime":1386523702288,"dislikes":[],"label":"Participatory Design","lastTimeUpdated":1386523316613,"likes":[]},"dogs":{"checked":false,"lastUpdateTime":1386523539236,"dislikes":[],"label":"dogs","lastTimeUpdated":1386522911468,"likes":[]},"Participatory Design / Cooperative Design":{"dislikes":[],"lastTimeUpdated":1386523569425,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"Participatory Design / Cooperative Design"},"diabetes":{"dislikes":[],"lastTimeUpdated":1386522743915,"checked":true,"likes":[],"label":"diabetes"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711773}},"creationTime":1900,"content":{"authorList":["Charlotte Robinson, The Open University","Clara Mancini, The Open University","Janet van der Linden, The Open University","Claire Guest, Medical Detection Dogs","Robert Harris, Medical Detection Dogs"],"title":"Canine-Centered Interface Design: Supporting the Work of Diabetes Alert Dogs","paperOrNote":"Paper","fullAbstract":"Many people with Diabetes live with the continuous threat of hypoglycaemic attacks and the danger of going into coma. Diabetic Alert Dogs are trained to detect the onset of an attack before the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alert system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on teasing out the requirements for a physical canine user interface, involving both dogs, their handlers and trainers in the design. We discuss tensions between the requirements for the canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics and reflect on how we can move from designing for dogs to designing with dogs. ","shortAbstract":"Many people with Diabetes live with the continuous threat of hypoglyca","id":"pn2368"},"session":"Design: Participatory Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2368"},"pn966":{"lastUpdateTime":1388785654801,"subcommitteeSplit":"","labels":{"Visualizing Uncertainty":{"dislikes":[],"lastTimeUpdated":1386525441516,"checked":true,"likes":[],"label":"Visualizing Uncertainty"},"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525589884,"label":"Visualization"},"information visualization":{"checked":false,"lastUpdateTime":1386525945503,"dislikes":[],"label":"information visualization","lastTimeUpdated":1386525458746,"likes":["benko@microsoft.com"]},"Database access / Information Retrieval":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525450916,"label":"Database access / Information Retrieval"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525605858,"checked":true,"likes":["elm@purdue.edu","dan@microsoft.com","benko@microsoft.com"],"label":"Information Visualization"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644712}},"creationTime":684,"content":{"authorList":["Nivan Ferreira, New York University","Danyel Fisher, Microsoft Research","Arnd Christian Konig, Microsoft Research"],"title":"Sample-Oriented Task-Driven Visualizations: Allowing Users to Make Better, More Confident Decisions","paperOrNote":"Paper","fullAbstract":"The datasets we use often reflect samples rather than full populations, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. compare two bars) becomes a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results, that users have a justified confidence in their answers with our system. ","shortAbstract":"The datasets we use often reflect samples rather than full populations","id":"pn966"},"session":"Viz: Visual System Design","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn966"},"pn2560":{"lastUpdateTime":1389591375652,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386522499265,"label":"Empirical Methods, Quantitative"},"eye tracking":{"checked":true,"lastUpdateTime":1386523136466,"dislikes":[],"label":"eye tracking","lastTimeUpdated":1386522777194,"likes":[]},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522495761,"label":"Usability Testing and Evaluation"},"goals":{"dislikes":[],"lastTimeUpdated":1386524370698,"checked":true,"likes":[],"label":"goals"},"User and Cognitive models":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de","D.StantonFraser@bath.ac.uk"],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"User Studies":{"checked":true,"dislikes":[],"likes":["D.StantonFraser@bath.ac.uk"],"lastUpdateTime":1386522500021,"label":"User Studies"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032747},"Human error":{"label":"Human error","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389104824022}},"creationTime":2044,"content":{"authorList":["Greg Trafton, Naval Research Laboratory","Raj Ratwani, MedStar"],"title":"The Law of Unintended Consequences: The case of external subgoal support","paperOrNote":"Paper","fullAbstract":"Many interfaces have been designed to prevent or reduce errors. These interfaces may, in fact, reduce the error rate of specific variables, but may also have unintended consequences. In this paper, we show a series of studies where a better interface did not reduce the number of errors but instead shifted errors from one error class (omissions) to another error class (perseverations). We also show that having access to progress tracking (a progress bar) does not reduce the number of errors. We propose and demonstrate a solution  a predictive error system  that reduces errors based on the class of error, not on the type of interface.","shortAbstract":"Many interfaces have been designed to prevent or reduce errors. These ","id":"pn2560"},"session":"Methods and Models: User Model 1","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2560"},"pn171":{"lastUpdateTime":1389221780441,"subcommitteeSplit":"A","labels":{"User and Cognitive models":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User and Cognitive models"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Model-based design and evaluation":{"dislikes":[],"lastTimeUpdated":1386524226316,"checked":true,"likes":["kris.luyten@uhasselt.be"],"label":"Model-based design and evaluation"},"replication":{"dislikes":[],"lastTimeUpdated":1386524153095,"checked":true,"likes":[],"label":"replication"},"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081869}},"creationTime":50,"content":{"authorList":["Kyung Wha Hong, North Carolina State University","Robert St. Amant, North Carolina State University"],"title":"Novice Use of a Predictive Human Performance Modeling Tool to Produce UI Recommendations","paperOrNote":"Note","fullAbstract":"This note describes two studies of the use of a performance modeling tool, CogTool, for making recommendations to improve a user interface. The first study replicates findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations (88.1%) and supported them (68.2%) are close to the values in Johns study (91.7% and 75.1%, respectively). A follow-on study of novice modelers on the same task without CogTool produced significantly lower values. CogTool improves the UI design recommendations made by novices.","shortAbstract":"This note describes two studies of the use of a performance modeling t","id":"pn171"},"session":"Systems: Machines Interactively Learning","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn171"},"pn1918":{"lastUpdateTime":1389221957843,"subcommitteeSplit":"","labels":{"gatekeeping":{"dislikes":[],"lastTimeUpdated":1386523386664,"checked":true,"likes":[],"label":"gatekeeping"},"Wikipedia":{"dislikes":[],"lastTimeUpdated":1386522226273,"checked":true,"likes":[],"label":"Wikipedia"},"newcomers":{"dislikes":[],"lastTimeUpdated":1386521677480,"checked":true,"likes":[],"label":"newcomers"},"socialization":{"dislikes":[],"lastTimeUpdated":1386522577435,"checked":true,"likes":[],"label":"socialization"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"Ethnography":{"checked":true,"dislikes":[],"likes":["dmrussell@gmail.com"],"lastUpdateTime":123456789,"label":"Ethnography"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522210220,"label":"Computer Supported Cooperative Work (CSCW)"},"participation":{"dislikes":[],"lastTimeUpdated":1386522573418,"checked":true,"likes":[],"label":"participation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556707}},"creationTime":1508,"content":{"authorList":["Aaron Halfaker, University of Minnesota","R.Stuart Geiger, University of California, Berkeley","Loren Terveen, University of Minnesota"],"title":"Snuggle: Designing for Efcient Socialization and Ideological Critique","paperOrNote":"Paper","fullAbstract":"Wikipedia, the encyclopedia \"anyone can edit\", has become increasingly less so. Academic research and popular discourse illustrates the often aggressive ways newcomers are treated by veteran Wikipedians. These are complex socio-technical issues, bound up in problematic infrastructures and ideologies. In response, we worked with a coalition of Wikipedians to design, develop and deploy Snuggle, a new user interface that served two critical functions: making the work of newcomer socialization more effective and bringing visibility to instances in which Wikipedians' current practice of gatekeeping socialization break down in order encourage reflection and critique.  Snuggle supports positive socialization tasks by helping mentors quickly find newcomers whose good-faith mistakes were reverted as damage.  Snuggle also supports ideological critique and reflection by bringing visibility to the broader implications of seeing newcomers through a lens of suspiciousness. Instead of seeing these two goals as incommensurable 'waves' of HCI, our pluralistic approach found these mutually beneficial.","shortAbstract":"Wikipedia, the encyclopedia \"anyone can edit\", has become increasingly","id":"pn1918"},"session":"Social: Online Communities","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn1918"},"pn1915":{"lastUpdateTime":1389238696698,"subcommitteeSplit":"B","labels":{"Sustainability":{"checked":true,"dislikes":[],"likes":["rob.comber@ncl.ac.uk","jfc@cs.berkeley.edu","alexander.de.luca@ifi.lmu.de","jonfroehlich@gmail.com","elainemayhuang@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Sustainability"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"Vision":{"dislikes":[],"lastTimeUpdated":1386522349246,"checked":true,"likes":[],"label":"Vision"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446330}},"creationTime":1505,"content":{"authorList":["Bran Knowles, Lancaster University","Lynne Blair, Lancaster University","Paul Coulton, Lancaster University","Jon Whittle, Lancaster University","Mark Lochrie, Lancaster University"],"title":"Rethinking Plan A for Sustainable HCI","paperOrNote":"Note","fullAbstract":"This paper challenges the sustainable HCI community to move away from a focus on demand and instead address climate change as a supply problem. We identify a new route to impact, namely to focus on addressing the psychological barriers that prevent the political action needed to affect the supply of fossil fuels. Five barriers are explored as a means of revealing new research objectives for the community.","shortAbstract":"This paper challenges the sustainable HCI community to move away from ","id":"pn1915"},"session":"HCI4D: PolitiCHI","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1915"},"pn1916":{"lastUpdateTime":1389591525028,"subcommitteeSplit":"B","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Fitts's Law":{"dislikes":[],"lastTimeUpdated":1386525354248,"checked":true,"likes":[],"label":"Fitts's Law"},"sorta fitz law":{"dislikes":[],"lastTimeUpdated":1386522945578,"checked":true,"likes":[],"label":"sorta fitz law"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["mmassimi@microsoft.com","l.ciolfi@shu.ac.uk","mc+frenzy@ecs.soton.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032702},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389105496485}},"creationTime":1506,"content":{"authorList":["Alexander Ng, University of Glasgow","Stephen Brewster, University of Glasgow","John Williamson, University of Glasgow"],"title":"Investigating the Effects of Encumbrance on One- and Two- Handed Interactions with Mobile Devices","paperOrNote":"Paper","fullAbstract":"In this paper, we investigate the effects of encumbrance (carrying typical objects such as shopping bags during interaction) and walking on target acquisition on a touchscreen mobile phone.  Users often hold objects and use mobile devices at the same time and we examined the impact encumbrance has on one- and two- handed interactions.  Three common input postures were evaluated: two-handed index finger, one-handed preferred thumb and two-handed both thumbs, to assess the effects on performance of carrying multiple objects in the hands (a bag in each hand) while walking.  The results showed a significant decrease in targeting performance when users were encumbered.  For example, input accuracy dropped to 48.1% for targeting with the index finger when encumbered, while targeting error using the preferred thumb to input when carrying the bags was 4.2mm, an increase of 38% compared to unencumbered.  We also introduce a new method to evaluate the users preferred walking speed when interacting - PWS&I, and suggest future studies should use this to get a more accurate reflection of the users input performance.  ","shortAbstract":"In this paper, we investigate the effects of encumbrance (carrying typ","id":"pn1916"},"session":"Methods and Models: User Model 2","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1916"},"pn1911":{"lastUpdateTime":1389236825484,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":["elm@purdue.edu","petra.isenberg@inria.fr"],"lastUpdateTime":1386525291744,"label":"Visualization"},"Information Visualization":{"dislikes":[],"lastTimeUpdated":1386525467521,"checked":true,"likes":["petra.isenberg@inria.fr","j.alexander@lancaster.ac.uk","no@spam.org"],"label":"Information Visualization"},"information visualization":{"checked":false,"lastUpdateTime":1386525579671,"dislikes":[],"label":"information visualization","lastTimeUpdated":1386525025967,"likes":["dan@microsoft.com","petra.isenberg@inria.fr","steimle@media.mit.edu","bulling@mpi-inf.mpg.de"]},"Tangible UIs":{"dislikes":[],"lastTimeUpdated":1386526010530,"checked":true,"likes":["pierre.dragice@gmail.com","aquigley@st-andrews.ac.uk"],"label":"Tangible UIs"},"fabrication":{"dislikes":[],"lastTimeUpdated":1386525023847,"checked":true,"likes":["petra.isenberg@inria.fr","no@spam.org","steimle@media.mit.edu","j.alexander@lancaster.ac.uk","aquigley@st-andrews.ac.uk","pierre.dragice@gmail.com"],"label":"fabrication"},"Tangibles":{"checked":false,"lastUpdateTime":1386526069659,"dislikes":[],"label":"Tangibles","lastTimeUpdated":1386525982306,"likes":["elm@purdue.edu"]},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644770}},"creationTime":1502,"content":{"authorList":["Saiganesh Swaminathan, INRIA","Conglei Shi, Hong Kong University of Science and Technology","Yvonne Jansen, INRIA","Pierre Dragicevic, INRIA","Lora Oehlberg, INRIA","Jean-Daniel Fekete, INRIA"],"title":"Supporting The Design and Fabrication of Physical Visualizations","paperOrNote":"Paper","fullAbstract":"An increasing variety of physical visualizations are being built, for purposes ranging from art and entertainment to business analytics and scientific research. However, crafting them remains a laborious process and demands expertise in both data visualization and digital fabrication. We illustrate the limitations of current workflows through three real case studies. We then present the MakerVis prototype, the first tool that integrates the whole workflow, from data filtering to physical fabrication. Design sessions with three end users shows that tools such as MakerVis can dramatically lower the barriers behind producing physical visualizations. Observations and interviews also revealed important directions for future research. These include rich support for customization, and extensive software support for materials that accounts for their unique physical properties as well as their limited supply.","shortAbstract":"An increasing variety of physical visualizations are being built, for ","id":"pn1911"},"session":"Making: 3D printing","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn1911"},"to111":{"lastUpdateTime":1388765600113,"subcommitteeSplit":"","labels":{"Social Networking":{"checked":false,"lastUpdateTime":1386528872236,"dislikes":[],"label":"Social Networking","lastTimeUpdated":1386528868750,"likes":[]},"Mental health":{"dislikes":[],"lastTimeUpdated":1386525175872,"checked":true,"likes":["dan@danielashbrook.com"],"label":"Mental health"},"health":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"health"},"SC_TOCHI":{"dislikes":[],"lastTimeUpdated":1386527699566,"checked":true,"likes":[],"label":"SC_TOCHI"}},"creationTime":2054,"content":{"authorList":["Reeva Lederman, University of Melbourne","Greg Wadley, The University of Melbourne","John Gleeson, Australian Catholic University","Sarah Bendall, Orygen Youth Health Research Centre","Mario Alvarez-Jimenez, The University of Melbourne"],"title":"Moderated Online Social Therapy: Designing and Evaluating Technology for Mental Health","paperOrNote":"TOCHI","fullAbstract":"While the use and prevalence of web-based mental health applications has grown over the last decade, many of these services suffer high rates of attrition. This is problematic as face-to-face support for mental health is limited. To determine appropriate design guidelines for increasing engagement we conducted a study of First Episode Psychosis (FEP) patients and reviewed theories on the use of existing online services. We produced a set of design goals, developed an online application that combined social networking and online therapy within a clinician moderated site and conducted a six week trial with a group of young FEP patients. The design goals, based on existing theory including Supportive Accountability and Positive Psychology are operationalised through a model we call MOST (Moderated Online Social Therapy). The trial results indicate that our implementation achieved the design goals and that the MOST model can inform the development of more effective and engaging online therapies.","shortAbstract":"While the use and prevalence of web-based mental health applications h","id":"to111"},"session":"Health: Network of care","replyCounter":0,"subcommittee":"TOCHI","replies":[],"id":"to111"},"pn2175":{"lastUpdateTime":1389238216391,"subcommitteeSplit":"B","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de","obristmarianna@gmail.com","mmassimi@microsoft.com","l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"College students":{"dislikes":[],"lastTimeUpdated":1386523039730,"checked":true,"likes":[],"label":"College students"},"Multimedia UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multimedia UIs"},"Office and Workplace":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522035399,"label":"Office and Workplace"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"breaking the addiction of social media":{"dislikes":[],"lastTimeUpdated":1386527723473,"checked":true,"likes":[],"label":"breaking the addiction of social media"},"phones":{"dislikes":[],"lastTimeUpdated":1386524550184,"checked":true,"likes":[],"label":"phones"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"addiction":{"dislikes":[],"lastTimeUpdated":1386522044531,"checked":true,"likes":[],"label":"addiction"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032710}},"creationTime":1735,"content":{"authorList":["Uichin Lee, KAIST","Changhoon Lee, KAIST","Yuhwan Kim, KAIST","Joon-Won Lee, KAIST","Gahgene Gweon, KAIST","Junehwa Song, KAIST (Korea Advanced Institute of Science and Technology)","KM Chung, Yeonsei","Koji Yatani, Microsoft Research Asia","Soobin Yang, KAIST"],"title":"Hooked on Smartphones: Exploring Smartphone Addiction on Campus","paperOrNote":"Paper","fullAbstract":"The impact of smartphone addiction among young adults, such as sleep deprivation, attentional deficits, has been increasingly recognized. In this paper, we identify addiction-pertinent aspects of smartphone usage among young user populations by analyzing multiple datasets (survey, interview, and usage logged data). We first group the participants into risk and normal categories based on self-reported psychometric scales on smartphone addiction. We then analyze the usage data to uncover group-specific usage differences, ranging from overall usage patterns to app-specific usage patterns. The results reveal several key differences: compared to the normal group, the risk group has longer usage time per day, has diurnal usage differences, is more susceptible to instant messaging push notifications, and tends to seek more stimulating content. We discuss how such usage patterns are related to the key symptoms of smartphone addiction and show that smartphone addiction can be automatically classified with usage data (F-score: 0.83).","shortAbstract":"The impact of smartphone addiction among young adults, such as sleep d","id":"pn2175"},"session":"People: Emotions and Mobiles","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2175"},"pn2054":{"lastUpdateTime":1389236125639,"subcommitteeSplit":"B","labels":{"Affective Communication":{"dislikes":[],"lastTimeUpdated":1386522368392,"checked":true,"likes":[],"label":"Affective Communication"},"Input and Interaction Technologies":{"dislikes":[],"lastTimeUpdated":1386522016940,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Input and Interaction Technologies"},"Tactile and Haptic UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Tactile and Haptic UIs"},"Emotion and Affective User Interface":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Emotion and Affective User Interface"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446298}},"creationTime":1624,"content":{"authorList":["Joseph Mullenbach, Northwestern University","Craig Shultz, Northwestern University","J. Edward Colgate, Northwestern University","Anne Marie Piper, Northwestern University"],"title":"Exploring Affective Communication Through Variable-Friction Surface Haptics","paperOrNote":"Paper","fullAbstract":"This paper explores the use of variable friction surface haptics enabled by the TPad Tablet to support affective communication between pairs of users. We introduce three haptic applications for the TPad tablet (text messaging, image sharing, and virtual touch) and evaluate the applications with 24 users, including intimate couples and strangers. Participants use haptics to communicate literal texture, denote action within a scene, convey emotional information, highlight content, express and engage in physical playfulness, and to provide ones partner with an experience or sensation. We find that users readily associate haptics with emotional expression and that the intimacy of touch in the contexts we study is best suited for communications with close social partners.","shortAbstract":"This paper explores the use of variable friction surface haptics enabl","id":"pn2054"},"session":"Social: Computer Mediated Romance","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2054"},"pn1736":{"lastUpdateTime":1389221516569,"subcommitteeSplit":"A","labels":{"Mobile health":{"dislikes":[],"lastTimeUpdated":1386523806675,"checked":true,"likes":["Jina.huh@gmail.com","vlh@acm.org"],"label":"Mobile health"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"detecting movement":{"dislikes":[],"lastTimeUpdated":1386523629442,"checked":true,"likes":[],"label":"detecting movement"},"Participatory Design / Cooperative Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523068271,"label":"Participatory Design / Cooperative Design"},"Older Adults":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386537119070,"label":"Older Adults"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188191}},"creationTime":1350,"content":{"authorList":["Sinziana Mazilu, ETH","Eran Gazit, Tel-Aviv Sourasky Medical Center","Michael Hardegger, ETH","Ulf Blanke, ETH","Jeffrey M. Hausdorff, Tel-Aviv Sourasky Medical Center","Gerhard Trster, ETH Zurich"],"title":"GaitAssist: A Daily-life Support and Training System for Parkinson's Disease Patients with Freezing of Gait","paperOrNote":"Paper","fullAbstract":"Parkinson's disease is a degenerative neurological disorder that is characterized by postural instability, rigidity, reduced movement, and tremor. \\ Patients often experience freezing of gait, which bears a high risk of falling, a prevalent cause for morbidity and mortality. \\ In this work we present GaitAssist, a wearable system for freezing of gait support in daily life. The system provides real-time auditory cueing on start of freezing episodes and thereby helps the patients to resume gait. Furthermore, GaitAssist implements training exercises to learn how to handle freezing situations. GaitAssist is the result of a design process where we considered the inputs of engineers, clinicians and 18 Parkinson's disease patients, in order to find an optimal trade-off between system wearability and performance. We tested the final system in a user study with 5 new patients. The patients report that the system helps to reduce freezing of gait duration. A quantitative analysis confirms the patient's feedback and shows that the system might help in improving the gait.","shortAbstract":"Parkinson's disease is a degenerative neurological disorder that is ch","id":"pn1736"},"session":"Health: HCI for Rehabilitation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1736"},"pn1732":{"lastUpdateTime":1389236916221,"subcommitteeSplit":"B","labels":{"ICT4D":{"checked":false,"lastUpdateTime":1386531697879,"dislikes":[],"label":"ICT4D","lastTimeUpdated":1386522397134,"likes":[]},"ICTD":{"dislikes":[],"lastTimeUpdated":1386531694070,"checked":true,"likes":[],"label":"ICTD"},"International Development":{"checked":false,"lastUpdateTime":1386522513432,"dislikes":[],"label":"International Development","lastTimeUpdated":1386522457124,"likes":[]},"Usability Research":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Research"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["kc@comp.lancs.ac.uk"],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","kc@comp.lancs.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":["kc@comp.lancs.ac.uk"],"lastUpdateTime":123456789,"label":"Ethnography"},"Home":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com"],"lastUpdateTime":123456789,"label":"Home"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032766}},"creationTime":1346,"content":{"authorList":["Erick Oduor, Simon Fraser University","Carman Neustaedter, Simon Fraser University","Tejinder Judge, Google Inc. ","Kate Hennessy, Simon Fraser University","Carolyn Pang, Simon Fraser University","Serena Hillman, Simon Fraser University"],"title":"How Technology Supports Family Communication in Rural, Suburban, and Urban Kenya","paperOrNote":"Paper","fullAbstract":"Much ICTD research for sub-Saharan Africa and India has focused on how technology related interventions have aimed to incorporate marginalized communities towards global economic growth. Our work builds on this. We present results from an exploratory qualitative study on the family communication practices of family members who communicate both within and between rural, suburban, and urban settings in Kenya. Our findings reveal that family communication focuses on economic support, well-being, life advice, and everyday coordination of activities.  We also outline social factors that affect family communication, including being an eldest child, having a widowed sibling, and having reduced access to technology because of gender, literacy, or ones financial situation. Lastly, we discuss new opportunities for technology design and articulate the challenges that designers will face if creating or deploying family communication technologies in Kenya.","shortAbstract":"Much ICTD research for sub-Saharan Africa and India has focused on how","id":"pn1732"},"session":"HCI4D: Family 2.0","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1732"},"pn2005":{"lastUpdateTime":1389238893968,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528719996,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526162456,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"Security":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","rob.comber@ncl.ac.uk","a.sasse@cs.ucl.ac.uk","nithyas@gmail.com","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Security"},"User Studies":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"User Studies"},"Privacy":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","rob.comber@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Privacy"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446309}},"creationTime":1582,"content":{"authorList":["Richard Shay, Carnegie Mellon University","Iulia Ion, ","Robert W. Reeder, Google","Sunny Consolvo, Google"],"title":"My religious aunt asked why I was trying to sell her viagra: Experiences with account hijacking","paperOrNote":"Paper","fullAbstract":"With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of two surveys about peoples experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are valuable to their owners, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users accept some responsibility for keeping their accounts secure, (4) users understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for adoption.","shortAbstract":"With so much of our lives digital, online, and not entirely under our ","id":"pn2005"},"session":"Security: Security","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2005"},"pn2003":{"lastUpdateTime":1389221516569,"subcommitteeSplit":"","labels":{"Exergames":{"dislikes":[],"lastTimeUpdated":1386528053468,"checked":true,"likes":["john.vines@ncl.ac.uk","marcodesa@gmail.com","judy.kay@gmail.com"],"label":"Exergames"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com","judy.kay@gmail.com"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Exergame":{"checked":false,"lastUpdateTime":1386528055154,"dislikes":[],"label":"Exergame","lastTimeUpdated":1386527754422,"likes":[]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165090}},"creationTime":1580,"content":{"authorList":["Monica Zaczynski, Carleton University","Anthony Whitehead, Carleton University"],"title":"Efficacy Before Novelty: Establishing Design Guidelines in Interactive Gaming for Rehabilitation and Training","paperOrNote":"Paper","fullAbstract":"Interactive gaming has demonstrated promise as a low-cost, at-home physiotherapy supplement. Gaming systems offer convenience and the ability to provide enhanced reporting and progress data if body measurement information is collected effectively. However, systems available today commercially are designed primarily for entertainment and as a result, the quality of instruction delivery and level of involvement may not meet the needs of a patient. \\  \\ This paper will look at adapting for occlusion and lack of visibility; learning and orientation; and providing feedback in an effort to determine if there is an ideal visual demonstration delivery that maximizes pose understanding and user self-efficacy, determine whether supplementary modalities are important for instruction, and determine if there is an ideal feedback delivery that promotes pose comprehension, confidence and motivation.  This information can provide a guideline for designing clear and supportive, interactive training or rehabilitation systems that can engage users, prevent injury and help maintain fitness. \\ ","shortAbstract":"Interactive gaming has demonstrated promise as a low-cost, at-home phy","id":"pn2003"},"session":"Health: HCI for Rehabilitation","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2003"},"pn2001":{"lastUpdateTime":1389220864045,"subcommitteeSplit":"C","labels":{"Blind":{"checked":false,"lastUpdateTime":1386527105504,"dislikes":[],"label":"Blind","lastTimeUpdated":1386526796590,"likes":["kgajos@eecs.harvard.edu"]},"Guided experiences":{"dislikes":[],"lastTimeUpdated":1386526682510,"checked":true,"likes":["andrew.sears@rit.edu"],"label":"Guided experiences"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["kgajos@eecs.harvard.edu","christopher.power@york.ac.uk"],"lastUpdateTime":1386527106845,"label":"Universal (or Disability)  Access"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527325974,"label":"User Interface Design"},"Vision-Impaired Users":{"checked":false,"lastUpdateTime":1386527099074,"dislikes":[],"label":"Vision-Impaired Users","lastTimeUpdated":1386526656976,"likes":[]},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527324082,"label":"User Studies"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486646}},"creationTime":1578,"content":{"authorList":["Roberto Manduchi, UCSC","James Coughlan, Smith-Kettlewell Eye Research Institute"],"title":"The Last Meter: Blind Visual Guidance to a Target","paperOrNote":"Paper","fullAbstract":"Smartphone apps can use object recognition software to provide information to blind or low vision users about objects in the visual environment. A crucial challenge for these users is aiming the camera properly to take a well-framed picture of the desired target object. We investigate the effects of two fundamental constraints of object recognition  frame rate and camera field of view  on a blind persons ability to use an object recognition smartphone app. The app was used by 18 blind participants to find visual targets beyond arms reach and approach them to within 30 cm. While we expected that a faster frame rate or wider camera field of view should always improve search performance, our experimental results show that in many cases increasing the field of view doesn't help, and may even hurt, performance. These results have important implications for the design of object recognition systems for blind users.","shortAbstract":"Smartphone apps can use object recognition software to provide informa","id":"pn2001"},"session":"Health: Accessibility","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2001"},"pn1452":{"lastUpdateTime":1389221983645,"subcommitteeSplit":"B","labels":{"ipad":{"dislikes":[],"lastTimeUpdated":1386522440613,"checked":true,"likes":[],"label":"ipad"},"arts":{"checked":false,"lastUpdateTime":1386522850850,"dislikes":[],"label":"arts","lastTimeUpdated":1386522843524,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":1386522447149,"label":"Handheld Devices and Mobile Computing"},"collaboration":{"dislikes":[],"lastTimeUpdated":1386522617416,"checked":true,"likes":[],"label":"collaboration"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386522601755,"checked":true,"likes":[],"label":"Gestural interaction"},"dance/movement":{"dislikes":[],"lastTimeUpdated":1386522672398,"checked":true,"likes":["wendyju@stanford.edu"],"label":"dance/movement"},"Creativity Support Tools":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu","aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"Creativity Support Tools"},"music":{"checked":false,"lastUpdateTime":1386530464871,"dislikes":[],"label":"music","lastTimeUpdated":1386523099987,"likes":[]},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["ztoups@nmsu.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Design Cards":{"checked":false,"lastUpdateTime":1386522466813,"dislikes":[],"label":"Design Cards","lastTimeUpdated":1386522419003,"likes":[]},"Music":{"dislikes":[],"lastTimeUpdated":1386530462622,"checked":true,"likes":[],"label":"Music"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755915}},"creationTime":1113,"content":{"authorList":["Charles Martin, The Australian National University","Henry Gardner, Australian National University","Ben Swift, The Australian National University"],"title":"Exploring Percussive Gesture on iPads with Ensemble Metatone","paperOrNote":"Note","fullAbstract":"Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. \\  \\ This paper examines Ensemble Metatone, a group formed to explore the \"infiltration'' of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.","shortAbstract":"Percussionists are unique among western classical instrumentalists in ","id":"pn1452"},"session":"Art: Performance 2","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1452"},"pn534":{"lastUpdateTime":1389221983645,"subcommitteeSplit":"A","labels":{"Social Presence":{"dislikes":[],"lastTimeUpdated":1386523463484,"checked":true,"likes":[],"label":"Social Presence"},"Virtual Community / Community Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Virtual Community / Community Computing"},"Ethnography":{"checked":true,"dislikes":[],"likes":["ledantec@gatech.edu"],"lastUpdateTime":123456789,"label":"Ethnography"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711756}},"creationTime":324,"content":{"authorList":["William A. Hamilton, Interface Ecology Lab @ Texas A&M University","Oliver Garretson, Texas A&M University ","Andruid Kerne, Interface Ecology Lab, Texas A&M University"],"title":"Twitch Streams as Third Places: Fostering Participatory Communities of Play within Live Mixed Media","paperOrNote":"Paper","fullAbstract":"Previously, video streaming sites were at the fringes of online social media.  \\ In the past 2 years, video gaming live streams on sites like Twitch.tv have become very popular. They serve as meeting grounds for player communities. The Twitch streaming medium combines live broadcast video and open IRC chat channels. In conjunction with gameplay, viewer participation and community building gain emphasis. Twitch streams range in size and nature, from intimate communities with fifty viewers, to massive broadcasts with tens of thousands.  \\ In this paper, we present an ethnographic investigation of live streaming of video games on Twitch. \\  \\ We find that Twitch streams act as virtual third places, in which informal communities emerge, socialize, and participate. Over time, stream communities form around a shared identity drawn from a stream's content and participants' shared experiences. We describe processes through which stream communities form, the motivations of members, and emergent issues in the medium.  \\ Finally, we draw from our findings to derive implications for design of live mixed-media environments to support participatory online communities.","shortAbstract":"Previously, video streaming sites were at the fringes of online social","id":"pn534"},"session":"Art: Performance 2","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn534"},"pn1454":{"lastUpdateTime":1389590993042,"subcommitteeSplit":"B","labels":{"Organizational Culture / Organizational Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Organizational Culture / Organizational Planning"},"Office and Workplace":{"dislikes":[],"lastTimeUpdated":1386522143443,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Office and Workplace"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Emergency Response":{"dislikes":[],"lastTimeUpdated":1386524442778,"checked":true,"likes":[],"label":"Emergency Response"},"Computer-Mediated Communication":{"dislikes":[],"lastTimeUpdated":1386522155986,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446333}},"creationTime":1114,"content":{"authorList":["Amanda L. Hughes, Utah State University","Lise A. St. Denis, University of Colorado Boulder","Leysia Palen, University of Colorado Boulder","Kenneth M. Anderson, University of Colorado Boulder"],"title":"Online Public Communications by Police & Fire Services during the 2012 Hurricane Sandy","paperOrNote":"Paper","fullAbstract":"Social media and other online communication tools are a subject of great interest in mass emergency response. Members of the public are turning to social media solutions to seek and offer information about emergencies. Emergency responders are working to determine what social media policies should be in terms of their public information functions. We report on the online communications from all the coastal fire and police departments within a 100 mile radius of Hurricane Sandys US landfall. Across four types of online communication media, we collected data from 840 fire and police departments. Findings indicate that few departments used these communication channels in their Sandy response efforts, and that communications differed between fire and police departments and across media type. However, among the highly engaged departments, there is evidence that they bend and adapt policies about what constitutes appropriate public communication in the face of emergency demands. We propose that the behaviors illustrated in these precedents will be the rule more than the exception, and that flexibility is therefore important in considering future emergency online communication policy.","shortAbstract":"Social media and other online communication tools are a subject of gre","id":"pn1454"},"session":"HCI4D: Emergency Response","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1454"},"pn400":{"lastUpdateTime":1389286027763,"subcommitteeSplit":"A","labels":{"digital archive":{"dislikes":[],"lastTimeUpdated":1386525022032,"checked":true,"likes":[],"label":"digital archive"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524569758,"label":"Empirical Methods, Quantitative"},"PIM":{"dislikes":[],"lastTimeUpdated":1386523656024,"checked":true,"likes":[],"label":"PIM"},"Getting Personal":{"dislikes":[],"lastTimeUpdated":1386526482855,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Getting Personal"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524570662,"label":"Empirical Methods, Qualitative"},"Personalization":{"dislikes":[],"lastTimeUpdated":1386525114917,"checked":true,"likes":["mark.hancock@uwaterloo.ca","coye.cheshire@gmail.com"],"label":"Personalization"},"Personality":{"dislikes":[],"lastTimeUpdated":1386523664737,"checked":true,"likes":[],"label":"Personality"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946721}},"creationTime":222,"content":{"authorList":["Charlotte Massey, University of California ","Steve Whittaker, University of California at Santa Cruz"],"title":"PIM and Personality: What do our personal file systems say about us?","paperOrNote":"Paper","fullAbstract":"Individual differences are prevalent in personal information management (PIM). There is large variation between individuals in how they organize and retrieve information from personal archives. These differences make it hard to develop general PIM tools. However we know little about the origins of these differences. We present two studies evaluating whether differences arise from personality traits, by exploring whether different personalities organize personal archives differently. We first show that personality can be inferred from structure: providing information about how a strangers archive is organized allows people to infer aspects of the owners personality, particularly their Openness. In a second study we directly measure relations between structure and traits. We demonstrate that Conscientiousness can be predicted from file organization, particularly from PC users desktops. Neurotic people may also keep more desktop files. One implication is that systems might be customizable for different personalities. We also advance personality theory, showing that personal digital artifacts signal personality.  ","shortAbstract":"Individual differences are prevalent in personal information managemen","id":"pn400"},"session":"Systems: Desktop Search and History","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn400"},"pn405":{"lastUpdateTime":1389591456731,"subcommitteeSplit":"A","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":1386525006283,"label":"Empirical Methods, Quantitative"},"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523906846,"checked":true,"likes":["Brumby@cs.ucl.ac.uk","coye.cheshire@gmail.com"],"label":"eye tracking"},"The Eyes Have It":{"dislikes":[],"lastTimeUpdated":1386526277120,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"The Eyes Have It"},"data organizing":{"dislikes":[],"lastTimeUpdated":1386523921208,"checked":true,"likes":[],"label":"data organizing"},"photography":{"dislikes":[],"lastTimeUpdated":1386524130325,"checked":true,"likes":[],"label":"photography"},"organization":{"dislikes":[],"lastTimeUpdated":1386524122827,"checked":true,"likes":[],"label":"organization"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["coye.cheshire@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":["Brumby@cs.ucl.ac.uk"],"lastUpdateTime":1386525008180,"label":"User Studies"},"photo sharing":{"dislikes":[],"lastTimeUpdated":1386524092912,"checked":true,"likes":[],"label":"photo sharing"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946685}},"creationTime":226,"content":{"authorList":["Tina Walber, Institute WeST","Ansgar Scherp, University of Mannheim","Steffen Staab, University of Koblenz-Landau"],"title":"Smart Photo Selection: Interpret Gaze as Personal Interest","paperOrNote":"Paper","fullAbstract":"Manually selecting subsets of photos from large collections in order to present them to friends or colleagues or to print them as photo books is a tedious task. Today, fully-automatic approaches, which alleviate users from this burden, are at hand. They either make use of pixel information extracted from the images, analyze contextual information such as capture time and focal aperture, or use both to determine a proper subset of photos. However, these approaches miss the most important factor in the photo selection process: the users. The goal of our approach is to consider the user's individual interest. By recording and analyzing gaze information from a user viewing a photo collection, we can obtain information on the user's interest and use this information in the creation of a personal photo selection. In a controlled experiment with 33 participants, we show that the selections can be significantly improved over a baseline approach by up to 22% when taking individual viewing behavior into account. We also obtained significantly better results for photos taken at an event participants were involved in, compared to photos from another event. \\ ","shortAbstract":"Manually selecting subsets of photos from large collections in order t","id":"pn405"},"session":"Methods and Models: The Eyes Have It","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn405"},"pn404":{"lastUpdateTime":1389222230397,"subcommitteeSplit":"C","labels":{"text entry":{"checked":false,"lastUpdateTime":1386528713526,"dislikes":[],"label":"text entry","lastTimeUpdated":1386526695262,"likes":[]},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386526929108,"label":"Empirical Methods, Quantitative"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526692988,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"User and Cognitive models":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527087000,"label":"User and Cognitive models"},"Evaluation methods":{"checked":false,"lastUpdateTime":1386527071931,"dislikes":[],"label":"Evaluation methods","lastTimeUpdated":1386526712589,"likes":[]},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386526202812,"checked":true,"likes":["tjvg@di.fc.ul.pt"],"label":"Text Entry"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486658}},"creationTime":225,"content":{"authorList":["Luis A. Leiva, ITI/DSIC, Universitat Politcnica de Valncia","Germn Sanchis-Trilles, Universitat Politcnica de Valncia"],"title":"Representatively Memorable: Sampling the Right Phrase Set to Get the Text Entry Experiment Right","paperOrNote":"Note","fullAbstract":"In text entry experiments, memorability is a desired property of the phrases used as stimuli. Unfortunately, to date there is no automated method to achieve this effect. As a result, researchers have to use either manually curated English-only phrase sets or sampling procedures that do not guarantee phrases being memorable. In response to this need, we present a sampling method based on two core ideas: a multiple regression model over language-independent features, and the statistical analysis of the corpus from which phrases will be drawn. Our results show that researchers can finally use a method to successfully curate their own stimuli targeting potentially any language or domain. The source code as well as our phrase sets are publicly available for download.","shortAbstract":"In text entry experiments, memorability is a desired property of the p","id":"pn404"},"session":"UIST: Text Entry and Evaluation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn404"},"pn664":{"lastUpdateTime":1389236450714,"subcommitteeSplit":"B","labels":{"Development Tools / Toolkits / Programming Environments":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Development Tools / Toolkits / Programming Environments"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446341}},"creationTime":431,"content":{"authorList":["Austin Henley, University of Memphis","Scott Fleming, University of Memphis"],"title":"The Patchworks Code Editor: Toward Faster Navigation with Less Code Arranging and Fewer Navigation Mistakes","paperOrNote":"Paper","fullAbstract":"Increasingly, people are faced with navigating large information spaces, and making such navigation efficient is of paramount concern. In this paper, we focus on the problems programmers face in navigating large code bases, and propose a novel code editor, Patchworks, that addresses the problems. In particular, Patchworks leverages two new interface idioms---the patch grid and the ribbon---to help programmers navigate more quickly, make fewer navigation errors, and spend less time arranging their code. To validate Patchworks, we conducted a user study that compared Patchworks to two existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were able to navigate significantly faster than with Eclipse (and comparably with Code Bubbles), (2) that programmers using Patchworks made significantly fewer navigation errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks spent significantly less time arranging their code than with Code Bubbles (and comparably with Eclipse).","shortAbstract":"Increasingly, people are faced with navigating large information space","id":"pn664"},"session":"Systems: Development Tools","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn664"},"pn887":{"lastUpdateTime":1388766330700,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu"],"lastUpdateTime":1386522367521,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Design requirements":{"dislikes":[],"lastTimeUpdated":1386522853728,"checked":true,"likes":[],"label":"Design requirements"},"Emotion and Affective User Interface":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522300318,"label":"Emotion and Affective User Interface"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu","wendyju@stanford.edu","aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Third World HCI":{"dislikes":[],"lastTimeUpdated":1386522884099,"checked":true,"likes":[],"label":"Third World HCI"},"Health Care":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu","wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Health Care"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu"],"lastUpdateTime":1386522324057,"label":"Computer-Mediated Communication"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["reinecke@umich.edu"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Third World design":{"dislikes":[],"lastTimeUpdated":1386522871172,"checked":true,"likes":[],"label":"Third World design"},"Transnational HCI":{"dislikes":[],"lastTimeUpdated":1386522637310,"checked":true,"likes":[],"label":"Transnational HCI"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu","silvia.lindtner@gmail.com"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755901}},"creationTime":616,"content":{"authorList":["Deana Brown, Georgia Institute of Technology","Victoria Ayo, Georgia Institute of Technology","Rebecca Grinter, Georgia Institute of Technology"],"title":"Immigrant Womens Traditional Practices in Managing Health and Wellness: Opportunities for HCI","paperOrNote":"Paper","fullAbstract":"Women comprise nearly half of the immigrant population worldwide and are susceptible to a wider range of health challenges compared to immigrant men. We present the findings of four participatory design sessions with immigrant women from the Caribbean to identify health and wellness challenges they faced and to conceptualize technologies to help them manage these issues. Stress, dietary challenges (specifically obesity), mental health care, and domestic abuse, as identified by the women, form the focal themes for the design sessions. Their solutions included rebuilding the support structure, reducing stressors through entertainment and relaxation and encouraging positive gradational lifestyle changes. In conceiving health and wellness technologies for immigrant women, our work highlights opportunities for HCI to consider the role of others (and who benefits), the role of culture and traditional practices in shaping designs, and the role of the design itself in highlighting opportunities for further health education.  ","shortAbstract":"Women comprise nearly half of the immigrant population worldwide and a","id":"pn887"},"session":"Health: HealthyCHI","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn887"},"pn884":{"lastUpdateTime":1389236648218,"subcommitteeSplit":"A","labels":{"Social Computing":{"checked":false,"lastUpdateTime":1386526363505,"dislikes":[],"label":"Social Computing","lastTimeUpdated":1386523573773,"likes":[]},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523559362,"label":"Usability Testing and Evaluation"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526303164,"label":"User Interface Design"},"Online Comments":{"dislikes":[],"lastTimeUpdated":1386530617021,"checked":true,"likes":[],"label":"Online Comments"},"Tutorials":{"dislikes":[],"lastTimeUpdated":1386523547147,"checked":true,"likes":[],"label":"Tutorials"},"User Studies":{"checked":false,"dislikes":[],"likes":["quintana@umich.edu"],"lastUpdateTime":1386523552793,"label":"User Studies"},"Tagging":{"dislikes":[],"lastTimeUpdated":1386530603667,"checked":true,"likes":[],"label":"Tagging"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188184}},"creationTime":613,"content":{"authorList":["Andrea Bunt, University of Manitoba","Patrick Dubois, University of Manitoba","Ben Lafreniere, University of Waterloo","Michael Terry, University of Waterloo","David Cormack, "],"title":"TaggedComments: Promoting and Integrating User Comments in Online Application Tutorials","paperOrNote":"Paper","fullAbstract":"Prior research suggests that user comments posted to popular online tutorials constitute a rich additional information source.  While these user comments may provide useful information, current designs for displaying user comments on tutorial webpages do little to support their use. Instead, comments are separated from the tutorial content they reference and are often displayed in reverse-chronological order according to post date. In this paper, we propose and evaluate the TaggedComments system, a new approach to displaying comments that users post to online tutorials.  Using tags supplied by the users when they submit their comments, TaggedComments seeks to enhance the role of user comments by 1) improving the visibility of user comments, 2) allowing users to personalize their use of the comments according to their particular information needs, and 3) providing direct access to potentially helpful comments from the tutorial content. A laboratory evaluation with 16 participants shows that, in comparison to the standard comment layout, TaggedComments significantly improves users subjective impressions of comment utility, and has positive impacts on users comment searching behaviour.","shortAbstract":"Prior research suggests that user comments posted to popular online tu","id":"pn884"},"session":"Systems: Tutorials","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn884"},"pn883":{"lastUpdateTime":1389285431303,"subcommitteeSplit":"A","labels":{"Play":{"dislikes":[],"lastTimeUpdated":1386523612845,"checked":true,"likes":[],"label":"Play"},"Video Analysis":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Analysis"},"Video Content / Communications":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Content / Communications"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526653864,"label":"User Studies"},"Children":{"checked":true,"dislikes":[],"likes":["hilary.hutchinson@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526671741,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188224}},"creationTime":612,"content":{"authorList":["Maayan Cohen, Ontario College of Art and Design","Kody Dillman, University of Calgary","Haley MacLeod, University of Indiana","Anthony Tang, University of Calgary","Seth Hunter, MIT Media Lab"],"title":"OneSpace: Shared Visual Scenes for Active Freeplay","paperOrNote":"Note","fullAbstract":"Children engage in free play for emotional, physical and social development. To support free play between physically remote playmates, researchers have used videoconferencing tools. We show that the configuration of the video conferencing setup affects play. Specifically, we show that a shared visual scene configuration promotes fundamentally active forms of engaged, co-operative play.","shortAbstract":"Children engage in free play for emotional, physical and social develo","id":"pn883"},"session":"Social: Connecting over Video","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn883"},"pn395":{"lastUpdateTime":1389238262241,"subcommitteeSplit":"","labels":{"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["davidmcgookin@gmail.com","steimle@media.mit.edu","bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Augmented Reality and Projection":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525931076,"label":"Augmented Reality and Projection"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644749}},"creationTime":217,"content":{"authorList":["Florian Heller, RWTH Aachen University","Aaron Krmer, RWTH Aachen University","Jan Borchers, RWTH Aachen University"],"title":"Simplifying Orientation Measurement for Mobile Audio Augmented Reality Applications","paperOrNote":"Paper","fullAbstract":"Audio augmented reality systems overlay the physical world with a virtual audio space. \\ Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. \\ To achieve this, additional hardware is required to get necessary information about the location and orientation of the user's head. \\ In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. \\ Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. \\  \\ To verify this approach, we present two studies:  \\ Our first study examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. \\ Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. \\ We found that when navigating close to sound sources head tracking is necessary, but that it can be replaced by device tracking in larger or more explorative usage scenarios. \\ These findings help reduce the technical complexity of certain audio augmented reality applications, and enable their wider dissemination as mobile software-only apps.","shortAbstract":"Audio augmented reality systems overlay the physical world with a virt","id":"pn395"},"session":"Art: Museum Experience","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn395"},"pn399":{"lastUpdateTime":1389236520278,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386521773080,"checked":true,"likes":["elainemayhuang@gmail.com"],"label":"Field Study"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["jonfroehlich@gmail.com","rob.comber@ncl.ac.uk","hazas@comp.lancs.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"citizen science":{"dislikes":[],"lastTimeUpdated":1386521835583,"checked":true,"likes":[],"label":"citizen science"},"Sustainability":{"checked":false,"dislikes":[],"likes":["jonfroehlich@gmail.com","elainemayhuang@gmail.com"],"lastUpdateTime":1386522662877,"label":"Sustainability"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"User Studies":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com"],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446303}},"creationTime":221,"content":{"authorList":["Stuart Moran, The University of Nottingham","Nadia Pantidi, The University of Nottingham","Tom Rodden, ","Alan Chamberlain, The University of Nottingham","Chloe Griffiths, Coed Phoenix Nature Reserve","Davide Zilli, The University of Southampton","Geoff Merrett, The University of Southampton","Alex Rogers, The University of Southampton"],"title":"Listening to the Forest and its Curators: Lessons Learnt from a Bioacoustic Smartphone Application Deployment","paperOrNote":"Paper","fullAbstract":"Our natural environment is complex and sensitive, and is home to a number of species on the verge of extinction. Surveying is one approach to their preservation, and can be supported by technology. This paper presents the deployment of a smartphone-based citizen science biodiversity application. Our findings from interviews with members of the biodiversity community revealed a tension between the technology and their established working practices. From our experience, we present a series of general guidelines for those designing citizen science apps.","shortAbstract":"Our natural environment is complex and sensitive, and is home to a num","id":"pn399"},"session":"HCI4D: doing the right thing - ethics","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn399"},"pn241":{"lastUpdateTime":1389222210195,"subcommitteeSplit":"","labels":{"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"game":{"dislikes":[],"lastTimeUpdated":1386525553427,"checked":true,"likes":[],"label":"game"},"Tangible UIs":{"dislikes":[],"lastTimeUpdated":1386526093687,"checked":true,"likes":["pierre.dragice@gmail.com"],"label":"Tangible UIs"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":["forlines@alumni.cmu.edu","benko@microsoft.com","bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"Tangibles":{"checked":false,"lastUpdateTime":1386528514728,"dislikes":[],"label":"Tangibles","lastTimeUpdated":1386525167415,"likes":[]},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644715}},"creationTime":105,"content":{"authorList":["Clment Pillias, CNAM","Raphal Robert-Bouchard, CNAM","Guillaume Levieux, CNAM"],"title":"Designing Tangible Video Games: Lessons Learned from the Sifteo Cubes","paperOrNote":"Note","fullAbstract":"In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible interface for multiplayer games. \\ We discuss how this game exploits the platform's interface to transfer some of the game mechanics into the non-digital world, and how this affects both the player's experience and the design process. \\ We present the technical limitations encountered during game development and analyze video recordings of play sessions with regard to the play strategies developed by the players. \\ Then, we discuss how two properties of tangible game platforms, and particularly Sifteo Cubes, influence both the game design process and the player experience. \\ We advocate that such platforms provide players with more freedom and relatedness, while helping to create an easy-to-learn and customizable gameplay, despite their own design limitations.  \\ ","shortAbstract":"In this paper, we present a collaborative game designed for Sifteo Cub","id":"pn241"},"session":"UIST: Tangibles","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn241"},"pn714":{"lastUpdateTime":1389220864045,"subcommitteeSplit":"C","labels":{"Technology adoption":{"dislikes":[],"lastTimeUpdated":1386527458474,"checked":true,"likes":["kgajos@eecs.harvard.edu"],"label":"Technology adoption"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526911049,"label":"User Studies"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["tjvg@di.fc.ul.pt"],"lastUpdateTime":1386527130274,"label":"Universal (or Disability)  Access"},"Handheld Devices and Mobile Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527140092,"label":"Handheld Devices and Mobile Computing"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386526491196,"checked":true,"likes":["awaller@computing.dundee.ac.uk"],"label":"Wearables"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486625}},"creationTime":473,"content":{"authorList":["Hanlu Ye, Wellesley College","Meethu Malu, University of Maryland","Uran Oh, University of Maryland","Leah Findlater, University of Maryland"],"title":"Current and Future Mobile and Wearable Device Use by People With and Without Visual Impairments","paperOrNote":"Paper","fullAbstract":"With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies. For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing. To explore the potential impacts of such technology, we conducted two studies with visually impaired and sighted participants: an online survey with 215 participants and an interview and design probe study with 20 participants. Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues. Additionally, we show that users with visual impairments responded more positively than sighted users to two wearable scenarios (a wristband or ring and a glasses-based device). Discussions on projected use suggest that small, easily accessible, and discreet wearable input could positively impact the ability for people with visual impairments to access information on the go and to participate in certain social interactions.","shortAbstract":"With the increasing popularity of mainstream wearable devices, it is c","id":"pn714"},"session":"Health: Accessibility","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn714"},"pn245":{"lastUpdateTime":1389221922387,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["tjvg@di.fc.ul.pt"],"lastUpdateTime":1386527199302,"label":"Older Adults"},"Social Network Sites":{"dislikes":[],"lastTimeUpdated":1386528840307,"checked":true,"likes":[],"label":"Social Network Sites"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527384946,"label":"User-Centered Design / Human-Centered Design"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527381944,"label":"Usability Testing and Evaluation"},"Social Computing and Social Navigation":{"dislikes":[],"lastTimeUpdated":1386526797994,"checked":true,"likes":["erinacarroll@gmail.com"],"label":"Social Computing and Social Navigation"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527386731,"label":"User Studies"},"Social Networking":{"checked":false,"lastUpdateTime":1386528842469,"dislikes":[],"label":"Social Networking","lastTimeUpdated":1386527512007,"likes":[]},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486599}},"creationTime":107,"content":{"authorList":["Chris Norval, University of Dundee","John Arnott, University of Dundee","Vicki Hanson, Rochester Institute of Technology"],"title":"What's on Your Mind? Investigating Recommendations for Inclusive Social Networking and Older Adults","paperOrNote":"Paper","fullAbstract":"Social networking sites (SNSs) are becoming increasingly popular as a method for social interaction. While research has reported benefits associated with components of SNS usage, a digital divide has emerged between younger and older users. SNSs can be useful for communicating with family members and helping one feel digitally included; however, there is a wide range of reasons why many older adults choose not to use this kind of technology. In this paper we present a series of user studies investigating the barriers and challenges that SNSs can present to older users. These user studies led to the derivation of user recommendations to mitigate these barriers. The recommendations were then evaluated within a comparative evaluation which involved 25 older adults completing tasks on two user interface (UI) versions of a simulation SNS. We present the recommendations and the methods of their creation and evaluation. Implications for developers of SNSs are discussed.","shortAbstract":"Social networking sites (SNSs) are becoming increasingly popular as a ","id":"pn245"},"session":"Health: Older Adults 2","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn245"},"pn248":{"lastUpdateTime":1389285590040,"subcommitteeSplit":"B","labels":{"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":["egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Universal (or Disability)  Access":{"checked":false,"lastUpdateTime":1386538139400,"dislikes":[],"label":"Universal (or Disability)  Access","lastTimeUpdated":1386522491467,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["alexander.de.luca@ifi.lmu.de","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"ICTD":{"dislikes":[],"lastTimeUpdated":1386522028729,"checked":true,"likes":["jonfroehlich@gmail.com","egelman@cs.berkeley.edu","nithyas@gmail.com"],"label":"ICTD"},"Internationalization / Localization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Internationalization / Localization"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446277}},"creationTime":110,"content":{"authorList":["Simon Robinson, Swansea University","Jennifer Pearson, Swansea University","Matt Jones, Swansea University"],"title":"AudioCanvas: Internet-Free Interactive Audio Photos","paperOrNote":"Note","fullAbstract":"In this paper we present a novel interaction technique that helps to make textual information more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which are often costly in developing regions. We show the value of the technique via user evaluations in both a rural Indian village and a South African township.","shortAbstract":"In this paper we present a novel interaction technique that helps to m","id":"pn248"},"session":"HCI4D: Multilingual Communication","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn248"},"pn718":{"lastUpdateTime":1389591412661,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Gaze":{"dislikes":[],"lastTimeUpdated":1386525697086,"checked":true,"likes":["dan@microsoft.com","bulling@mpi-inf.mpg.de","benko@microsoft.com","wolfgang@cse.yorku.ca"],"label":"Gaze"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":["bulling@mpi-inf.mpg.de"],"lastUpdateTime":123456789,"label":"Performance Metrics"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644787}},"creationTime":475,"content":{"authorList":["Xianta Jiang, Zhejiang University","M Stella Atkins, Simon Fraser University","Geoffrey Tien, Simon Fraser University","Roman Bednarik, University of Eastern Finland","Bin Zheng, University of Alberta"],"title":"Pupil Responses during Discrete Goal-directed Movements","paperOrNote":"Paper","fullAbstract":"Pupil size is known to correlate with the changes of cognitive task workloads, but the pupillary response to requirements of basic goal-directed motor tasks involved in human-machine interactions is not yet clear. This work conducted a user study to investigate the pupil dilations during aiming in a tele-operation setting, with the purpose of better understanding how the changes in task requirements are reflected by the changes of pupil size. The task requirements, managed by Fitts index of difficulty (ID), i.e. the size and distance of the targets, were varied between tasks and pupil responses to different task IDs were recorded. The results showed that pupil diameter can be employed as an indicator of task requirements in goal-directed movements, i.e., higher task difficulty evoked higher peak pupil dilation that occurred with longer latency. These findings contribute to the foundation for developing methods to objectively evaluate interactive task requirements in real-time using pupil parameters during goal-directed movements in HCI.","shortAbstract":"Pupil size is known to correlate with the changes of cognitive task wo","id":"pn718"},"session":"Methods and Models: The Eyes Have It","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn718"},"pn435":{"lastUpdateTime":1389237026654,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Visualization"},"search":{"checked":false,"lastUpdateTime":1386530789344,"dislikes":[],"label":"search","lastTimeUpdated":1386527774248,"likes":[]},"User Interface Design":{"checked":true,"dislikes":[],"likes":["dominicfurniss@gmail.com","marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"User Interface Design"},"Interaction techniques":{"checked":false,"lastUpdateTime":1386530496784,"dislikes":[],"label":"Interaction techniques","lastTimeUpdated":1386527754196,"likes":[]},"Desktop interactions":{"dislikes":[],"lastTimeUpdated":1386530481392,"checked":true,"likes":[],"label":"Desktop interactions"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165006}},"creationTime":253,"content":{"authorList":["Thomas Geymayer, Graz University of Technology","Markus Steinberger, Graz University of Technology","Dieter Schmalstieg, Graz University of Technology","Marc Streit, Johannes Kepler University Linz","Alexander Lex, Harvard University"],"title":"Show me the Invisible: Guidance to Hidden Content","paperOrNote":"Paper","fullAbstract":"Content on modern computer screens is displayed within the boundaries of windows. In many cases, however, not all content relevant for a task is immediately accessible to a user: It can be distributed over multiple windows that can occlude each other or can be minimized. Also, not all content fits into the viewport of a window, so that part of the content is \"scrolled away\". In search tasks, the efficient retrieval of such content is important. Current software, however, only provides limited support to visualize occurrences of entries outside of the current viewport within individual applications, and rarely supports crossing application boundaries. In this work, we introduce novel visualization methods to guide users to such hidden content. \\ Our method generates awareness for occluded content covered by other windows and inaccessible content outside an application's viewport using a see-through visualization. For content outside the viewport, we introduce a smartly stitched preview, which is displayed on-demand. We use visual links, i.e., line connections between the elements, to connect individual occurrences, off-screen visualizations, etc. \\ We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.","shortAbstract":"Content on modern computer screens is displayed within the boundaries ","id":"pn435"},"session":"Systems: GUIs","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn435"},"pn2483":{"lastUpdateTime":1389236270605,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["dan@danielashbrook.com"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Accessibility":{"checked":false,"lastUpdateTime":1386536589920,"dislikes":[],"label":"Accessibility","lastTimeUpdated":1386523864684,"likes":[]},"Facebook":{"dislikes":[],"lastTimeUpdated":1386524075744,"checked":true,"likes":[],"label":"Facebook"},"Vision-Impaired Users":{"checked":false,"lastUpdateTime":1386541247916,"dislikes":[],"label":"Vision-Impaired Users","lastTimeUpdated":1386524638956,"likes":[]},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081876}},"creationTime":1993,"content":{"authorList":["Shaomei Wu, Facebook Inc.","Lada Adamic, Facebook Inc","Cameron Marlow, Facebook Inc"],"title":"Visually Impaired Users on an Online Social Network","paperOrNote":"Paper","fullAbstract":"In this paper we present the first large-scale empirical study of how visually impaired people use online social networks, particularly Facebook. We identify a sample of 50K visually impaired users, and study the activities they perform, the content they produce, and the friendship networks they build on Facebook. We find that visually impaired users participate on Facebook (e.g. status updates, comments, likes) as much as the general population, and receive more feedback (comments and likes) on their content. By analyzing the content produced by visually impaired users, we find that they openly share their experience and issues related to vision impairment. We also identify distinctive patterns in their language and technology usage. We also show that, compared to other users, visually impaired users have  smaller social networks, but such differences have decreased over time. Our findings have implications for improving the utility and usability of online social networks for visually impaired users, and can shed light on the design of more accessible sociotechnical systems. \\ ","shortAbstract":"In this paper we present the first large-scale empirical study of how ","id":"pn2483"},"session":"Social: Connecting through Social Media","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn2483"},"pn2487":{"lastUpdateTime":1389221516569,"subcommitteeSplit":"A","labels":{"Physical Therapy":{"dislikes":[],"lastTimeUpdated":1386523244336,"checked":true,"likes":["mentis@umbc.edu","a.parker@neu.edu"],"label":"Physical Therapy"},"Pervasive Health":{"dislikes":[],"lastTimeUpdated":1386523251265,"checked":true,"likes":[],"label":"Pervasive Health"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Probes":{"dislikes":[],"lastTimeUpdated":1386536545870,"checked":true,"likes":[],"label":"Probes"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188234}},"creationTime":1997,"content":{"authorList":["Kevin Huang, Carnegie Mellon University","Patrick Sparto, UPMC","Sara Kiesler, HCII, Carnegie Mellon University, Pittsburgh","Dan Siewiorek, Carnegie Mellon University","Asim Smailagic, Carnegie Mellon University"],"title":"SenseCap: A Technology Probe for In-Home Wearable Computer-Assisted Physical Therapy Systems","paperOrNote":"Paper","fullAbstract":"Physical therapists could make better treatment decisions if they had accurate patient home exercise data but today this information is only available from patient self report. A more accurate source of data could be gained from wearable computing designed for physical therapy exercise support. Existing systems have been tested in the lab but we lack evidence on their feasibility in patient homes. We present SenseCap, a technology probe deployed for seven days in ten physical therapy patients homes. SenseCap is a representative wearable physical therapy support system that gathers patient exercise compliance and performance data. The exercise data are summarized in charts on an iPad Dashboard for physical therapists to view when patients return to the clinic. In this paper, we present the results of the technology probe, show some in-home patient exercise data gathered by the probe, and make design recommendations based on patient and physical therapist responses. ","shortAbstract":"Physical therapists could make better treatment decisions if they had ","id":"pn2487"},"session":"Health: HCI for Rehabilitation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2487"},"pn2488":{"lastUpdateTime":1389221709637,"subcommitteeSplit":"","labels":{"social media at work":{"dislikes":[],"lastTimeUpdated":1386522765621,"checked":true,"likes":[],"label":"social media at work"},"social media":{"dislikes":[],"lastTimeUpdated":1386521614436,"checked":true,"likes":["dmrussell@gmail.com"],"label":"social media"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523505045,"label":"Social Computing and Social Navigation"},"enterprise":{"dislikes":[],"lastTimeUpdated":1386521617103,"checked":true,"likes":["teevan@gmail.com","dmrussell@gmail.com"],"label":"enterprise"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Office and Workplace"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556729}},"creationTime":1998,"content":{"authorList":["N. Sadat Shami, IBM","Jeffrey Nichols, IBM Research","Jilin Chen, IBM Research"],"title":"Social Media Participation and Performance at Work: A Longitudinal Study","paperOrNote":"Note","fullAbstract":"The use of social media at work is gaining traction, and there is evidence to suggest that various benefits accrue from its use. Yet the relationship between using social media at work and employee performance has not been analyzed. Through a study of 75,747 employees of a large global company over the course of 3 years, we find that some social media usage (number of forum posts, forum post length, and status update length) was positively associated with performance ratings. The study is one of the first to show the relationship among different forms of social media use and performance ratings. ","shortAbstract":"The use of social media at work is gaining traction, and there is evid","id":"pn2488"},"session":"Social: Lonely, Sad and Awful","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn2488"},"pn2489":{"lastUpdateTime":1389236520278,"subcommitteeSplit":"B","labels":{"behavioural economics":{"dislikes":[],"lastTimeUpdated":1386524245645,"checked":true,"likes":[],"label":"behavioural economics"},"Surveys":{"dislikes":[],"lastTimeUpdated":1386522918235,"checked":true,"likes":[],"label":"Surveys"},"financial incentives":{"dislikes":[],"lastTimeUpdated":1386524239895,"checked":true,"likes":[],"label":"financial incentives"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Incentives":{"dislikes":[],"lastTimeUpdated":1386522098344,"checked":true,"likes":[],"label":"Incentives"},"Motiviation for Participation":{"dislikes":[],"lastTimeUpdated":1386522114956,"checked":true,"likes":[],"label":"Motiviation for Participation"},"Social Psychology":{"dislikes":[],"lastTimeUpdated":1386522985347,"checked":true,"likes":["coye.cheshire@gmail.com"],"label":"Social Psychology"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Marketing / Market Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522226952,"label":"Marketing / Market Research"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032760}},"creationTime":1999,"content":{"authorList":["Andrew Fiore, Facebook","Coye Cheshire, School of Information - UC Berkeley","Lindsay Shaw Taylor, UC Berkeley","G.A. Mendelsohn, UC Berkeley"],"title":"Incentives to Participate in Online Research: An Experimental Examination of Surprise Incentives","paperOrNote":"Paper","fullAbstract":"The recruitment of participants for online survey research presents many challenges. In this work, we present four experiments examining how two different kinds of surprise financial incentives affect the rate of participation in a longitudinal study when participants are initially solicited with either an appeal to intrinsic motivation to participate in research or one that also offers extrinsic financial incentives. We find that unexpected financial incentives (existence surprises) presented to people who click a recruitment advertisement focused on intrinsic incentives lead to a lower recruitment rate than do the same incentives offered to those who clicked an advertisement that led them to expect it. We interpret this result as a possible example of crowding out of intrinsic motivation. However, when potential participants expect a financial incentive, surprising them with a higher amount (amount surprises) yields a higher recruitment rate. Neither type of surprise affects ongoing participation, measured as the number of questions and questionnaires completed over the course of the study. ","shortAbstract":"The recruitment of participants for online survey research presents ma","id":"pn2489"},"session":"HCI4D: doing the right thing - ethics","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2489"},"pn866":{"lastUpdateTime":1389238477951,"subcommitteeSplit":"A","labels":{"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Health Care":{"checked":true,"dislikes":[],"likes":["carmster@gmail.com"],"lastUpdateTime":123456789,"label":"Health Care"},"Personas":{"dislikes":[],"lastTimeUpdated":1386522948334,"checked":true,"likes":[],"label":"Personas"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Children":{"checked":true,"dislikes":[],"likes":["carmster@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711738}},"creationTime":596,"content":{"authorList":["Pontus Wrnestl, School of Information Science, Computer and Electrical Engineering","Petra Svedberg, School of Social and Health Sciences","Jens Nygren, School of Social and Health Sciences"],"title":"Co-constructing Child Personas for Health-Promoting Services with Vulnerable Children","paperOrNote":"Paper","fullAbstract":"The availability of health-promoting resources for young children diagnosed with cancer who are transitioning from intensive care to everyday life is scarce. In the context of designing digital peer support services for children who are considered vulnerable due to clinical and age-related aspects, there are several challenges that put critical requirements on a user-centered design process.  This paper reports on a new method for co-constructing child-personas that are tailored for developing health-promoting services where empirical data is restricted due to practical and ethical reasons. In particular, we are proposing to focus children design workshop sessions on salutogenesis, and complement this with a pathogenic perspective by interviewing healthcare professionals and parents. We also introduce the use of proxy personas, and redemption stories in the form of comicboards, both collaboratively constructed by children and designers through storytelling. By applying four progressive steps of data collection and analysis we arrive at authentic child-personas that can be used to design and develop health-promoting services for children in vulnerable life stages.","shortAbstract":"The availability of health-promoting resources for young children diag","id":"pn866"},"session":"Design: Participatory Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn866"},"pn862":{"lastUpdateTime":1389222136220,"subcommitteeSplit":"A","labels":{"Social Media":{"checked":false,"lastUpdateTime":1386528871927,"dislikes":[],"label":"Social Media","lastTimeUpdated":1386521379060,"likes":["mark.hancock@uwaterloo.ca"]},"Organizational Culture / Organizational Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Organizational Culture / Organizational Planning"},"Office and Workplace":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524798804,"label":"Office and Workplace"},"social media":{"dislikes":[],"lastTimeUpdated":1386528869899,"checked":true,"likes":[],"label":"social media"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524793801,"label":"Empirical Methods, Qualitative"},"The Pros versus the Citizens":{"dislikes":[],"lastTimeUpdated":1386524899785,"checked":true,"likes":[],"label":"The Pros versus the Citizens"},"Trust":{"dislikes":[],"lastTimeUpdated":1386524914689,"checked":true,"likes":[],"label":"Trust"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946740}},"creationTime":592,"content":{"authorList":["Andrew Garbett, Newcastle University","Rob Comber, Newcastle University","Paul Egglestone, University of Central Lancashire","Maxine Glancy, BBC","Patrick Olivier, Newcastle University"],"title":"Finding Real People: Trust and Diversity in the Interface Between Professional and Citizen Journalists","paperOrNote":"Paper","fullAbstract":"The increase of social media and web blogs has enabled a new generation of citizen journalism, providing new perspectives into local communities. However traditional news organisations are currently struggling to incorporate this new form of journalism into their existing organisational workflow and as a result are potentially neglecting community perspectives. We explore the current issues faced by professional journalists when searching for reliable and reputable local news sources as well as the perceived role of citizen journalists within a large news organisation. We present an analysis from 10 interviews with professional journalists from a national news organisation. From this analysis we present a set of design implications for building systems that support interaction between citizen and professional journalists in order to encourage participatory news production and diversify national news perspectives.","shortAbstract":"The increase of social media and web blogs has enabled a new generatio","id":"pn862"},"session":"Social: Social News","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn862"},"pn2284":{"lastUpdateTime":1388766320872,"subcommitteeSplit":"A","labels":{"Handheld Devices and Mobile Computing":{"dislikes":[],"lastTimeUpdated":1386523191676,"checked":true,"likes":[],"label":"Handheld Devices and Mobile Computing"},"twitter":{"checked":false,"lastUpdateTime":1386528674409,"dislikes":[],"label":"twitter","lastTimeUpdated":1386523195301,"likes":[]},"Twitter":{"dislikes":[],"lastTimeUpdated":1386523744514,"checked":true,"likes":[],"label":"Twitter"},"Health Care":{"checked":false,"dislikes":[],"likes":["J.Good@sussex.ac.uk"],"lastUpdateTime":1386523142323,"label":"Health Care"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523163434,"label":"Social Computing and Social Navigation"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523151004,"label":"User Studies"},"Children":{"checked":true,"dislikes":[],"likes":["mentis@umbc.edu","a.parker@neu.edu"],"lastUpdateTime":123456789,"label":"Children"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188164}},"creationTime":1827,"content":{"authorList":["Hyewon Suh, University of Washington","John Porter, University of Washington","Alexis Hiniker, University of Washington","Julie Kientz, University of Washington"],"title":"@BabySteps: Design and Evaluation of a System for using Twitter for Tracking Childrens Developmental Milestones","paperOrNote":"Paper","fullAbstract":"The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their childrens progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.","shortAbstract":"The tracking of developmental milestones in young children is an impor","id":"pn2284"},"session":"Health: Health and Everyday Life","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2284"},"pn1859":{"lastUpdateTime":1388766268669,"subcommitteeSplit":"A","labels":{"Health Care":{"checked":true,"dislikes":[],"likes":["carmster@gmail.com"],"lastUpdateTime":123456789,"label":"Health Care"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["ledantec@gatech.edu"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711788}},"creationTime":1458,"content":{"authorList":["Diana Kusunoki, Drexel University","Aleksandra Sarcevic, Drexel University","Nadir Weibel, University of California, San Diego","Ivan Marsic, Rutgers University","Zhan Zhang, Drexel University","Genevieve Tuveson, Children's National Medical Center","Randall Burd, Children's National Medical Center"],"title":"Balancing Design Tensions: Iterative Display Design to Support Ad Hoc and Interdisciplinary Medical Teamwork","paperOrNote":"Paper","fullAbstract":"In this paper, we describe how we developed an information display prototype for trauma resuscitation teams based on design ideas and feedback from clinicians. Our approach is grounded in participatory design and action research, emphasizing the importance of gaining long-term commitment from clinicians in system development. Through a series of participatory design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified the main information features to include on our display. Our results focus on how we balanced the design tensions that emerged when addressing the ad hoc, hierarchical, and interdisciplinary nature of trauma teamwork. We discuss the implications of balancing role-based differences for each information feature, as well as two major design tensions: role-based vs. team-based displays and activity-based vs. state-based designs.","shortAbstract":"In this paper, we describe how we developed an information display pro","id":"pn1859"},"session":"Health: Interfaces for Care and Support","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1859"},"pn1850":{"lastUpdateTime":1388786266496,"subcommitteeSplit":"B","labels":{"Older Adults":{"checked":true,"dislikes":[],"likes":["obristmarianna@gmail.com","l.ciolfi@shu.ac.uk","dr.mark.j.perry@googlemail.com"],"lastUpdateTime":123456789,"label":"Older Adults"},"Social and Legal issues":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"is sustainability human centered?":{"dislikes":[],"lastTimeUpdated":1386523068324,"checked":true,"likes":[],"label":"is sustainability human centered?"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":["obristmarianna@gmail.com","l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032729}},"creationTime":1451,"content":{"authorList":["Johanna Meurer, University","Martin Stein, University of Siegen","David Randall, University Siegen","Markus Rohde, University of Siegen","Volker Wulf, University of Siegen"],"title":"Social dependency and mobile autonomy   Supporting older adults mobility with ridesharing ICT","paperOrNote":"Paper","fullAbstract":"Alternative mobility modes for older adults are increasingly important for economic, ecological and social reasons. A promising option is ridesharing, defined as use of the same vehicle by two or more people traveling to a common desti-nation. In particular, mobile computer supported rideshar-ing provides a promising way to enlarge older adults mo-bility choices in addition to private driving and public transportation options. In order to understand the opportunities and obstacles of ridesharing from the elderly point of view, we conducted an ethnographical study. It turns out that mobile independence and decisional autonomy are key issues for their mobile wellbeing, which however, partially conflicts with common ridesharing concepts. Hence, we further analyze older adults strategies dealing with these conflicts and show that these strategies offer departure points to design ridesharing solutions which are better suited to the demands of older adults. ","shortAbstract":"Alternative mobility modes for older adults are increasingly important","id":"pn1850"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1850"},"pn340":{"lastUpdateTime":1389236481152,"subcommitteeSplit":"","labels":{"Agents and Intelligent Systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Agents and Intelligent Systems"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523629513,"label":"Empirical Methods, Quantitative"},"Software Engineering Methods and Processes - Mathematical/Formal":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Software Engineering Methods and Processes - Mathematical/Formal"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386522321751,"checked":true,"likes":["gabriela.avram@gmail.com"],"label":"crowdsourcing"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"Semi-autonomous systems":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Semi-autonomous systems"},"Annotation":{"dislikes":[],"lastTimeUpdated":1386523187923,"checked":true,"likes":["myriam.lewkowicz@utt.fr"],"label":"Annotation"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556715}},"creationTime":170,"content":{"authorList":["Jia Deng, University of Michigan","Olga Russakovsky, Stanford University","Jonathan Krause, Stanford University","Michael Bernstein, ","Alex Berg, UNC Chapel Hill","Li Fei-Fei, Stanford University"],"title":"Scalable multi-label annotation","paperOrNote":"Note","fullAbstract":"In this paper we discuss strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits (1) correlation between labels, (2) inherent grouping of labels into a semantic hierarchy, and (3) sparsity of the labels. A case study on the task of labeling 200 objects in 20,000 images demonstrates the effectiveness of this approach. The algorithm results in up to 5.93x reduction in human computation time compared to the naive method of querying a human annotator for the presence or absence of every object in every image.  ","shortAbstract":"In this paper we discuss strategies for scalable multi-label annotatio","id":"pn340"},"session":"CSCW: Document and Intertextuality","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn340"},"pn2399":{"lastUpdateTime":1389238477951,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528928764,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"Smartphones":{"dislikes":[],"lastTimeUpdated":1386529524474,"checked":true,"likes":["lorrie@acm.org"],"label":"Smartphones"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Privacy":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu","a.sasse@cs.ucl.ac.uk"],"lastUpdateTime":123456789,"label":"Privacy"},"phones":{"dislikes":[],"lastTimeUpdated":1386529517178,"checked":true,"likes":["lorrie@acm.org"],"label":"phones"},"Usable Security":{"dislikes":[],"lastTimeUpdated":1386526040549,"checked":true,"likes":["lorrie@acm.org"],"label":"Usable Security"},"Security":{"checked":true,"dislikes":[],"likes":["jfc@cs.berkeley.edu","egelman@cs.berkeley.edu","lorrie@acm.org"],"lastUpdateTime":123456789,"label":"Security"},"Development Tools / Toolkits / Programming Environments":{"dislikes":[],"lastTimeUpdated":1386522201030,"checked":true,"likes":["egelman@cs.berkeley.edu"],"label":"Development Tools / Toolkits / Programming Environments"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446292}},"creationTime":1923,"content":{"authorList":["Josh Tan, ","Khanh Nguyen, University of California, Riverside","Michael Theodorides, ","Heidi Negron-Arroyo, University of Puerto Rico, Mayaguez","Christopher Thompson, University of California, Berkeley","Serge Egelman, University of California, Berkeley","David Wagner, University of California, Berkeley"],"title":"The Effect of Developer-Specified Explanations for Permission Requests on Smartphone User Behavior","paperOrNote":"Paper","fullAbstract":"In Apple's iOS 6, when an app requires access to a protected resource (e.g., location or photos), the user is prompted with a permission request that she can allow or deny.  These permission request dialogs include space for developers to optionally include strings of text to explain to the user why access to the resource is needed.  We examine how app developers are using this mechanism and the effect that it has on user behavior.  Through an online survey of 772 smartphone users, we show that permission requests that include explanations are significantly more likely to be approved.  At the same time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature by developers is relatively small: around 19% of permission requests include developer-specified explanations.  Finally, we surveyed 30 iOS developers to better understand why they do or do not use this feature.","shortAbstract":"In Apple's iOS 6, when an app requires access to a protected resource ","id":"pn2399"},"session":"Design: Participatory Design","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn2399"},"pn2129":{"lastUpdateTime":1389236351048,"subcommitteeSplit":"A","labels":{"design implication":{"dislikes":[],"lastTimeUpdated":1386535597321,"checked":true,"likes":[],"label":"design implication"},"research through design":{"dislikes":[],"lastTimeUpdated":1386523310309,"checked":true,"likes":[],"label":"research through design"},"Empirical Methods, Qualitative":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Empirical Methods, Qualitative"},"Understanding Design":{"dislikes":[],"lastTimeUpdated":1386523217090,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"Understanding Design"},"Design Research":{"checked":false,"lastUpdateTime":1386528423073,"dislikes":[],"label":"Design Research","lastTimeUpdated":1386522858567,"likes":[]},"design research":{"dislikes":[],"lastTimeUpdated":1386522849164,"checked":true,"likes":[],"label":"design research"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711722}},"creationTime":1693,"content":{"authorList":["Corina Sas, Lancaster University","Steve Whittaker, University of California at Santa Cruz"],"title":"Generating Design Knowledge through Design Research","paperOrNote":"Paper","fullAbstract":"A central tenet of HCI is that technology should be user-centric, with designs being based around social science findings about users. Nevertheless a repeated but critical challenge in interaction design is translating empirical findings into actionable ideas that inform design. Despite various concrete design methods aiming to bridge this gap, such knowledge informing design are still seen as problematic. However there has been little empirical exploration into what design researchers understand by such design knowledge, the functions and principles behind their creation. We report on interviews with twelve expert HCI design researchers probing: the roles and types of design knowledge, and the process of generating and evaluating them. We synthesize different types of design knowledge into a framework to guide their generation. Our findings identify a broader range than previously described, additional sources and heuristics supporting their development, as well some important evaluation criteria. We discuss the value of these findings and their implications for design research. ","shortAbstract":"A central tenet of HCI is that technology should be user-centric, with","id":"pn2129"},"session":"Design: Design Theory","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2129"},"pn2394":{"lastUpdateTime":1389591476714,"subcommitteeSplit":"B","labels":{"Analysis Methods (e.g. Task/Interaction Modeling)":{"dislikes":[],"lastTimeUpdated":1386522738663,"checked":true,"likes":[],"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"3D Interaction and Graphics":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522069579,"label":"3D Interaction and Graphics"},"Context-Aware Computing":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522071391,"label":"Context-Aware Computing"},"Interaction techniques":{"dislikes":[],"lastTimeUpdated":1386522672771,"checked":true,"likes":[],"label":"Interaction techniques"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522073519,"label":"User-Centered Design / Human-Centered Design"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386522710426,"checked":true,"likes":[],"label":"Multitouch"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522072556,"label":"User Interface Design"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386522140203,"label":"Multi-modal interfaces"},"User Studies":{"checked":true,"dislikes":[],"likes":["mmassimi@microsoft.com"],"lastUpdateTime":123456789,"label":"User Studies"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522142588,"label":"User Experience Design / Experience Design"},"Usability Research":{"checked":true,"dislikes":[],"likes":["oantti@mpi-inf.mpg.de","mmassimi@microsoft.com"],"lastUpdateTime":123456789,"label":"Usability Research"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032784},"was touch:grip before":{"label":"was touch:grip before","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1389106064995}},"creationTime":1919,"content":{"authorList":["Quan Nguyen, DFKI","Michael Kipp, University of Applied Sciences Augsburg"],"title":"Orientation Matters: Efficiency of translation-rotation multitouch tasks","paperOrNote":"Note","fullAbstract":" Theoretical models of interaction techniques like Fitts Law are \\   important tools for interaction designers. The multitouch technique of \\   translation and rotation with two fingers \\   is well explored. However, there are some unsolved \\   questions with regard to the optimal conditions under which this \\   technique functions best. Does it matter in which direction the \\   movement is oriented? Does parallel or sequential performance of the \\   two operations work best? This study attempts to answer this question \\   using a typical Fitts Law setup but with varying translation-rotation  \\   orientation combinations.  The results show that \\   right-oriented movements were faster and easier than \\   left-oriented ones. Movement combinations which went in different \\   directions (translation right, rotation left, and vice versa) were \\   less efficient, were found more tiresome by users and resulted in \\   more changes in strategies. Our findings can inform interaction  \\   design and contribute to theoretical adjustments to Fitts Law.","shortAbstract":" Theoretical models of interaction techniques like Fitts Law are \\   i","id":"pn2394"},"session":"Methods and Models: User Model 2","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2394"},"pn343":{"lastUpdateTime":1388776489997,"subcommitteeSplit":"","labels":{"Multitouch":{"dislikes":[],"lastTimeUpdated":1386532383453,"checked":true,"likes":["olwal@mit.edu"],"label":"Multitouch"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531816022,"checked":true,"likes":["rsodhi2@illinois.edu","tomer@moscovich.net","olwal@mit.edu"],"label":"Touch Input"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["rsodhi2@illinois.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Gestural Interaction":{"dislikes":[],"lastTimeUpdated":1386531993600,"checked":true,"likes":["rsodhi2@illinois.edu","tomer@moscovich.net"],"label":"Gestural Interaction"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840615}},"creationTime":173,"content":{"authorList":["Chris Harrison, Carnegie Mellon University","Robert Xiao, Carnegie Mellon University","Julia Schwarz, Carnegie Mellon University","Scott Hudson, Carnegie Mellon University"],"title":"TouchTools: Leveraging Familiarity and Skill with Physical Tools to Augment Touch Interaction","paperOrNote":"Note","fullAbstract":"The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on todays touch devices are simplistic, relying primarily on chording of the fingers: one-finger pan, two-finger click, four-finger swipe and similar. We propose that gestures design be inspired by the manipulation of real world artifacts  specifically tools. The result is a set of rich gestures for touch interaction that leverages user familiarity and fluency with real world objects. With only a few minutes of training on a proof-of-concept implementation, users were able to summon seven different virtual tools by replicating the appropriate real-world grasp with 96% accuracy.","shortAbstract":"The average person can skillfully manipulate a plethora of tools, from","id":"pn343"},"session":"Touch: Multitouchy Feely","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn343"},"pn431":{"lastUpdateTime":1388762117118,"subcommitteeSplit":"A","labels":{"search":{"dislikes":[],"lastTimeUpdated":1386523179233,"checked":true,"likes":[],"label":"search"},"eye tracking":{"dislikes":[],"lastTimeUpdated":1386523185239,"checked":true,"likes":[],"label":"eye tracking"},"World Wide Web and Hypermedia":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"World Wide Web and Hypermedia"},"Children":{"checked":true,"dislikes":[],"likes":["hilary.hutchinson@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523328212,"label":"User Studies"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188229}},"creationTime":250,"content":{"authorList":["Tatiana Gossen, Otto von Guericke University Magdeburg","Juliane Hbel, Otto von Guericke University Magdeburg","Andreas Nrnberger, Otto-von-Guericke-University Magdeburg"],"title":"A Comparative Study about Children's and Adults' Perception of Targeted Web Search Engines","paperOrNote":"Note","fullAbstract":"In this paper we describe an eye-tracking study where we compare childrens and adults search behavior and perception of search interface elements on search engine results pages (SERPs) during an informational and a navigational search with Google and a search engine for children. Our first results indicate that children employ an exhaustive scanning strategy combined with cued visual jumps. Then they navigate to the next result page and only then modify their query. Adults only scan the first three results, following the F-shaped strategy, and immediately reformulate the query. Children pay less attention to textual summaries and more to thumbnails than adults do. Children take notice of a navigational menu with categories while adults do not.","shortAbstract":"In this paper we describe an eye-tracking study where we compare child","id":"pn431"},"session":"Information in Use","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn431"},"pn1923":{"lastUpdateTime":1389221922387,"subcommitteeSplit":"C","labels":{"Older Adults":{"checked":false,"dislikes":[],"likes":["f.hwang@reading.ac.uk","kgajos@eecs.harvard.edu"],"lastUpdateTime":1386527111498,"label":"Older Adults"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"connectedness":{"dislikes":[],"lastTimeUpdated":1386527574559,"checked":true,"likes":[],"label":"connectedness"},"User-Centered Design / Human-Centered Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527604708,"label":"User-Centered Design / Human-Centered Design"},"Materiality":{"dislikes":[],"lastTimeUpdated":1386527506039,"checked":true,"likes":[],"label":"Materiality"},"objects and people":{"dislikes":[],"lastTimeUpdated":1386527189519,"checked":true,"likes":[],"label":"objects and people"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527603151,"label":"User Experience Design / Experience Design"},"Tangibles":{"checked":false,"lastUpdateTime":1386527122011,"dislikes":[],"label":"Tangibles","lastTimeUpdated":1386526841444,"likes":[]},"internet of things":{"dislikes":[],"lastTimeUpdated":1386527159701,"checked":true,"likes":[],"label":"internet of things"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486632}},"creationTime":1512,"content":{"authorList":["Kate Vaisutis, Queensland University of Technology","Margot Brereton, Queensland University of Technology","Laurie Buys, Queensland University of Technology"],"title":"Invisible Connections: Investigating Older Peoples Emotions and Social Relations Around Objects","paperOrNote":"Note","fullAbstract":"With the advent of the Internet of Things, there is interest in how people might interrelate through and with networks of internet enabled objects. With an interest in fostering social connection and physical activity among older people, this preliminary study investigated objects that people over aged 65 viewed as significant to them. We conducted contextual interviews in peoples homes about their significant objects in order to understand the role of the objects in their lives and the extent to which they fostered emotional and social connections and physical activity.  \\  \\ Discussion of significant objects generated considerable emotion in the participants. We identified objects of comfort and routine, objects that exhibited status, those that fostered independence and connection, and those that symbolized relationships with loved ones. These findings lead us to consider implication for design of interconnected objects. \\ ","shortAbstract":"With the advent of the Internet of Things, there is interest in how pe","id":"pn1923"},"session":"Health: Older Adults 2","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1923"},"pn2160":{"lastUpdateTime":1389236520278,"subcommitteeSplit":"B","labels":{"Social and Legal issues":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com","com@psychology.nottingham.ac.uk"],"lastUpdateTime":123456789,"label":"Social and Legal issues"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"ethics":{"dislikes":[],"lastTimeUpdated":1386523103691,"checked":true,"likes":[],"label":"ethics"},"Ethics":{"checked":false,"lastUpdateTime":1386536835738,"dislikes":[],"label":"Ethics","lastTimeUpdated":1386522547147,"likes":[]},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":["l.ciolfi@shu.ac.uk"],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032719}},"creationTime":1722,"content":{"authorList":["Barbara Grimpe, University of Oxford","Mark Hartswood, University of Oxford","Marina Jirotka, University of Oxford"],"title":"Towards a Closer Dialogue between Policy and Practice: Responsible Design in HCI","paperOrNote":"Paper","fullAbstract":"Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this the paper will first compare and contrast an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: (1) reflexivity; (2) responsibility, and responsiveness in particular; (3) inclusion; and (4) anticipation. We conclude with a summary and recommendations for the mutual shaping of the RRI agenda and designer's practices.","shortAbstract":"Given the potent and pervasive nature of modern technologies, this pap","id":"pn2160"},"session":"HCI4D: doing the right thing - ethics","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2160"},"pn1632":{"lastUpdateTime":1389238262241,"subcommitteeSplit":"C","labels":{"Guided experiences":{"dislikes":[],"lastTimeUpdated":1386526447766,"checked":true,"likes":["andrew.sears@rit.edu","christopher.power@york.ac.uk"],"label":"Guided experiences"},"Video Analysis":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526710634,"label":"Video Analysis"},"Entertainment":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Entertainment"},"Museums":{"dislikes":[],"lastTimeUpdated":1386526146610,"checked":true,"likes":[],"label":"Museums"},"Museum experience":{"dislikes":[],"lastTimeUpdated":1386526329849,"checked":true,"likes":["kgajos@eecs.harvard.edu","mtory@cs.uvic.ca","christopher.power@york.ac.uk","bpbailey@illinois.edu"],"label":"Museum experience"},"Empirical Methods, Qualitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386526718764,"label":"Empirical Methods, Qualitative"},"heritage":{"dislikes":[],"lastTimeUpdated":1386526356193,"checked":true,"likes":[],"label":"heritage"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486593}},"creationTime":1260,"content":{"authorList":["Lesley Fosh, The University of Nottingham","Steve Benford, University of Nottingham","Stuart Reeves, University of Nottingham","Boriana Koleva, The University of Nottingham"],"title":"Gifting Personal Interpretations in Galleries","paperOrNote":"Paper","fullAbstract":"The designers of mobile guides for museums and galleries face three major challenges: fostering rich interpretation, delivering deep personalization, and enabling a coherent social visit. We propose an approach to tackling all three simultaneously by inviting visitors to design an interpretation that is specifically tailored for a friend or loved one that they then experience together. We describe a trial of this approach at a contemporary art gallery, revealing how visitors designed personal and sometimes provocative experiences for people they knew well. We reveal how pairs of visitors negotiated these experiences together, showing how our approach could deliver intense experiences for both, but also required them to manage social risk. By interpreting our findings through the lens of gift giving we shed new light on ongoing explorations of interpretation, personalization and social visiting within HCI.","shortAbstract":"The designers of mobile guides for museums and galleries face three ma","id":"pn1632"},"session":"Art: Museum Experience","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1632"},"pn2168":{"lastUpdateTime":1389591839536,"subcommitteeSplit":"","labels":{"3D Interaction and Graphics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"3D Interaction and Graphics"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["kris.luyten@uhasselt.be"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":["xiangcao@acm.org","roudauta@gmail.com","kris.luyten@uhasselt.be"],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Mobile Projection":{"dislikes":[],"lastTimeUpdated":1386523807599,"checked":true,"likes":["roudauta@gmail.com","xiangcao@acm.org"],"label":"Mobile Projection"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Crowd-Powered Systems":{"checked":false,"lastUpdateTime":1386523809981,"dislikes":[],"label":"Crowd-Powered Systems","lastTimeUpdated":1386523755313,"likes":[]},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081838}},"creationTime":1729,"content":{"authorList":["Christian Winkler, Ulm University","Julian Seifert, Ulm University","David Dobbelstein, Ulm University","Enrico Rukzio, Ulm University"],"title":"Pervasive Information through Constant Personal Projection: The Ambient Mobile Pervasive Display (AMP-D)","paperOrNote":"Paper","fullAbstract":"The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display (AMP-D) which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.","shortAbstract":"The vision of pervasive ambient information displays which show releva","id":"pn2168"},"session":"Displays: Novel Mobile Displays (UIST)","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn2168"},"pn1700":{"lastUpdateTime":1389222230397,"subcommitteeSplit":"C","labels":{"Blind":{"checked":false,"lastUpdateTime":1386527047495,"dislikes":[],"label":"Blind","lastTimeUpdated":1386526167728,"likes":["erinacarroll@gmail.com"]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Braille":{"dislikes":[],"lastTimeUpdated":1386526172760,"checked":true,"likes":[],"label":"Braille"},"Universal (or Disability)  Access":{"checked":false,"dislikes":[],"likes":["bpbailey@illinois.edu","tjvg@di.fc.ul.pt"],"lastUpdateTime":1386526892690,"label":"Universal (or Disability)  Access"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Text-Entry":{"checked":false,"lastUpdateTime":1386527530642,"dislikes":[],"label":"Text-Entry","lastTimeUpdated":1386527492560,"likes":[]},"mobile":{"checked":false,"lastUpdateTime":1386527508149,"dislikes":[],"label":"mobile","lastTimeUpdated":1386526181757,"likes":[]},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386526880132,"checked":true,"likes":[],"label":"Multitouch"},"Mobile Accessibility":{"checked":false,"lastUpdateTime":1386537507666,"dislikes":[],"label":"Mobile Accessibility","lastTimeUpdated":1386526666911,"likes":[]},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["awaller@computing.dundee.ac.uk"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Text Entry":{"dislikes":[],"lastTimeUpdated":1386527540754,"checked":true,"likes":["tjvg@di.fc.ul.pt"],"label":"Text Entry"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486618}},"creationTime":1319,"content":{"authorList":["Hugo Nicolau, University of Dundee","Kyle Montague, University of Dundee","Tiago Guerreiro, University of Lisbon","Joo Guerreiro, INESC-ID/IST-Technical University of Lisbon","Vicki Hanson, University of Dundee"],"title":"B#: Chord-based Correction for Multitouch Braille Input","paperOrNote":"Note","fullAbstract":"Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.","shortAbstract":"Braille has paved its way into mobile touchscreen devices, providing f","id":"pn1700"},"session":"UIST: Text Entry and Evaluation","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1700"},"pn1707":{"lastUpdateTime":1389590847814,"subcommitteeSplit":"B","labels":{"Empirical Methods, Quantitative":{"dislikes":[],"lastTimeUpdated":1386521870074,"checked":true,"likes":["elainemayhuang@gmail.com"],"label":"Empirical Methods, Quantitative"},"Sustainability":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","rob.comber@ncl.ac.uk"],"lastUpdateTime":1386522259337,"label":"Sustainability"},"User Studies":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","egelman@cs.berkeley.edu"],"lastUpdateTime":1386522254412,"label":"User Studies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["elainemayhuang@gmail.com","rob.comber@ncl.ac.uk","hazas@comp.lancs.ac.uk","egelman@cs.berkeley.edu"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446295}},"creationTime":1326,"content":{"authorList":["Kumaripaba Athukorala, University of Helsinki","Eemil Lagerspetz, University of Helsinki","Maria von Kugelgen, University of Helsinki","Antti Jylh, University of Helsinki","Adam Oliner, University of California Berkeley","Giulio Jacucci, Helsinki Institute for Information Technology","Sasu Tarkoma, University of Helsinki"],"title":"How Carat Affects User Behavior: Implications for Mobile Battery Awareness Applications","paperOrNote":"Paper","fullAbstract":"Mobile devices have limited battery life, and numerous battery management applications are available that aim to improve it. This paper examines a large-scale mobile battery awareness application, called Carat, to see how it changes user behavior. We conducted a survey of current Carat Android users and analyzed \\ their interaction logs. The results show that long-term Carat users save more battery, charge their phones less often, learn to manage their battery with less help from Carat, have a better understanding of how Carat works, and enjoy competing against other users. Based on these findings, we propose a set of guidelines for mobile battery awareness applications: battery awareness applications should make the reasoning behind their recommendations understandable to the user, be tailored to retain long-term users, provide unambiguous instructions, and distinguish third-party and system applications.","shortAbstract":"Mobile devices have limited battery life, and numerous battery managem","id":"pn1707"},"session":"UBI: Battery Life","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1707"},"pn2016":{"lastUpdateTime":1389221887645,"subcommitteeSplit":"A","labels":{"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Industrial Design":{"dislikes":[],"lastTimeUpdated":1386523047272,"checked":true,"likes":[],"label":"Industrial Design"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Robots":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr","ledantec@gatech.edu","carmster@gmail.com"],"lastUpdateTime":123456789,"label":"Robots"},"Health Care":{"checked":true,"dislikes":[],"likes":["scott.davidoff@jpl.nasa.gov"],"lastUpdateTime":123456789,"label":"Health Care"},"eco-design":{"dislikes":[],"lastTimeUpdated":1386523732558,"checked":true,"likes":["younlim.cixd@gmail.com"],"label":"eco-design"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711731}},"creationTime":1592,"content":{"authorList":["Anthony Threatt, Clemson University","Jessica Merino, Clemson University","Keith Green, Clemson University","Johnell Brooks, Clemson University","Ian Walker, Clemson University","Stan Healy, Greenville Health System"],"title":"An Assistive Robotic Table for Older and Post-Stroke  Adults: Results from Participatory Design and   Evaluation Activities with Clinical Staff","paperOrNote":"Paper","fullAbstract":"In hospitals, technology has become pervasive and indispensable during medical crises.  In homes, technology proliferates as computerized health monitoring systems and, perhaps in the future, as assistive, humanoid robots.  The physical aspects of these built environments, however, remain conventional, low-tech, and ill adaptive to dramatic life changes.  How can the built environment be outfitted with intelligent hardware promoting wellbeing and independent living?  We focus on the key component of our envisioned home+ suite of networked, robotic furnishings for hospitals and homes: an Assistive, Robotic Table (ART).  We begin with the motivations for ART, and elaborate its iterative, five-phase, participatory design-and-evaluation process involving clinicians at a rehabilitation hospital, focusing on our final usability study.  ART was found to be promising, but also challenging; and the lessons elaborated in this paper are invaluable as design researchers come to develop larger-scale cyber-physical artifacts assisting an increasingly digital society that is growing older.","shortAbstract":"In hospitals, technology has become pervasive and indispensable during","id":"pn2016"},"session":"Health: Older Adults","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2016"},"pn2011":{"lastUpdateTime":1389236845002,"subcommitteeSplit":"B","labels":{"repair":{"dislikes":[],"lastTimeUpdated":1386522690922,"checked":true,"likes":[],"label":"repair"},"critical design":{"dislikes":[],"lastTimeUpdated":1386522603113,"checked":true,"likes":[],"label":"critical design"},"make":{"dislikes":[],"lastTimeUpdated":1386522778131,"checked":true,"likes":[],"label":"make"},"design theory":{"dislikes":[],"lastTimeUpdated":1386522713054,"checked":true,"likes":[],"label":"design theory"},"making practices":{"dislikes":[],"lastTimeUpdated":1386522731091,"checked":true,"likes":[],"label":"making practices"},"art practice":{"dislikes":[],"lastTimeUpdated":1386522860503,"checked":true,"likes":[],"label":"art practice"},"post-humanist theory":{"dislikes":[],"lastTimeUpdated":1386522751458,"checked":true,"likes":[],"label":"post-humanist theory"},"Sustainability":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"Sustainability"},"diy":{"dislikes":[],"lastTimeUpdated":1386522794324,"checked":true,"likes":["silvia.lindtner@gmail.com"],"label":"diy"},"Ethnography":{"checked":true,"dislikes":[],"likes":["aantle@sfu.ca"],"lastUpdateTime":123456789,"label":"Ethnography"},"Multidisciplinary Design / Interdisciplinary Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Multidisciplinary Design / Interdisciplinary Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755981}},"creationTime":1587,"content":{"authorList":["Steven Jackson, Cornell University","Laewoo Kang, Cornell University"],"title":"Breakdown, Obsolescence and Reuse:  HCI and The Art of Repair","paperOrNote":"Paper","fullAbstract":"This paper describes an integrated program of theoretical, ethnographic, and building work meant to explore post-humanist alternatives to questions around HCI creativity and design. We review recent theories in the humanities, social sciences, and HCI that argue for different ways of framing the relationship between human agents and the object world around them. We then describe a program of ethnographic work with artists who feature found and broken technologies as central methods and topics of work. Finally, we describe an installation and self-study project of our own, Scale, that extends these lines of analysis through collaborative acts of building with broken and discarded technologies. We argue that such integrated programs of work offer one useful model for leveraging the theoretical, ethnographic and material dimensions of HCI work; and that the distinct propensities of found and broken objects can challenge and extend HCI notions of creativity and design itself.","shortAbstract":"This paper describes an integrated program of theoretical, ethnographi","id":"pn2011"},"session":"Making: how things don't work","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn2011"},"pn2010":{"lastUpdateTime":1389222210195,"subcommitteeSplit":"","labels":{"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Sensing":{"dislikes":[],"lastTimeUpdated":1386532679054,"checked":true,"likes":[],"label":"Sensing"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["david.kim@newcastle.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"3D Interaction":{"dislikes":[],"lastTimeUpdated":1386532043011,"checked":true,"likes":["j.d.hook@ncl.ac.uk"],"label":"3D Interaction"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840718}},"creationTime":1586,"content":{"authorList":["Mathieu Le Goc, Microsoft Research","Stuart Taylor, Microsoft Research","Shahram Izadi, Microsoft Research","Cem Keskin, Microsoft Research"],"title":"A Low-cost Transparent Electric Field Sensor for 3D Motion Gestures on Mobile Devices","paperOrNote":"Note","fullAbstract":"We contribute a thin, transparent, and low-cost design for \\ electric field sensing (EFS), allowing for 3D motion gestures \\ and coarse hand tracking on mobile devices. Our sensor design \\ requires no direct instrumentation of the hand or body, \\ and is non-optical, allowing for a compact form-factor that is \\ resilient to outdoor ambient illumination. Our simple driver \\ electronics are based on an off-the-shelf chip that removes \\ the need for writing custom firmware. We measure the performance \\ of various antenna designs, and present a machine \\ learning algorithm for mapping from signal measurements at \\ the receivers to 3D positions. We demonstrate non-contact 3D \\ motion gestures, and more precise hand and finger localization. \\ We conclude by discussing limitations, more practical \\ designs that incorporate touch, and future work.","shortAbstract":"We contribute a thin, transparent, and low-cost design for \\ electric ","id":"pn2010"},"session":"UIST: Tangibles","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn2010"},"pn1447":{"lastUpdateTime":1389107617949,"subcommitteeSplit":"","labels":{"Visualization":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Visualization"},"Cartography":{"checked":false,"lastUpdateTime":1386531359769,"dislikes":[],"label":"Cartography","lastTimeUpdated":1386527604616,"likes":[]},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531348073,"label":"Usability Testing and Evaluation"},"maps":{"dislikes":[],"lastTimeUpdated":1386529992722,"checked":true,"likes":[],"label":"maps"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531351806,"label":"User Interface Design"},"Navigation":{"dislikes":[],"lastTimeUpdated":1386528324959,"checked":true,"likes":["marcodesa@gmail.com","judy.kay@gmail.com","dabbish@cmu.edu"],"label":"Navigation"},"Transport":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386531369843,"label":"Transport"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165078}},"creationTime":1108,"content":{"authorList":["Sungsoo (Ray) Hong, University of Washington","Yeaseul Kim, University of Washington","Sean Mitchell, University of Washington","Cecilia Aragon, University of Washington"],"title":"Traffigram: Distortion for Clarification via Isochronal Cartography","paperOrNote":"Paper","fullAbstract":"Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its value. To address these issues, we conducted a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design of this type of distortion for clarification in cartographic visualizations.","shortAbstract":"Most geographic maps visually represent physical distance; however, tr","id":"pn1447"},"session":"Viz: Novel Visual Elements","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1447"},"pn1446":{"lastUpdateTime":1389238866997,"subcommitteeSplit":"A","labels":{"Body":{"dislikes":[],"lastTimeUpdated":1386523220821,"checked":true,"likes":["mentis@umbc.edu","a.parker@neu.edu"],"label":"Body"},"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"Pain":{"dislikes":[],"lastTimeUpdated":1386523567983,"checked":true,"likes":["mentis@umbc.edu","a.parker@neu.edu"],"label":"Pain"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386523299958,"label":"Health Care"},"User Interface Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523289559,"label":"User Interface Design"},"Computer-Mediated Communication":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Computer-Mediated Communication"},"Visual System Design / Visual Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visual System Design / Visual Design"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188200}},"creationTime":1107,"content":{"authorList":["Amy Jang, Stanford University","Diana MacLean, Stanford University","Jeffrey Heer, University of Washington"],"title":"BodyDiagrams: Improving Communication of Pain Symptoms through Drawing","paperOrNote":"Paper","fullAbstract":"Thousands of people use the Internet to discuss pain symptoms. While communication between patients and physicians involves both verbal and physical interactions, online discussions of symptoms typically comprise text only. We present BodyDiagrams, an online interface for expressing symptoms via drawings and text. BodyDiagrams augment textual descriptions with pain diagrams drawn over a reference body and annotated with severity and temporal metadata. The resulting diagrams can easily be shared to solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams and a text-only interface; in the second phase, medical professionals evaluate these descriptions. We find that authors are significantly more confident that their BodyDiagrams will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly more informative than text descriptions. Both groups indicated a preference for using diagrams to communicate physical symptoms in the future.","shortAbstract":"Thousands of people use the Internet to discuss pain symptoms. While c","id":"pn1446"},"session":"Health: Quantified Self","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1446"},"pn1442":{"lastUpdateTime":1389238884539,"subcommitteeSplit":"B","labels":{"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"Industrial Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Industrial Design"},"constructive design research":{"dislikes":[],"lastTimeUpdated":1386522933214,"checked":true,"likes":[],"label":"constructive design research"},"appropriation":{"dislikes":[],"lastTimeUpdated":1386522953028,"checked":true,"likes":[],"label":"appropriation"},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"research through design":{"dislikes":[],"lastTimeUpdated":1386530552802,"checked":true,"likes":[],"label":"research through design"},"Product Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Product Design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Everyday design":{"dislikes":[],"lastTimeUpdated":1386522721434,"checked":true,"likes":[],"label":"Everyday design"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":["fuzhiyong@tsinghua.edu.cn"],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Participatory Design / Cooperative Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Participatory Design / Cooperative Design"},"research thorugh design":{"checked":false,"lastUpdateTime":1386530554807,"dislikes":[],"label":"research thorugh design","lastTimeUpdated":1386522939140,"likes":[]},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755908}},"creationTime":1103,"content":{"authorList":["Jin-min Seok, KAIST","Jong-bum Woo, KAIST","Youn-kyung Lim, KAIST"],"title":"Non-Finito Products: A New Design Space of User Creativity for Personal User Experience","paperOrNote":"Paper","fullAbstract":"Conventional wisdom says that to be successful, an idea must be concrete, complete, and certain. What if unfinished ideas work? This CHI paper proposes a new design space, we call non-finito products, for the HCI community. This new design space is about intentionally unfinished products and how they foster new creations by end-users as they are actually used on the purpose of solving peoples own problems. The central idea comes from the background of growing complexity associated with the IT advancement and from the new way of dealing with it, with assistance from user creativity in the instances of actual use of the products. This paper begins with the exploration of the non-finito products as a new design space for the end-user creativity of personal user experience. We then define and propose the non-finito products. We framed the design space of the non-finito products by revealing the design contexts in which non-finito products may fit and produce benefits. We discuss three case studies that will help to understand the characteristics, beneficial contexts and values of the non-finito products. Finally, we suggested the implications of designing non-finito products. We believe that this perspective of non-finito products will open a new design space in HCI and prompt a new means of replacing value-destroying complexity with a value-creating version and help to make a product better fit to user experience.","shortAbstract":"Conventional wisdom says that to be successful, an idea must be concre","id":"pn1442"},"session":"Design: Research through Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1442"},"pn1448":{"lastUpdateTime":1389590888412,"subcommitteeSplit":"A","labels":{"wearables":{"checked":false,"lastUpdateTime":1386528560065,"dislikes":[],"label":"wearables","lastTimeUpdated":1386522916558,"likes":[]},"Energy":{"dislikes":[],"lastTimeUpdated":1386523104066,"checked":true,"likes":["jonfroehlich@gmail.com"],"label":"Energy"},"Child Labor":{"dislikes":[],"lastTimeUpdated":1386523134443,"checked":true,"likes":[],"label":"Child Labor"},"Wearable":{"checked":false,"lastUpdateTime":1386528608752,"dislikes":[],"label":"Wearable","lastTimeUpdated":1386528557816,"likes":[]},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr","jonfroehlich@gmail.com"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Augmented Reality and Tangible UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Tangible UI"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"Children":{"checked":true,"dislikes":[],"likes":["fernaeus@kth.se","carmster@gmail.com","Mark.blythe@northumbria.ac.uk","lennart.nacke@uoit.ca","jonfroehlich@gmail.com"],"lastUpdateTime":123456789,"label":"Children"},"Wearables":{"dislikes":[],"lastTimeUpdated":1386528605408,"checked":true,"likes":["jonfroehlich@gmail.com"],"label":"Wearables"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711800}},"creationTime":1109,"content":{"authorList":["Kimiko Ryokai, UC Berkeley","Peiqi Su, New York University","Eungchan Kim, University of California Berkeley","Bob Rollins, Park Day School"],"title":"EnergyBugs: Energy Harvesting Wearables for Children","paperOrNote":"Paper","fullAbstract":"EnergyBugs are energy harvesting wearables with features that invite children to move their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only convert childrens kinetic energy into usable electrical energy, but also let children power a specially designed LED lamp with the energy the children have personally harvested. EnergyBugs therefore turn the electrical energy into a tangible object that children can manipulate and think with. Two studies of EnergyBugs with 34 elementary school children have revealed that children carefully observed and negotiated the use of personally harvested energy with their classmates, as well as developed emotional connections to energy. In particular, moving their own bodies to generate energy led the children to more actively ask questions about energy from new perspectives. We report our iterative design process and discuss the implications of our results for HCI.","shortAbstract":"EnergyBugs are energy harvesting wearables with features that invite c","id":"pn1448"},"session":"UBI: Battery Life","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn1448"},"pn529":{"lastUpdateTime":1389236836254,"subcommitteeSplit":"","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net","jonfroehlich@gmail.com"],"lastUpdateTime":123456789,"label":"Prototyping"},"Tangible UIs":{"checked":true,"dislikes":[],"likes":["mdixon@cs.washington.edu","dvogel@uwaterloo.ca"],"lastUpdateTime":123456789,"label":"Tangible UIs"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Fabrication":{"dislikes":[],"lastTimeUpdated":1386531773620,"checked":true,"likes":["eve.hoggan@hiit.fi"],"label":"Fabrication"},"Small Display Interaction":{"dislikes":[],"lastTimeUpdated":1386531837915,"checked":true,"likes":[],"label":"Small Display Interaction"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840680}},"creationTime":321,"content":{"authorList":["Yoshio Ishiguro, Disney Research","Ivan Poupyrev, Disney Research"],"title":"3D Printed Interactive Speakers","paperOrNote":"Paper","fullAbstract":"We propose technology for designing and manufacturing interactive 3D printed speakers. With the proposed technology, the sound reproduction functionality can be easily integrated into various objects, such as toys, at the design stage and little, if any, assembly is required. The speaker can take the shape of anything from an abstract spiral to a rubber duck, opening new opportunities in product design. Furthermore, both audible sound and inaudible ultrasound can be produced with the same design, which allows for identifying and tracking 3D printed objects in space using common microphones integrated in laptops and displays. The design of 3D printed speakers is based on electrostatic loudspeaker technology first explored in the early 1930s but not broadly applied until now. These speakers are simpler and less expensive than common electromagnetic speakers, while allowing for high quality sound reproduction at 60dB levels with arbitrary directivity from highly focused to omnidirectional. 3D printed speaker technology contributes to the growing body of work exploring functional 3D printing in interactive applications.","shortAbstract":"We propose technology for designing and manufacturing interactive 3D p","id":"pn529"},"session":"Making: Hacking","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn529"},"pn521":{"lastUpdateTime":1389221756152,"subcommitteeSplit":"B","labels":{"body-based identification":{"dislikes":[],"lastTimeUpdated":1386521878662,"checked":true,"likes":[],"label":"body-based identification"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Kinect":{"dislikes":[],"lastTimeUpdated":1386521979846,"checked":true,"likes":[],"label":"Kinect"},"Authentication":{"checked":false,"lastUpdateTime":1386538632711,"dislikes":[],"label":"Authentication","lastTimeUpdated":1386522359491,"likes":["egelman@cs.berkeley.edu","lorrie@acm.org"]},"Home":{"checked":true,"dislikes":[],"likes":["jonfroehlich@gmail.com"],"lastUpdateTime":1386522130017,"label":"Home"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["rob.comber@ncl.ac.uk","hazas@comp.lancs.ac.uk","egelman@cs.berkeley.edu","nithyas@gmail.com"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"Biometrics":{"dislikes":[],"lastTimeUpdated":1386522238345,"checked":true,"likes":[],"label":"Biometrics"},"SC_Applications-B":{"label":"SC_Applications-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315446338}},"creationTime":315,"content":{"authorList":["Eiji Hayashi, Carnegie Mellon University","Manuel Maas, Karlsruhe Institute of Technology","Jason Hong, Carnegie Mellon University"],"title":"Wave to Me: User Identification Using Body Lengths and Natural Gestures","paperOrNote":"Paper","fullAbstract":"We introduce a body-based identification system that leverages individual differences in body segment lengths and hand waving gesture patterns. The system identifies users based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate our system, we collected 8640 gesture measurements from 75 participants through two lab studies and a field study. In the first lab study, we evaluated the feasibility of our concept and basic properties of features to narrow down the design space. In the second lab study, our system achieved a 1% equal error rate in user identification among seven registered users after two weeks following initial registration. We also found that our system was robust even when lower body segments could not be measured because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error rates, demonstrating that the system also works well in ecologically valid situations. Lastly, throughout the studies, our participants were positive about the system.","shortAbstract":"We introduce a body-based identification system that leverages individ","id":"pn521"},"session":"UIST: Motion and Haptics","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn521"},"pn525":{"lastUpdateTime":1388780839452,"subcommitteeSplit":"","labels":{"Security":{"dislikes":[],"lastTimeUpdated":1386532329844,"checked":true,"likes":["fanny@dgp.toronto.edu"],"label":"Security"},"touch input":{"checked":false,"lastUpdateTime":1386532061959,"dislikes":[],"label":"touch input","lastTimeUpdated":1386532000801,"likes":[]},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386532059908,"checked":true,"likes":["j.d.hook@ncl.ac.uk"],"label":"Touch Input"},"Gestural interaction":{"dislikes":[],"lastTimeUpdated":1386532382506,"checked":true,"likes":[],"label":"Gestural interaction"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840632}},"creationTime":318,"content":{"authorList":["Khai Truong, University of Toronto","Thariq Shihipar, University of Toronto","Daniel Wigdor, University of Toronto"],"title":"Slide to X: Unlocking the Potential of Smartphone Unlocking","paperOrNote":"Paper","fullAbstract":"Unlock gestures are performed by billions of users across the world multiple times a day. Beyond preventing accidental input on mobile devices, they currently serve little to no other purpose. In this paper, we explore how replacing the regular unlock screen with one that asks the user to perform a simple, optional task, can benefit a wealth of application domains, including data collection, personal-health metrics collection, and human intelligence tasks. We evaluate this concept, which we refer to as Slide to X. Further, we show that people are willing to perform microtasks presented through this interface and continue to do so throughout the day while they visit different locations as part of their daily routines. We then discuss how to implement this concept and demonstrate three applications.","shortAbstract":"Unlock gestures are performed by billions of users across the world mu","id":"pn525"},"session":"Touch: Touch-me Mobile Interaction","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn525"},"pn526":{"lastUpdateTime":1389285488228,"subcommitteeSplit":"","labels":{"crowdfunding":{"dislikes":[],"lastTimeUpdated":1386523511729,"checked":true,"likes":[],"label":"crowdfunding"},"prediction":{"dislikes":[],"lastTimeUpdated":1386523536713,"checked":true,"likes":["teevan@gmail.com"],"label":"prediction"},"crowdsourcing":{"dislikes":[],"lastTimeUpdated":1386523533828,"checked":true,"likes":[],"label":"crowdsourcing"},"predicting project success":{"dislikes":[],"lastTimeUpdated":1386522289969,"checked":true,"likes":[],"label":"predicting project success"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523385780,"label":"Social Computing and Social Navigation"},"HCI and finance":{"dislikes":[],"lastTimeUpdated":1386527345920,"checked":true,"likes":[],"label":"HCI and finance"},"Show Me the Money":{"dislikes":[],"lastTimeUpdated":1386527306010,"checked":true,"likes":[],"label":"Show Me the Money"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523504190,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556686}},"creationTime":319,"content":{"authorList":["Anbang Xu, University of Illinois at Urbana-Champaign","Xiao Yang, Tsinghua University","Huaming Rao, University of Illinois at Urbana-Champaign","Wai-Tat Fu, University of Illinois at Urbana-Champaign","Shih-Wen Huang, University of Washington","Brian Bailey, University of Illinois at Urbana-Champaign"],"title":"Show me the Money! An Analysis of Project Updates during Crowdfunding Campaigns","paperOrNote":"Paper","fullAbstract":"Hundreds of thousands of crowdfunding campaigns have been launched, but more than half of them failed. This paper targets the content and usage patterns of project updates and how these relate to the outcomes of campaigns. We report the results of an analysis of the content of a large corpus of project updates made on Kickstarter, one of the largest crowdfunding platforms. Using semantic analysis techniques, we developed a taxonomy of the types of updates created during campaigns. Logistic regression analysis also showed how different types of updates and the representation of updates were associated with the success of campaigns. We found that project creators had various innovative uses of project updates to promote their project. We also found these innovative uses of project updates had stronger association with campaign success than project description. The results and insights gained from this work are distilled into design implications for improving crowdfunding tools that support update activities.","shortAbstract":"Hundreds of thousands of crowdfunding campaigns have been launched, bu","id":"pn526"},"session":"CSCW: interactions in the crowd","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn526"},"pn493":{"lastUpdateTime":1389238866997,"subcommitteeSplit":"A","labels":{"Personal Informatics":{"dislikes":[],"lastTimeUpdated":1386524646319,"checked":true,"likes":["asellen@microsoft.com"],"label":"Personal Informatics"},"life logging":{"dislikes":[],"lastTimeUpdated":1386524571611,"checked":true,"likes":[],"label":"life logging"},"activity tracking":{"dislikes":[],"lastTimeUpdated":1386524546220,"checked":true,"likes":[],"label":"activity tracking"},"Getting Personal":{"dislikes":[],"lastTimeUpdated":1386526428153,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Getting Personal"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"Ethnography":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ethnography"},"activity monitoring":{"dislikes":[],"lastTimeUpdated":1386524559829,"checked":true,"likes":[],"label":"activity monitoring"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524448706,"label":"User Studies"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946677}},"creationTime":298,"content":{"authorList":["John Rooksby, University of Glasgow","Mattias Rost, University of Glasgow","Alistair Morrison, University of Glasgow","Matthew Chalmers, University of Glasgow"],"title":"Personal Tracking as Lived Informatics","paperOrNote":"Paper","fullAbstract":"This paper characterizes the use of activity trackers as lived informatics.  This characterization is contrasted with discussions of personal informatics and the quantified self.  The paper reports an interview study with activity tracker users.  It finds: people do not logically organize, but interweave various activity trackers, sometimes with ostensibly the same functionality; that tracking is often social and collaborative rather than personal; that there are different styles of tracking, including goal driven tracking and documentary tracking; and that tracking information is often used and interpreted with reference to daily or short term goals and decision making.  The paper likens personal informatics to health informatics.  In health informatics electronic records proved difficult to implement, partly because they are not just stocks of information but documents enmeshed with practice.  We suggest there will also be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and peoples outlook on their future.        ","shortAbstract":"This paper characterizes the use of activity trackers as lived info","id":"pn493"},"session":"Health: Quantified Self","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn493"},"pn419":{"lastUpdateTime":1389222073366,"subcommitteeSplit":"","labels":{"Whimsical":{"checked":false,"lastUpdateTime":1386523155448,"dislikes":[],"label":"Whimsical","lastTimeUpdated":1386521410780,"likes":[]},"ephemera":{"dislikes":[],"lastTimeUpdated":1386523512632,"checked":true,"likes":["teevan@gmail.com"],"label":"ephemera"},"Office and Workplace":{"dislikes":[],"lastTimeUpdated":1386523688622,"checked":true,"likes":[],"label":"Office and Workplace"},"Food":{"checked":true,"lastUpdateTime":1386523456477,"dislikes":[],"label":"Food","lastTimeUpdated":1386522456267,"likes":[]},"social messaging":{"dislikes":[],"lastTimeUpdated":1386523694866,"checked":true,"likes":[],"label":"social messaging"},"3d printing":{"dislikes":[],"lastTimeUpdated":1386523466926,"checked":true,"likes":[],"label":"3d printing"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523653470,"label":"Computer-Mediated Communication"},"Fun":{"checked":false,"lastUpdateTime":1386523154187,"dislikes":[],"label":"Fun","lastTimeUpdated":1386521406419,"likes":[]},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Food Messaging":{"checked":false,"lastUpdateTime":1386523455214,"dislikes":[],"label":"Food Messaging","lastTimeUpdated":1386523152124,"likes":[]},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556735}},"creationTime":238,"content":{"authorList":["Jun Wei, National University of Singapore","Xiaojuan Ma, Noah's Ark Lab","Shengdong Zhao, National University of Singapore"],"title":"Eat My Words: Investigation of an Edible Medium for Social Messaging","paperOrNote":"Paper","fullAbstract":"Food is more than just a means of survival; it is also a form of communication. In this paper, we investigate the potential of food as a social message carrier (a.k.a., food messaging). We conducted exploratory interviews followed by a field study in a large information technology (IT) company over four weeks and follow-up interviews to investigate how people accept, use, and perceive food messaging. We collected 904 messages sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative social channel. Further analysis implies that food messaging embodies both characteristics of text messaging and gifting and is preferred in close relationships for its evocation of positive emotions. As the first field study on edible social messaging, our empirical findings provide valuable insights into the uniqueness of food as a message carrier and its capabilities to promote greater social bonding.","shortAbstract":"Food is more than just a means of survival; it is also a form of commu","id":"pn419"},"session":"UIST: sensible sensory","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn419"},"pn1281":{"lastUpdateTime":1389590968756,"subcommitteeSplit":"C","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["christopher.power@york.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":["maria.wolters@ed.ac.uk","mtory@cs.uvic.ca"],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Office and Workplace":{"checked":true,"dislikes":[],"likes":["tjvg@di.fc.ul.pt","christopher.power@york.ac.uk"],"lastUpdateTime":123456789,"label":"Office and Workplace"},"Emergency Response":{"dislikes":[],"lastTimeUpdated":1386526453212,"checked":true,"likes":[],"label":"Emergency Response"},"Prototyping":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527244876,"label":"Prototyping"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":["joanna@cs.ub.ca","tjvg@di.fc.ul.pt"],"lastUpdateTime":1386527234279,"label":"Computer Supported Cooperative Work (CSCW)"},"Ethnography":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527221700,"label":"Ethnography"},"Interaction Design":{"checked":false,"dislikes":[],"likes":["maria.wolters@ed.ac.uk"],"lastUpdateTime":1386527424427,"label":"Interaction Design"},"Security":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Security"},"User Experience Design / Experience Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527420649,"label":"User Experience Design / Experience Design"},"Participatory Design / Cooperative Design":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527239285,"label":"Participatory Design / Cooperative Design"},"SC_Applications-V":{"label":"SC_Applications-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315486653}},"creationTime":960,"content":{"authorList":["Matthias Betz, University of Siegen","Volker Wulf, University of Siegen and Fraunhofer FIT"],"title":"EmergencyMessenger: A text based communication concept for indoor firefighting","paperOrNote":"Paper","fullAbstract":"Finding and rescuing missing or injured people or fighting fire inside burning buildings is a central challenge for fire brigades. To ensure the safety of indoor attacking firefighting units monitoring their operations is crucial. As in most countries firefighters in Germany utilize radio sets to establish voice communication between operating units and the superordinated leading structures. Based on findings from a long term ethnographic study in cooperation with different German fire brigades over a time span of more than 5 years we analyzed the advantages and disadvantages of the established voice over radio communication tactics and techniques. We designed and evaluated a complementary text based communication device - the EmergencyMessenger - to support the time critical work of indoor attacking troops working under harsh conditions with Self-Contained-Breathing-Apparatus (SCBA). We conducted 13 full scale training missions including extensive debriefings to design and evaluate the communication concept and the corresponding device.","shortAbstract":"Finding and rescuing missing or injured people or fighting fire inside","id":"pn1281"},"session":"HCI4D: Emergency Response","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1281"},"pn898":{"lastUpdateTime":1389221449828,"subcommitteeSplit":"","labels":{"gestures":{"dislikes":[],"lastTimeUpdated":1386531534132,"checked":true,"likes":["hq@northwestern.edu"],"label":"gestures"},"Entertainment":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386527507411,"label":"Entertainment"},"Usability Testing and Evaluation":{"checked":false,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","marcodesa@gmail.com"],"lastUpdateTime":1386531203456,"label":"Usability Testing and Evaluation"},"Gestures":{"checked":false,"lastUpdateTime":1386527288579,"dislikes":[],"label":"Gestures","lastTimeUpdated":1386527285036,"likes":[]},"Input and Interaction Technologies":{"checked":false,"dislikes":[],"likes":["mark.dunlop@strath.ac.uk","marcodesa@gmail.com"],"lastUpdateTime":1386531196831,"label":"Input and Interaction Technologies"},"Gesture":{"checked":false,"lastUpdateTime":1386531571303,"dislikes":[],"label":"Gesture","lastTimeUpdated":1386527294464,"likes":["mark.dunlop@strath.ac.uk","judy.kay@gmail.com"]},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165067}},"creationTime":625,"content":{"authorList":["Arun Kulshreshth, University of Central Florida","Joseph LaViola, University of Central Florida"],"title":"Exploring the Usefulness of Finger-Based 3D Gesture Menu Selection","paperOrNote":"Paper","fullAbstract":"Counting using one's fingers is a potentially intuitive way to enumerate a list of items and lends itself naturally to gesture-based menu systems. In this paper, we investigate the usefulness of finger counting gestures as a menu selection method for motion-controlled video games. We conducted a user study that compares 3D gesture-based finger counting (Finger Count menus) with 3D Marking menus and with two gesture-based menu selection techniques (Hand-n-Hold, Thumbs-Up) derived from existing motion-controlled video game menu selection strategies. We examined selection time, selection accuracy and user preference for all techniques. We also examined the impact of different spatial layouts for menu items and different menu depths. Our results indicate that Finger-Count menus are significantly faster than the other menu techniques we tested and are the most liked by participants. Additionally, we found that while Finger-Count menus and 3D Marking menus have similar selection accuracy, Finger-Count menu are almost twice as fast compared to 3D Marking menus.","shortAbstract":"Counting using one's fingers is a potentially intuitive way to enumera","id":"pn898"},"session":"UIST: Gesture Entry","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn898"},"pn677":{"lastUpdateTime":1388766330700,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522150314,"label":"Empirical Methods, Quantitative"},"sex":{"dislikes":[],"lastTimeUpdated":1386522377612,"checked":true,"likes":[],"label":"sex"},"Health Care":{"checked":true,"dislikes":[],"likes":["teevan@gmail.com","jacovi@il.ibm.com"],"lastUpdateTime":123456789,"label":"Health Care"},"health":{"dislikes":[],"lastTimeUpdated":1386521833531,"checked":true,"likes":[],"label":"health"},"Social Computing and Social Navigation":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523509380,"label":"Social Computing and Social Navigation"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386522148156,"label":"Computer-Mediated Communication"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556654}},"creationTime":442,"content":{"authorList":["Oliver Haimson, University of California, Irvine","Jed Brubaker, University of California, Irvine","Gillian Hayes, University of California, Irvine"],"title":"DDF Seeks Same: Sexual Health-Related Language in Online Personal Ads For Men Who Have Sex With Men","paperOrNote":"Paper","fullAbstract":"The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who have sex with men (MSM) in the U.S., including increased usage of sexual health-related (SHR) language in personal advertisements. Analyzing online personal ads from Craigslist, we found a substantial increase in SHR language, from 22.99% in 1988 to over 53% today, indicating continuing concern that echoes rising HIV rates. We argue that SHR language in Craigslist ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse among particular communities. We show a positive significant relationship between prevalence rate of HIV in an ads location and use of SHR language in that location. Analysis highlights implications for public health, including the opportunity for SHR information found in Craigslist personal ads to serve as a data source for HIV prevention research, and ways to leverage user-generated content to facilitate increased safety of sexual encounters arranged online.","shortAbstract":"The HIV/AIDS crisis of the 1980s fundamentally changed sexual practice","id":"pn677"},"session":"Health: HealthyCHI","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn677"},"pn671":{"lastUpdateTime":1389236966690,"subcommitteeSplit":"","labels":{"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523608555,"label":"Empirical Methods, Quantitative"},"E-Commerce":{"checked":true,"dislikes":[],"likes":["Marilyn.McGee-Lennon@glasgow.ac.uk"],"lastUpdateTime":123456789,"label":"E-Commerce"},"World Wide Web and Hypermedia":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386523610856,"label":"World Wide Web and Hypermedia"},"gaming":{"dislikes":[],"lastTimeUpdated":1386522493407,"checked":true,"likes":["gabriela.avram@gmail.com","myriam.lewkowicz@utt.fr","Marilyn.McGee-Lennon@glasgow.ac.uk"],"label":"gaming"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315556710}},"creationTime":436,"content":{"authorList":["Donghee Yvette Wohn, Northwestern University"],"title":"Spending Real Money: Purchasing Patterns of Virtual Goods in an Online Social Game","paperOrNote":"Paper","fullAbstract":"Researchers have found that social factors contribute to purchasing intentions of virtual goods in an online social game, but little is known about actual purchasing behavior.  Study 1 examined the relationship between social factors and virtual goods purchasing patterns using large scale data obtained by server logs of an online social game. Exchange of virtual goods and number of friends increased the likelihood of spending real money compared to no spending. However, among those who did spend real money, time spent in the game was the strongest predictor of the amount of spending. Study 2 examined purchasing patterns of players who spent real money: high real-money spenders were buying items for visual customization while low spenders were buying consumable items necessary to sustain playing the game. ","shortAbstract":"Researchers have found that social factors contribute to purchas","id":"pn671"},"session":"HCI4D: Finances","replyCounter":0,"subcommittee":"Beyond Indiv.","replies":[],"id":"pn671"},"pn672":{"lastUpdateTime":1389591851860,"subcommitteeSplit":"A","labels":{"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"engineering":{"dislikes":[],"lastTimeUpdated":1386531311432,"checked":true,"likes":[],"label":"engineering"},"Engineering":{"checked":false,"lastUpdateTime":1386531313824,"dislikes":[],"label":"Engineering","lastTimeUpdated":1386523928400,"likes":[]},"Augmented Reality and Projection":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Augmented Reality and Projection"},"Mobile Projection":{"dislikes":[],"lastTimeUpdated":1386523989897,"checked":true,"likes":["xiangcao@acm.org"],"label":"Mobile Projection"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"SC_Systems & Tools":{"label":"SC_Systems & Tools","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316081829}},"creationTime":437,"content":{"authorList":["Christian Winkler, Ulm University","Markus Lchtefeld, German Research Center for Artificial Intelligence (DFKI)","David Dobbelstein, Ulm University","Antonio Krger, German Research Center for Artificial Intelligence (DFKI)","Enrico Rukzio, Ulm University"],"title":"SurfacePhone: A Mobile Projection Device for Single- and Multiuser Everywhere Tabletop Interaction","paperOrNote":"Paper","fullAbstract":"To maintain a mobile form factor, the screen real estate of a mobile device can only be extended to a certain size. However, the continuous shift of mobile computing demands has already led to devices that are barely pocketable. In this paper we present SurfacePhone; a novel configuration of a projector phone which aligns the projector to project onto a physical surface to allow tabletop-like interaction in a mobile setup. The projection is created behind the upright standing phone and is touch and gesture-enabled. Multiple projections can be merged to create shared spaces for multi-user collaboration. We investigate this new setup, starting with the concept that we evaluated with a low-fidelity prototype. Furthermore we present our high-fidelity prototype, a phone case with integrated projector that is fully mobile and allows for the aforementioned interaction. We discuss its technical requirements and evaluate the accuracy of interaction in a second user study.","shortAbstract":"To maintain a mobile form factor, the screen real estate of a mobile d","id":"pn672"},"session":"Displays: Novel Mobile Displays (UIST)","replyCounter":0,"subcommittee":"Systems & Tools","replies":[],"id":"pn672"},"pn673":{"lastUpdateTime":1389222059201,"subcommitteeSplit":"","labels":{"EEG-based HCI":{"dislikes":[],"lastTimeUpdated":1386525285472,"checked":true,"likes":["S.fairclough@ljmu.ac.uk","abe.karnik@gmail.com","bulling@mpi-inf.mpg.de","wolfgang@cse.yorku.ca"],"label":"EEG-based HCI"},"Auditory I/O and Sound in the UI":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Auditory I/O and Sound in the UI"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"passive BCI":{"dislikes":[],"lastTimeUpdated":1386525472251,"checked":true,"likes":["tzander@gmail.com","bulling@mpi-inf.mpg.de"],"label":"passive BCI"},"(passive) Brain-Computer Interfaces":{"dislikes":[],"lastTimeUpdated":1386525120337,"checked":true,"likes":["S.fairclough@ljmu.ac.uk"],"label":"(passive) Brain-Computer Interfaces"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644727}},"creationTime":438,"content":{"authorList":["Yi Chieh Li, Computer Science and information Engineering","Wen-Chieh Lin, National Chiao Tung University","Jung-Tai King, Brain Research Center","Li-Wei Ko, National Chiao Tung University","Yu-Ting Huang, Institutes of Multimedia Engineering","Fu-Yin Cherng, Institutes of Multimedia Engineering"],"title":"An EEG-based Approach for Evaluating Audio Notifications under Ambient Sounds","paperOrNote":"Paper","fullAbstract":"Audio notifications are an important way to prompt users of electronic products. Although effective in most environments, audio notifications are unable to effectively alert users in certain situations, particularly when the user is in different backgrounds or is distracted. Several studies have used behavioral performance to evaluate audio notifications, but failed to achieve consistent results because of factors such as user subjectivity or environmental differences; thus, a new method and more objective indicators are necessary. In this study, we propose an approach based on electroencephalography (EEG) to evaluate audio notifications by measuring users' auditory perceptual responses (mismatch negativity) and attention shifting (P3a). We demonstrate our approach by applying it to the usability testing of audio notifications in more realistic scenarios such as users perform a major task under ambient noises. Our approach could open a new perspective for evaluating the design of the audio notifications.","shortAbstract":"Audio notifications are an important way to prompt users of electronic","id":"pn673"},"session":"UIST: Read My Mind: Passive BCI","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn673"},"pn389":{"lastUpdateTime":1389591719634,"subcommitteeSplit":"","labels":{"Visualization":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525358275,"label":"Visualization"},"Empirical Methods, Quantitative":{"checked":true,"dislikes":[],"likes":["davidmcgookin@gmail.com","wolfgang@cse.yorku.ca"],"lastUpdateTime":123456789,"label":"Empirical Methods, Quantitative"},"Wall Displays":{"dislikes":[],"lastTimeUpdated":1386525371637,"checked":true,"likes":[],"label":"Wall Displays"},"public displays":{"dislikes":[],"lastTimeUpdated":1386525641970,"checked":true,"likes":[],"label":"public displays"},"best paper ever":{"dislikes":[],"lastTimeUpdated":1386526172797,"checked":true,"likes":[],"label":"best paper ever"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"general awesome":{"dislikes":[],"lastTimeUpdated":1386526166010,"checked":true,"likes":[],"label":"general awesome"},"heck frickin' yeah":{"dislikes":[],"lastTimeUpdated":1386526178745,"checked":true,"likes":["davidmcgookin@gmail.com","j.alexander@lancaster.ac.uk"],"label":"heck frickin' yeah"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644789}},"creationTime":211,"content":{"authorList":["Can Liu, Univ Paris-Sud, CNRS & Inria","Olivier Chapuis, Univ Paris-Sud & CNRS","Michel Beaudouin-Lafon, Univ Paris-Sud","Eric Lecolinet, Telecom ParisTech","Wendy Mackay, INRIA"],"title":"Effects of Display Size and Navigation Type on a Classification Task","paperOrNote":"Paper","fullAbstract":"The advent of ultra-high resolution wall-size displays and their use for complex tasks requires a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. In a follow-up study we compare other navigation techniques on the desktop (overview+detail, lenses) and find that they do not perform better than the wall for difficult tasks.","shortAbstract":"The advent of ultra-high resolution wall-size displays and their use f","id":"pn389"},"session":"Displays: Displays (UIST)","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn389"},"pn385":{"lastUpdateTime":1389222102553,"subcommitteeSplit":"","labels":{"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524836757,"label":"User Studies"},"Usability Research":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524832988,"label":"Usability Research"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"shape changing interfaces":{"dislikes":[],"lastTimeUpdated":1386524827686,"checked":true,"likes":["sriramable@gmail.com","S.fairclough@ljmu.ac.uk","no@spam.org","bulling@mpi-inf.mpg.de"],"label":"shape changing interfaces"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644814}},"creationTime":208,"content":{"authorList":["Esben Warming Pedersen, University of Copenhagen","Sriram Subramanian, University of Bristol","Kasper Hornbk, University of Copenhagen"],"title":"Is my Phone Alive? A Large-Scale Study of Shape Change in Handheld Devices Using Videos","paperOrNote":"Paper","fullAbstract":"Shape-changing handhelds are emerging as research prototypes, but it is unclear how users perceive them and which experiences they engender. The little data we have on user experience is from single prototypes, only covering a small part of the possibilities in shape change. We produce 51 videos of a shape-changing handheld device by systematically varying seven parameters of shape change. In a crowd-sourced study, 187 participants watched the videos and described their experiences using rating scales and free text. We find significant and large differences among parameters of shape-change. Shapes that have previously been used for notifications were rated the least urgent; the degree of shape change was found to impact experience more than type of shape change. The experience of shape-change was surprisingly complex: hedonic quality were inversely related to urgency, and some shapes were perceived as ugly, yet useful. We discuss how to advance models of shape-change and improve research on the experience of shape change.","shortAbstract":"Shape-changing handhelds are emerging as research prototypes, but it i","id":"pn385"},"session":"UIST: Shape-Changers","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn385"},"pn386":{"lastUpdateTime":1389221416620,"subcommitteeSplit":"A","labels":{"touch input":{"checked":false,"lastUpdateTime":1386528692018,"dislikes":[],"label":"touch input","lastTimeUpdated":1386523957403,"likes":[]},"Touchy Feely":{"dislikes":[],"lastTimeUpdated":1386525476069,"checked":true,"likes":["sameer.patil@hiit.fi","paul.marshall@ucl.ac.uk"],"label":"Touchy Feely"},"force":{"dislikes":[],"lastTimeUpdated":1386523960749,"checked":true,"likes":[],"label":"force"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524063257,"label":"Empirical Methods, Quantitative"},"Multitouchy Feely":{"dislikes":[],"lastTimeUpdated":1386526802698,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Multitouchy Feely"},"interaction techniques":{"checked":false,"lastUpdateTime":1386531828906,"dislikes":[],"label":"interaction techniques","lastTimeUpdated":1386523975171,"likes":[]},"Touch Input":{"dislikes":[],"lastTimeUpdated":1386528688687,"checked":true,"likes":[],"label":"Touch Input"},"Touchy":{"dislikes":[],"lastTimeUpdated":1386525397278,"checked":true,"likes":["dgergle@northwestern.edu","sameer.patil@hiit.fi"],"label":"Touchy"},"Multitouch":{"dislikes":[],"lastTimeUpdated":1386524367968,"checked":true,"likes":["mark.hancock@uwaterloo.ca"],"label":"Multitouch"},"tabletop":{"dislikes":[],"lastTimeUpdated":1386524377733,"checked":true,"likes":["mark.hancock@uwaterloo.ca"],"label":"tabletop"},"Interaction techniques":{"dislikes":[],"lastTimeUpdated":1386531826169,"checked":true,"likes":[],"label":"Interaction techniques"},"acoustic":{"dislikes":[],"lastTimeUpdated":1386525049756,"checked":true,"likes":[],"label":"acoustic"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["dabbish@cmu.edu"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"User Studies":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524066525,"label":"User Studies"},"horizontal displays":{"dislikes":[],"lastTimeUpdated":1386523967643,"checked":true,"likes":[],"label":"horizontal displays"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946729}},"creationTime":209,"content":{"authorList":["Esben Warming Pedersen, University of Copenhagen","Kasper Hornbk, University of Copenhagen"],"title":"Expressive Touch: Studying Tapping Force on Tabletops","paperOrNote":"Paper","fullAbstract":"This paper investigates users ability to perform force-sensitive tapping and explores its potential as an input modality in touch-based systems. We study force-sensitive tapping using Expressive Touch, a tabletop interface that infers tapping force from the sound waves created by the users finger upon impact. The first part of the paper describes the implementation details of Expressive Touch and shows how existing tabletop interfaces can be augmented to reliably detect tapping force across the entire surface. The second part of the paper report on the results of three studies of force-sensitive tapping. First, we use a classic psychophysic task to gain insights into participants perception of tapping force (Study 1). Results show that though participants tap with different absolute tapping force, they have a similar perception of relative tapping force. Second, we investigate participants ability to control tapping force (Study 2) and find that users can produce two different force levels with 99% accuracy. For six levels of force, accuracy drops to 58%. Third, we investigate the usability of force tapping by studying users reactions to seven force-sensitive touch applications (Study 3).","shortAbstract":"This paper investigates users ability to perform force-sensitive ta","id":"pn386"},"session":"UIST: Force Input","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn386"},"pn701":{"lastUpdateTime":1389108535206,"subcommitteeSplit":"A","labels":{"Interaction Design":{"checked":true,"dislikes":[],"likes":["joonhwan@snu.ac.kr"],"lastUpdateTime":123456789,"label":"Interaction Design"},"Visualization":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visualization"},"Monads":{"dislikes":[],"lastTimeUpdated":1386523500546,"checked":true,"likes":[],"label":"Monads"},"Database access / Information Retrieval":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Database access / Information Retrieval"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"SC_Design-R":{"label":"SC_Design-R","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315711770}},"creationTime":462,"content":{"authorList":["Marian Drk, Newcastle University","Rob Comber, Newcastle University","Martyn Dade-Robertson, School of Architecture, Planning, and Landscape, University of Newcastle"],"title":"Monadic Exploration: Seeing the Whole Through Its Parts","paperOrNote":"Paper","fullAbstract":"Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization interface for a highly cross-referenced book and its six-month deployment.","shortAbstract":"Monadic exploration is a new approach to interacting with relational i","id":"pn701"},"session":"Viz: Visual Aesthetics","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn701"},"pn250":{"lastUpdateTime":1388786174911,"subcommitteeSplit":"","labels":{"Context-Aware Computing":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Context-Aware Computing"},"User Interface Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Interface Design"},"Navigation":{"dislikes":[],"lastTimeUpdated":1386527511029,"checked":true,"likes":["marcodesa@gmail.com"],"label":"Navigation"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":1386526984810,"label":"Usability Testing and Evaluation"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165046}},"creationTime":111,"content":{"authorList":["Simon Robinson, Swansea University","Jennifer Pearson, Swansea University","Matt Jones, Swansea University"],"title":"A Billion Signposts: Repurposing Barcodes for Indoor Navigation","paperOrNote":"Note","fullAbstract":"Barcodes are all around uson books, groceries and other productsbut these everyday markers are typically used for a single focused purpose. In this paper we explore the concept of piggybacking on ubiquitous markers to facilitate indoor navigation. Our initial probeBookMarkallows library visitors to scan any nearby book to provide a custom map to the location of a desired item. In contrast to previous indoor navigation systems, our approach repurposes existing markers on physical items that are already in the navigation space, meaning that no additional infrastructure is required. We evaluate the BookMark probe in a large university library, showing its potential with real library users. In addition, we show how the general technique shows further potential in other similar barcode-rich environments.","shortAbstract":"Barcodes are all around uson books, groceries and other products","id":"pn250"},"session":"Transportation: Transportation and Wayfinding","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn250"},"pn704":{"lastUpdateTime":1389221887645,"subcommitteeSplit":"B","labels":{"Field Study":{"dislikes":[],"lastTimeUpdated":1386531429470,"checked":true,"likes":[],"label":"Field Study"},"Aging":{"dislikes":[],"lastTimeUpdated":1386522842002,"checked":true,"likes":[],"label":"Aging"},"Design Planning":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Design Planning"},"Older Adults":{"checked":false,"lastUpdateTime":1386536678510,"dislikes":[],"label":"Older Adults","lastTimeUpdated":1386522836990,"likes":[]},"Elders":{"checked":false,"lastUpdateTime":1386536681718,"dislikes":[],"label":"Elders","lastTimeUpdated":1386522833289,"likes":[]},"User-Centered Design / Human-Centered Design":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"User-Centered Design / Human-Centered Design"},"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Health Care":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Health Care"},"presence technologies":{"dislikes":[],"lastTimeUpdated":1386536772403,"checked":true,"likes":[],"label":"presence technologies"},"Fieldstudy":{"checked":false,"lastUpdateTime":1386531432858,"dislikes":[],"label":"Fieldstudy","lastTimeUpdated":1386522846346,"likes":[]},"Socioeconomic status":{"dislikes":[],"lastTimeUpdated":1386522862570,"checked":true,"likes":[],"label":"Socioeconomic status"},"Low SES":{"dislikes":[],"lastTimeUpdated":1386522831284,"checked":true,"likes":[],"label":"Low SES"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755941}},"creationTime":465,"content":{"authorList":["Ingrid Arreola, Indiana University","Zan Morris, Indiana University, Bloomington","Matthew Francisco, Indiana University, Bloomington","Kay Connelly, Indiana University","Kelly Caine, Clemson University","Ginger White, Indiana University, Bloomington"],"title":"From Checking On to Checking In: Designing for Low Socio-Economic Status Older Adults","paperOrNote":"Note","fullAbstract":"In this paper we describe the design evolution of a novel technology that collects and displays presence information to be used in the homes of older adults. The first two iterations, the Ambient Plant and Presence Clock were designed for higher socio-economic status (SES) older adults; whereas the Check-In Tree was designed for low SES older adults. We describe how feedback from older adult participants drove our design decisions, and give an in-depth account of how the Check-In Tree evolved from concept to a final design object ready for in situ deployment.","shortAbstract":"In this paper we describe the design evolution of a novel technology t","id":"pn704"},"session":"Health: Older Adults","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn704"},"pn255":{"lastUpdateTime":1389591624805,"subcommitteeSplit":"A","labels":{"targeting":{"dislikes":[],"lastTimeUpdated":1386523673070,"checked":true,"likes":[],"label":"targeting"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524579048,"label":"Empirical Methods, Quantitative"},"online content":{"dislikes":[],"lastTimeUpdated":1386526001156,"checked":true,"likes":[],"label":"online content"},"tailoring":{"dislikes":[],"lastTimeUpdated":1386525955700,"checked":true,"likes":[],"label":"tailoring"},"values":{"dislikes":[],"lastTimeUpdated":1386523657864,"checked":true,"likes":[],"label":"values"},"Personalization":{"dislikes":[],"lastTimeUpdated":1386525062770,"checked":true,"likes":["mark.hancock@uwaterloo.ca","paul.marshall@ucl.ac.uk"],"label":"Personalization"},"Computer-Mediated Communication":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524650891,"label":"Computer-Mediated Communication"},"reading":{"dislikes":[],"lastTimeUpdated":1386523665814,"checked":true,"likes":[],"label":"reading"},"Computer Supported Cooperative Work (CSCW)":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386524649625,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946715}},"creationTime":114,"content":{"authorList":["Gary Hsieh, University of Washington","Jilin Chen, IBM Research - Almaden","Jalal Mahmud, IBM Research - Almaden","Jeffrey Nichols, IBM Research"],"title":"You Read What You Value: Understanding Personal Values and Reading Interests","paperOrNote":"Note","fullAbstract":"This paper presents an experiment on the relationship between personal values and reading interests of online articles. Results suggest that individuals values can predict their topical interests. For example, holding stronger universalism values predict interests towards environmental articles, whereas holding stronger achievement values predict interest towards work-related articles. Findings demonstrate the possibility of targeting based on individuals personal values, but also highlight certain challenges and limitations when applying this approach for online content. ","shortAbstract":"This paper presents an experiment on the relationship between personal","id":"pn255"},"session":"People: Personal Information","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn255"},"pn2490":{"lastUpdateTime":1388785673817,"subcommitteeSplit":"","labels":{"Aesthetics":{"dislikes":[],"lastTimeUpdated":1386527113973,"checked":true,"likes":[],"label":"Aesthetics"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["elaw@mcs.le.ac.uk"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"Usability Testing and Evaluation":{"checked":true,"dislikes":[],"likes":["judy.kay@gmail.com","marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Usability Testing and Evaluation"},"Visual Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Visual Design"},"User Studies":{"checked":false,"dislikes":[],"likes":["elaw@mcs.le.ac.uk"],"lastUpdateTime":1386530552939,"label":"User Studies"},"usability-aestheic relationship":{"dislikes":[],"lastTimeUpdated":1386527847259,"checked":true,"likes":[],"label":"usability-aestheic relationship"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165043}},"creationTime":2000,"content":{"authorList":["Andreas Sonderegger, University of Fribourg","Andreas Uebelbacher, University of Fribourg","Manuela Pugliese, University of Fribourg","Juergen Sauer, University of Fribourg"],"title":"The influence of aesthetics in usability testing: the case of dual-domain products","paperOrNote":"Paper","fullAbstract":"An experimental study examined whether the effects of aesthetic appeal on usability test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone was experimentally manipulated in both home- and work-based usage domains. The two usage domains were modeled in a usability laboratory. 60 participants completed a series of typical cell phone user tasks. Dependent measures such as performance, perceived usability, and emotion were taken. The results showed that high aesthetic appeal had a positive effect on perceived usability but a negative effect on performance. The effects of aesthetic appeal on usability test outcomes were not moderated by usage domain. The results of this study imply that it may be sufficient to test dual-domain products in only one of their usage domains.","shortAbstract":"An experimental study examined whether the effects of aesthetic appeal","id":"pn2490"},"session":"Viz: Visual Aesthetics","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn2490"},"pn876":{"lastUpdateTime":1389285111611,"subcommitteeSplit":"","labels":{"Activity recognition":{"dislikes":[],"lastTimeUpdated":1386525628649,"checked":true,"likes":[],"label":"Activity recognition"},"Sports":{"dislikes":[],"lastTimeUpdated":1386525447671,"checked":true,"likes":["benko@microsoft.com","dan@microsoft.com","no@spam.org"],"label":"Sports"},"Multi-modal interfaces":{"checked":true,"dislikes":[],"likes":["dan@microsoft.com"],"lastUpdateTime":123456789,"label":"Multi-modal interfaces"},"activity monitoring":{"dislikes":[],"lastTimeUpdated":1386525620915,"checked":true,"likes":[],"label":"activity monitoring"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"activity tracking":{"dislikes":[],"lastTimeUpdated":1386525647242,"checked":true,"likes":[],"label":"activity tracking"},"activity recognition":{"checked":false,"lastUpdateTime":1386528220808,"dislikes":[],"label":"activity recognition","lastTimeUpdated":1386525805800,"likes":[]},"Exercise":{"dislikes":[],"lastTimeUpdated":1386525424458,"checked":true,"likes":[],"label":"Exercise"},"SC_Cap & Mod":{"label":"SC_Cap & Mod","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315644824}},"creationTime":606,"content":{"authorList":["Dan Morris, Microsoft Research","Scott Saponas, Microsoft Research","Andrew Guillory, Microsoft Research","Ilya Kelner, Microsoft Research"],"title":"RecoFit: Using a Wearable Sensor to Find, Recognize, and Count Exercises","paperOrNote":"Paper","fullAbstract":"Although numerous devices exist to track and share exercise routines based on running and walking, these devices offer limited functionality for strength-training exercises. We introduce RecoFit, a system for automatically tracking repetitive exercises  such as weight training and calisthenics  via an arm-worn inertial sensor. Our goal is to provide real-time and post-workout feedback, with no user-specific training and no intervention during a workout. Toward this end, we address three challenges: (1) segmenting exercise from intermittent non-exercise periods, (2) recognizing which exercise is being performed, and (3) counting repetitions. We present cross-validation results on our training data and results from a study assessing the final system, totaling 114 participants over 146 sessions. We achieve precision and recall greater than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits of 4, 7, and 13 exercises respectively, and counting that is accurate to 1 repetition 93% of the time. These results suggest that our approach enables a new category of fitness tracking devices.","shortAbstract":"Although numerous devices exist to track and share exercise routines b","id":"pn876"},"session":"UBI: Activity Recognition","replyCounter":0,"subcommittee":"Cap. & Mod.","replies":[],"id":"pn876"},"pn758":{"lastUpdateTime":1389238884539,"subcommitteeSplit":"B","labels":{"Prototyping":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Prototyping"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"checked":true,"dislikes":[],"likes":["wendyju@stanford.edu"],"lastUpdateTime":123456789,"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)"},"design theory":{"dislikes":[],"lastTimeUpdated":1386522116137,"checked":true,"likes":[],"label":"design theory"},"constructive design research":{"dislikes":[],"lastTimeUpdated":1386522069617,"checked":true,"likes":[],"label":"constructive design research"},"design fiction":{"dislikes":[],"lastTimeUpdated":1386522104615,"checked":true,"likes":["adf"],"label":"design fiction"},"Concept Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Concept Design"},"research through design":{"dislikes":[],"lastTimeUpdated":1386522058813,"checked":true,"likes":["aantle@sfu.ca"],"label":"research through design"},"Interaction Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Interaction Design"},"Home":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Home"},"User Experience Design / Experience Design":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Experience Design / Experience Design"},"SC_Design-B":{"label":"SC_Design-B","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315755959}},"creationTime":508,"content":{"authorList":["Mark Blythe, Northumbria University"],"title":"Research Through Design Fiction: Narratives in Real and Imaginary Abstracts","paperOrNote":"Paper","fullAbstract":"This paper presents an analysis of research through design abstracts in the ACM digital library using a corpus query system called Sketch Engine. It identifies an emerging lexicon and a recurring narrative structure. The abstracts frame a problem space, introduce a study sometimes involving the deployment of a prototype and conclude with considerations, reflections and discussion. This format is applied in a series of design fictions that were written during a project investigating new forms of digital prints and reproductions. The fictions take the form of imaginary abstracts which summarise findings of papers that have not been written about prototypes that do not exist. It is argued that framing concept designs as fictional studies can provide a space for research focused critique and development. ","shortAbstract":"This paper presents an analysis of research through design abstr","id":"pn758"},"session":"Design: Research through Design","replyCounter":0,"subcommittee":"Design","replies":[],"id":"pn758"},"pn420":{"lastUpdateTime":1389238054489,"subcommitteeSplit":"A","labels":{"motion capture":{"dislikes":[],"lastTimeUpdated":1386524967035,"checked":true,"likes":[],"label":"motion capture"},"Kinecting People":{"dislikes":[],"lastTimeUpdated":1386524796122,"checked":true,"likes":[],"label":"Kinecting People"},"Performance Metrics":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Performance Metrics"},"Empirical Methods, Quantitative":{"checked":false,"dislikes":[],"likes":[],"lastUpdateTime":1386525552468,"label":"Empirical Methods, Quantitative"},"Multitouchy Feely":{"dislikes":[],"lastTimeUpdated":1386526835199,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Multitouchy Feely"},"Touchy Feely":{"dislikes":[],"lastTimeUpdated":1386526838195,"checked":true,"likes":["sameer.patil@hiit.fi"],"label":"Touchy Feely"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Analysis Methods (e.g. Task/Interaction Modeling)"},"ergonomics":{"dislikes":[],"lastTimeUpdated":1386524957294,"checked":true,"likes":[],"label":"ergonomics"},"whole body interaction":{"dislikes":[],"lastTimeUpdated":1386524812405,"checked":true,"likes":["eva@ehornecker.de"],"label":"whole body interaction"},"Video Analysis":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Video Analysis"},"muscles":{"dislikes":[],"lastTimeUpdated":1386524970698,"checked":true,"likes":[],"label":"muscles"},"Biometrics":{"dislikes":[],"lastTimeUpdated":1386524624620,"checked":true,"likes":[],"label":"Biometrics"},"SC_People-V":{"label":"SC_People-V","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315946723}},"creationTime":239,"content":{"authorList":["Myroslav Bachynskyi, Max Planck Institute for Informatics","Gregorio Palmas, Max Planck Institute for Informatics","Antti Oulasvirta, Max Planck Institute for Informatics","Tino Weinkauf, Max Planck Institute for Informatics"],"title":"Is Motion Capture-Based Biomechanical Simulation Valid for HCI Studies? Study and Implications","paperOrNote":"Paper","fullAbstract":"Motion-capture-based biomechanical simulation is a non-invasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement. The method is presently gaining ground in sports, medicine, and industrial ergonomics, but we argue that it bears great potential also for studies in HCI where the ergonomics of a design is important. To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI. Study I tested typical movement types from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement. Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task. The data show high validity that is however constrained by movement characteristics and user demographics. We draw several concrete recommendations to practitioners and discuss challenges to developing the method further for HCI.","shortAbstract":"Motion-capture-based biomechanical simulation is a non-invasive analys","id":"pn420"},"session":"People: Kinecting People","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn420"},"pn1845":{"lastUpdateTime":1389221215807,"subcommitteeSplit":"A","labels":{"Ubiquitous Computing / Smart Environments":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Ubiquitous Computing / Smart Environments"},"Physical Fitness":{"checked":true,"lastUpdateTime":1386523265814,"dislikes":[],"label":"Physical Fitness","lastTimeUpdated":1386522977259,"likes":["klasnja@umich.edu","jkientz@uw.edu","weibel@ucsd.edu","jonfroehlich@gmail.com"]},"Running":{"dislikes":[],"lastTimeUpdated":1386523784971,"checked":true,"likes":[],"label":"Running"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Get Up! Technology for Physical Fitness":{"checked":false,"lastUpdateTime":1386523574682,"dislikes":[],"label":"Get Up! Technology for Physical Fitness","lastTimeUpdated":1386523509753,"likes":["weibel@ucsd.edu"]},"Wearable technology":{"dislikes":[],"lastTimeUpdated":1386523800410,"checked":true,"likes":["jonfroehlich@gmail.com"],"label":"Wearable technology"},"SC_Applications-W":{"label":"SC_Applications-W","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315188231}},"creationTime":1447,"content":{"authorList":["Matthew Mauriello, University of Maryland","Michael Gubbels, University of Maryland, College Park","Jon Froehlich, University of Maryland"],"title":"Social Fabric Fitness: The Design and Evaluation of Wearable E-Textile Displays to Support Group Running","paperOrNote":"Paper","fullAbstract":"Group exercise has multiple benefits including increases in enjoyment, adherence to fitness regimens, and workout intensity. While a large number of technology tools have emerged to support real-time feedback of individual performance, tools to support group fitness are limited. In this paper, we present a set of wearable e-textile displays for running groups called Social Fabric Fitness (SFF). SFF provides a glanceable, shared screen on the back of the wearers shirt to increase awareness and motivation of group fitness performance. We discuss parallel prototyping of three designsone flexible e-ink and two flexible LED-based displays; the selection and refinement of one design; and two evaluationsa field study of 10 running groups and two case studies of running races. Our qualitative findings indicate that SFF improves awareness of individual and group performance, helps groups stay together, and improves in-situ motivation. We close with reflections for future athletic e-textile displays.","shortAbstract":"Group exercise has multiple benefits including increases in enjoyment,","id":"pn1845"},"session":"Health: Exergaming for healthcare","replyCounter":0,"subcommittee":"Applic.","replies":[],"id":"pn1845"},"pn2380":{"lastUpdateTime":1389591648850,"subcommitteeSplit":"B","labels":{"usable privacy and security":{"dislikes":[],"lastTimeUpdated":1386528517712,"checked":true,"likes":["lorrie@acm.org"],"label":"usable privacy and security"},"recommender systems":{"dislikes":[],"lastTimeUpdated":1386522590733,"checked":true,"likes":[],"label":"recommender systems"},"Privacy":{"checked":true,"dislikes":[],"likes":["david.kirk@ncl.ac.uk"],"lastUpdateTime":123456789,"label":"Privacy"},"Social Computing and Social Navigation":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Social Computing and Social Navigation"},"Social Psychology":{"dislikes":[],"lastTimeUpdated":1386522977206,"checked":true,"likes":[],"label":"Social Psychology"},"User Studies":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"User Studies"},"Personality":{"dislikes":[],"lastTimeUpdated":1386523096168,"checked":true,"likes":[],"label":"Personality"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032782}},"creationTime":1907,"content":{"authorList":["Liang Gou, IBM Almaden Research Center","Michelle Zhou, IBM Almaden Research Center","Huahai Yang, IBM Almaden Research Center"],"title":"KnowMe and ShareMe: Understanding Automatically Discovered Personality Traits from Social Media and User Sharing Preferences","paperOrNote":"Paper","fullAbstract":"Since hundreds of millions of people leave their digital foot- prints in public on social media, researchers have started to use these footprints to predict personality traits and gain a deeper understanding of individuals. Due to the veracity of social media data, imperfections in prediction algorithms, and the sensitive nature of ones personality traits, much re- search is still needed to better understand the effectiveness of this line of work, including users preferences of using these computationally derived traits. In this paper, we report a two-part study involving 256 participants, which (1) examines the effectiveness of automatically deriving three types of personality traits from Twitter, including Big 5 personality, basic human values, and fundamental needs, and (2) investigates users opinions of using and sharing these traits. Our findings show that for over 80.8% of participants, all three types of traits derived from Twitter are significantly correlated with the participants corresponding psycho-metric test scores. The results also indicate that over 61.5% users are willing to share their derived traits in workplace Since our findings demonstrate the feasibility and effectiveness of automatically infer- ring a users personal traits from social media, we discuss their implications for designing a new generation of privacy- preserving, hyper-personalized systems.","shortAbstract":"Since hundreds of millions of people leave their digital foot- prints ","id":"pn2380"},"session":"People: Personal Information","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn2380"},"pn1936":{"lastUpdateTime":1389221950963,"subcommitteeSplit":"","labels":{"Touch Input":{"dislikes":[],"lastTimeUpdated":1386531754899,"checked":true,"likes":[],"label":"Touch Input"},"Wall Displays":{"dislikes":[],"lastTimeUpdated":1386532010297,"checked":true,"likes":[],"label":"Wall Displays"},"full body interaction":{"dislikes":[],"lastTimeUpdated":1386531703890,"checked":true,"likes":["tomer@moscovich.net"],"label":"full body interaction"},"Feet":{"dislikes":[],"lastTimeUpdated":1386540235541,"checked":true,"likes":[],"label":"Feet"},"Gestural Interaction":{"dislikes":[],"lastTimeUpdated":1386531772710,"checked":true,"likes":[],"label":"Gestural Interaction"},"Input and Interaction Technologies":{"checked":true,"dislikes":[],"likes":["tomer@moscovich.net"],"lastUpdateTime":123456789,"label":"Input and Interaction Technologies"},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387315840674}},"creationTime":1524,"content":{"authorList":["Ricardo Jota, University of Toronto","Pedro Lopes, Hasso Plattner Institute","Joaquim Jorge, INESC-ID","Daniel Wigdor, University of Toronto"],"title":"Let's Kick It: How to Stop Wasting the Bottom Third of your Large Screen Display","paperOrNote":"Note","fullAbstract":"Large-scale touch surfaces have been widely studied in literature and adopted for public installations such as interactive billboards. However, current designs do not take into consideration that touching the interactive surface at different heights is not the same; for body-height displays, the bottom portion of the screen is within easier reach of the foot than the hand. We explore the design space of foot input on vertical surfaces and propose three distinct interaction modalities: hand, foot tapping, and foot gesturing. Our design exploration pays particular attention to areas of the touch surface that were previously overlooked: out of hands reach and close to the floor. We instantiate our design space with a working prototype of an interactive surface, in which we are able to distinguish between finger and foot tapping and extend the input area beyond the bottom of the display to support foot gestures. ","shortAbstract":"Large-scale touch surfaces have been widely studied in literature and ","id":"pn1936"},"session":"UIST: On the surface","replyCounter":0,"subcommittee":"Int. Techniques","replies":[],"id":"pn1936"},"pn1932":{"lastUpdateTime":1389221977983,"subcommitteeSplit":"B","labels":{"Pro-Am":{"dislikes":[],"lastTimeUpdated":1386522147526,"checked":true,"likes":["dr.mark.j.perry@googlemail.com"],"label":"Pro-Am"},"Camera-based UIs":{"checked":true,"dislikes":[],"likes":[],"lastUpdateTime":123456789,"label":"Camera-based UIs"},"Computer Supported Cooperative Work (CSCW)":{"checked":true,"dislikes":[],"likes":["dr.mark.j.perry@googlemail.com"],"lastUpdateTime":123456789,"label":"Computer Supported Cooperative Work (CSCW)"},"SC_People-D":{"label":"SC_People-D","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316032692}},"creationTime":1520,"content":{"authorList":["Oskar Juhlin, Mobile Life @ Stockholm University","Arvid Engstrm, Mobile Life @ Stockholm University","Elin nnevall, Mobile Life @ Stockholm Universitty"],"title":"Long Tail TV revisited: From ordinary camera phone use to Pro-Am video production","paperOrNote":"Paper","fullAbstract":"Pro-Am live video producers broadcast events on a regular basis. They are here selected for an ethnographic study since their continuous content generation can teach us something of what it takes for amateurs, who currently struggle with mastering the video medium, to become proficient producers. We learn from media theory that Pro-Ams are distinguished from professionals in terms of inherent skills and identities, and have therefore focused on these characteristics. We add to this research by showing on-going challenges that the former face in their production, i.e. how their learning practices, such as learning through instructions, are situated and related to particular settings. Learning and development of skills were done as organizations, rather than as individuals. Furthermore, the recurrent nature of both events and  broadcasts appears to be an important contition for establishing the terms needed to carry out a production, and to learn the skills of a producer. This understanding may explain in part why accounts in previous research, of single users struggling with the affordances of the live video, point to such difficulties in mastering the medium. The findings guide design to better support activities contiguous with the set-up of the production, rather than individual. ","shortAbstract":"Pro-Am live video producers broadcast events on a regular basis. They ","id":"pn1932"},"session":"Art: Performance","replyCounter":0,"subcommittee":"People","replies":[],"id":"pn1932"},"pn1282":{"lastUpdateTime":1389592139292,"subcommitteeSplit":"","labels":{"mobile apps":{"dislikes":[],"lastTimeUpdated":1386527116714,"checked":true,"likes":[],"label":"mobile apps"},"notifications":{"dislikes":[],"lastTimeUpdated":1386527997093,"checked":true,"likes":[],"label":"notifications"},"Large-Scale User Studies":{"dislikes":[],"lastTimeUpdated":1386527097842,"checked":true,"likes":[],"label":"Large-Scale User Studies"},"Handheld Devices and Mobile Computing":{"checked":true,"dislikes":[],"likes":["elaw@mcs.le.ac.uk","e.karapanos@gmail.com","judy.kay@gmail.com","marcodesa@gmail.com"],"lastUpdateTime":123456789,"label":"Handheld Devices and Mobile Computing"},"data mining":{"dislikes":[],"lastTimeUpdated":1386527024898,"checked":true,"likes":[],"label":"data mining"},"SC_Usability":{"label":"SC_Usability","checked":true,"likes":[],"dislikes":[],"lastTimeUpdated":1387316165070}},"creationTime":961,"content":{"authorList":["Alireza Sahami, University of Stuttgart","Niels Henze, University of Stuttgart","Tilman Dingler, University of Stuttgart","Martin Pielot, Telefonica Research","Dominik Weber, University of Stuttgart","Albrecht Schmidt, University of Stuttgart"],"title":"Large-Scale Assessment of Mobile Notifications","paperOrNote":"Paper","fullAbstract":"Notifications are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notification as well as their current context. The nature of notifications is manifold, applications use them both sparsely and frequently. In this paper we present the first large-scale analysis of mobile notifications with a focus on users' subjective perceptions. We derive a holistic picture of notifications on mobile phones by collecting close to 200 million notifications from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notifications. Our results reveal differences in importance of notifications and how users value notifications from messaging apps as well as notifications that include information about people and events. Based on these results we derive a number of findings about the nature of notifications and guidelines to effectively use them.","shortAbstract":"Notifications are a core feature of mobile phones. They inform users a","id":"pn1282"},"session":"CSCW: Interruptions and Distractions","replyCounter":0,"subcommittee":"Usability","replies":[],"id":"pn1282"}},"userLocations":[],"sessionsLastUpdated":1390664589479,"deprecatedItems":{},"tfidfLastUpdated":-1,"tfidf":{},"sessionIds":{"7yGK-10ZH3vq7yimGvLeJEbe":{"email":"mona@cs.umd.edu"},"hraRjwO-imYUSe6VPigY3NJg":{"email":"haochuan@cs.nthu.edu.tw"},"tBzSlQ1nI7Cyri7ed2i0SLhU":{"email":"lana@research.att.com"},"LsKcFjeLzPpcdY7P_D-sqhl0":{"email":"bellotti@parc.com"},"GvohL1WibFoWAEjvK2IVXSoR":{"email":"lennart.nacke@uoit.ca"},"doNrg_ErsmbOnOj57wlBTUkN":{"email":"obristmarianna@gmail.com"},"_M7Y9X7yzbZg5_O8tEYEhkaD":{"email":"otmar.hilliges@inf.ethz.ch"},"GcJf7-LfgyUy2ICfpmPaHZUp":{"email":"yangli@acm.org"},"dAc1Fn--Jlt2c5KwXGoY8mHe":{"email":"johnz@cs.cmu.edu"},"HgpX6AKWtU_gkZnXgMpmhyaJ":{"email":"projector"},"xAAgIUc-_qVdlmlbF51Vny3V":{"email":"david.kirk@ncl.ac.uk"},"tLtsXQsohWiEyt-nrexf6yYV":{"email":"rob@ncl.ac.uk"},"fSLWKrD6aNyWGY7FmaQGKdlA":{"email":"mark.hancock@uwaterloo.ca"},"qwkC9R0_cW_GNK8re6qmKj82":{"email":"Mark.blythe@northumbria.ac.uk"},"ikiqoQUIF_sFDN4exityvcN-":{"email":"hq@northwestern.edu"},"dynF0ylElqaVyGt7bQcW7hzD":{"email":"albrecht.schmidt@vis.uni-stuttgart.de"},"1VzQ-RnnYmEsp8IsoicA1IYy":{"email":"xiangcao@acm.org"},"u_I1bvL5DriAs5fKjkA6DZei":{"email":"davidmcgookin@gmail.com"},"bq9qwhcE4hUmVzOSgWSqYTVk":{"email":"dan@microsoft.com"},"kt0L_1WEgGHudlVKdw2C8Iej":{"email":"olwal@mit.edu"},"OWfKaMnDYH89WeSzdXGwkecL":{"email":"vlh@acm.org"},"nQUHB9FNgV53scKwcr70JIlt":{"email":"jkientz@uw.edu"},"oCoxU3NHmYqjdb_wy2U7xFLs":{"email":"carmster@gmail.com"},"guPWi8cF_G9J_IlENkKtnNDf":{"email":"sadat@us.ibm.com"},"Lmc68-Q5DWawftQ2964gFsK0":{"email":"spdow@cs.cmu.edu"},"kozKwzSZtaZeV6kwwXGCioSI":{"email":"jbigham@cmu.edu"},"8Yr3Nr9pM3gVoF-uVj7vNswc":{"email":"reinecke@umich.edu"},"95BmG7_Tbhdz8TQ9Jiiat0_j":{"email":"bulling@mpi-inf.mpg.de"},"rTh9wz1nanHP2zAWvNhdxAjj":{"email":"bellotti@parc.com"},"qkMn0HFhLEmEER7Cm80N72kY":{"email":"joonhwan@snu.ac.kr"},"3kARnkqk6lddERyzncz70Rbc":{"email":"asdf"},"DpxSuOoi1h8qSZJKL0ZsQaXy":{"email":"no@spam.org"},"_GXtluyAXOjdKnKJWJZkZq4-":{"email":"egelman@cs.berkeley.edu"},"KrqSXYDSOx38uisO2d6l8EBt":{"email":"kgajos@eecs.harvard.edu"},"WPlwbO8W00S9kzVGgbP7qf_e":{"email":"giulio.jacucci@hiit.fi"},"UpgZEIT-bd3e5_WkrPwpgP_U":{"email":"S.fairclough@ljmu.ac.uk"},"Z_ooZ0_UTVLZnikVbcI3SsCY":{"email":"pierre.dragice@gmail.com"},"qUVfg3BgH5o7Ap50r7LOtQ5I":{"email":"mmassimi@microsoft.com"},"hz7JjsdA4g2QNsr6cDZeeVkR":{"email":"dabbish@cmu.edu"},"aIuyaoLF3jgyeX7G_yvk2glp":{"email":"spdow@cs.cmu.edu"},"Ha4AwaPfTLDcFl61bXPNmvho":{"email":"kris.luyten@uhasselt.be"},"l18_vlLRhwCtZYbyH_PK86NZ":{"email":"dr.mark.j.perry@googlemail.com"},"Gc7th5FSoUKFdKTCclj06iFe":{"email":"rob.comber@ncl.ac.uk"},"rIh1YImczbNDFURBPDveYpa-":{"email":"awaller@computing.dundee.ac.uk"},"5oeM7iukocvFj-G__wpQnEsY":{"email":"vlh@acm.org"},"z5RZjh20Tl5MdoTmu1r2OORM":{"email":"Tovi.Grossman@autodesk.com"},"PmNAyNAQMQvb93NHFv9Ll3f2":{"email":"sszhao@yahoo.com"},"lS691r2_kem3ydTAEo3rEgHZ":{"email":"bthies@gmail.com"},"KQY_a52bMQDxUGg_VkNCJH4a":{"email":"sameer.patil@hitt.fi"},"xOjTeBmdv4agGoBIAifPuOeg":{"email":"kash@diku.dk"},"N65F5RtSpASCR6ZTwNS56iil":{"email":"bilge@cs.wisc.edu"},"QyYVMwJfWKnDwFs3Ibl8oix0":{"email":"asellen@microsoft.com"},"Tx04wnmGVc1gxOP0il9CXGA2":{"email":"Mark.blythe@northumbria.ac.uk"},"w7J7PIXyopByGlG7RVkivMOu":{"email":"dmrussell@gmail.com"},"-vZI2xgZakGfjn9Gx7SsFgPY":{"email":"andrew.sears@rit.edu"},"UgU4XLfr3C6aW5WVBpTricah":{"email":"ledantec@gatech.edu"},"5cUe4maUMOIvMu1oY5Vo7IdD":{"email":"abe.karnik@gmail.com"},"oOIGG5F4E2QdtsVi1K3-Lmgc":{"email":"nebeling@inf.ethz.ch"},"pNKwTKCIkOSv0kv-NHjtvHXl":{"email":"antonella.deangeli@disi.unitn.it"},"fgyfvI-x6pmRihZTnTbu0-zj":{"email":"e.v.d.hoven@tue.nl"},"y6ZsWgJ1A8S3YsQvPo1xNzNQ":{"email":"roudauta@gmail.com"},"R_3RPVP7xV76xaAZc2kD0I99":{"email":"nchen@microsoft.com"},"hRAm6ysvqBPqfFHAQqlt8W9t":{"email":"Tovi.Grossman@autodesk.com"},"BOdo7Dm2gKDYbm3iImzrAzGh":{"email":"steimle@media.mit.edu"},"oyG-5y47n6mvPhUSSP_HFhY_":{"email":"Jina.huh@gmail.com"},"fUIE0_qPGHQgzO09-TU4zzHQ":{"email":"younlim.cixd@gmail.com"},"74Fzrnos1QSgpTRaHl4NJ4gJ":{"email":"jacovi@il.ibm.com"},"lLDzlwNrnAcx8ViZG7qhBlWb":{"email":"shahrami@microsoft.com"},"wJQrr0iXv-_Rtxh_17FXBNlt":{"email":"daverandall2008@gmail.com"},"MfPYtLDYagvOT0RXz3m_pcxM":{"email":"yunanc@ics.uci.edu"},"xhqrtLWynAheYmM2MqFvutXt":{"email":"Mark.blythe@northumbria.ac.uk"},"7WK2l_0KEn0plLNLyJPh80-f":{"email":"fatchanceyouregettingmyemail@gmail.com"},"1iiRzHL7QOjbwhAAVOfNyVb6":{"email":"eadar@mit.edu"},"QmdRgAjUSsPP6mAzF_L6aLFH":{"email":"lennart.nacke@uoit.ca"},"5ybascyIeJ4rV194_ttUtKo1":{"email":"e.karapanos@gmail.com"},"2GMNGHn__kP8Uus88Q8kVHBE":{"email":"nithyas@gmail.com"},"hocf_ULLPE-0dnP_JblSbil0":{"email":"rwakkary@sfu.ca"},"aRUFAAb2UKiX0T3NPcTjRt3b":{"email":"yutak@acm.org"},"TFsBlZsWbHY55iimuezOi6TX":{"email":"lirani@ucsd.edu"},"QDlTE_M_fag4fH1C5AiwwO5L":{"email":"paul.marshall@ucl.ac.uk"},"7Ec4xwVMhg4wtG2veIDaapto":{"email":"lennart.nacke@uoit.ca"},"FLPk9xXPB_i7Si-1c0iLExek":{"email":"marcodesa@gmail.com"},"Bsu2uWkRO03Tc7h73b2khtod":{"email":"kc@comp.lancs.ac.uk"},"54kNcIvfq5Zp0U2F3BqQaKn5":{"email":"stuart@tropic.org.uk"},"68X2PrH6YObbF9rS-vNRTFEs":{"email":"aeo@andrew.cmu.edu"},"A6Yg0T7vZ56FGTZJX-VDsh1_":{"email":"mc+frenzy@ecs.soton.ac.uk"},"edXr-BzHlqbvJMyWDD7qbT5n":{"email":"mdixon@cs.washington.edu"},"7IIhZBH3H5qaTVF9VQNub0Ge":{"email":"aaa"},"K6Z0_TZ-7XCvofmUiElYcOvJ":{"email":"coye.cheshire@gmail.com"},"btIkWdSQXCiioze7RAbJ_SGY":{"email":"ian.r.oakley@gmail.com"},"-_VSOStcoyjQW5fLFXSAz23y":{"email":"corina@comp.lancs.ac.uk"},"l2dyxJ0KS8srz5Pp7Rs4uzCm":{"email":"feiner@cs.columbia.edu"},"RfDClXk2LzHlk50cW90VfPp-":{"email":"lana@research.att.com"},"trGdsPsrcFkpdZm6qRSllMxM":{"email":"manfred.tscheligi@sbg.ac.at"},"a-Or1PL_MdKfRTzeWeJ_Gui3":{"email":"bpbailey@illinois.edu"},"OFSJ0xvcbEADsxDUlBpvXGAx":{"email":"Mark.blythe@northumbria.ac.uk"},"ns4NVJenzEp4nk_rMT0-1Gtj":{"email":"fanny@dgp.toronto.edu"},"4r3COFtYgteiSOh4ZLkMzHKf":{"email":"emilee@gmail.com"},"q8gIjlidfjRVwVJsGBJOsobh":{"email":"j.d.hook@ncl.ac.uk"},"_OGtwHVQ8Iri0Q1jhfg2_B4_":{"email":"depaula@acm.org"},"DVNrWiaNvJSPX_N1J-yuiHQ4":{"email":"p.l.olivier@ncl.ac.uk"},"_mX-uY_OefWWZLme59qhWIR1":{"email":"olwal@mit.edu"},"RGJZziGykHVnJvVfo05brB6R":{"email":"rsodhi2@illinois.edu"},"VbEwWh-Z3JRrLHtQ0kETYvH1":{"email":"judy.kay@gmail.com"},"aBBwTiJaAzsj0BgVEqHmpl8I":{"email":"benko@microsoft.com"},"UzJtHqbmjajETNpjRCwuXXf2":{"email":"haochuan@cs.nthu.edu.tw"},"25UQEZ6Jdn5zNQCEWsK1fyiN":{"email":"gabriela.avram@gmail.com"},"wp0ZveTBg1G0CZ_-4cvnHZgr":{"email":"sameer.patil@hiit.fi"},"ss3ZBUN5v9WOn8l080HiQ2gE":{"email":"weibel@ucsd.edu"},"nK3LETrHTxEnlJQWDzltVAac":{"email":"sharrison@vt.edu"},"hFkqR4N2HYQ2Td1G5VvAriRc":{"email":"jws@microsoft.com"},"h1-pP5Yg-fkKj-MVCitErtdO":{"email":"adf"},"GL0inaTo9d05I3uxo_MqlLXn":{"email":"mulderi@acm.org"},"odKJdfQxij8OR6AmFp97OpSY":{"email":"dan@danielashbrook.com"},"-VM-4-Wf8UbPpUQxPNYnqM_Z":{"email":"smunson@uw.edu"},"dL3ip7v634Wpyl4Oyjg3s-8P":{"email":"mattjonez@gmail.com"},"XdzrvXK_Al-42XQgqW5xTeKY":{"email":"moher@uic.edu"},"dx10HwylMPcoX-ZAFnzabHnT":{"email":"fuzhiyong@tsinghua.edu.cn"},"QoZisRFtItvTYYUjitjPoglO":{"email":"klasnja@umich.edu"},"xAyNNUUdz6575Bj9eI4OMEFB":{"email":"D.StantonFraser@bath.ac.uk"},"XnoYXwzgvXIHZ56j7hbfVcw8":{"email":"fuzhiyong@tsinghua.edu.cn"},"I9J_-sFHY8uInhDVPqsVFU4K":{"email":"mglueck@dgp.toronto.edu"},"YGRMUvQ85kVokTIV1TxJ1rqb":{"email":"stuart@tropic.org.uk"},"eHA3LXdBrsE_bp1_NVp0AmUc":{"email":"rcm@mit.edu"},"NKGvI6Okzt0tiaLYOTSc4QxK":{"email":"ackerm@gmail.com"},"hxkZZaLPH6DemZr6G6v6s1sZ":{"email":"D.StantonFraser@bath.ac.uk"},"1JSyuvK9JMetPg2ASb7wida6":{"email":"eve.hoggan@hiit.fi"},"Xxj8fxkJAfKNKJFw1IDGWby6":{"email":"david.kirk@ncl.ac.uk"},"Z0Mf7-Iq3mbshPv0mbrbdFE7":{"email":"fabio.paterno@isti.cnr.it"},"wUHYlSpeAhcK2_ONbKliqhgG":{"email":"dominicfurniss@gmail.com"},"T8ZL96SYZTHAeX-7YA4IKpEJ":{"email":"hq@northwestern.edu"},"3BegaPu6RIM7l9QCGJfPBHQp":{"email":"hazas@comp.lancs.ac.uk"},"ROm6fxTsQMuV8AIWSJNep7Io":{"email":"jonfroehlich@gmail.com"},"ETmaeuueGweMEaGEEWMGjQ5H":{"email":"mentis@umbc.edu"},"fVarhahyThdwwWFafZd7NE_B":{"email":"jeff@jeffreynichols.com"},"JsmOmuRv7kO5y8c85NjlOLMh":{"email":"jesper@cs.aau.dk"},"V327KgiWjUWx-rOtq9k91_-C":{"email":"abe.karnik@gmail.com"},"HzQkxQmkb_8YBtGSnRf3CeVl":{"email":"erinacarroll@gmail.com"},"yjtHx32vs65aATJkAK_2EXMo":{"email":"christopher.power@york.ac.uk"},"q7XzdD7V9z5b7BJaY46v5Ucz":{"email":"hilary.hutchinson@gmail.com"},"EWFxbNJMiPbqDaLEtEJmNnBX":{"email":"ztoups@nmsu.edu"},"akT7kApE-bBSwMw1TspoXkCr":{"email":"j.alexander@lancaster.ac.uk"},"sl3vi9oMbATsQt-z6lCRihm_":{"email":"alexander.de.luca@ifi.lmu.de"},"2ld92aZQn8g8n_OR3pHV8GDm":{"email":"takagih@jp.ibm.com"},"vtBbiNpyNdGWg7eTZBUtmzAT":{"email":"wendyju@stanford.edu"},"UBxte2Hgu3vrMRXXuC3Y_4ED":{"email":"aantle@sfu.ca"},"02OVxoSnrg-5aR55vaXllJuG":{"email":"johnz@cs.cmu.edu"},"TvDlL253pvrqjCWcaSyTiDXL":{"email":"dgergle@northwestern.edu"},"cgx7nzMwZDyUNRhsKs-Xz9dG":{"email":"oantti@mpi-inf.mpg.de"},"FQXFMhQ_nE8L7hVDu8ih3Bdi":{"email":"mzhou@us.ibm.com"},"tugUlAoshJ8s3ZqEHqzNrnpp":{"email":"tomer@moscovich.net"},"HG8pwMIRf9zNM2tVpbNWkHKT":{"email":"rcm@mit.edu"},"-PONQSnCXeYZySrCxZe3tKDN":{"email":"rcm"},"yVdZjmi7CXZVjGZ_3vYt4dB7":{"email":"jettie.hoonhout@philips.com"},"IrdK6wD1k9PEluIRRB0rscos":{"email":"lorrie@acm.org"},"wjCIDfDCkYKV-8nVQMRubi9J":{"email":"elaw@mcs.le.ac.uk"},"leFUwJBqiy4_pWji6LIvgqxi":{"email":"bickmore@ccs.neu.edu"},"7ManA_V2qdrKg3dWkQBUCguu":{"email":"a.parker@neu.edu"},"qK1XuTeFSr3W-PpMoFo3sy9u":{"email":"takagih@jp.ibm.com"},"2ILQUvDTe-nTpWFbAhs3B1fU":{"email":"john.vines@ncl.ac.uk"},"AYZg_GfXt3z_tGcMYUI0EtcX":{"email":"ajbrush@microsoft.com"},"adsv461rc1zlHiOFLkaehJU0":{"email":"maria.wolters@ed.ac.uk"},"LRp7GcffYSrNamumhsxha8dN":{"email":"Marilyn.McGee-Lennon@glasgow.ac.uk"},"HcDB22wgv9P78jhRyZrf4ez6":{"email":"mattjonez@gmail.com"},"AW8wFYtpQWMb9NaYY03HUsKw":{"email":"mglueck@dgp.toronto.edu"},"3CDqs7mOdIBIwLrtUPpYLLBn":{"email":"mtory@cs.uvic.ca"},"HTqGz-UC8xOHAXZkRr3_OEa1":{"email":"scott.davidoff@jpl.nasa.gov"},"Cm3qyVvMWLylUqzEJlc2wuW8":{"email":"mark.dunlop@strath.ac.uk"},"Mev3UGa7RKb7mBumww247c5B":{"email":"com@psychology.nottingham.ac.uk"},"FFYNrBawlyECwNxlk6psycPY":{"email":"wilcox@cc.gatech.edu"},"iyHCy3ME5Py1IbYUDdnc3EQj":{"email":"asellen@microsoft.com"},"AJSigxfdoQH-kT6um3N5f9iW":{"email":"david.geerts@soc.kuleuven.be"},"pWm6y6907TiCWB4Vsgu5Ks49":{"email":"aquigley@st-andrews.ac.uk"},"SOH_B9KjYQtVIr9HdLsYA7Wz":{"email":"sriramable@gmail.com"},"V_HwhpzidWEyLGo2X6QtHmDr":{"email":"fernaeus@kth.se"},"vHWk9I5jU6o-GJnfe-KQ6ypS":{"email":"a.sasse@cs.ucl.ac.uk"},"F3JfbYnKZTpTp-vFDK83dgbl":{"email":"elm@purdue.edu"},"45OrPjG3KWx5umtg6dfUdKY_":{"email":"karyn.moffatt@mcgill.ca"},"hEflNsjpglp_wqA1O9EEJ2Zk":{"email":"jantin@gmail.com"},"dmCvZ9Xywcwgos8ehLDKiNhX":{"email":"hmslydia@gmail.com"},"x7hbcdTSgHBoWVOP15oVl74P":{"email":"feiner@cs.columbia.edu"},"khe1zQISaP7boMuLGWXMw7gq":{"email":"elainemayhuang@gmail.com"},"oIFq_ifKtrAbZAK5LYkoxXHz":{"email":"petra.isenberg@inria.fr"},"azLfixw42AQUXbCmakq2Rjpa":{"email":"erin@cs.drexel.edu"},"oa_wFQwl1Qg29DuoqC0EKHo0":{"email":"dabbish@cmu.edu"},"pgTTFTkFJU8McqcCU-A5ubB-":{"email":"sfussell@cornell.edu"},"MIHUg43MSaDvoCgP2XzpPJV0":{"email":"J.Good@sussex.ac.uk"},"5F2rota5XO9ftWjGdW34j9or":{"email":"joerg.mueller@tu-berlin.de"},"JOqudcUZwxbEmfVRCJZFvKVg":{"email":"m.rouncefield@lancaster.ac.uk"},"St6uAq04U89FDGYNasdiMOwg":{"email":"quintana@umich.edu"},"9LVDfg9dl-4W67pPTXNJM4Ls":{"email":"forlines@alumni.cmu.edu"},"zW-5vJJkh15b8SGFBDkLGeyt":{"email":"tzander@gmail.com"},"OToicjmoA-frs2myfdl42oR3":{"email":"garyhsieh@gmail.com"},"yi5jzZiiPVrB5mc7sWi8ntTk":{"email":"jonfroehlich@gmail.com"},"m58HuxH5MjHh1hXZv1uAbM6L":{"email":"Joerg.mueller@tu-berlin.de"},"pvn9xI5v2hjjIGpFFHQH9V9b":{"email":"fabio.paterno@isti.cnr.it"},"3P_NzizuiMNmCGLYqKeldZuu":{"email":"awaller@dundee.ac.uk"},"R46G0wLriMOEtJQZp1KZunOe":{"email":"f.hwang@reading.ac.uk"},"ItQXvuUiWWmQhGVyeNEFxrzW":{"email":"silvia.lindtner@gmail.com"},"kU1Iyh5637jpqpo1MBNyDjD2":{"email":"john.vines@ncl.ac.uk"},"77Iub9KPLev4fhGBBmdEHCJm":{"email":"bellotti@parc.com"},"2xFnkeaMuaPqc-U6gtC9saSB":{"email":"wmoncur@dundee.ac.uk"},"SvJFd9vgXg-4zxWob-RuITFC":{"email":"joanna@cs.ub.ca"},"9okeJoO8Aovjz8IAI8JS9xId":{"email":"myriam.lewkowicz@utt.fr"},"0HbZlMVZpr5q5c1lFdxdFGQi":{"email":"Nchen@microsoft.com"},"xFOFRSCJHxB2jXwhjV0YeFxT":{"email":"emailaddress"},"_e0M7y8ruD4OSl66LroKIqQX":{"email":"vlh@acm.org"},"wyOWW68zz-nIMmuMLf2w710b":{"email":"wolfgang@cse.yorku.ca"},"NXYLrwFoDZdNsrSw9Q34mKkV":{"email":"tjvg@di.fc.ul.pt"},"vSKcrL3iILc4GSccBbBBKMl7":{"email":"maria.wolters@ed.ac.uk"},"YIC6c2i3UelcZyVGJpEgC00P":{"email":"jfc@cs.berkeley.edu"},"CJRVCxH7nTrH3qpNNZpVf3ku":{"email":"depaula@acm.org"},"G7JBig2ATy6TJRuXLHvENTqM":{"email":"yardi@umich.edu"},"85TRs28SCHWkjVWEDig_sf-Q":{"email":"Xmyzhou@rutgers.edu"},"p5rVMwtl_RJxdz1P7FSD4AeQ":{"email":"l.ciolfi@shu.ac.uk"},"2QQd7KtjXBmBGnUQkCvJgKx2":{"email":"dvogel@uwaterloo.ca"},"-RVOw7Hxr8K1rORZsjwduRJn":{"email":"teevan@gmail.com"},"3X2SDRCdV0T2QwFyN1wEEDwQ":{"email":"mulderi@acm.org"},"9Jq7t9MEy93vz792jg5AYTos":{"email":"me@patrickgage.com"},"kNkGzuJ8LuuX6bfc__8rZqj1":{"email":"Mark.blythe@northumbria"},"Qp3pZmiZdEGvUxf5FWMStnJv":{"email":"ninggu@fudan.edu.cn"},"WhFYrUCEDDHFwey5c4RgthZU":{"email":"david.kim@newcastle.ac.uk"},"3qNqIQ2X2N7BPqb8HecdY2L9":{"email":"krueger@dfki.de"},"OAb0urtvEVnsrOgE5Nov5tt0":{"email":"Brumby@cs.ucl.ac.uk"},"l1ttV7yozStLOkTrWloiMcba":{"email":"Mark.blythe@northumbria.ac.uk"},"NeGSY-pSqBYuO-3mivv7sOjt":{"email":"teevan@gmail.com"},"paMY5S_SijcgLAA8Ie8ZWbb9":{"email":"aantle@sfu.ca"},"elZst-zhlE99owPwxc1XgACl":{"email":"dtatar@cs.vt.edu"},"fIAvlSGeRpzvaNf7BWZ-AEYg":{"email":"gutwin@cs.usask.ca"},"X79jOKt9H4Bo4mRrurp0H3SB":{"email":"rcm"},"ysDcYX_BoR9H4OKCEjC9YeB8":{"email":"rcm"},"JPUH-ZgR9qW1XJZaFwRpsOzQ":{"email":"albrecht.schmidt@vis.uni-stuttgart.de"},"JosNeA7cEZs9FFplLzEBiOxk":{"email":"Tovi.Grossman@autodesk.com"},"HC1R58hCqV1-LoS5y3NogG8J":{"email":"eadar@umich.edu"},"YpCPEtlUD_lDUfFptFDv1nLB":{"email":"Tovi.Grossman@autodesk.com"},"oRq2GlMkHvRzyoLaJJMH_lvX":{"email":"Tovi.Grossman@autodesk.com"},"QMgsoX6KygXDkZPD9MJe81Le":{"email":"rcm"},"gg-bSe0GLLzlaDxgPnZJm2uC":{"email":"hq@northwestern.edu"},"m6cO4zV7tuwTrNqjv6kCxVXW":{"email":"rcm"},"_jYdNSttchbnxHM1ztxkcEzb":{"email":"Tovi.Grossman@autodesk.com"},"l60Yxl1z7iyNwlAOkCefiY_s":{"email":"albrecht.schmidt@vis.uni-stuttgart.de"},"V3VVktj9DWYO_OHEn3PwG3pH":{"email":"Tovi.Grossman@autodesk.com"},"BRsEu0GXJYb8GnGtvzpw3F2v":{"email":"rcm"},"b1hPcSBo87CSP9Xhc8LpgpxA":{"email":"Tovi.Grossman@autodesk.com"},"A7DxAopydUgSwuHRq03nlWhf":{"email":"tovi.grossman@autodesk.com"},"roKuWgtX1bxXTtilh3utG6L-":{"email":"tovi.grossman@autodesk.com"},"exQuB-UzyE4LzwvXLSqIa7Zm":{"email":"tovi.grossman@autodesk.com"},"-m48yJMFYSs-XppE2s6OF_BP":{"email":"tovi.grossman@autodesk.com"},"kQTNitt9HCgA3_st5DHk58Ix":{"email":"Tovi.Grossman@autodesk.com"},"MVv8rXsf8uZi2ozB8Ks7dZ_Y":{"email":"Tovi.Grossman@autodesk.com"},"rd-ExIwLHtRE_NgvATybCeKK":{"email":"albrecht.schmidt@vis.uni-stuttgart.de"},"-Ik7dKRysU15bmSUqXJi_xOS":{"email":"Tovi.Grossman@autodesk.com"},"NcjLT1GFVVkVPmhCc_2MsT7l":{"email":"eadar@umich.edu"},"MYHzN2yk4o-dgm5Y5pQ3FrT9":{"email":"tovi.grossman@autodesk.com"},"3quyXx6aSe_rbHCrD7SLubuO":{"email":"rcm@mit.edu"},"946wZhn78ExYV-RZt1KbKfdJ":{"email":"eadar@umich.edu"},"GMMpAFSxMzsqS0ghbNjZ7VjM":{"email":"Tovi.Grossman@autodesk.com"},"3x7DeXgCFn7hgGfrG8rJLFMg":{"email":"Tovi.Grossman@autodesk.com"},"ijvn5bkPUeyXYQlOWREPwkQb":{"email":"Tovi.Grossman@autodesk.com"},"48Q1Wkr5s-eRcgUqXpymEwfY":{"email":"Tovi.Grossman@autodesk.com"},"nnVSwTn0g_udjb4xiuVRmduD":{"email":"Tovi.Grossman@autodesk.com"},"hImRgfSWp7QuSf-ydEvv5awp":{"email":"tovi.grossman@autodesk.com"}},"chat":[],"labelList":{"":{"label":"","itemsUsedBy":["pn466","pn881","pn933","pn939","pn989","pn990","pn1390","pn2256"],"creationTime":0,"user":"cscw","creator":"system"},"Third-party software add-on development":{"creationTime":1386525286894,"itemsUsedBy":["pn2096"],"creator":"sszhao@yahoo.com","user":"sszhao@yahoo.com","label":"Third-party software add-on development"},"global":{"creationTime":1386522142179,"itemsUsedBy":["pn1347"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"global"},"it is NOT pen input":{"creationTime":1386525916116,"itemsUsedBy":["pn1865"],"creator":"steimle@media.mit.edu","user":"steimle@media.mit.edu","label":"it is NOT pen input"},"Tabletop interaction":{"creationTime":1386525161970,"itemsUsedBy":["pn1983"],"creator":"elm@purdue.edu","user":"elm@purdue.edu","label":"Tabletop interaction"},"Crowdsourcing":{"creationTime":1386523847975,"itemsUsedBy":[],"creator":"nebeling@inf.ethz.ch","user":"nebeling@inf.ethz.ch","label":"Crowdsourcing"},"best paper ever":{"creationTime":1386526172797,"itemsUsedBy":["pn389"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"best paper ever"},"Affective computing":{"creationTime":1386528390462,"itemsUsedBy":["pn1188"],"creator":"e.karapanos@gmail.com","user":"e.karapanos@gmail.com","label":"Affective computing"},"Gestural interaction":{"creationTime":1386522601755,"itemsUsedBy":["pn1452","pn2216","pn799","pn601","pn1722","pn138","pn965","pn1046","pn2157","pn425","pn2022","pn525"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Gestural interaction"},"Tutorials":{"creationTime":1386523547147,"itemsUsedBy":["pn884","pn2441","pn224"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"Tutorials"},"Google Glass":{"creationTime":1386521755230,"itemsUsedBy":["pn2112","pn739"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Google Glass"},"Caring for people":{"creationTime":1386523128226,"itemsUsedBy":["pn1896","pn590"],"creator":"dtatar@cs.vt.edu","user":"dtatar@cs.vt.edu","label":"Caring for people"},"ethics":{"creationTime":1386523103691,"itemsUsedBy":["pn2160","pn1325"],"creator":"daverandall2008@gmail.com","user":"daverandall2008@gmail.com","label":"ethics"},"hackerspace culture":{"creationTime":1386522935681,"itemsUsedBy":["pn1428"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"hackerspace culture"},"Critical infrastructures":{"creationTime":1386522692889,"itemsUsedBy":["pn581"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Critical infrastructures"},"sorta fitz law":{"creationTime":1386522945578,"itemsUsedBy":["pn1916","pn750","pn272"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"sorta fitz law"},"Vulnerable groups":{"creationTime":1386522985136,"itemsUsedBy":["pn1517"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Vulnerable groups"},"far-out interaction styles":{"creationTime":1386525334408,"itemsUsedBy":["pn728","pn371","pn775"],"creator":"no@spam.org","user":"no@spam.org","label":"far-out interaction styles"},"Incentives":{"creationTime":1386522098344,"itemsUsedBy":["pn2489"],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Incentives"},"file browser":{"creationTime":1386524544465,"itemsUsedBy":["pn361"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"file browser"},"predictive model":{"creationTime":1386523912450,"itemsUsedBy":["pn750"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"predictive model"},"User studies of medical devices":{"creationTime":1386523793878,"itemsUsedBy":["pn1242"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"User studies of medical devices"},"Physical Computing":{"creationTime":1386523323634,"itemsUsedBy":["pn2327"],"creator":"joonhwan@snu.ac.kr","user":"joonhwan@snu.ac.kr","label":"Physical Computing"},"Interruption management":{"creationTime":1386522063161,"itemsUsedBy":["pn641","pn806"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Interruption management"},"User and Cognitive models":{"label":"User and Cognitive models","itemsUsedBy":["pn162","pn171","pn183","pn220","pn240","pn247","pn272","pn342","pn378","pn392","pn396","pn398","pn422","pn471","pn478","pn494","pn577","pn582","pn591","pn600","pn623","pn626","pn659","pn661","pn689","pn698","pn750","pn785","pn818","pn856","pn867","pn880","pn911","pn920","pn940","pn1004","pn1026","pn1047","pn1071","pn1111","pn1115","pn1117","pn1163","pn1195","pn1204","pn1215","pn1224","pn1247","pn1250","pn1293","pn1339","pn1379","pn1391","pn1399","pn1417","pn1435","pn1450","pn1514","pn1524","pn1531","pn1554","pn1555","pn1633","pn1655","pn1662","pn1703","pn1708","pn1740","pn1742","pn1780","pn1787","pn1827","pn1831","pn1853","pn1892","pn1902","pn1910","pn1975","pn1982","pn2072","pn2105","pn2113","pn2155","pn2187","pn2196","pn2217","pn2230","pn2241","pn2286","pn2289","pn2316","pn2348","pn2379","pn2400","pn2405","pn2410","pn2420","pn2426","pn2433","pn2466","pn2486","pn2494","pn2513","pn2516","pn2560","pn2119"],"creationTime":0,"user":"cscw","creator":"system"},"special issue - sustainability":{"creationTime":1386523446735,"itemsUsedBy":["to133","to110","to127","to112","to136"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"special issue - sustainability"},"non-interactive artifact":{"creationTime":1386523432518,"itemsUsedBy":["pn1241"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"non-interactive artifact"},"Stress":{"creationTime":1386522930853,"itemsUsedBy":["pn1514"],"creator":"weibel@ucsd.edu","user":"weibel@ucsd.edu","label":"Stress"},"internet of things":{"creationTime":1386526851231,"itemsUsedBy":["pn1923"],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"internet of things"},"crowdwork":{"creationTime":1386521270680,"itemsUsedBy":["pn1123","pn2208"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"crowdwork"},"Debugging":{"creationTime":1386524300958,"itemsUsedBy":["pn2447"],"creator":"krueger@dfki.de","user":"krueger@dfki.de","label":"Debugging"},"Mobile health":{"creationTime":1386523694465,"itemsUsedBy":["pn1298","pn686","pn1736"],"creator":"Jina.huh@gmail.com","user":"Jina.huh@gmail.com","label":"Mobile health"},"interactive furniture":{"creationTime":1386529829377,"itemsUsedBy":["pn2150"],"creator":"judy.kay@gmail.com","user":"judy.kay@gmail.com","label":"interactive furniture"},"replication":{"creationTime":1386523700328,"itemsUsedBy":["pn345","pn171","pn292","pn1071"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"replication"},"appropriation":{"creationTime":1386522953028,"itemsUsedBy":["pn1442"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"appropriation"},"Performing Arts":{"creationTime":1386526850551,"itemsUsedBy":["pn541"],"creator":"erinacarroll@gmail.com","user":"erinacarroll@gmail.com","label":"Performing Arts"},"social network and social movement":{"creationTime":1386522763059,"itemsUsedBy":["pn1330"],"creator":"myriam.lewkowicz@utt.fr","user":"myriam.lewkowicz@utt.fr","label":"social network and social movement"},"Text analysis":{"creationTime":1386527152011,"itemsUsedBy":["pn164"],"creator":"mtory@cs.uvic.ca","user":"mtory@cs.uvic.ca","label":"Text analysis"},"Content Strategy / Content Creation":{"label":"Content Strategy / Content Creation","itemsUsedBy":["pn411","pn518","pn573","pn663","pn774","pn858","pn1004","pn1114","pn1137","pn1424","pn2055","pn2410","pn1992"],"creationTime":0,"user":"cscw","creator":"system"},"exergames":{"creationTime":1386521769329,"itemsUsedBy":["pn1521"],"creator":"gutwin@cs.usask.ca","user":"gutwin@cs.usask.ca","label":"exergames"},"Modalities":{"creationTime":1386522879710,"itemsUsedBy":["pn320"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Modalities"},"Intergenerational Communication":{"creationTime":1386521927562,"itemsUsedBy":["pn1617"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"Intergenerational Communication"},"in the city":{"creationTime":1386523556447,"itemsUsedBy":["pn558","pn1675"],"creator":"antonella.deangeli@disi.unitn.it","user":"antonella.deangeli@disi.unitn.it","label":"in the city"},"cmc":{"creationTime":1386525356864,"itemsUsedBy":[],"creator":"mark.hancock@uwaterloo.ca","user":"mark.hancock@uwaterloo.ca","label":"cmc"},"End-user programming":{"creationTime":1386524986115,"itemsUsedBy":[],"creator":"haochuan@cs.nthu.edu.tw","user":"haochuan@cs.nthu.edu.tw","label":"End-user programming"},"Taste":{"creationTime":1386527798893,"itemsUsedBy":["pn319"],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Taste"},"planning":{"creationTime":1386524848745,"itemsUsedBy":["to137"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"planning"},"Memory":{"creationTime":1386524282572,"itemsUsedBy":["pn1161"],"creator":"xiangcao@acm.org","user":"xiangcao@acm.org","label":"Memory"},"diy":{"creationTime":1386521864783,"itemsUsedBy":["pn1904","pn1428","pn2011","pn1682","pn1264"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"diy"},"information overload":{"creationTime":1386523713601,"itemsUsedBy":["pn345","pn116"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"information overload"},"adversarial design":{"creationTime":1386522442140,"itemsUsedBy":["pn2140"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"adversarial design"},"Prosociality":{"creationTime":1386522889881,"itemsUsedBy":["pn2193","pn602"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"Prosociality"},"technology-enhanced learning":{"creationTime":1386527214148,"itemsUsedBy":["pn2472"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"technology-enhanced learning"},"scheduling and time":{"creationTime":1386523699348,"itemsUsedBy":["pn1110","pn1227"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"scheduling and time"},"force":{"creationTime":1386523960749,"itemsUsedBy":["pn386"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"force"},"pragmatic design":{"creationTime":1386522672003,"itemsUsedBy":["pn999"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"pragmatic design"},"New Design Methods":{"creationTime":1386523556066,"itemsUsedBy":["pn576","pn118","pn2303"],"creator":"scott.davidoff@jpl.nasa.gov","user":"scott.davidoff@jpl.nasa.gov","label":"New Design Methods"},"Friendsourcing":{"creationTime":1386521680286,"itemsUsedBy":["pn1255"],"creator":"sfussell@cornell.edu","user":"sfussell@cornell.edu","label":"Friendsourcing"},"prediction":{"creationTime":1386523536713,"itemsUsedBy":["pn526","pn180","pn150","pn1982"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"prediction"},"Virtual Community / Community Computing":{"label":"Virtual Community / Community Computing","itemsUsedBy":["pn101","pn117","pn166","pn167","pn197","pn240","pn243","pn317","pn534","pn568","pn600","pn668","pn675","pn676","pn695","pn708","pn725","pn731","pn746","pn766","pn782","pn792","pn802","pn871","pn888","pn993","pn1018","pn1138","pn1235","pn1259","pn1283","pn1301","pn1304","pn1341","pn1359","pn1374","pn1395","pn1410","pn1424","pn1450","pn1499","pn1512","pn1558","pn1715","pn1733","pn1807","pn1822","pn1849","pn1897","pn1956","pn1968","pn2014","pn2018","pn2024","pn2095","pn2108","pn2183","pn2199","pn2201","pn2298","pn2455","pn2461","pn2465","pn2471","pn2478","pn2504","pn2542"],"creationTime":0,"user":"cscw","creator":"system"},"design":{"label":"design","itemsUsedBy":["to102","to104","to105","to106","to107","to108","to110","to114","to117","to123","to127","to128","to131","to133","to134","to136"],"creationTime":0,"user":"cscw","creator":"system"},"repliCHI":{"creationTime":1386524195560,"itemsUsedBy":["pn292","pn1071","pn345"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"repliCHI"},"I'm (in)secure":{"creationTime":1386526777469,"itemsUsedBy":[],"creator":"aaa","user":"aaa","label":"I'm (in)secure"},"Reality-Based Interfaces":{"creationTime":1386525688429,"itemsUsedBy":[],"creator":"pierre.dragice@gmail.com","user":"pierre.dragice@gmail.com","label":"Reality-Based Interfaces"},"3D User Interfaces":{"creationTime":1386525884608,"itemsUsedBy":["pn1983"],"creator":"wolfgang@cse.yorku.ca","user":"wolfgang@cse.yorku.ca","label":"3D User Interfaces"},"PCG":{"creationTime":1386523048001,"itemsUsedBy":["pn2046"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"PCG"},"Location Location Location":{"creationTime":1386523236479,"itemsUsedBy":["pn1110","pn897"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Location Location Location"},"International Development":{"creationTime":1386522457124,"itemsUsedBy":[],"creator":"com@psychology.nottingham.ac.uk","user":"com@psychology.nottingham.ac.uk","label":"International Development"},"pinterest":{"creationTime":1386522333955,"itemsUsedBy":["pn1710"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"pinterest"},"Automotive":{"creationTime":1386524176510,"itemsUsedBy":["pn1969","pn233","pn648"],"creator":"krueger@dfki.de","user":"krueger@dfki.de","label":"Automotive"},"Usability Testing and Evaluation":{"label":"Usability Testing and Evaluation","itemsUsedBy":["pn115","pn153","pn172","pn184","pn192","pn221","pn247","pn252","pn268","pn270","pn357","pn359","pn361","pn374","pn392","pn406","pn415","pn416","pn417","pn424","pn427","pn445","pn452","pn478","pn480","pn481","pn543","pn545","pn548","pn553","pn591","pn635","pn636","pn639","pn647","pn648","pn673","pn682","pn685","pn737","pn743","pn774","pn803","pn808","pn835","pn852","pn854","pn867","pn879","pn903","pn918","pn934","pn936","pn980","pn998","pn1010","pn1025","pn1048","pn1054","pn1068","pn1082","pn1085","pn1086","pn1097","pn1100","pn1106","pn1109","pn1112","pn1116","pn1138","pn1142","pn1147","pn1158","pn1163","pn1176","pn1191","pn1193","pn1196","pn1223","pn1229","pn1259","pn1300","pn1324","pn1399","pn1407","pn1437","pn1450","pn1466","pn1480","pn1494","pn1510","pn1516","pn1526","pn1574","pn1579","pn1599","pn1600","pn1634","pn1637","pn1656","pn1668","pn1670","pn1680","pn1690","pn1691","pn1695","pn1735","pn1741","pn1758","pn1786","pn1787","pn1796","pn1797","pn1803","pn1813","pn1828","pn1833","pn1837","pn1846","pn1892","pn1893","pn1907","pn1920","pn1927","pn1965","pn1976","pn1995","pn2007","pn2016","pn2019","pn2031","pn2036","pn2044","pn2057","pn2068","pn2072","pn2092","pn2098","pn2106","pn2120","pn2135","pn2142","pn2151","pn2155","pn2161","pn2185","pn2187","pn2192","pn2209","pn2234","pn2236","pn2238","pn2247","pn2263","pn2329","pn2336","pn2341","pn2345","pn2360","pn2376","pn2383","pn2384","pn2389","pn2403","pn2411","pn2422","pn2426","pn2444","pn2484","pn2490","pn2493","pn2519","pn250"],"creationTime":0,"user":"cscw","creator":"system"},"remote intimacy":{"creationTime":1386524627486,"itemsUsedBy":["pn1238"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"remote intimacy"},"epistemic":{"creationTime":1386524546991,"itemsUsedBy":["pn190"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"epistemic"},"Online Comments":{"creationTime":1386530617021,"itemsUsedBy":["pn884"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Online Comments"},"values":{"creationTime":1386523657864,"itemsUsedBy":["pn255","pn1325"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"values"},"Mice":{"creationTime":1386531806979,"itemsUsedBy":["pn755"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Mice"},"photo sharing":{"creationTime":1386521751354,"itemsUsedBy":["pn1525","pn2417","pn405","pn1295","pn1241"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"photo sharing"},"usability-aestheic relationship":{"creationTime":1386527847259,"itemsUsedBy":["pn2490","pn643"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"usability-aestheic relationship"},"Plants":{"creationTime":1386522829556,"itemsUsedBy":["pn2406"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Plants"},"Multi-modal":{"creationTime":1386527816679,"itemsUsedBy":[],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Multi-modal"},"Sketch-based":{"creationTime":1386532452533,"itemsUsedBy":["pn228"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Sketch-based"},"tags":{"creationTime":1386522599317,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"tags"},"Animal-computer interaction":{"creationTime":1386523419720,"itemsUsedBy":["pn2368"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Animal-computer interaction"},"Service Design":{"label":"Service Design","itemsUsedBy":["pn103","pn192","pn517","pn569","pn679","pn722","pn725","pn1076","pn1176","pn1309","pn1324","pn1720","pn1866","pn1888","pn2296","pn2389","pn2460","pn2462","pn2516","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"Health Care":{"label":"Health Care","itemsUsedBy":["pn109","pn117","pn120","pn129","pn162","pn311","pn341","pn347","pn348","pn357","pn376","pn402","pn417","pn472","pn493","pn510","pn515","pn546","pn548","pn551","pn569","pn578","pn595","pn600","pn610","pn622","pn623","pn639","pn655","pn677","pn686","pn688","pn704","pn725","pn731","pn732","pn738","pn739","pn759","pn761","pn784","pn787","pn802","pn816","pn820","pn821","pn850","pn866","pn887","pn903","pn929","pn937","pn946","pn951","pn956","pn959","pn960","pn968","pn973","pn984","pn996","pn1009","pn1030","pn1047","pn1053","pn1076","pn1093","pn1140","pn1142","pn1156","pn1171","pn1196","pn1232","pn1234","pn1242","pn1256","pn1258","pn1259","pn1272","pn1298","pn1317","pn1322","pn1344","pn1357","pn1358","pn1377","pn1395","pn1400","pn1413","pn1415","pn1420","pn1450","pn1451","pn1457","pn1458","pn1463","pn1475","pn1486","pn1498","pn1511","pn1545","pn1546","pn1563","pn1584","pn1592","pn1600","pn1601","pn1622","pn1633","pn1637","pn1684","pn1698","pn1736","pn1740","pn1744","pn1748","pn1764","pn1794","pn1807","pn1812","pn1814","pn1815","pn1830","pn1859","pn1896","pn1903","pn1919","pn1925","pn1952","pn1960","pn2016","pn2020","pn2038","pn2055","pn2062","pn2074","pn2076","pn2087","pn2088","pn2089","pn2093","pn2107","pn2115","pn2122","pn2139","pn2146","pn2148","pn2172","pn2182","pn2185","pn2201","pn2214","pn2274","pn2286","pn2293","pn2300","pn2312","pn2347","pn2350","pn2386","pn2388","pn2403","pn2414","pn2415","pn2421","pn2425","pn2439","pn2457","pn2476","pn2487","pn2499","pn2502","pn2509","pn2519","pn2530","pn1446","pn444"],"creationTime":0,"user":"cscw","creator":"system"},"anticipation":{"creationTime":1386523451513,"itemsUsedBy":["pn1241"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"anticipation"},"User Authentication":{"creationTime":1386527239803,"itemsUsedBy":["pn1097"],"creator":"e.karapanos@gmail.com","user":"e.karapanos@gmail.com","label":"User Authentication"},"illustration":{"creationTime":1386523037743,"itemsUsedBy":["pn614"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"illustration"},"Multi-modal interfaces":{"label":"Multi-modal interfaces","itemsUsedBy":["pn111","pn172","pn187","pn204","pn246","pn267","pn276","pn281","pn311","pn416","pn428","pn436","pn477","pn495","pn569","pn595","pn634","pn651","pn709","pn745","pn803","pn824","pn828","pn876","pn908","pn925","pn927","pn1072","pn1074","pn1085","pn1091","pn1128","pn1160","pn1169","pn1181","pn1193","pn1219","pn1223","pn1226","pn1263","pn1279","pn1334","pn1339","pn1367","pn1385","pn1403","pn1434","pn1443","pn1494","pn1502","pn1509","pn1545","pn1585","pn1604","pn1618","pn1635","pn1645","pn1674","pn1684","pn1702","pn1703","pn1706","pn1714","pn1777","pn1779","pn1893","pn1927","pn1950","pn1990","pn2003","pn2008","pn2120","pn2137","pn2149","pn2155","pn2184","pn2185","pn2190","pn2247","pn2265","pn2290","pn2293","pn2295","pn2338","pn2345","pn2383","pn2406","pn2455","pn2466","pn2497","pn2508","pn2394","pn319"],"creationTime":0,"user":"cscw","creator":"system"},"motor control":{"creationTime":1386524432539,"itemsUsedBy":["pn426"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"motor control"},"Design Research":{"creationTime":1386522858567,"itemsUsedBy":[],"creator":"joonhwan@snu.ac.kr","user":"joonhwan@snu.ac.kr","label":"Design Research"},"Social Networking":{"creationTime":1386526370271,"itemsUsedBy":[],"creator":"christopher.power@york.ac.uk","user":"christopher.power@york.ac.uk","label":"Social Networking"},"Multidisciplinary Design / Interdisciplinary Design":{"label":"Multidisciplinary Design / Interdisciplinary Design","itemsUsedBy":["pn141","pn178","pn207","pn357","pn377","pn510","pn515","pn540","pn578","pn581","pn614","pn634","pn689","pn759","pn769","pn872","pn886","pn899","pn918","pn986","pn987","pn999","pn1001","pn1037","pn1095","pn1104","pn1117","pn1155","pn1213","pn1253","pn1334","pn1369","pn1387","pn1428","pn1430","pn1518","pn1542","pn1633","pn1682","pn1691","pn1720","pn1735","pn1779","pn1793","pn1820","pn1841","pn1854","pn1874","pn1890","pn1905","pn1915","pn2011","pn2040","pn2056","pn2060","pn2077","pn2143","pn2155","pn2160","pn2180","pn2193","pn2207","pn2262","pn2297","pn2320","pn2341","pn2358","pn2359","pn2433","pn2455","pn2458","pn2497"],"creationTime":0,"user":"cscw","creator":"system"},"Social Systems":{"creationTime":1386523494916,"itemsUsedBy":["pn1343"],"creator":"ninggu@fudan.edu.cn","user":"ninggu@fudan.edu.cn","label":"Social Systems"},"Museums":{"creationTime":1386526146610,"itemsUsedBy":["pn1632"],"creator":"kash@diku.dk","user":"kash@diku.dk","label":"Museums"},"search":{"creationTime":1386521943824,"itemsUsedBy":["pn1982","pn2128","pn1558","pn431","pn750","pn626","pn1071","pn361","pn1413"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"search"},"Aesthetics":{"creationTime":1386522409091,"itemsUsedBy":["pn1095","pn2490"],"creator":"giulio.jacucci@hiit.fi","user":"giulio.jacucci@hiit.fi","label":"Aesthetics"},"deformable interfaces":{"creationTime":1386532589514,"itemsUsedBy":["pn2041","pn1883"],"creator":"yutak@acm.org","user":"yutak@acm.org","label":"deformable interfaces"},"3D Modeling":{"creationTime":1386531648797,"itemsUsedBy":["pn330"],"creator":"mdixon@cs.washington.edu","user":"mdixon@cs.washington.edu","label":"3D Modeling"},"Energy":{"creationTime":1386523104066,"itemsUsedBy":["pn1448","to106","pn505"],"creator":"fernaeus@kth.se","user":"fernaeus@kth.se","label":"Energy"},"interaction techniques":{"creationTime":1386523975171,"itemsUsedBy":[],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"interaction techniques"},"ultrasonic haptics":{"creationTime":1386525877472,"itemsUsedBy":["pn438"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"ultrasonic haptics"},"Children":{"label":"Children","itemsUsedBy":["pn106","pn129","pn130","pn212","pn334","pn355","pn391","pn397","pn431","pn443","pn445","pn470","pn595","pn600","pn610","pn669","pn695","pn740","pn791","pn866","pn883","pn886","pn894","pn950","pn955","pn960","pn976","pn987","pn1061","pn1104","pn1117","pn1182","pn1185","pn1267","pn1270","pn1276","pn1290","pn1317","pn1348","pn1354","pn1358","pn1393","pn1403","pn1430","pn1432","pn1434","pn1448","pn1458","pn1465","pn1494","pn1501","pn1517","pn1547","pn1563","pn1568","pn1570","pn1574","pn1578","pn1584","pn1588","pn1649","pn1664","pn1685","pn1691","pn1745","pn1750","pn1765","pn1789","pn1798","pn1817","pn1827","pn1831","pn1843","pn1861","pn1873","pn1880","pn1924","pn1941","pn1966","pn1974","pn2007","pn2020","pn2028","pn2031","pn2116","pn2155","pn2162","pn2163","pn2185","pn2199","pn2234","pn2268","pn2278","pn2284","pn2308","pn2313","pn2323","pn2330","pn2347","pn2406","pn2433","pn2444","pn2491","pn2510","pn2534","pn1820","pn2317"],"creationTime":0,"user":"cscw","creator":"system"},"ExtendedFamily":{"creationTime":1386521713907,"itemsUsedBy":["pn1617"],"creator":"ajbrush@microsoft.com","user":"ajbrush@microsoft.com","label":"ExtendedFamily"},"time-delay":{"creationTime":1386524294883,"itemsUsedBy":["pn1227"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"time-delay"},"targeting":{"creationTime":1386523673070,"itemsUsedBy":["pn255"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"targeting"},"spherical displays":{"creationTime":1386523098679,"itemsUsedBy":["pn1727"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"spherical displays"},"Home":{"label":"Home","itemsUsedBy":["pn101","pn119","pn139","pn155","pn172","pn214","pn229","pn270","pn285","pn334","pn345","pn367","pn421","pn457","pn606","pn619","pn634","pn656","pn680","pn695","pn699","pn758","pn774","pn788","pn819","pn821","pn840","pn844","pn849","pn868","pn888","pn902","pn929","pn969","pn978","pn984","pn986","pn998","pn1034","pn1068","pn1076","pn1083","pn1090","pn1125","pn1130","pn1156","pn1169","pn1171","pn1176","pn1184","pn1192","pn1207","pn1208","pn1241","pn1263","pn1270","pn1289","pn1306","pn1339","pn1377","pn1381","pn1393","pn1397","pn1403","pn1450","pn1462","pn1467","pn1479","pn1494","pn1511","pn1523","pn1527","pn1529","pn1539","pn1568","pn1577","pn1617","pn1652","pn1657","pn1663","pn1684","pn1691","pn1692","pn1695","pn1724","pn1732","pn1733","pn1740","pn1743","pn1792","pn1794","pn1829","pn1831","pn1842","pn1886","pn1893","pn1905","pn1909","pn1917","pn1919","pn1925","pn1945","pn1954","pn1962","pn1964","pn2003","pn2012","pn2035","pn2042","pn2050","pn2073","pn2115","pn2125","pn2148","pn2165","pn2175","pn2179","pn2185","pn2191","pn2217","pn2233","pn2244","pn2247","pn2261","pn2276","pn2282","pn2283","pn2308","pn2315","pn2329","pn2335","pn2392","pn2395","pn2418","pn2425","pn2444","pn2460","pn2471","pn2480","pn2515","pn2522","pn2528","pn2548","pn521","pn186","to106"],"creationTime":0,"user":"cscw","creator":"system"},"Materiality":{"creationTime":1386527506039,"itemsUsedBy":["pn1923"],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Materiality"},"Physical interaction":{"creationTime":1386523294480,"itemsUsedBy":["pn2327"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Physical interaction"},"User Experience Design / Experience Design":{"label":"User Experience Design / Experience Design","itemsUsedBy":["pn101","pn103","pn118","pn122","pn131","pn140","pn157","pn168","pn172","pn184","pn195","pn247","pn259","pn260","pn269","pn281","pn286","pn302","pn309","pn334","pn345","pn388","pn392","pn427","pn447","pn456","pn469","pn477","pn485","pn508","pn513","pn517","pn542","pn543","pn551","pn553","pn555","pn569","pn577","pn582","pn606","pn609","pn624","pn629","pn645","pn659","pn682","pn695","pn703","pn706","pn729","pn735","pn746","pn758","pn759","pn769","pn774","pn779","pn788","pn791","pn801","pn807","pn810","pn811","pn839","pn855","pn878","pn888","pn895","pn901","pn903","pn911","pn918","pn926","pn931","pn936","pn941","pn942","pn953","pn957","pn986","pn997","pn998","pn1017","pn1034","pn1041","pn1043","pn1067","pn1075","pn1079","pn1082","pn1090","pn1094","pn1101","pn1128","pn1133","pn1134","pn1145","pn1146","pn1166","pn1168","pn1172","pn1179","pn1190","pn1195","pn1215","pn1229","pn1231","pn1240","pn1241","pn1263","pn1265","pn1268","pn1274","pn1275","pn1291","pn1309","pn1315","pn1320","pn1325","pn1344","pn1348","pn1379","pn1380","pn1381","pn1383","pn1393","pn1428","pn1442","pn1448","pn1450","pn1452","pn1455","pn1467","pn1476","pn1487","pn1494","pn1507","pn1518","pn1519","pn1523","pn1546","pn1547","pn1551","pn1568","pn1572","pn1594","pn1618","pn1619","pn1625","pn1629","pn1632","pn1646","pn1652","pn1654","pn1655","pn1657","pn1665","pn1667","pn1668","pn1672","pn1676","pn1677","pn1701","pn1730","pn1733","pn1741","pn1743","pn1780","pn1798","pn1806","pn1830","pn1832","pn1841","pn1848","pn1858","pn1866","pn1874","pn1887","pn1906","pn1933","pn1940","pn1943","pn1962","pn1972","pn2006","pn2017","pn2019","pn2032","pn2044","pn2048","pn2055","pn2065","pn2075","pn2089","pn2092","pn2116","pn2127","pn2159","pn2165","pn2175","pn2178","pn2182","pn2185","pn2196","pn2202","pn2209","pn2224","pn2234","pn2240","pn2243","pn2247","pn2248","pn2289","pn2292","pn2316","pn2320","pn2335","pn2341","pn2353","pn2354","pn2355","pn2359","pn2364","pn2372","pn2376","pn2383","pn2416","pn2436","pn2441","pn2444","pn2453","pn2455","pn2460","pn2466","pn2471","pn2477","pn2479","pn2497","pn2498","pn2499","pn2513","pn2515","pn2516","pn2518","pn2534","pn2537","pn2544","pn2548","pn2552","pn1811","pn1710","pn2150"],"creationTime":0,"user":"cscw","creator":"system"},"human rights":{"creationTime":1386524746889,"itemsUsedBy":["pn1325"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"human rights"},"usable privacy and security":{"creationTime":1386528477183,"itemsUsedBy":["pn897","pn2094","pn2112","pn1776","pn2380","pn2463","pn785","pn191","pn757","pn2227","pn1724","pn1399","pn2005","pn1097","pn2525","pn2159","pn2399","pn1525"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"usable privacy and security"},"Cartography":{"creationTime":1386527101736,"itemsUsedBy":[],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Cartography"},"wearables":{"creationTime":1386522916558,"itemsUsedBy":[],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"wearables"},"Privacy":{"label":"Privacy","itemsUsedBy":["pn156","pn191","pn199","pn203","pn285","pn355","pn356","pn365","pn409","pn457","pn567","pn645","pn689","pn695","pn719","pn785","pn854","pn879","pn897","pn1037","pn1052","pn1079","pn1144","pn1146","pn1165","pn1191","pn1266","pn1288","pn1412","pn1416","pn1480","pn1492","pn1496","pn1525","pn1544","pn1561","pn1641","pn1720","pn1776","pn1785","pn1802","pn1803","pn1888","pn1898","pn1962","pn1991","pn2005","pn2078","pn2080","pn2085","pn2112","pn2125","pn2142","pn2144","pn2158","pn2159","pn2162","pn2179","pn2195","pn2219","pn2342","pn2351","pn2380","pn2399","pn2403","pn2434","pn2456","pn2463","pn2498","pn2505","pn2525","pn1097"],"creationTime":0,"user":"cscw","creator":"system"},"network of care":{"creationTime":1386523749606,"itemsUsedBy":["pn1896","pn802","pn2074","pn1814"],"creator":"Marilyn.McGee-Lennon@glasgow.ac.uk","user":"Marilyn.McGee-Lennon@glasgow.ac.uk","label":"network of care"},"On your Feet":{"creationTime":1386525425171,"itemsUsedBy":["pn371"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"On your Feet"},"Multitouch":{"creationTime":1386522710426,"itemsUsedBy":["pn2394","pn426","pn386","pn1092","pn1700","pn1473","pn583","pn198","pn343","pn988"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"Multitouch"},"MESH Networking":{"creationTime":1386521716894,"itemsUsedBy":["pn286"],"creator":"emailaddress","user":"emailaddress","label":"MESH Networking"},"The Pros versus the Citizens":{"creationTime":1386524899785,"itemsUsedBy":["pn862"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"The Pros versus the Citizens"},"Usable Security":{"creationTime":1386521996829,"itemsUsedBy":["pn1976","pn2227","pn1399","pn191","pn2399","pn2005","pn2094","pn1811","pn757","pn1724","pn1097"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Usable Security"},"Semi-autonomous systems":{"label":"Semi-autonomous systems","itemsUsedBy":["pn196","pn340","pn635","pn762","pn1072","pn1343","pn1398","pn1593","pn1812","pn2040","pn2203","pn2244","pn2273","pn2389"],"creationTime":0,"user":"cscw","creator":"system"},"forums":{"creationTime":1386521919082,"itemsUsedBy":["pn1296","pn1341","pn802","pn2074"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"forums"},"sensors":{"creationTime":1386522992919,"itemsUsedBy":["pn1626","pn1225"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"sensors"},"cloud":{"creationTime":1386524348898,"itemsUsedBy":["pn785"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"cloud"},"social media":{"creationTime":1386521564350,"itemsUsedBy":["pn2095","pn1954","pn1347","pn2488","pn653","pn1763","pn1236","pn975","pn219","pn1806","pn862","pn190"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"social media"},"Multi-modal Interaction":{"creationTime":1386525486226,"itemsUsedBy":["pn730"],"creator":"j.alexander@lancaster.ac.uk","user":"j.alexander@lancaster.ac.uk","label":"Multi-modal Interaction"},"Wearable computing":{"creationTime":1386532168422,"itemsUsedBy":["pn589","pn222","pn505"],"creator":"yangli@acm.org","user":"yangli@acm.org","label":"Wearable computing"},"Mobile phone interaction":{"creationTime":1386523737951,"itemsUsedBy":["pn263"],"creator":"ninggu@fudan.edu.cn","user":"ninggu@fudan.edu.cn","label":"Mobile phone interaction"},"Mturk":{"creationTime":1386521842845,"itemsUsedBy":["pn2227"],"creator":"alexander.de.luca@ifi.lmu.de","user":"alexander.de.luca@ifi.lmu.de","label":"Mturk"},"cultural archives":{"creationTime":1386523842433,"itemsUsedBy":["pn1325"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"cultural archives"},"socialization":{"creationTime":1386522577435,"itemsUsedBy":["pn1918","pn444"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"socialization"},"Automation":{"creationTime":1386523340736,"itemsUsedBy":["pn2046"],"creator":"scott.davidoff@jpl.nasa.gov","user":"scott.davidoff@jpl.nasa.gov","label":"Automation"},"crowdsourcing":{"creationTime":1386521276805,"itemsUsedBy":["pn1123","pn1343","pn2235","pn150","pn2225","pn263","pn1558","pn1255","pn2208","pn340","pn526","to126","to137","pn775","pn1161","pn1421"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"crowdsourcing"},"Computer Vision":{"creationTime":1386532313478,"itemsUsedBy":["pn2022"],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"Computer Vision"},"User Interface Design":{"label":"User Interface Design","itemsUsedBy":["pn101","pn109","pn115","pn132","pn133","pn153","pn189","pn207","pn208","pn210","pn213","pn216","pn221","pn247","pn250","pn252","pn262","pn269","pn280","pn288","pn302","pn303","pn309","pn329","pn342","pn354","pn357","pn360","pn382","pn388","pn390","pn392","pn406","pn415","pn416","pn421","pn430","pn435","pn441","pn451","pn471","pn482","pn489","pn503","pn508","pn528","pn535","pn538","pn542","pn543","pn555","pn569","pn577","pn599","pn608","pn617","pn619","pn623","pn629","pn634","pn641","pn643","pn646","pn678","pn689","pn695","pn706","pn748","pn753","pn768","pn774","pn800","pn807","pn808","pn809","pn812","pn824","pn833","pn841","pn846","pn849","pn857","pn861","pn863","pn865","pn899","pn901","pn908","pn912","pn918","pn927","pn935","pn936","pn943","pn955","pn958","pn977","pn980","pn991","pn1010","pn1026","pn1040","pn1041","pn1044","pn1046","pn1048","pn1052","pn1054","pn1063","pn1070","pn1073","pn1082","pn1094","pn1096","pn1101","pn1109","pn1116","pn1118","pn1127","pn1128","pn1131","pn1138","pn1143","pn1147","pn1154","pn1160","pn1185","pn1191","pn1194","pn1195","pn1197","pn1201","pn1203","pn1205","pn1206","pn1240","pn1245","pn1249","pn1251","pn1262","pn1309","pn1314","pn1335","pn1352","pn1364","pn1384","pn1397","pn1407","pn1417","pn1430","pn1437","pn1450","pn1473","pn1494","pn1495","pn1502","pn1507","pn1511","pn1522","pn1530","pn1532","pn1553","pn1554","pn1559","pn1568","pn1574","pn1579","pn1589","pn1592","pn1641","pn1651","pn1655","pn1656","pn1657","pn1661","pn1676","pn1691","pn1695","pn1711","pn1720","pn1738","pn1739","pn1740","pn1742","pn1743","pn1752","pn1759","pn1761","pn1772","pn1778","pn1783","pn1802","pn1816","pn1825","pn1831","pn1848","pn1856","pn1873","pn1876","pn1880","pn1892","pn1902","pn1905","pn1907","pn1961","pn1965","pn1986","pn1989","pn2010","pn2015","pn2019","pn2036","pn2044","pn2057","pn2068","pn2075","pn2082","pn2088","pn2089","pn2114","pn2116","pn2127","pn2136","pn2146","pn2149","pn2159","pn2165","pn2166","pn2185","pn2187","pn2192","pn2196","pn2199","pn2211","pn2217","pn2218","pn2241","pn2263","pn2267","pn2288","pn2291","pn2292","pn2299","pn2300","pn2301","pn2303","pn2309","pn2316","pn2341","pn2350","pn2355","pn2368","pn2369","pn2372","pn2374","pn2381","pn2383","pn2390","pn2400","pn2403","pn2416","pn2420","pn2436","pn2439","pn2441","pn2453","pn2460","pn2466","pn2468","pn2473","pn2484","pn2485","pn2497","pn2499","pn2506","pn2518","pn2528","pn2542","pn2544","pn2548","pn1360"],"creationTime":0,"user":"cscw","creator":"system"},"music":{"creationTime":1386522436696,"itemsUsedBy":[],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"music"},"hci4d":{"label":"hci4d","itemsUsedBy":["to112","to123"],"creationTime":0,"user":"cscw","creator":"system"},"activity monitoring":{"creationTime":1386524559829,"itemsUsedBy":["pn493","pn876"],"creator":"asellen@microsoft.com","user":"asellen@microsoft.com","label":"activity monitoring"},"causal interactions":{"creationTime":1386524191136,"itemsUsedBy":["pn1417"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"causal interactions"},"Causal Encounters":{"creationTime":1386525172400,"itemsUsedBy":["pn1417","pn785"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Causal Encounters"},"Self-reported experiences":{"creationTime":1386522882343,"itemsUsedBy":["pn320"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Self-reported experiences"},"Wearable technology":{"creationTime":1386522169478,"itemsUsedBy":["pn1579","pn1845"],"creator":"stuart@tropic.org.uk","user":"stuart@tropic.org.uk","label":"Wearable technology"},"3D Interaction and Graphics":{"label":"3D Interaction and Graphics","itemsUsedBy":["pn138","pn147","pn172","pn173","pn267","pn269","pn287","pn297","pn321","pn330","pn359","pn415","pn416","pn421","pn444","pn477","pn587","pn600","pn606","pn736","pn775","pn779","pn801","pn832","pn839","pn849","pn888","pn912","pn964","pn977","pn981","pn1100","pn1157","pn1174","pn1212","pn1403","pn1404","pn1423","pn1465","pn1494","pn1513","pn1533","pn1727","pn1767","pn1837","pn1851","pn1919","pn1938","pn1983","pn2022","pn2049","pn2062","pn2075","pn2168","pn2173","pn2234","pn2247","pn2259","pn2324","pn2369","pn2389","pn2457","pn2493","pn1901","pn734"],"creationTime":0,"user":"cscw","creator":"system"},"Older adults":{"creationTime":1386526208935,"itemsUsedBy":[],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Older adults"},"Visual Design":{"label":"Visual Design","itemsUsedBy":["pn269","pn377","pn382","pn469","pn528","pn540","pn555","pn695","pn713","pn748","pn797","pn798","pn801","pn805","pn849","pn922","pn926","pn945","pn1082","pn1086","pn1138","pn1172","pn1180","pn1201","pn1464","pn1574","pn1685","pn1866","pn1879","pn1892","pn1971","pn2019","pn2075","pn2082","pn2089","pn2141","pn2340","pn2350","pn2477","pn2490"],"creationTime":0,"user":"cscw","creator":"system"},"Reflection":{"creationTime":1386523330327,"itemsUsedBy":["pn1241"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Reflection"},"Older Adults":{"label":"Older Adults","itemsUsedBy":["pn117","pn120","pn145","pn162","pn334","pn412","pn536","pn543","pn548","pn600","pn652","pn695","pn767","pn854","pn867","pn894","pn903","pn962","pn1001","pn1040","pn1134","pn1135","pn1196","pn1205","pn1207","pn1258","pn1267","pn1357","pn1400","pn1415","pn1416","pn1420","pn1438","pn1449","pn1466","pn1494","pn1506","pn1528","pn1568","pn1600","pn1672","pn1678","pn1691","pn1702","pn1706","pn1786","pn1787","pn1791","pn1808","pn1831","pn1850","pn1905","pn1919","pn1925","pn1943","pn2032","pn2050","pn2059","pn2088","pn2116","pn2155","pn2172","pn2185","pn2236","pn2270","pn2280","pn2302","pn2331","pn2444","pn2499","pn2507","pn2508","pn2534","pn2543"],"creationTime":0,"user":"cscw","creator":"system"},"Research on Social Media Systems":{"creationTime":1386522653496,"itemsUsedBy":["pn1710"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Research on Social Media Systems"},"Peepholes":{"creationTime":1386531794188,"itemsUsedBy":["pn654"],"creator":"otmar.hilliges@inf.ethz.ch","user":"otmar.hilliges@inf.ethz.ch","label":"Peepholes"},"Tabletops":{"creationTime":1386525651389,"itemsUsedBy":["pn2424"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Tabletops"},"Persuasive Technologies":{"creationTime":1386523483207,"itemsUsedBy":["pn2274"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Persuasive Technologies"},"wiki wiki wiki":{"creationTime":1386524219733,"itemsUsedBy":["pn1410"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"wiki wiki wiki"},"Medication":{"creationTime":1386522948026,"itemsUsedBy":["pn1377","pn686"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Medication"},"digital archive":{"creationTime":1386525022032,"itemsUsedBy":["pn400"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"digital archive"},"Technology adoption":{"creationTime":1386527346638,"itemsUsedBy":["pn2115","pn714"],"creator":"awaller@computing.dundee.ac.uk","user":"awaller@computing.dundee.ac.uk","label":"Technology adoption"},"Instant Annotation":{"creationTime":1386522836181,"itemsUsedBy":[],"creator":"emailaddress","user":"emailaddress","label":"Instant Annotation"},"crowdsourced experiments":{"creationTime":1386525999438,"itemsUsedBy":["to135"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"crowdsourced experiments"},"Family":{"creationTime":1386522238257,"itemsUsedBy":["pn1617"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Family"},"citizen science":{"creationTime":1386521835583,"itemsUsedBy":["pn399","pn1646"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"citizen science"},"Ephemera":{"creationTime":1386523559756,"itemsUsedBy":[],"creator":"dtatar@cs.vt.edu","user":"dtatar@cs.vt.edu","label":"Ephemera"},"Prototyping":{"label":"Prototyping","itemsUsedBy":["pn101","pn109","pn153","pn229","pn252","pn260","pn286","pn297","pn310","pn329","pn334","pn368","pn412","pn448","pn449","pn454","pn505","pn529","pn536","pn613","pn662","pn663","pn678","pn695","pn704","pn758","pn769","pn779","pn794","pn858","pn929","pn955","pn956","pn1012","pn1021","pn1038","pn1041","pn1065","pn1066","pn1068","pn1077","pn1081","pn1098","pn1139","pn1147","pn1201","pn1206","pn1210","pn1225","pn1251","pn1254","pn1262","pn1263","pn1280","pn1307","pn1367","pn1383","pn1387","pn1393","pn1432","pn1457","pn1494","pn1511","pn1526","pn1534","pn1536","pn1545","pn1603","pn1628","pn1634","pn1654","pn1673","pn1683","pn1684","pn1712","pn1761","pn1764","pn1786","pn1792","pn1793","pn1836","pn1904","pn1905","pn1919","pn1965","pn1977","pn2008","pn2028","pn2029","pn2037","pn2043","pn2050","pn2060","pn2063","pn2116","pn2120","pn2136","pn2138","pn2165","pn2187","pn2250","pn2292","pn2327","pn2354","pn2378","pn2390","pn2406","pn2412","pn2455","pn2466","pn2495","pn2504","pn2506","pn2519","pn775"],"creationTime":0,"user":"cscw","creator":"system"},"Video":{"creationTime":1386522370085,"itemsUsedBy":["pn1558","pn796","pn1872","pn147"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Video"},"practice theory":{"creationTime":1386526135634,"itemsUsedBy":["to110"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"practice theory"},"Web 2.0":{"creationTime":1386522655748,"itemsUsedBy":["pn581","pn455","to120"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Web 2.0"},"ludic engagement":{"creationTime":1386527510045,"itemsUsedBy":["pn1569","pn444"],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"ludic engagement"},"Funny":{"creationTime":1386527531771,"itemsUsedBy":["pn2150"],"creator":"dominicfurniss@gmail.com","user":"dominicfurniss@gmail.com","label":"Funny"},"Mental health":{"creationTime":1386523273049,"itemsUsedBy":["pn787","to111","pn1055"],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"Mental health"},"Game User Research":{"creationTime":1386522680920,"itemsUsedBy":["pn1942"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Game User Research"},"Organizational Culture / Organizational Planning":{"label":"Organizational Culture / Organizational Planning","itemsUsedBy":["pn403","pn707","pn708","pn770","pn862","pn888","pn967","pn1256","pn1309","pn1331","pn1340","pn1368","pn1400","pn1420","pn1454","pn1546","pn1697","pn1822","pn1903","pn1956","pn2098","pn2266","pn2465","pn2492","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"ITCD":{"creationTime":1386531664277,"itemsUsedBy":[],"creator":"hq@northwestern.edu","user":"hq@northwestern.edu","label":"ITCD"},"visualization composition":{"creationTime":1386524469207,"itemsUsedBy":["to126"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"visualization composition"},"non-work group activity":{"creationTime":1386522368422,"itemsUsedBy":["pn2294"],"creator":"daverandall2008@gmail.com","user":"daverandall2008@gmail.com","label":"non-work group activity"},"choice overload":{"creationTime":1386524031785,"itemsUsedBy":["pn1071"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"choice overload"},"Sexual harassment":{"creationTime":1386521836397,"itemsUsedBy":["pn2226"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Sexual harassment"},"Activity recognition":{"creationTime":1386524667784,"itemsUsedBy":["pn1969","pn1057","pn876","to134"],"creator":"dan@danielashbrook.com","user":"dan@danielashbrook.com","label":"Activity recognition"},"social triangulation":{"creationTime":1386522866321,"itemsUsedBy":["pn279"],"creator":"sharrison@vt.edu","user":"sharrison@vt.edu","label":"social triangulation"},"Laban":{"creationTime":1386522988274,"itemsUsedBy":["pn1626"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Laban"},"collaborative ethnography":{"creationTime":1386522337298,"itemsUsedBy":["pn2220"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"collaborative ethnography"},"Collaborative analysis":{"creationTime":1386522262161,"itemsUsedBy":["pn1470"],"creator":"sfussell@cornell.edu","user":"sfussell@cornell.edu","label":"Collaborative analysis"},"Graphical Passwords":{"creationTime":1386522023922,"itemsUsedBy":["pn1399","pn1097"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Graphical Passwords"},"Passwords":{"creationTime":1386521723898,"itemsUsedBy":["pn1399","pn2227"],"creator":"egelman@cs.berkeley.edu","user":"egelman@cs.berkeley.edu","label":"Passwords"},"Biofeedback":{"creationTime":1386523125807,"itemsUsedBy":["pn490"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Biofeedback"},"Ludic engagement":{"creationTime":1386527410007,"itemsUsedBy":[],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Ludic engagement"},"HIV":{"creationTime":1386522083749,"itemsUsedBy":["pn1475"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"HIV"},"local communities":{"creationTime":1386522864543,"itemsUsedBy":["pn1954","to122"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"local communities"},"Gesture-Based Interaction":{"creationTime":1386531605701,"itemsUsedBy":["pn113"],"creator":"yangli@acm.org","user":"yangli@acm.org","label":"Gesture-Based Interaction"},"Video Games":{"creationTime":1386522161369,"itemsUsedBy":["pn1987","pn1901","pn799","pn139"],"creator":"jantin@gmail.com","user":"jantin@gmail.com","label":"Video Games"},"Participatory Design":{"creationTime":1386523316613,"itemsUsedBy":[],"creator":"Mark.blythe@northumbria.ac.uk","user":"Mark.blythe@northumbria.ac.uk","label":"Participatory Design"},"Real-world applications":{"creationTime":1386522456934,"itemsUsedBy":[],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Real-world applications"},"maps":{"creationTime":1386522955931,"itemsUsedBy":["pn1460","pn1447"],"creator":"david.kirk@ncl.ac.uk","user":"david.kirk@ncl.ac.uk","label":"maps"},"Lost and Found in Translation":{"creationTime":1386524904438,"itemsUsedBy":["pn1203","pn1414"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Lost and Found in Translation"},"I'm on board":{"creationTime":1386525825490,"itemsUsedBy":["pn166"],"creator":"paul.marshall@ucl.ac.uk","user":"paul.marshall@ucl.ac.uk","label":"I'm on board"},"Lost In Translation":{"creationTime":1386523604989,"itemsUsedBy":["pn1414","pn1203"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Lost In Translation"},"peer learning":{"creationTime":1386527040518,"itemsUsedBy":["to114"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"peer learning"},"Infrastructures":{"creationTime":1386522682627,"itemsUsedBy":["pn581"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Infrastructures"},"Q&A":{"creationTime":1386522143157,"itemsUsedBy":["pn1236","pn1343"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Q&A"},"Gaze Interaction":{"creationTime":1386525441258,"itemsUsedBy":["pn495"],"creator":"j.alexander@lancaster.ac.uk","user":"j.alexander@lancaster.ac.uk","label":"Gaze Interaction"},"gaming":{"creationTime":1386522065424,"itemsUsedBy":["pn671","pn1987","pn558","pn2277","pn2046"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"gaming"},"financial incentives":{"creationTime":1386524239895,"itemsUsedBy":["pn2489"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"financial incentives"},"crowdfunding":{"creationTime":1386521236318,"itemsUsedBy":["pn526","pn810","to107"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"crowdfunding"},"aging":{"creationTime":1386525117932,"itemsUsedBy":[],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"aging"},"hashtag use":{"creationTime":1386522172152,"itemsUsedBy":[],"creator":"dmrussell@gmail.com","user":"dmrussell@gmail.com","label":"hashtag use"},"dance/movement":{"creationTime":1386522102828,"itemsUsedBy":["pn1579","pn1709","pn1034","pn1452","pn1626"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"dance/movement"},"Apps":{"creationTime":1386532069253,"itemsUsedBy":[],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"Apps"},"Selection Techniques":{"creationTime":1386532135345,"itemsUsedBy":["pn2432","pn1583","pn2449","pn755","pn2372"],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"Selection Techniques"},"product ratings":{"creationTime":1386523940423,"itemsUsedBy":["pn691"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"product ratings"},"information literacy":{"creationTime":1386523809022,"itemsUsedBy":["pn657"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"information literacy"},"Smartwatches":{"creationTime":1386531709241,"itemsUsedBy":["pn372","pn142","pn1007","pn1628"],"creator":"eve.hoggan@hiit.fi","user":"eve.hoggan@hiit.fi","label":"Smartwatches"},"cell phone":{"creationTime":1386523099125,"itemsUsedBy":["pn1904"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"cell phone"},"Crowd-Powered Systems":{"creationTime":1386523670596,"itemsUsedBy":["pn1237","pn271","pn224","pn1161","pn1503","pn806","pn602","pn1103"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Crowd-Powered Systems"},"Sensing":{"creationTime":1386524139330,"itemsUsedBy":["pn1969","pn1426","pn2010"],"creator":"xiangcao@acm.org","user":"xiangcao@acm.org","label":"Sensing"},"Transnational HCI":{"creationTime":1386522637310,"itemsUsedBy":["pn887"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Transnational HCI"},"behavior change":{"creationTime":1386523893913,"itemsUsedBy":["pn761"],"creator":"klasnja@umich.edu","user":"klasnja@umich.edu","label":"behavior change"},"social computing issues":{"creationTime":1386523619616,"itemsUsedBy":["pn924"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"social computing issues"},"Social Q&A":{"creationTime":1386523750846,"itemsUsedBy":["pn802"],"creator":"Xmyzhou@rutgers.edu","user":"Xmyzhou@rutgers.edu","label":"Social Q&A"},"communities":{"creationTime":1386524564920,"itemsUsedBy":["pn1978","pn1410","pn166","pn602"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"communities"},"Social data analysis":{"creationTime":1386522244803,"itemsUsedBy":["pn1330","pn1763"],"creator":"dmrussell@gmail.com","user":"dmrussell@gmail.com","label":"Social data analysis"},"Emotion and Affective User Interface":{"label":"Emotion and Affective User Interface","itemsUsedBy":["pn141","pn151","pn172","pn192","pn210","pn213","pn269","pn334","pn339","pn422","pn436","pn485","pn489","pn494","pn556","pn591","pn597","pn600","pn642","pn702","pn709","pn735","pn860","pn869","pn870","pn901","pn940","pn964","pn1026","pn1091","pn1099","pn1113","pn1163","pn1169","pn1175","pn1178","pn1190","pn1213","pn1218","pn1229","pn1247","pn1252","pn1268","pn1328","pn1351","pn1414","pn1422","pn1431","pn1471","pn1507","pn1518","pn1557","pn1570","pn1572","pn1580","pn1598","pn1629","pn1633","pn1662","pn1664","pn1683","pn1684","pn1688","pn1695","pn1720","pn1730","pn1787","pn1832","pn1861","pn1884","pn1887","pn1972","pn1975","pn1986","pn2054","pn2063","pn2120","pn2124","pn2137","pn2141","pn2151","pn2153","pn2155","pn2196","pn2197","pn2279","pn2286","pn2396","pn2406","pn2433","pn2437","pn2453","pn2466","pn2494","pn2499","pn2508","pn2516","pn2528","pn2538","pn1818","pn639"],"creationTime":0,"user":"cscw","creator":"system"},"art practice":{"creationTime":1386522860503,"itemsUsedBy":["pn2011"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"art practice"},"Machine Learning":{"creationTime":1386523692320,"itemsUsedBy":["pn583","pn2157","pn2454"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Machine Learning"},"data organizing":{"creationTime":1386522839660,"itemsUsedBy":["pn2225","pn405"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"data organizing"},"ontology development tools":{"creationTime":1386523013931,"itemsUsedBy":["pn1760"],"creator":"daverandall2008@gmail.com","user":"daverandall2008@gmail.com","label":"ontology development tools"},"Well-being":{"creationTime":1386523043097,"itemsUsedBy":["pn2153"],"creator":"jantin@gmail.com","user":"jantin@gmail.com","label":"Well-being"},"assessability":{"creationTime":1386523782813,"itemsUsedBy":["pn657"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"assessability"},"Biological Computing":{"creationTime":1386522754582,"itemsUsedBy":["pn2406"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Biological Computing"},"Politics":{"creationTime":1386521892843,"itemsUsedBy":["pn763","pn1330"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Politics"},"framing constructs":{"creationTime":1386522195899,"itemsUsedBy":["pn2048"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"framing constructs"},"Trust":{"creationTime":1386522482238,"itemsUsedBy":["pn1727","pn862"],"creator":"gutwin@cs.usask.ca","user":"gutwin@cs.usask.ca","label":"Trust"},"Target Acquistion":{"creationTime":1386532129405,"itemsUsedBy":[],"creator":"yangli@acm.org","user":"yangli@acm.org","label":"Target Acquistion"},"Relationships":{"creationTime":1386524413206,"itemsUsedBy":["pn1238"],"creator":"dgergle@northwestern.edu","user":"dgergle@northwestern.edu","label":"Relationships"},"emotion":{"creationTime":1386524479578,"itemsUsedBy":["pn1036"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"emotion"},"multi-display interfaces":{"creationTime":1386525476941,"itemsUsedBy":["pn1983","pn2424","pn791"],"creator":"forlines@alumni.cmu.edu","user":"forlines@alumni.cmu.edu","label":"multi-display interfaces"},"feedback":{"creationTime":1386524684021,"itemsUsedBy":["pn897"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"feedback"},"sustainability_and_everyday_practice":{"creationTime":1386522355506,"itemsUsedBy":["pn2244","pn1192","pn155"],"creator":"hazas@comp.lancs.ac.uk","user":"hazas@comp.lancs.ac.uk","label":"sustainability_and_everyday_practice"},"health and behavior change":{"creationTime":1386526453042,"itemsUsedBy":["to101","pn1171","pn1521"],"creator":"aaa","user":"aaa","label":"health and behavior change"},"classroom learning & teaching":{"creationTime":1386523647725,"itemsUsedBy":["pn1182","pn1817"],"creator":"moher@uic.edu","user":"moher@uic.edu","label":"classroom learning & teaching"},"Surveillance":{"creationTime":1386522188216,"itemsUsedBy":["pn1470"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Surveillance"},"predicting project success":{"creationTime":1386522289969,"itemsUsedBy":["pn526"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"predicting project success"},"Social TV":{"creationTime":1386522182832,"itemsUsedBy":["pn653"],"creator":"gabriela.avram@gmail.com","user":"gabriela.avram@gmail.com","label":"Social TV"},"formal caregivers":{"creationTime":1386526569042,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"formal caregivers"},"external representations":{"creationTime":1386523378521,"itemsUsedBy":["pn1470"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"external representations"},"HCI and finance":{"creationTime":1386524230470,"itemsUsedBy":["pn119","pn186","pn526"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"HCI and finance"},"Computer Supported Cooperative Work (CSCW)":{"label":"Computer Supported Cooperative Work (CSCW)","itemsUsedBy":["pn104","pn105","pn106","pn109","pn120","pn131","pn169","pn175","pn181","pn195","pn210","pn211","pn212","pn218","pn273","pn275","pn279","pn317","pn342","pn344","pn354","pn358","pn365","pn370","pn394","pn398","pn410","pn411","pn417","pn429","pn433","pn445","pn454","pn470","pn473","pn486","pn489","pn506","pn517","pn524","pn531","pn562","pn575","pn584","pn599","pn611","pn612","pn613","pn644","pn663","pn667","pn668","pn670","pn695","pn707","pn708","pn760","pn768","pn774","pn783","pn789","pn823","pn844","pn874","pn882","pn889","pn937","pn943","pn961","pn967","pn968","pn970","pn981","pn993","pn1001","pn1039","pn1069","pn1107","pn1126","pn1140","pn1165","pn1174","pn1198","pn1201","pn1203","pn1213","pn1221","pn1243","pn1272","pn1283","pn1284","pn1297","pn1308","pn1310","pn1321","pn1331","pn1349","pn1355","pn1374","pn1376","pn1392","pn1394","pn1395","pn1396","pn1402","pn1406","pn1409","pn1410","pn1424","pn1425","pn1427","pn1438","pn1461","pn1468","pn1484","pn1490","pn1498","pn1501","pn1510","pn1527","pn1556","pn1575","pn1576","pn1584","pn1595","pn1597","pn1602","pn1631","pn1636","pn1644","pn1659","pn1668","pn1689","pn1696","pn1697","pn1717","pn1721","pn1759","pn1770","pn1774","pn1807","pn1850","pn1859","pn1871","pn1909","pn1930","pn1932","pn1948","pn1958","pn1968","pn1978","pn1983","pn1993","pn2014","pn2015","pn2018","pn2024","pn2040","pn2045","pn2053","pn2061","pn2082","pn2083","pn2097","pn2107","pn2110","pn2118","pn2132","pn2134","pn2156","pn2158","pn2191","pn2194","pn2233","pn2260","pn2266","pn2294","pn2295","pn2298","pn2312","pn2316","pn2320","pn2325","pn2332","pn2347","pn2354","pn2374","pn2388","pn2391","pn2395","pn2424","pn2451","pn2461","pn2471","pn2479","pn2504","pn602"],"creationTime":0,"user":"cscw","creator":"system"},"Body":{"creationTime":1386523220821,"itemsUsedBy":["pn1446","pn2293"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Body"},"EEG-based HCI":{"creationTime":1386525285472,"itemsUsedBy":["pn673","pn648","pn366","pn183"],"creator":"tzander@gmail.com","user":"tzander@gmail.com","label":"EEG-based HCI"},"Model-based design and evaluation":{"creationTime":1386524226316,"itemsUsedBy":["pn171","pn239","pn1760"],"creator":"fabio.paterno@isti.cnr.it","user":"fabio.paterno@isti.cnr.it","label":"Model-based design and evaluation"},"menus":{"creationTime":1386523927067,"itemsUsedBy":["pn750","pn626","pn189","pn1473","pn988"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"menus"},"Rapid prototyping":{"creationTime":1386531596526,"itemsUsedBy":["pn2029"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Rapid prototyping"},"Design practice":{"creationTime":1386523032330,"itemsUsedBy":["pn614","pn1667"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Design practice"},"post-humanist theory":{"creationTime":1386522751458,"itemsUsedBy":["pn2011"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"post-humanist theory"},"Feminist HCI":{"creationTime":1386522661639,"itemsUsedBy":["pn581"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Feminist HCI"},"Pressure":{"creationTime":1386531834750,"itemsUsedBy":[],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Pressure"},"Therapeutic Interfaces":{"creationTime":1386523097936,"itemsUsedBy":["pn2406"],"creator":"bilge@cs.wisc.edu","user":"bilge@cs.wisc.edu","label":"Therapeutic Interfaces"},"personas":{"creationTime":1386522977043,"itemsUsedBy":[],"creator":"sharrison@vt.edu","user":"sharrison@vt.edu","label":"personas"},"Dramatic Research":{"creationTime":1386536843926,"itemsUsedBy":["pn787"],"creator":"Mark.blythe@northumbria","user":"Mark.blythe@northumbria","label":"Dramatic Research"},"connectedness":{"creationTime":1386526445404,"itemsUsedBy":["pn975","pn444","pn1923"],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"connectedness"},"Installation":{"creationTime":1386523193212,"itemsUsedBy":[],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Installation"},"finance":{"creationTime":1386523066734,"itemsUsedBy":[],"creator":"D.StantonFraser@bath.ac.uk","user":"D.StantonFraser@bath.ac.uk","label":"finance"},"Office and Workplace":{"label":"Office and Workplace","itemsUsedBy":["pn115","pn172","pn231","pn269","pn270","pn275","pn285","pn342","pn345","pn388","pn392","pn417","pn421","pn433","pn441","pn454","pn473","pn506","pn514","pn524","pn549","pn606","pn617","pn634","pn639","pn644","pn646","pn663","pn668","pn695","pn729","pn742","pn770","pn774","pn807","pn815","pn857","pn880","pn888","pn909","pn926","pn970","pn1001","pn1087","pn1088","pn1110","pn1129","pn1132","pn1137","pn1140","pn1143","pn1169","pn1191","pn1248","pn1263","pn1281","pn1297","pn1309","pn1340","pn1341","pn1343","pn1351","pn1381","pn1393","pn1394","pn1397","pn1402","pn1403","pn1408","pn1424","pn1433","pn1478","pn1479","pn1489","pn1494","pn1510","pn1554","pn1573","pn1592","pn1625","pn1657","pn1689","pn1691","pn1697","pn1705","pn1713","pn1733","pn1743","pn1747","pn1748","pn1762","pn1773","pn1782","pn1831","pn1866","pn1875","pn1881","pn1886","pn1892","pn1893","pn1903","pn1940","pn1947","pn1948","pn1959","pn1999","pn2012","pn2026","pn2036","pn2040","pn2045","pn2053","pn2063","pn2067","pn2075","pn2082","pn2083","pn2095","pn2103","pn2116","pn2125","pn2126","pn2156","pn2165","pn2176","pn2187","pn2199","pn2206","pn2217","pn2240","pn2247","pn2266","pn2303","pn2320","pn2374","pn2376","pn2437","pn2444","pn2460","pn2467","pn2482","pn2488","pn2504","pn2544","pn1454","pn419","pn1257"],"creationTime":0,"user":"cscw","creator":"system"},"Value-Sensitive Design":{"creationTime":1386521847099,"itemsUsedBy":["pn169"],"creator":"ajbrush@microsoft.com","user":"ajbrush@microsoft.com","label":"Value-Sensitive Design"},"design theory":{"creationTime":1386522116137,"itemsUsedBy":["pn758","pn999","pn2011","pn2140","pn2048"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"design theory"},"Social and Legal issues":{"label":"Social and Legal issues","itemsUsedBy":["pn110","pn140","pn157","pn169","pn197","pn199","pn257","pn258","pn269","pn365","pn447","pn681","pn719","pn722","pn766","pn774","pn822","pn823","pn837","pn879","pn882","pn905","pn986","pn1001","pn1126","pn1130","pn1315","pn1349","pn1359","pn1392","pn1412","pn1492","pn1499","pn1512","pn1557","pn1636","pn1671","pn1678","pn1721","pn1771","pn1774","pn1775","pn1780","pn1785","pn1850","pn1856","pn1878","pn1897","pn1937","pn1991","pn1999","pn2079","pn2125","pn2134","pn2160","pn2169","pn2175","pn2191","pn2206","pn2226","pn2279","pn2398","pn2427","pn2434"],"creationTime":0,"user":"cscw","creator":"system"},"Quantified Health":{"creationTime":1386523441314,"itemsUsedBy":["pn2214","to101"],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"Quantified Health"},"Landauer Trouble with Computer":{"creationTime":1386523755135,"itemsUsedBy":["pn924"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"Landauer Trouble with Computer"},"Handheld Projection":{"creationTime":1386525909165,"itemsUsedBy":["pn1796"],"creator":"elm@purdue.edu","user":"elm@purdue.edu","label":"Handheld Projection"},"spatial audio":{"creationTime":1386525732172,"itemsUsedBy":["pn1193"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"spatial audio"},"HRI":{"creationTime":1386522776197,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"HRI"},"Adherence":{"creationTime":1386523476341,"itemsUsedBy":["pn686"],"creator":"wilcox@cc.gatech.edu","user":"wilcox@cc.gatech.edu","label":"Adherence"},"Benefit Analysis":{"label":"Benefit Analysis","itemsUsedBy":["pn243","pn1001","pn1170","pn1599","pn2185"],"creationTime":0,"user":"cscw","creator":"system"},"Password Policies":{"creationTime":1386521836910,"itemsUsedBy":["pn2227"],"creator":"alexander.de.luca@ifi.lmu.de","user":"alexander.de.luca@ifi.lmu.de","label":"Password Policies"},"Technology use in under-represented populations":{"creationTime":1386536515058,"itemsUsedBy":["pn1549","pn1264"],"creator":"vlh@acm.org","user":"vlh@acm.org","label":"Technology use in under-represented populations"},"Help":{"creationTime":1386532108261,"itemsUsedBy":[],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"Help"},"Pro-Am":{"creationTime":1386522147526,"itemsUsedBy":["pn1932","pn1834"],"creator":"obristmarianna@gmail.com","user":"obristmarianna@gmail.com","label":"Pro-Am"},"Text Entry":{"creationTime":1386525160836,"itemsUsedBy":["to135","pn138","to118","pn404","pn1700","pn2454","pn2464","pn2090","pn2157"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Text Entry"},"shape-changing interfaces":{"creationTime":1386525221134,"itemsUsedBy":[],"creator":"forlines@alumni.cmu.edu","user":"forlines@alumni.cmu.edu","label":"shape-changing interfaces"},"NIRS":{"creationTime":1386525605180,"itemsUsedBy":["pn183"],"creator":"erin@cs.drexel.edu","user":"erin@cs.drexel.edu","label":"NIRS"},"cognition":{"creationTime":1386524553181,"itemsUsedBy":["pn190","pn1103"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"cognition"},"Smart Home":{"creationTime":1386522268978,"itemsUsedBy":["pn2522","pn1192","pn2244"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"Smart Home"},"Pen-based UIs":{"label":"Pen-based UIs","itemsUsedBy":["pn228","pn363","pn462","pn463","pn464","pn465","pn807","pn1121","pn1513","pn1644","pn1651","pn1723","pn1749","pn1755","pn2022","pn2165","pn2166","pn2544"],"creationTime":0,"user":"cscw","creator":"system"},"passive BCI":{"creationTime":1386525411236,"itemsUsedBy":["pn366","pn648","pn183","pn673","pn2031"],"creator":"tzander@gmail.com","user":"tzander@gmail.com","label":"passive BCI"},"get a grip":{"creationTime":1386524750572,"itemsUsedBy":["pn426"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"get a grip"},"design for learning":{"creationTime":1386524839668,"itemsUsedBy":["pn1417"],"creator":"asellen@microsoft.com","user":"asellen@microsoft.com","label":"design for learning"},"Pointing Techniques":{"creationTime":1386531937810,"itemsUsedBy":["pn2432","pn755","pn2372","pn756","pn264"],"creator":"mdixon@cs.washington.edu","user":"mdixon@cs.washington.edu","label":"Pointing Techniques"},"Collaborative editing":{"creationTime":1386524190194,"itemsUsedBy":["pn2343"],"creator":"ninggu@fudan.edu.cn","user":"ninggu@fudan.edu.cn","label":"Collaborative editing"},"Interaction Design":{"label":"Interaction Design","itemsUsedBy":["pn103","pn113","pn131","pn162","pn172","pn184","pn209","pn210","pn222","pn262","pn310","pn319","pn334","pn388","pn415","pn441","pn445","pn448","pn451","pn547","pn549","pn569","pn589","pn606","pn608","pn619","pn630","pn634","pn643","pn646","pn650","pn652","pn655","pn686","pn695","pn701","pn706","pn753","pn758","pn759","pn774","pn791","pn797","pn798","pn800","pn801","pn807","pn821","pn824","pn839","pn841","pn849","pn852","pn855","pn866","pn872","pn885","pn888","pn894","pn896","pn899","pn901","pn918","pn926","pn953","pn955","pn973","pn984","pn986","pn997","pn999","pn1017","pn1040","pn1063","pn1070","pn1075","pn1084","pn1094","pn1101","pn1105","pn1108","pn1113","pn1118","pn1129","pn1131","pn1135","pn1150","pn1155","pn1158","pn1167","pn1169","pn1172","pn1180","pn1190","pn1191","pn1195","pn1201","pn1218","pn1239","pn1240","pn1248","pn1250","pn1287","pn1291","pn1308","pn1309","pn1317","pn1319","pn1325","pn1350","pn1352","pn1373","pn1379","pn1380","pn1383","pn1384","pn1389","pn1417","pn1425","pn1430","pn1438","pn1442","pn1450","pn1451","pn1473","pn1479","pn1483","pn1494","pn1495","pn1505","pn1507","pn1526","pn1527","pn1528","pn1534","pn1554","pn1568","pn1573","pn1574","pn1577","pn1589","pn1601","pn1606","pn1620","pn1630","pn1639","pn1648","pn1655","pn1657","pn1666","pn1667","pn1668","pn1671","pn1682","pn1685","pn1695","pn1703","pn1713","pn1716","pn1718","pn1730","pn1740","pn1767","pn1768","pn1772","pn1779","pn1783","pn1787","pn1796","pn1799","pn1807","pn1810","pn1836","pn1837","pn1866","pn1875","pn1882","pn1893","pn1907","pn1908","pn1919","pn1934","pn1965","pn1967","pn1971","pn1972","pn1974","pn1980","pn1989","pn1994","pn2008","pn2014","pn2019","pn2028","pn2043","pn2044","pn2048","pn2056","pn2060","pn2061","pn2063","pn2068","pn2082","pn2089","pn2103","pn2113","pn2116","pn2140","pn2147","pn2163","pn2166","pn2177","pn2178","pn2182","pn2184","pn2185","pn2187","pn2196","pn2199","pn2206","pn2207","pn2212","pn2224","pn2238","pn2247","pn2248","pn2255","pn2257","pn2270","pn2287","pn2292","pn2296","pn2301","pn2307","pn2309","pn2311","pn2316","pn2335","pn2341","pn2358","pn2376","pn2387","pn2406","pn2410","pn2416","pn2439","pn2441","pn2455","pn2458","pn2466","pn2493","pn2497","pn2507","pn2516","pn2518","pn2534","pn2538","pn2539"],"creationTime":0,"user":"cscw","creator":"system"},"acoustic":{"creationTime":1386525049756,"itemsUsedBy":["pn386"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"acoustic"},"Transport":{"label":"Transport","itemsUsedBy":["pn128","pn192","pn221","pn233","pn369","pn377","pn552","pn621","pn625","pn648","pn948","pn954","pn1082","pn1110","pn1214","pn1340","pn1573","pn1585","pn1669","pn1750","pn1754","pn1969","pn2086","pn2099","pn2104","pn2187","pn2196"],"creationTime":0,"user":"cscw","creator":"system"},"Development Tools / Toolkits / Programming Environments":{"label":"Development Tools / Toolkits / Programming Environments","itemsUsedBy":["pn104","pn132","pn133","pn171","pn184","pn198","pn205","pn246","pn271","pn329","pn388","pn505","pn586","pn595","pn627","pn632","pn637","pn663","pn664","pn694","pn774","pn788","pn808","pn818","pn922","pn963","pn1075","pn1081","pn1098","pn1137","pn1189","pn1211","pn1307","pn1316","pn1336","pn1367","pn1368","pn1393","pn1449","pn1465","pn1489","pn1651","pn1778","pn1816","pn1833","pn1839","pn1993","pn2008","pn2029","pn2043","pn2057","pn2087","pn2091","pn2092","pn2096","pn2103","pn2154","pn2177","pn2323","pn2327","pn2416","pn2433","pn2447","pn2530","pn2399","pn1760"],"creationTime":0,"user":"cscw","creator":"system"},"interruption":{"creationTime":1386524272904,"itemsUsedBy":["pn1351","pn806"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"interruption"},"Touch Input":{"creationTime":1386525384145,"itemsUsedBy":["pn1488","pn1628","pn1635","pn1225","pn386","pn2372","pn1473","pn1936","pn343","pn142","pn583","pn264","pn525","pn1046","pn756","pn1583","pn198","pn1007"],"creator":"steimle@media.mit.edu","user":"steimle@media.mit.edu","label":"Touch Input"},"Science and Technology Studies":{"creationTime":1386522020668,"itemsUsedBy":["pn2140"],"creator":"stuart@tropic.org.uk","user":"stuart@tropic.org.uk","label":"Science and Technology Studies"},"research methods":{"creationTime":1386524153455,"itemsUsedBy":["to132"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"research methods"},"Design Planning":{"label":"Design Planning","itemsUsedBy":["pn269","pn302","pn334","pn342","pn421","pn441","pn501","pn695","pn704","pn838","pn1155","pn1309","pn1364","pn1405","pn1746","pn1866","pn2075","pn2354"],"creationTime":0,"user":"cscw","creator":"system"},"conference organization":{"creationTime":1386521934746,"itemsUsedBy":["pn2225"],"creator":"jacovi@il.ibm.com","user":"jacovi@il.ibm.com","label":"conference organization"},"Software Engineering Methods and Processes - Mathematical/Formal":{"label":"Software Engineering Methods and Processes - Mathematical/Formal","itemsUsedBy":["pn207","pn239","pn340","pn622","pn1065","pn1137","pn1260","pn1293","pn2139","pn2309","pn2450"],"creationTime":0,"user":"cscw","creator":"system"},"availability":{"creationTime":1386531516677,"itemsUsedBy":["pn2266"],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"availability"},"urban informatics":{"creationTime":1386523707650,"itemsUsedBy":["pn1110"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"urban informatics"},"Sports":{"creationTime":1386525384937,"itemsUsedBy":["pn876","pn1796","pn2242"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Sports"},"Models of trust":{"creationTime":1386523456118,"itemsUsedBy":["pn1727"],"creator":"dmrussell@gmail.com","user":"dmrussell@gmail.com","label":"Models of trust"},"camera tracking":{"creationTime":1386526116106,"itemsUsedBy":["pn288"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"camera tracking"},"The Road Ahead":{"creationTime":1386525979112,"itemsUsedBy":["pn838","pn657"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"The Road Ahead"},"personalization":{"creationTime":1386537061414,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"personalization"},"Augmented Reality and Tangible UI":{"label":"Augmented Reality and Tangible UI","itemsUsedBy":["pn130","pn134","pn153","pn162","pn172","pn185","pn237","pn241","pn251","pn268","pn276","pn288","pn299","pn311","pn312","pn334","pn370","pn451","pn452","pn474","pn564","pn571","pn616","pn621","pn698","pn736","pn769","pn775","pn840","pn849","pn888","pn901","pn916","pn1061","pn1074","pn1096","pn1174","pn1184","pn1193","pn1212","pn1306","pn1365","pn1403","pn1404","pn1432","pn1434","pn1448","pn1516","pn1534","pn1583","pn1591","pn1669","pn1675","pn1730","pn1756","pn1765","pn1777","pn1796","pn1866","pn1870","pn1912","pn1928","pn1938","pn1950","pn1963","pn2165","pn2260","pn2336","pn2378","pn2406","pn2412","pn2466","pn2473","pn2493","pn2517","pn2544","pn2112"],"creationTime":0,"user":"cscw","creator":"system"},"Tangibles":{"creationTime":1386525167415,"itemsUsedBy":["pn1241"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Tangibles"},"Intelligent transport":{"creationTime":1386522396784,"itemsUsedBy":["pn2203"],"creator":"david.kirk@ncl.ac.uk","user":"david.kirk@ncl.ac.uk","label":"Intelligent transport"},"In School":{"creationTime":1386523426500,"itemsUsedBy":["pn1290","pn1182","pn1817"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"In School"},"Human-Robot Interaction":{"creationTime":1386522889308,"itemsUsedBy":["pn586","pn1227","pn1722"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Human-Robot Interaction"},"Ubiquitous Computing / Smart Environments":{"label":"Ubiquitous Computing / Smart Environments","itemsUsedBy":["pn109","pn159","pn172","pn196","pn226","pn269","pn276","pn279","pn284","pn289","pn299","pn312","pn352","pn381","pn383","pn393","pn402","pn414","pn432","pn488","pn492","pn543","pn549","pn569","pn575","pn633","pn634","pn640","pn648","pn652","pn678","pn705","pn739","pn744","pn788","pn828","pn830","pn842","pn888","pn896","pn901","pn942","pn946","pn956","pn963","pn1001","pn1050","pn1055","pn1059","pn1066","pn1073","pn1082","pn1084","pn1087","pn1098","pn1119","pn1122","pn1132","pn1182","pn1200","pn1206","pn1208","pn1212","pn1214","pn1222","pn1232","pn1237","pn1253","pn1269","pn1279","pn1281","pn1303","pn1306","pn1308","pn1320","pn1336","pn1365","pn1372","pn1377","pn1397","pn1426","pn1438","pn1441","pn1443","pn1462","pn1511","pn1512","pn1598","pn1652","pn1663","pn1676","pn1678","pn1693","pn1705","pn1740","pn1748","pn1776","pn1793","pn1830","pn1831","pn1843","pn1845","pn1892","pn1905","pn1908","pn1923","pn1950","pn1952","pn1980","pn1995","pn2023","pn2052","pn2057","pn2060","pn2067","pn2075","pn2081","pn2100","pn2112","pn2116","pn2120","pn2126","pn2133","pn2154","pn2165","pn2168","pn2172","pn2175","pn2179","pn2187","pn2205","pn2206","pn2217","pn2254","pn2255","pn2262","pn2270","pn2341","pn2354","pn2357","pn2362","pn2396","pn2406","pn2425","pn2482","pn2502","pn2517","pn2522","pn2525","pn2544"],"creationTime":0,"user":"cscw","creator":"system"},"Virtual Reality":{"label":"Virtual Reality","itemsUsedBy":["pn162","pn268","pn287","pn302","pn334","pn415","pn416","pn600","pn775","pn832","pn885","pn888","pn918","pn1157","pn1195","pn1287","pn1339","pn1435","pn1450","pn1583","pn1594","pn1703","pn1714","pn1727","pn1831","pn1837","pn1966","pn2137","pn2185","pn2199","pn2369","pn2453"],"creationTime":0,"user":"cscw","creator":"system"},"Video search":{"creationTime":1386523948519,"itemsUsedBy":["pn1558"],"creator":"ninggu@fudan.edu.cn","user":"ninggu@fudan.edu.cn","label":"Video search"},"Real-world study":{"creationTime":1386523225644,"itemsUsedBy":["pn687"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Real-world study"},"gamification":{"creationTime":1386527165278,"itemsUsedBy":["pn2472","pn1521"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"gamification"},"health":{"label":"health","itemsUsedBy":["to101","to111","to113","to134","pn802","pn677","pn2276","pn2074","pn2368","pn951"],"creationTime":0,"user":"cscw","creator":"system"},"social networks":{"creationTime":1386522386421,"itemsUsedBy":[],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"social networks"},"Small Display Interaction":{"creationTime":1386531837915,"itemsUsedBy":["pn529","pn1007"],"creator":"david.kim@newcastle.ac.uk","user":"david.kim@newcastle.ac.uk","label":"Small Display Interaction"},"pan and zoom":{"creationTime":1386531583456,"itemsUsedBy":["pn425"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"pan and zoom"},"Theater":{"creationTime":1386523131375,"itemsUsedBy":["pn118"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"Theater"},"workflow":{"creationTime":1386524285910,"itemsUsedBy":["pn1351"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"workflow"},"Braille":{"creationTime":1386526172760,"itemsUsedBy":["pn1700"],"creator":"takagih@jp.ibm.com","user":"takagih@jp.ibm.com","label":"Braille"},"Presentations":{"creationTime":1386522939231,"itemsUsedBy":["pn2303"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Presentations"},"Experience Sampling":{"creationTime":1386524119758,"itemsUsedBy":["pn1295","pn897","to129"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Experience Sampling"},"spatial sound":{"creationTime":1386525472040,"itemsUsedBy":["pn1193"],"creator":"benko@microsoft.com","user":"benko@microsoft.com","label":"spatial sound"},"Management of Online Communities":{"creationTime":1386521634310,"itemsUsedBy":["pn1341"],"creator":"emailaddress","user":"emailaddress","label":"Management of Online Communities"},"Document management":{"creationTime":1386522980081,"itemsUsedBy":["pn1881","pn2225","pn514"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Document management"},"Narrative":{"creationTime":1386523628230,"itemsUsedBy":["pn2303","pn1518"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Narrative"},"Security":{"label":"Security","itemsUsedBy":["pn191","pn207","pn269","pn374","pn409","pn413","pn457","pn522","pn545","pn636","pn649","pn681","pn695","pn699","pn719","pn757","pn865","pn1025","pn1060","pn1068","pn1127","pn1144","pn1146","pn1191","pn1254","pn1266","pn1281","pn1370","pn1391","pn1399","pn1407","pn1416","pn1480","pn1492","pn1538","pn1544","pn1561","pn1638","pn1720","pn1724","pn1735","pn1747","pn1788","pn1802","pn1803","pn1811","pn1828","pn1863","pn1924","pn1946","pn1962","pn1976","pn2005","pn2085","pn2090","pn2122","pn2142","pn2156","pn2162","pn2169","pn2217","pn2227","pn2275","pn2342","pn2376","pn2389","pn2399","pn2467","pn2481","pn2498","pn2500","pn950","pn525"],"creationTime":0,"user":"cscw","creator":"system"},"Drawing":{"creationTime":1386522201607,"itemsUsedBy":["pn2343","pn583"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Drawing"},"Blind":{"creationTime":1386526167728,"itemsUsedBy":[],"creator":"takagih@jp.ibm.com","user":"takagih@jp.ibm.com","label":"Blind"},"Supporting Participation":{"creationTime":1386521699988,"itemsUsedBy":["pn558"],"creator":"emailaddress","user":"emailaddress","label":"Supporting Participation"},"Video Analysis":{"label":"Video Analysis","itemsUsedBy":["pn358","pn373","pn420","pn545","pn574","pn587","pn644","pn748","pn820","pn873","pn883","pn1050","pn1210","pn1237","pn1403","pn1516","pn1558","pn1692","pn1730","pn1796","pn1832","pn1909","pn2019","pn2073","pn2333","pn2391","pn2509"],"creationTime":0,"user":"cscw","creator":"system"},"it's not correlation":{"creationTime":1386524804600,"itemsUsedBy":[],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"it's not correlation"},"sustainability":{"label":"sustainability","itemsUsedBy":[],"creationTime":0,"user":"cscw","creator":"system"},"Touch Interaction":{"creationTime":1386525654701,"itemsUsedBy":["pn1628"],"creator":"elm@purdue.edu","user":"elm@purdue.edu","label":"Touch Interaction"},"curation":{"creationTime":1386523011030,"itemsUsedBy":["pn2401","pn1325"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"curation"},"rehabilitation":{"creationTime":1386523320405,"itemsUsedBy":[],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"rehabilitation"},"privacy":{"creationTime":1386524675510,"itemsUsedBy":[],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"privacy"},"geo-social media":{"creationTime":1386526555161,"itemsUsedBy":["pn1675"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"geo-social media"},"SSL":{"creationTime":1386521735159,"itemsUsedBy":["pn1811"],"creator":"alexander.de.luca@ifi.lmu.de","user":"alexander.de.luca@ifi.lmu.de","label":"SSL"},"Usability testing":{"creationTime":1386522741055,"itemsUsedBy":["pn189"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Usability testing"},"Values":{"creationTime":1386523802955,"itemsUsedBy":[],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"Values"},"Persuasive Games":{"creationTime":1386522252179,"itemsUsedBy":["pn2317","pn121"],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Persuasive Games"},"Everyday design":{"creationTime":1386522721434,"itemsUsedBy":["pn1442"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Everyday design"},"information search":{"creationTime":1386524038618,"itemsUsedBy":["pn1071","pn1032","pn1558","pn2235"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"information search"},"public performance":{"creationTime":1386523809958,"itemsUsedBy":["to103"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"public performance"},"Alternate Reality Games":{"creationTime":1386522858140,"itemsUsedBy":["pn1518","pn775"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Alternate Reality Games"},"social messaging":{"creationTime":1386523694866,"itemsUsedBy":["pn419"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"social messaging"},"mid-air":{"creationTime":1386524438102,"itemsUsedBy":["pn1092"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"mid-air"},"dementia":{"creationTime":1386526376994,"itemsUsedBy":["pn444","pn1896"],"creator":"f.hwang@reading.ac.uk","user":"f.hwang@reading.ac.uk","label":"dementia"},"Large-Scale User Studies":{"creationTime":1386522517225,"itemsUsedBy":["pn1750","pn1282"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Large-Scale User Studies"},"detecting movement":{"creationTime":1386523002425,"itemsUsedBy":["pn1626","pn1736"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"detecting movement"},"tie strength":{"creationTime":1386522411771,"itemsUsedBy":["pn751"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"tie strength"},"customization":{"creationTime":1386524209063,"itemsUsedBy":["pn1398"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"customization"},"Touchy Feely":{"creationTime":1386525469811,"itemsUsedBy":["pn1092","pn386","pn426","pn420"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Touchy Feely"},"Flickr":{"creationTime":1386523475730,"itemsUsedBy":["pn1241"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"Flickr"},"Photo sharing":{"creationTime":1386522169019,"itemsUsedBy":[],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Photo sharing"},"Exercise":{"creationTime":1386521748208,"itemsUsedBy":["pn737","pn876"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Exercise"},"Personality":{"creationTime":1386523096168,"itemsUsedBy":["pn2380","pn400"],"creator":"dr.mark.j.perry@googlemail.com","user":"dr.mark.j.perry@googlemail.com","label":"Personality"},"management":{"label":"management","itemsUsedBy":["to107","to131"],"creationTime":0,"user":"cscw","creator":"system"},"non-native speakers":{"creationTime":1386524488636,"itemsUsedBy":["pn1203"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"non-native speakers"},"Localization":{"creationTime":1386522778087,"itemsUsedBy":["pn555"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Localization"},"Text-Entry":{"creationTime":1386527492560,"itemsUsedBy":[],"creator":"tjvg@di.fc.ul.pt","user":"tjvg@di.fc.ul.pt","label":"Text-Entry"},"constructive design research":{"creationTime":1386522069617,"itemsUsedBy":["pn758","pn2048","pn999","pn1442"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"constructive design research"},"situational awareness":{"creationTime":1386525672529,"itemsUsedBy":["pn233"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"situational awareness"},"social care":{"creationTime":1386526512514,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"social care"},"contestational design":{"creationTime":1386522409967,"itemsUsedBy":["pn2140"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"contestational design"},"phones":{"creationTime":1386524284610,"itemsUsedBy":["pn2525","pn2175","pn2399"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"phones"},"everyday creativity":{"creationTime":1386522342375,"itemsUsedBy":["pn1710"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"everyday creativity"},"dogs":{"creationTime":1386522723555,"itemsUsedBy":[],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"dogs"},"mobiles":{"creationTime":1386523092197,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"mobiles"},"urban":{"creationTime":1386522253507,"itemsUsedBy":["pn558","pn2401","pn1954","pn1675"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"urban"},"Stereoscopic 3D (S3D)":{"creationTime":1386523160130,"itemsUsedBy":["pn1262","pn1758","pn977"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"Stereoscopic 3D (S3D)"},"muscles":{"creationTime":1386524970698,"itemsUsedBy":["pn420"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"muscles"},"multimodal interfaces":{"creationTime":1386525313980,"itemsUsedBy":["pn208"],"creator":"dan@microsoft.com","user":"dan@microsoft.com","label":"multimodal interfaces"},"CMC":{"creationTime":1386523334676,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"CMC"},"Social Capitalism":{"creationTime":1386525859079,"itemsUsedBy":["pn905"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Social Capitalism"},"Social justice":{"creationTime":1386523073480,"itemsUsedBy":["pn2193"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Social justice"},"is this product any good? (ratings)":{"creationTime":1386525317835,"itemsUsedBy":["pn691"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"is this product any good? (ratings)"},"Defromable Interfaces":{"creationTime":1386532163195,"itemsUsedBy":[],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Defromable Interfaces"},"technology development":{"creationTime":1386528518186,"itemsUsedBy":["to123"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"technology development"},"Crisis computing":{"creationTime":1386521950151,"itemsUsedBy":["pn1014","pn1330"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Crisis computing"},"Enterprise":{"creationTime":1386521888366,"itemsUsedBy":[],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Enterprise"},"Fun":{"creationTime":1386521406419,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Fun"},"sex":{"creationTime":1386522377612,"itemsUsedBy":["pn677"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"sex"},"selfmanagement":{"creationTime":1386523558247,"itemsUsedBy":["pn802","pn2074"],"creator":"Marilyn.McGee-Lennon@glasgow.ac.uk","user":"Marilyn.McGee-Lennon@glasgow.ac.uk","label":"selfmanagement"},"ipad":{"creationTime":1386522440613,"itemsUsedBy":["pn1452"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"ipad"},"E-Learning and Education":{"label":"E-Learning and Education","itemsUsedBy":["pn212","pn224","pn315","pn391","pn397","pn398","pn417","pn445","pn468","pn510","pn511","pn515","pn595","pn635","pn663","pn669","pn675","pn676","pn692","pn727","pn791","pn818","pn874","pn875","pn886","pn894","pn909","pn910","pn937","pn940","pn960","pn976","pn985","pn997","pn1026","pn1028","pn1061","pn1276","pn1363","pn1369","pn1376","pn1387","pn1388","pn1421","pn1430","pn1432","pn1436","pn1443","pn1455","pn1465","pn1487","pn1501","pn1510","pn1552","pn1566","pn1570","pn1574","pn1636","pn1648","pn1661","pn1715","pn1733","pn1750","pn1789","pn1799","pn1812","pn1827","pn1839","pn1843","pn1861","pn1870","pn1871","pn1920","pn1924","pn1928","pn1941","pn1947","pn1959","pn1963","pn2004","pn2031","pn2092","pn2093","pn2211","pn2234","pn2267","pn2278","pn2289","pn2317","pn2320","pn2327","pn2328","pn2330","pn2344","pn2381","pn2409","pn2433","pn2468","pn2480","pn2504","pn2510","pn1820","pn2472","pn1020"],"creationTime":0,"user":"cscw","creator":"system"},"television":{"creationTime":1386521327356,"itemsUsedBy":["pn653"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"television"},"Handheld Devices and Mobile Computing":{"label":"Handheld Devices and Mobile Computing","itemsUsedBy":["pn105","pn109","pn113","pn116","pn126","pn142","pn172","pn176","pn191","pn206","pn209","pn222","pn246","pn248","pn250","pn251","pn261","pn262","pn270","pn281","pn286","pn288","pn289","pn299","pn302","pn305","pn321","pn322","pn327","pn333","pn343","pn348","pn355","pn368","pn370","pn372","pn381","pn383","pn385","pn396","pn399","pn408","pn413","pn414","pn423","pn425","pn450","pn451","pn468","pn488","pn496","pn503","pn511","pn525","pn535","pn538","pn552","pn553","pn589","pn594","pn618","pn619","pn624","pn631","pn633","pn640","pn641","pn643","pn649","pn654","pn672","pn686","pn698","pn703","pn730","pn744","pn756","pn757","pn761","pn775","pn779","pn788","pn791","pn804","pn807","pn815","pn816","pn823","pn830","pn842","pn844","pn849","pn852","pn865","pn879","pn891","pn896","pn902","pn903","pn916","pn925","pn927","pn930","pn932","pn935","pn950","pn958","pn960","pn969","pn983","pn988","pn1001","pn1006","pn1007","pn1046","pn1048","pn1054","pn1055","pn1059","pn1070","pn1074","pn1082","pn1084","pn1088","pn1094","pn1096","pn1107","pn1108","pn1121","pn1122","pn1142","pn1144","pn1151","pn1152","pn1156","pn1158","pn1160","pn1166","pn1169","pn1176","pn1181","pn1182","pn1186","pn1187","pn1190","pn1193","pn1200","pn1210","pn1211","pn1212","pn1226","pn1232","pn1239","pn1242","pn1275","pn1276","pn1281","pn1282","pn1315","pn1319","pn1336","pn1363","pn1365","pn1370","pn1372","pn1380","pn1386","pn1397","pn1426","pn1430","pn1433","pn1457","pn1469","pn1473","pn1488","pn1497","pn1511","pn1533","pn1534","pn1538","pn1539","pn1553","pn1572","pn1593","pn1598","pn1638","pn1648","pn1666","pn1675","pn1676","pn1680","pn1695","pn1698","pn1700","pn1707","pn1708","pn1726","pn1740","pn1757","pn1767","pn1776","pn1777","pn1780","pn1788","pn1810","pn1818","pn1821","pn1825","pn1827","pn1831","pn1857","pn1863","pn1864","pn1865","pn1888","pn1898","pn1899","pn1905","pn1912","pn1916","pn1917","pn1930","pn1938","pn1946","pn1949","pn1951","pn1952","pn1960","pn1969","pn1977","pn1981","pn1989","pn2001","pn2010","pn2028","pn2040","pn2041","pn2057","pn2076","pn2078","pn2100","pn2117","pn2127","pn2135","pn2138","pn2144","pn2152","pn2154","pn2175","pn2181","pn2182","pn2187","pn2190","pn2192","pn2194","pn2198","pn2202","pn2204","pn2205","pn2223","pn2233","pn2234","pn2237","pn2238","pn2254","pn2258","pn2263","pn2265","pn2274","pn2288","pn2290","pn2301","pn2304","pn2306","pn2342","pn2351","pn2354","pn2364","pn2376","pn2390","pn2396","pn2399","pn2411","pn2430","pn2431","pn2460","pn2464","pn2481","pn2487","pn2490","pn2499","pn2500","pn2503","pn2526","pn2531","pn2548","pn2134","pn1452","pn2294","pn2284","pn263","pn2525","pn2084","pn1257","pn2454"],"creationTime":0,"user":"cscw","creator":"system"},"Social Activism":{"creationTime":1386523256613,"itemsUsedBy":["pn576","pn1646"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Social Activism"},"Exertion games":{"creationTime":1386522750664,"itemsUsedBy":["pn1626","pn1521"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Exertion games"},"youtube":{"creationTime":1386525767403,"itemsUsedBy":["pn796"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"youtube"},"photo work":{"creationTime":1386526502453,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"photo work"},"Monads":{"creationTime":1386523500546,"itemsUsedBy":["pn701"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"Monads"},"Tagging":{"creationTime":1386530603667,"itemsUsedBy":["pn884","pn2225"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Tagging"},"Social Presence":{"creationTime":1386523034354,"itemsUsedBy":["pn1252","pn534"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Social Presence"},"Product Management":{"label":"Product Management","itemsUsedBy":["pn680","pn1137","pn2014","pn2155"],"creationTime":0,"user":"cscw","creator":"system"},"User Studies":{"label":"User Studies","itemsUsedBy":["pn109","pn115","pn134","pn138","pn162","pn172","pn183","pn197","pn207","pn210","pn213","pn222","pn226","pn231","pn240","pn251","pn259","pn260","pn270","pn278","pn279","pn281","pn302","pn312","pn319","pn320","pn339","pn341","pn342","pn346","pn354","pn356","pn359","pn362","pn363","pn367","pn368","pn374","pn382","pn388","pn399","pn402","pn408","pn412","pn413","pn414","pn416","pn417","pn419","pn425","pn430","pn452","pn453","pn458","pn463","pn464","pn465","pn469","pn474","pn486","pn492","pn496","pn500","pn501","pn503","pn506","pn508","pn517","pn524","pn536","pn545","pn546","pn550","pn559","pn562","pn567","pn569","pn573","pn575","pn589","pn591","pn597","pn606","pn638","pn648","pn651","pn654","pn656","pn663","pn667","pn672","pn678","pn681","pn688","pn689","pn699","pn703","pn710","pn716","pn733","pn740","pn742","pn743","pn757","pn760","pn762","pn769","pn774","pn778","pn796","pn797","pn804","pn807","pn808","pn812","pn813","pn819","pn833","pn834","pn839","pn843","pn846","pn850","pn854","pn856","pn864","pn868","pn871","pn873","pn878","pn879","pn889","pn891","pn894","pn895","pn900","pn901","pn902","pn907","pn918","pn925","pn929","pn930","pn946","pn948","pn949","pn956","pn957","pn959","pn960","pn980","pn1007","pn1017","pn1021","pn1024","pn1038","pn1046","pn1047","pn1051","pn1053","pn1061","pn1068","pn1069","pn1076","pn1079","pn1082","pn1085","pn1087","pn1090","pn1094","pn1096","pn1097","pn1099","pn1106","pn1111","pn1114","pn1115","pn1117","pn1125","pn1127","pn1131","pn1137","pn1139","pn1170","pn1174","pn1176","pn1178","pn1180","pn1185","pn1191","pn1192","pn1195","pn1198","pn1205","pn1214","pn1223","pn1229","pn1234","pn1254","pn1256","pn1258","pn1263","pn1276","pn1277","pn1278","pn1279","pn1299","pn1300","pn1301","pn1304","pn1306","pn1314","pn1319","pn1320","pn1337","pn1342","pn1345","pn1348","pn1358","pn1365","pn1389","pn1393","pn1397","pn1399","pn1409","pn1415","pn1422","pn1430","pn1434","pn1437","pn1444","pn1449","pn1450","pn1455","pn1456","pn1464","pn1465","pn1468","pn1479","pn1488","pn1492","pn1494","pn1496","pn1501","pn1502","pn1509","pn1510","pn1519","pn1523","pn1524","pn1532","pn1533","pn1538","pn1539","pn1543","pn1544","pn1545","pn1555","pn1557","pn1558","pn1574","pn1578","pn1579","pn1585","pn1604","pn1619","pn1628","pn1631","pn1645","pn1646","pn1652","pn1666","pn1669","pn1676","pn1678","pn1683","pn1692","pn1693","pn1694","pn1695","pn1724","pn1726","pn1732","pn1744","pn1747","pn1750","pn1751","pn1765","pn1767","pn1770","pn1772","pn1775","pn1781","pn1787","pn1788","pn1790","pn1791","pn1803","pn1806","pn1828","pn1836","pn1837","pn1842","pn1843","pn1848","pn1850","pn1864","pn1876","pn1882","pn1886","pn1889","pn1891","pn1892","pn1893","pn1894","pn1902","pn1916","pn1925","pn1937","pn1939","pn1942","pn1943","pn1946","pn1951","pn1952","pn1958","pn1959","pn1961","pn1962","pn1971","pn1973","pn1976","pn1977","pn1987","pn1988","pn1991","pn1992","pn2005","pn2006","pn2012","pn2015","pn2017","pn2019","pn2020","pn2026","pn2027","pn2032","pn2040","pn2044","pn2059","pn2062","pn2063","pn2067","pn2073","pn2076","pn2079","pn2080","pn2085","pn2088","pn2090","pn2106","pn2112","pn2120","pn2122","pn2125","pn2128","pn2133","pn2135","pn2136","pn2141","pn2142","pn2149","pn2151","pn2152","pn2153","pn2158","pn2163","pn2166","pn2169","pn2174","pn2175","pn2178","pn2179","pn2183","pn2187","pn2188","pn2190","pn2196","pn2199","pn2205","pn2211","pn2216","pn2217","pn2227","pn2230","pn2231","pn2233","pn2234","pn2236","pn2238","pn2240","pn2247","pn2250","pn2253","pn2259","pn2265","pn2267","pn2273","pn2276","pn2278","pn2283","pn2301","pn2302","pn2304","pn2313","pn2315","pn2316","pn2318","pn2321","pn2322","pn2324","pn2333","pn2339","pn2345","pn2351","pn2352","pn2355","pn2360","pn2364","pn2367","pn2374","pn2376","pn2380","pn2390","pn2392","pn2394","pn2395","pn2398","pn2400","pn2402","pn2408","pn2410","pn2415","pn2421","pn2423","pn2424","pn2430","pn2431","pn2439","pn2441","pn2444","pn2448","pn2453","pn2454","pn2463","pn2480","pn2484","pn2486","pn2489","pn2491","pn2493","pn2496","pn2499","pn2502","pn2503","pn2509","pn2511","pn2516","pn2519","pn2522","pn2526","pn2531","pn2540","pn2545","pn1707","pn2560","pn2226","pn1242","pn264"],"creationTime":0,"user":"cscw","creator":"system"},"E-Government":{"creationTime":1386522791225,"itemsUsedBy":["pn169"],"creator":"egelman@cs.berkeley.edu","user":"egelman@cs.berkeley.edu","label":"E-Government"},"Sleep interaction":{"creationTime":1386523880648,"itemsUsedBy":["pn1426"],"creator":"roudauta@gmail.com","user":"roudauta@gmail.com","label":"Sleep interaction"},"autoethnography":{"creationTime":1386523746803,"itemsUsedBy":["pn1242"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"autoethnography"},"horizontal displays":{"creationTime":1386523967643,"itemsUsedBy":["pn386"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"horizontal displays"},"Large displays":{"creationTime":1386532222140,"itemsUsedBy":["pn1222"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Large displays"},"Aging":{"creationTime":1386522842002,"itemsUsedBy":["pn704","to113"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Aging"},"World Wide Web and Hypermedia":{"label":"World Wide Web and Hypermedia","itemsUsedBy":["pn204","pn205","pn224","pn261","pn365","pn390","pn392","pn431","pn488","pn518","pn561","pn568","pn572","pn657","pn695","pn812","pn817","pn837","pn996","pn1004","pn1049","pn1060","pn1127","pn1159","pn1187","pn1197","pn1202","pn1205","pn1224","pn1240","pn1273","pn1347","pn1352","pn1361","pn1369","pn1490","pn1495","pn1498","pn1515","pn1544","pn1568","pn1597","pn1670","pn1733","pn1734","pn1849","pn1866","pn1876","pn1891","pn1910","pn1929","pn1962","pn1976","pn1993","pn1999","pn2014","pn2058","pn2128","pn2230","pn2257","pn2355","pn2392","pn2400","pn2423","pn2470","pn2498","pn2513"],"creationTime":0,"user":"cscw","creator":"system"},"bad reputation":{"creationTime":1386522980438,"itemsUsedBy":["pn924"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"bad reputation"},"Time-series Data":{"creationTime":1386525860146,"itemsUsedBy":["pn1337","pn337"],"creator":"elm@purdue.edu","user":"elm@purdue.edu","label":"Time-series Data"},"3d printing":{"creationTime":1386521925607,"itemsUsedBy":["pn1034","pn419","pn2029"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"3d printing"},"Third World HCI":{"creationTime":1386522884099,"itemsUsedBy":["pn887"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Third World HCI"},"Data ownership":{"creationTime":1386523149850,"itemsUsedBy":["pn590"],"creator":"Xmyzhou@rutgers.edu","user":"Xmyzhou@rutgers.edu","label":"Data ownership"},"Animation":{"label":"Animation","itemsUsedBy":["pn106","pn228","pn339","pn563","pn614","pn638","pn655","pn964","pn1403","pn1404","pn1464","pn1530","pn1574","pn1577","pn1625","pn1745","pn1884","pn147"],"creationTime":0,"user":"cscw","creator":"system"},"ergonomics":{"creationTime":1386524957294,"itemsUsedBy":["pn420"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"ergonomics"},"whole body interaction":{"creationTime":1386522394892,"itemsUsedBy":["pn1709","pn1626","pn799","pn1425","pn420"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"whole body interaction"},"informaion visualization":{"creationTime":1386525128786,"itemsUsedBy":[],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"informaion visualization"},"usable security":{"creationTime":1386525977109,"itemsUsedBy":["pn191","pn950"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"usable security"},"Input and Interaction Technologies":{"label":"Input and Interaction Technologies","itemsUsedBy":["pn101","pn104","pn107","pn108","pn113","pn126","pn128","pn134","pn138","pn142","pn143","pn144","pn153","pn173","pn185","pn191","pn198","pn207","pn208","pn209","pn210","pn235","pn237","pn241","pn247","pn252","pn265","pn267","pn269","pn270","pn287","pn289","pn297","pn299","pn303","pn310","pn313","pn321","pn324","pn327","pn343","pn359","pn360","pn361","pn366","pn367","pn368","pn370","pn372","pn373","pn386","pn388","pn389","pn392","pn396","pn405","pn421","pn422","pn423","pn425","pn428","pn441","pn444","pn450","pn451","pn453","pn462","pn463","pn464","pn465","pn477","pn482","pn487","pn495","pn503","pn521","pn535","pn549","pn551","pn563","pn583","pn589","pn594","pn595","pn597","pn599","pn617","pn618","pn625","pn634","pn637","pn643","pn649","pn654","pn672","pn673","pn702","pn705","pn718","pn730","pn732","pn733","pn742","pn743","pn745","pn753","pn755","pn756","pn757","pn771","pn775","pn782","pn792","pn794","pn799","pn803","pn812","pn819","pn824","pn828","pn835","pn841","pn843","pn847","pn849","pn851","pn855","pn861","pn869","pn876","pn885","pn890","pn894","pn896","pn900","pn903","pn912","pn925","pn930","pn934","pn940","pn958","pn964","pn974","pn977","pn981","pn983","pn988","pn995","pn1006","pn1007","pn1008","pn1028","pn1054","pn1057","pn1059","pn1065","pn1066","pn1068","pn1070","pn1073","pn1077","pn1083","pn1084","pn1091","pn1092","pn1105","pn1106","pn1107","pn1109","pn1113","pn1118","pn1119","pn1121","pn1129","pn1131","pn1132","pn1154","pn1158","pn1160","pn1162","pn1169","pn1176","pn1181","pn1186","pn1188","pn1191","pn1194","pn1201","pn1212","pn1218","pn1219","pn1222","pn1223","pn1225","pn1226","pn1239","pn1248","pn1263","pn1266","pn1273","pn1287","pn1289","pn1303","pn1307","pn1316","pn1334","pn1335","pn1345","pn1360","pn1367","pn1370","pn1380","pn1384","pn1385","pn1387","pn1389","pn1397","pn1404","pn1407","pn1430","pn1441","pn1451","pn1457","pn1469","pn1471","pn1479","pn1494","pn1497","pn1502","pn1513","pn1514","pn1522","pn1526","pn1529","pn1533","pn1536","pn1553","pn1568","pn1583","pn1593","pn1606","pn1616","pn1628","pn1633","pn1634","pn1639","pn1645","pn1648","pn1657","pn1661","pn1674","pn1675","pn1684","pn1690","pn1698","pn1700","pn1708","pn1712","pn1716","pn1718","pn1720","pn1726","pn1738","pn1743","pn1748","pn1749","pn1752","pn1754","pn1756","pn1757","pn1759","pn1764","pn1767","pn1768","pn1779","pn1786","pn1793","pn1796","pn1797","pn1802","pn1825","pn1832","pn1837","pn1851","pn1863","pn1864","pn1865","pn1882","pn1886","pn1887","pn1893","pn1901","pn1905","pn1906","pn1908","pn1916","pn1919","pn1927","pn1935","pn1936","pn1939","pn1950","pn1961","pn1966","pn1967","pn1974","pn1975","pn1981","pn1983","pn1990","pn1992","pn1993","pn2003","pn2010","pn2012","pn2015","pn2022","pn2037","pn2040","pn2047","pn2049","pn2052","pn2084","pn2086","pn2090","pn2116","pn2138","pn2139","pn2149","pn2150","pn2154","pn2156","pn2157","pn2165","pn2166","pn2168","pn2176","pn2181","pn2184","pn2185","pn2187","pn2190","pn2195","pn2196","pn2198","pn2206","pn2212","pn2223","pn2236","pn2237","pn2238","pn2239","pn2247","pn2253","pn2258","pn2259","pn2263","pn2265","pn2288","pn2290","pn2293","pn2297","pn2306","pn2320","pn2336","pn2352","pn2376","pn2378","pn2384","pn2387","pn2389","pn2402","pn2411","pn2416","pn2424","pn2430","pn2432","pn2449","pn2454","pn2464","pn2482","pn2493","pn2497","pn2500","pn2503","pn2506","pn2508","pn2510","pn2526","pn2548","pn2054","pn737","pn426","to135","pn1482","pn1883"],"creationTime":0,"user":"cscw","creator":"system"},"design process":{"creationTime":1386522627219,"itemsUsedBy":["pn999"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"design process"},"objects and people":{"creationTime":1386527189519,"itemsUsedBy":["pn1923"],"creator":"vlh@acm.org","user":"vlh@acm.org","label":"objects and people"},"Photosharing":{"creationTime":1386524395408,"itemsUsedBy":[],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"Photosharing"},"design in publics":{"creationTime":1386522949421,"itemsUsedBy":["pn2140","pn576","pn279"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"design in publics"},"ICT4D":{"creationTime":1386522185884,"itemsUsedBy":[],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"ICT4D"},"Citizen Journalism":{"creationTime":1386523212082,"itemsUsedBy":["pn576"],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"Citizen Journalism"},"Exergames":{"creationTime":1386521852744,"itemsUsedBy":["pn737","pn1183","pn122","pn1171","pn1521","pn2003","pn2277","pn1709"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Exergames"},"Interruptions":{"creationTime":1386526981326,"itemsUsedBy":["pn806"],"creator":"e.karapanos@gmail.com","user":"e.karapanos@gmail.com","label":"Interruptions"},"Food":{"creationTime":1386522456267,"itemsUsedBy":["pn419","to104","pn2276"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Food"},"Speech I/O":{"label":"Speech I/O","itemsUsedBy":["pn111","pn206","pn710","pn864","pn960","pn1403","pn1893","pn2007","pn2155","pn2339","pn2495"],"creationTime":0,"user":"cscw","creator":"system"},"comics":{"creationTime":1386523060172,"itemsUsedBy":["pn1820"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"comics"},"Ethnography":{"label":"Ethnography","itemsUsedBy":["pn109","pn159","pn231","pn232","pn234","pn493","pn534","pn576","pn732","pn873","pn882","pn913","pn918","pn954","pn967","pn1012","pn1037","pn1043","pn1110","pn1122","pn1195","pn1270","pn1309","pn1334","pn1400","pn1402","pn1420","pn1428","pn1438","pn1512","pn1527","pn1547","pn1549","pn1576","pn1642","pn1652","pn1659","pn1672","pn1710","pn1732","pn1771","pn1775","pn1850","pn1918","pn2011","pn2077","pn2099","pn2111","pn2131","pn2206","pn2220","pn2226","pn2266","pn2313","pn2315","pn2347","pn2466","pn2471","pn2486","pn2508","pn2509","pn2368","to136","pn2150","to132","pn166"],"creationTime":0,"user":"cscw","creator":"system"},"natural language processing":{"creationTime":1386525049254,"itemsUsedBy":["to137"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"natural language processing"},"Mobile Projection":{"creationTime":1386523807599,"itemsUsedBy":["pn2168","pn672"],"creator":"xiangcao@acm.org","user":"xiangcao@acm.org","label":"Mobile Projection"},"Third World design":{"creationTime":1386522871172,"itemsUsedBy":["pn887"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Third World design"},"longitudinal field study":{"creationTime":1386523151262,"itemsUsedBy":["pn1241","to103"],"creator":"mulderi@acm.org","user":"mulderi@acm.org","label":"longitudinal field study"},"Fabrication":{"creationTime":1386531620145,"itemsUsedBy":["pn529","pn2029"],"creator":"mdixon@cs.washington.edu","user":"mdixon@cs.washington.edu","label":"Fabrication"},"Hermeneutics":{"creationTime":1386522599934,"itemsUsedBy":["pn999"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Hermeneutics"},"location media":{"creationTime":1386526330820,"itemsUsedBy":["pn1569"],"creator":"bpbailey@illinois.edu","user":"bpbailey@illinois.edu","label":"location media"},"head pose":{"creationTime":1386525593150,"itemsUsedBy":[],"creator":"bulling@mpi-inf.mpg.de","user":"bulling@mpi-inf.mpg.de","label":"head pose"},"motion capture":{"creationTime":1386524967035,"itemsUsedBy":["pn420"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"motion capture"},"interactive narrative":{"creationTime":1386523071148,"itemsUsedBy":["pn1820"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"interactive narrative"},"collaboration":{"creationTime":1386522617416,"itemsUsedBy":["pn1452","pn1470","pn1032"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"collaboration"},"Journalism":{"creationTime":1386523177148,"itemsUsedBy":["pn576"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Journalism"},"Multilingual communication":{"creationTime":1386521465688,"itemsUsedBy":["pn1867","pn1347","pn1375"],"creator":"sfussell@cornell.edu","user":"sfussell@cornell.edu","label":"Multilingual communication"},"Vehicular":{"creationTime":1386524066161,"itemsUsedBy":["pn1969","to131"],"creator":"jws@microsoft.com","user":"jws@microsoft.com","label":"Vehicular"},"User Generated Content":{"creationTime":1386526826861,"itemsUsedBy":["pn1269"],"creator":"manfred.tscheligi@sbg.ac.at","user":"manfred.tscheligi@sbg.ac.at","label":"User Generated Content"},"addiction":{"creationTime":1386522044531,"itemsUsedBy":["pn2175"],"creator":"oantti@mpi-inf.mpg.de","user":"oantti@mpi-inf.mpg.de","label":"addiction"},"Vision":{"creationTime":1386522349246,"itemsUsedBy":["pn1915","pn951"],"creator":"elainemayhuang@gmail.com","user":"elainemayhuang@gmail.com","label":"Vision"},"theory-driven design":{"creationTime":1386523584859,"itemsUsedBy":["pn761"],"creator":"a.parker@neu.edu","user":"a.parker@neu.edu","label":"theory-driven design"},"in car technology":{"creationTime":1386523016706,"itemsUsedBy":["pn2203","pn233"],"creator":"D.StantonFraser@bath.ac.uk","user":"D.StantonFraser@bath.ac.uk","label":"in car technology"},"Do Ask Do Tell":{"creationTime":1386525082566,"itemsUsedBy":["pn691"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Do Ask Do Tell"},"failure":{"creationTime":1386522445464,"itemsUsedBy":["pn810"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"failure"},"mobile":{"creationTime":1386522845764,"itemsUsedBy":["to108","pn443","to102","pn1904"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"mobile"},"aggregating social network data":{"creationTime":1386522448938,"itemsUsedBy":["pn150","pn1009"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"aggregating social network data"},"Wall Displays":{"creationTime":1386525371637,"itemsUsedBy":["pn389","pn1936"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Wall Displays"},"newcomers":{"creationTime":1386521677480,"itemsUsedBy":["pn1918"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"newcomers"},"Cross-cultural studies":{"creationTime":1386522386255,"itemsUsedBy":["pn2074","pn906"],"creator":"dmrussell@gmail.com","user":"dmrussell@gmail.com","label":"Cross-cultural studies"},"China":{"creationTime":1386522426297,"itemsUsedBy":["pn1549"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"China"},"Personas":{"creationTime":1386522948334,"itemsUsedBy":["pn866","pn687"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Personas"},"enterprise":{"creationTime":1386521568967,"itemsUsedBy":["pn2095","pn2488","pn1341","pn1881"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"enterprise"},"Show Me the Money":{"creationTime":1386523272822,"itemsUsedBy":["pn119","pn186","pn526"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Show Me the Money"},"strong concepts":{"creationTime":1386522158248,"itemsUsedBy":["pn2048"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"strong concepts"},"intertextuality":{"creationTime":1386523115774,"itemsUsedBy":["pn1881"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"intertextuality"},"social capital":{"creationTime":1386523991894,"itemsUsedBy":["pn1255","pn905"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"social capital"},"Practitioners":{"creationTime":1386523461438,"itemsUsedBy":["pn687"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Practitioners"},"Authentication":{"creationTime":1386521643597,"itemsUsedBy":["pn757","pn1399","pn2227","pn1097"],"creator":"alexander.de.luca@ifi.lmu.de","user":"alexander.de.luca@ifi.lmu.de","label":"Authentication"},"social media at work":{"creationTime":1386521998166,"itemsUsedBy":["pn2488"],"creator":"myriam.lewkowicz@utt.fr","user":"myriam.lewkowicz@utt.fr","label":"social media at work"},"Systems":{"creationTime":1386526395784,"itemsUsedBy":[],"creator":"kgajos@eecs.harvard.edu","user":"kgajos@eecs.harvard.edu","label":"Systems"},"algorithms":{"creationTime":1386528177211,"itemsUsedBy":["pn806"],"creator":"david.geerts@soc.kuleuven.be","user":"david.geerts@soc.kuleuven.be","label":"algorithms"},"live casting":{"creationTime":1386523080427,"itemsUsedBy":["pn653"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"live casting"},"geography":{"creationTime":1386522212214,"itemsUsedBy":["pn2401","pn1954","pn1333","pn1460"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"geography"},"online reputation":{"creationTime":1386522947440,"itemsUsedBy":["pn924"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"online reputation"},"design implication":{"creationTime":1386535597321,"itemsUsedBy":["pn2129"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"design implication"},"big data":{"creationTime":1386521879393,"itemsUsedBy":["pn555","pn581","pn1413","pn2134"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"big data"},"human senses":{"creationTime":1386523379898,"itemsUsedBy":["pn320"],"creator":"fernaeus@kth.se","user":"fernaeus@kth.se","label":"human senses"},"decision support system":{"creationTime":1386524204064,"itemsUsedBy":["pn1398"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"decision support system"},"pressure interaction":{"creationTime":1386525340075,"itemsUsedBy":["pn1635","pn1046"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"pressure interaction"},"Sustainability":{"label":"Sustainability","itemsUsedBy":["pn155","pn214","pn394","pn417","pn424","pn528","pn559","pn695","pn766","pn770","pn900","pn905","pn931","pn948","pn957","pn984","pn1001","pn1038","pn1044","pn1064","pn1087","pn1192","pn1280","pn1340","pn1397","pn1483","pn1597","pn1641","pn1771","pn1781","pn1889","pn1915","pn1945","pn1949","pn1956","pn2011","pn2042","pn2067","pn2079","pn2143","pn2244","pn2287","pn2386","pn2458","pn2193","pn1707","to104","to112","to106","to127","to117","to110","to136"],"creationTime":0,"user":"cscw","creator":"system"},"Analysis Methods (e.g. Task/Interaction Modeling)":{"label":"Analysis Methods (e.g. Task/Interaction Modeling)","itemsUsedBy":["pn162","pn171","pn190","pn247","pn269","pn270","pn272","pn293","pn315","pn340","pn348","pn378","pn392","pn420","pn421","pn422","pn453","pn471","pn482","pn586","pn595","pn613","pn619","pn623","pn659","pn698","pn718","pn748","pn822","pn880","pn920","pn978","pn1017","pn1053","pn1093","pn1137","pn1145","pn1191","pn1245","pn1277","pn1303","pn1309","pn1329","pn1388","pn1392","pn1397","pn1422","pn1478","pn1489","pn1494","pn1506","pn1524","pn1568","pn1606","pn1668","pn1716","pn1784","pn1962","pn1987","pn1993","pn1999","pn2040","pn2056","pn2101","pn2117","pn2119","pn2139","pn2142","pn2155","pn2187","pn2309","pn2328","pn2329","pn2363","pn2400","pn2435","pn2482","pn2494","pn2516","pn2545","pn2330","pn2394"],"creationTime":0,"user":"cscw","creator":"system"},"Social Psychology":{"creationTime":1386522977206,"itemsUsedBy":["pn2380","pn2489"],"creator":"jantin@gmail.com","user":"jantin@gmail.com","label":"Social Psychology"},"special issue - turn to wild":{"creationTime":1386522973794,"itemsUsedBy":["to103","to132","to123","to122","to102","to105"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"special issue - turn to wild"},"awareness":{"creationTime":1386523123418,"itemsUsedBy":["pn2463","pn180","pn1425"],"creator":"kc@comp.lancs.ac.uk","user":"kc@comp.lancs.ac.uk","label":"awareness"},"User Interface Engineering":{"creationTime":1386523712423,"itemsUsedBy":[],"creator":"nebeling@inf.ethz.ch","user":"nebeling@inf.ethz.ch","label":"User Interface Engineering"},"cinematography":{"creationTime":1386531669320,"itemsUsedBy":["pn147"],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"cinematography"},"social computing":{"creationTime":1386521247555,"itemsUsedBy":["pn802","pn2095","pn1710","pn1727","pn2294"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"social computing"},"Design patterns":{"creationTime":1386522155050,"itemsUsedBy":["pn2048","pn586"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Design patterns"},"recommender systems":{"creationTime":1386522590733,"itemsUsedBy":["pn2380","pn1398"],"creator":"com@psychology.nottingham.ac.uk","user":"com@psychology.nottingham.ac.uk","label":"recommender systems"},"Desktop interactions":{"creationTime":1386523930842,"itemsUsedBy":["pn361","pn435"],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"Desktop interactions"},"photography":{"creationTime":1386524130325,"itemsUsedBy":["pn405","pn1295","pn147"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"photography"},"Experience Strategy":{"label":"Experience Strategy","itemsUsedBy":["pn302","pn334","pn394","pn616","pn740","pn741","pn746","pn1004","pn1016","pn1067","pn1079","pn1114","pn1166","pn1201","pn1239","pn1309","pn1424","pn1542","pn1546","pn1551","pn1568","pn1579","pn1976","pn1994","pn2017","pn2048","pn2241","pn2261","pn2296","pn2435","pn2499","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"text to speech":{"creationTime":1386525653596,"itemsUsedBy":["to131"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"text to speech"},"Product Design":{"label":"Product Design","itemsUsedBy":["pn103","pn184","pn230","pn421","pn424","pn462","pn682","pn695","pn971","pn986","pn992","pn999","pn1211","pn1231","pn1309","pn1364","pn1442","pn1630","pn1705","pn1904","pn2014","pn2066","pn2178","pn2180","pn2187","pn2208","pn2466","pn2477","pn2497","pn2508","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"Computer-Mediated Communication":{"label":"Computer-Mediated Communication","itemsUsedBy":["pn109","pn151","pn156","pn167","pn195","pn197","pn210","pn279","pn285","pn306","pn357","pn358","pn376","pn433","pn447","pn458","pn486","pn496","pn524","pn532","pn566","pn595","pn600","pn611","pn612","pn613","pn656","pn663","pn668","pn670","pn674","pn693","pn716","pn722","pn760","pn774","pn784","pn789","pn791","pn808","pn855","pn868","pn874","pn889","pn919","pn923","pn937","pn979","pn1016","pn1049","pn1079","pn1090","pn1125","pn1151","pn1152","pn1198","pn1199","pn1201","pn1202","pn1203","pn1208","pn1240","pn1250","pn1272","pn1277","pn1278","pn1284","pn1290","pn1317","pn1346","pn1359","pn1381","pn1392","pn1393","pn1394","pn1396","pn1406","pn1414","pn1427","pn1430","pn1440","pn1445","pn1446","pn1454","pn1455","pn1461","pn1467","pn1474","pn1492","pn1501","pn1507","pn1537","pn1595","pn1598","pn1617","pn1633","pn1636","pn1668","pn1671","pn1697","pn1702","pn1713","pn1715","pn1732","pn1782","pn1785","pn1787","pn1799","pn1800","pn1806","pn1819","pn1821","pn1829","pn1840","pn1871","pn1873","pn1948","pn1951","pn1988","pn2014","pn2018","pn2040","pn2045","pn2053","pn2064","pn2083","pn2088","pn2097","pn2125","pn2131","pn2132","pn2148","pn2153","pn2158","pn2159","pn2191","pn2196","pn2199","pn2201","pn2211","pn2253","pn2260","pn2266","pn2270","pn2283","pn2286","pn2298","pn2304","pn2320","pn2329","pn2412","pn2417","pn2437","pn2459","pn2465","pn2466","pn2471","pn2472","pn2475","pn2483","pn2496","pn2515","pn2516","pn2525","pn2528","pn2542","pn887","pn1238","pn975"],"creationTime":0,"user":"cscw","creator":"system"},"Conflict Zone":{"creationTime":1386525404561,"itemsUsedBy":["pn1238"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Conflict Zone"},"Target Aquisition":{"creationTime":1386522226371,"itemsUsedBy":[],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Target Aquisition"},"Computer Supported Collaborative Romance":{"creationTime":1386524330217,"itemsUsedBy":["pn1238"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Computer Supported Collaborative Romance"},"stigma":{"creationTime":1386526730872,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"stigma"},"Guided experiences":{"creationTime":1386526392601,"itemsUsedBy":["pn1569","pn1632","pn2001"],"creator":"andrew.sears@rit.edu","user":"andrew.sears@rit.edu","label":"Guided experiences"},"Low SES":{"creationTime":1386522831284,"itemsUsedBy":["pn704"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Low SES"},"Programming by Demonstration":{"creationTime":1386532577100,"itemsUsedBy":["pn2441"],"creator":"mdixon@cs.washington.edu","user":"mdixon@cs.washington.edu","label":"Programming by Demonstration"},"second language learning":{"creationTime":1386523260329,"itemsUsedBy":[],"creator":"mona@cs.umd.edu","user":"mona@cs.umd.edu","label":"second language learning"},"Design implications":{"creationTime":1386523386907,"itemsUsedBy":["pn320"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Design implications"},"Living design":{"creationTime":1386522788646,"itemsUsedBy":["pn2406"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Living design"},"text entry":{"creationTime":1386525503175,"itemsUsedBy":[],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"text entry"},"Instagram":{"creationTime":1386522853341,"itemsUsedBy":["pn2417"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"Instagram"},"collaborative filtering":{"creationTime":1386524744048,"itemsUsedBy":["pn691","pn806"],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"collaborative filtering"},"Computer  Vision":{"creationTime":1386538219152,"itemsUsedBy":["pn235"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Computer  Vision"},"personality inferrence":{"creationTime":1386524188265,"itemsUsedBy":[],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"personality inferrence"},"E-Commerce":{"label":"E-Commerce","itemsUsedBy":["pn381","pn650","pn661","pn671","pn689","pn695","pn705","pn920","pn1032","pn1191","pn1263","pn1450","pn1561","pn1629","pn1711","pn1761","pn2543"],"creationTime":0,"user":"cscw","creator":"system"},"Motiviation for Participation":{"creationTime":1386522114956,"itemsUsedBy":["pn2489"],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Motiviation for Participation"},"Education":{"creationTime":1386523445611,"itemsUsedBy":["pn1120","pn1182"],"creator":"quintana@umich.edu","user":"quintana@umich.edu","label":"Education"},"Health and social media":{"creationTime":1386523147040,"itemsUsedBy":["pn1413","pn1814","pn1290","pn1821","pn219"],"creator":"Jina.huh@gmail.com","user":"Jina.huh@gmail.com","label":"Health and social media"},"Auditory Interface Design":{"creationTime":1386526279619,"itemsUsedBy":["pn1569"],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"Auditory Interface Design"},"Driving":{"creationTime":1386523098860,"itemsUsedBy":["pn2420","pn621","pn648","pn233"],"creator":"ian.r.oakley@gmail.com","user":"ian.r.oakley@gmail.com","label":"Driving"},"Motivation":{"creationTime":1386527123460,"itemsUsedBy":["pn1171"],"creator":"kgajos@eecs.harvard.edu","user":"kgajos@eecs.harvard.edu","label":"Motivation"},"Wikipedia":{"creationTime":1386522226273,"itemsUsedBy":["pn1918","pn657","pn1410"],"creator":"gutwin@cs.usask.ca","user":"gutwin@cs.usask.ca","label":"Wikipedia"},"Sketching":{"creationTime":1386521862719,"itemsUsedBy":["pn2343","pn1992"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Sketching"},"Ideation":{"creationTime":1386522214488,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Ideation"},"Kinect":{"creationTime":1386521979846,"itemsUsedBy":["pn521","pn601"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Kinect"},"content popularity":{"creationTime":1386523311253,"itemsUsedBy":["pn1763"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"content popularity"},"Location":{"creationTime":1386522554092,"itemsUsedBy":["pn1675","pn2401","pn1333"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Location"},"Performance":{"creationTime":1386522147563,"itemsUsedBy":["pn2202","pn118","pn1099"],"creator":"david.kirk@ncl.ac.uk","user":"david.kirk@ncl.ac.uk","label":"Performance"},"social transparency":{"creationTime":1386523239807,"itemsUsedBy":["pn180"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"social transparency"},"breaking the addiction of social media":{"creationTime":1386524772528,"itemsUsedBy":["pn219","pn2175"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"breaking the addiction of social media"},"mobile apps":{"creationTime":1386522401262,"itemsUsedBy":["pn2525","pn1282","pn2441"],"creator":"kc@comp.lancs.ac.uk","user":"kc@comp.lancs.ac.uk","label":"mobile apps"},"Participatory Design / Cooperative Design":{"label":"Participatory Design / Cooperative Design","itemsUsedBy":["pn117","pn118","pn204","pn210","pn232","pn234","pn257","pn258","pn410","pn424","pn430","pn457","pn501","pn540","pn576","pn620","pn622","pn630","pn631","pn632","pn675","pn676","pn738","pn747","pn759","pn769","pn815","pn838","pn846","pn854","pn866","pn887","pn903","pn908","pn910","pn926","pn931","pn955","pn967","pn1012","pn1037","pn1063","pn1064","pn1076","pn1133","pn1135","pn1155","pn1256","pn1268","pn1348","pn1393","pn1401","pn1405","pn1440","pn1442","pn1458","pn1479","pn1497","pn1517","pn1528","pn1543","pn1576","pn1600","pn1601","pn1720","pn1746","pn1764","pn1786","pn1798","pn1859","pn1880","pn1918","pn1926","pn1941","pn1945","pn1964","pn1978","pn2018","pn2035","pn2055","pn2097","pn2127","pn2140","pn2146","pn2160","pn2162","pn2170","pn2191","pn2206","pn2220","pn2261","pn2359","pn2426","pn2468","pn2504","pn2368"],"creationTime":0,"user":"cscw","creator":"system"},"Social Media":{"creationTime":1386522215718,"itemsUsedBy":[],"creator":"jantin@gmail.com","user":"jantin@gmail.com","label":"Social Media"},"Shopping":{"creationTime":1386521874060,"itemsUsedBy":["pn1032"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"Shopping"},"Vision-Impaired Users":{"creationTime":1386524638956,"itemsUsedBy":[],"creator":"fabio.paterno@isti.cnr.it","user":"fabio.paterno@isti.cnr.it","label":"Vision-Impaired Users"},"social inference":{"creationTime":1386523955763,"itemsUsedBy":["pn691","pn583"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"social inference"},"design guidelines":{"creationTime":1386524197655,"itemsUsedBy":["pn1417"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"design guidelines"},"presence technologies":{"creationTime":1386536772403,"itemsUsedBy":["pn704"],"creator":"vlh@acm.org","user":"vlh@acm.org","label":"presence technologies"},"Gestures":{"creationTime":1386527285036,"itemsUsedBy":[],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Gestures"},"Visualizing Uncertainty":{"creationTime":1386525441516,"itemsUsedBy":["pn966"],"creator":"aquigley@st-andrews.ac.uk","user":"aquigley@st-andrews.ac.uk","label":"Visualizing Uncertainty"},"Dialog Analysis":{"label":"Dialog Analysis","itemsUsedBy":["pn595","pn2321"],"creationTime":0,"user":"cscw","creator":"system"},"reading":{"creationTime":1386523665814,"itemsUsedBy":["pn255"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"reading"},"email":{"creationTime":1386523705289,"itemsUsedBy":["pn345","pn1257"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"email"},"Field Study":{"creationTime":1386521768371,"itemsUsedBy":["pn2244","pn399","pn155","pn2276","pn2226","pn1475","to123","pn361","to129","pn704"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Field Study"},"Remote Presence":{"creationTime":1386522787974,"itemsUsedBy":["pn279"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Remote Presence"},"Design and responsibility":{"creationTime":1386523102890,"itemsUsedBy":["pn2220"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Design and responsibility"},"web":{"creationTime":1386525075939,"itemsUsedBy":["to120"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"web"},"Empirical Methods, Quantitative":{"label":"Empirical Methods, Quantitative","itemsUsedBy":["pn101","pn109","pn113","pn135","pn140","pn151","pn155","pn156","pn162","pn183","pn189","pn199","pn203","pn226","pn240","pn264","pn270","pn293","pn315","pn320","pn322","pn344","pn346","pn350","pn388","pn389","pn390","pn391","pn392","pn394","pn397","pn398","pn403","pn429","pn436","pn454","pn458","pn474","pn508","pn537","pn546","pn555","pn562","pn572","pn597","pn599","pn622","pn636","pn639","pn640","pn647","pn661","pn663","pn674","pn683","pn693","pn709","pn710","pn735","pn741","pn746","pn753","pn760","pn766","pn767","pn771","pn774","pn801","pn832","pn833","pn860","pn861","pn864","pn868","pn871","pn889","pn918","pn934","pn936","pn956","pn962","pn969","pn983","pn988","pn1001","pn1004","pn1008","pn1047","pn1078","pn1111","pn1112","pn1114","pn1127","pn1165","pn1235","pn1247","pn1249","pn1263","pn1267","pn1277","pn1283","pn1300","pn1309","pn1315","pn1321","pn1323","pn1327","pn1328","pn1337","pn1346","pn1374","pn1376","pn1384","pn1392","pn1396","pn1397","pn1400","pn1406","pn1410","pn1419","pn1422","pn1427","pn1431","pn1444","pn1445","pn1450","pn1454","pn1456","pn1464","pn1467","pn1474","pn1490","pn1509","pn1510","pn1512","pn1515","pn1530","pn1531","pn1532","pn1537","pn1555","pn1557","pn1568","pn1575","pn1579","pn1592","pn1619","pn1622","pn1656","pn1657","pn1668","pn1670","pn1674","pn1690","pn1694","pn1723","pn1730","pn1733","pn1743","pn1756","pn1782","pn1784","pn1785","pn1791","pn1796","pn1838","pn1846","pn1858","pn1870","pn1886","pn1898","pn1901","pn1910","pn1928","pn1937","pn1948","pn1950","pn1963","pn1968","pn1976","pn2000","pn2013","pn2072","pn2077","pn2101","pn2106","pn2108","pn2118","pn2119","pn2120","pn2132","pn2134","pn2135","pn2144","pn2148","pn2151","pn2153","pn2155","pn2175","pn2181","pn2187","pn2201","pn2212","pn2229","pn2231","pn2234","pn2239","pn2250","pn2257","pn2264","pn2267","pn2278","pn2279","pn2317","pn2318","pn2320","pn2321","pn2328","pn2352","pn2398","pn2402","pn2414","pn2417","pn2421","pn2422","pn2431","pn2437","pn2444","pn2453","pn2456","pn2460","pn2470","pn2476","pn2483","pn2485","pn2489","pn2508","pn2516","pn2522","pn2525","pn2543","pn2548","pn1707","pn1525","pn2560","pn2330","pn2105","pn1193"],"creationTime":0,"user":"cscw","creator":"system"},"Design Professions":{"creationTime":1386523032191,"itemsUsedBy":["pn1667"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Design Professions"},"Interaction techniques":{"creationTime":1386522672771,"itemsUsedBy":["pn2394","pn386"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"Interaction techniques"},"shape changing interfaces":{"creationTime":1386523728845,"itemsUsedBy":["pn313","pn385","pn1186","pn2041"],"creator":"kris.luyten@uhasselt.be","user":"kris.luyten@uhasselt.be","label":"shape changing interfaces"},"alternative currency":{"creationTime":1386528336492,"itemsUsedBy":["pn602"],"creator":"judy.kay@gmail.com","user":"judy.kay@gmail.com","label":"alternative currency"},"navigation":{"creationTime":1386523296964,"itemsUsedBy":["pn1032"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"navigation"},"ethnography":{"creationTime":1386523934886,"itemsUsedBy":[],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"ethnography"},"3D Interaction":{"creationTime":1386522212472,"itemsUsedBy":["pn1901","pn2010","pn2022"],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"3D Interaction"},"crowd innovation":{"creationTime":1386523271570,"itemsUsedBy":["pn602"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"crowd innovation"},"social support":{"creationTime":1386521727722,"itemsUsedBy":["pn802"],"creator":"myriam.lewkowicz@utt.fr","user":"myriam.lewkowicz@utt.fr","label":"social support"},"Emotion":{"creationTime":1386524633322,"itemsUsedBy":[],"creator":"manfred.tscheligi@sbg.ac.at","user":"manfred.tscheligi@sbg.ac.at","label":"Emotion"},"Speech recognition":{"creationTime":1386523017599,"itemsUsedBy":[],"creator":"dmrussell@gmail.com","user":"dmrussell@gmail.com","label":"Speech recognition"},"Fieldstudy":{"creationTime":1386522846346,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Fieldstudy"},"The Eyes Have It":{"creationTime":1386526246076,"itemsUsedBy":["pn626","pn951","pn405","pn750"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"The Eyes Have It"},"text input":{"creationTime":1386525486328,"itemsUsedBy":["to118"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"text input"},"games":{"label":"games","itemsUsedBy":["to103","pn737","pn2330","pn1750","pn1626","pn2046","pn2317","pn1120","pn122","pn121","pn1758"],"creationTime":0,"user":"cscw","creator":"system"},"faces":{"creationTime":1386524571992,"itemsUsedBy":["pn2417"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"faces"},"Design Narrative":{"creationTime":1386522876288,"itemsUsedBy":["pn1518"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Design Narrative"},"post-apocalyptic design":{"creationTime":1386528170229,"itemsUsedBy":["to127"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"post-apocalyptic design"},"Information Architecture":{"label":"Information Architecture","itemsUsedBy":["pn109","pn115","pn168","pn184","pn239","pn247","pn393","pn573","pn581","pn880","pn889","pn998","pn1143","pn1191","pn1196","pn1597","pn1866","pn1929","pn2075","pn2204","pn2354","pn2418","pn2545"],"creationTime":0,"user":"cscw","creator":"system"},"Instragram":{"creationTime":1386522828107,"itemsUsedBy":[],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"Instragram"},"Death":{"creationTime":1386521849398,"itemsUsedBy":["pn590"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Death"},"nudges":{"creationTime":1386525887068,"itemsUsedBy":["pn2463"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"nudges"},"cancer":{"creationTime":1386522921132,"itemsUsedBy":["pn1298"],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"cancer"},"Video Chat":{"creationTime":1386522783708,"itemsUsedBy":["pn279"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Video Chat"},"Faces":{"creationTime":1386536904210,"itemsUsedBy":["pn222","pn2417"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Faces"},"eco-design":{"creationTime":1386522717466,"itemsUsedBy":["pn1949","pn2016"],"creator":"younlim.cixd@gmail.com","user":"younlim.cixd@gmail.com","label":"eco-design"},"data mining":{"creationTime":1386527024898,"itemsUsedBy":["pn1282"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"data mining"},"Aging society":{"creationTime":1386521491788,"itemsUsedBy":["pn1896"],"creator":"emailaddress","user":"emailaddress","label":"Aging society"},"ideation":{"creationTime":1386521271998,"itemsUsedBy":["pn1123","pn2235","pn2208"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"ideation"},"design research":{"creationTime":1386522849164,"itemsUsedBy":["pn2129"],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"design research"},"2D Graphical Interfaces":{"creationTime":1386522576425,"itemsUsedBy":["pn189","pn796"],"creator":"stuart@tropic.org.uk","user":"stuart@tropic.org.uk","label":"2D Graphical Interfaces"},"arts":{"label":"arts","itemsUsedBy":["to103","to114","pn1579","pn614","pn547"],"creationTime":0,"user":"cscw","creator":"system"},"Perception":{"creationTime":1386523393383,"itemsUsedBy":["pn320"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Perception"},"critical design":{"creationTime":1386521940408,"itemsUsedBy":["pn999","pn2140","pn581","pn2011"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"critical design"},"idea generation":{"creationTime":1386523257577,"itemsUsedBy":["pn2208"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"idea generation"},"audience interaction":{"creationTime":1386523059212,"itemsUsedBy":["pn2202","pn139"],"creator":"daverandall2008@gmail.com","user":"daverandall2008@gmail.com","label":"audience interaction"},"creativity":{"creationTime":1386522337589,"itemsUsedBy":["pn1710","pn2235"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"creativity"},"Maker":{"creationTime":1386523030107,"itemsUsedBy":["pn967"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"Maker"},"Tablet application":{"creationTime":1386523146556,"itemsUsedBy":["pn2020"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Tablet application"},"Phone":{"creationTime":1386522812991,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Phone"},"stuff and things":{"creationTime":1386522917718,"itemsUsedBy":["pn967"],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"stuff and things"},"Empirical Methods, Qualitative":{"label":"Empirical Methods, Qualitative","itemsUsedBy":["pn101","pn105","pn109","pn110","pn115","pn117","pn155","pn159","pn167","pn169","pn181","pn189","pn195","pn202","pn210","pn214","pn226","pn257","pn258","pn259","pn278","pn285","pn293","pn306","pn319","pn320","pn333","pn341","pn342","pn358","pn381","pn388","pn394","pn399","pn406","pn417","pn433","pn449","pn456","pn468","pn486","pn506","pn540","pn547","pn552","pn573","pn609","pn611","pn612","pn630","pn647","pn655","pn663","pn687","pn699","pn702","pn708","pn732","pn738","pn749","pn766","pn774","pn783","pn791","pn815","pn818","pn820","pn826","pn834","pn854","pn860","pn882","pn887","pn889","pn900","pn913","pn918","pn926","pn929","pn941","pn948","pn949","pn954","pn956","pn957","pn996","pn1001","pn1024","pn1043","pn1051","pn1069","pn1076","pn1079","pn1104","pn1112","pn1115","pn1140","pn1143","pn1156","pn1170","pn1172","pn1198","pn1201","pn1217","pn1234","pn1235","pn1240","pn1245","pn1250","pn1270","pn1272","pn1274","pn1295","pn1301","pn1304","pn1309","pn1340","pn1344","pn1388","pn1395","pn1420","pn1431","pn1451","pn1452","pn1454","pn1462","pn1465","pn1484","pn1499","pn1504","pn1505","pn1510","pn1512","pn1518","pn1534","pn1549","pn1551","pn1556","pn1557","pn1576","pn1580","pn1617","pn1631","pn1636","pn1652","pn1657","pn1659","pn1667","pn1683","pn1714","pn1715","pn1724","pn1732","pn1734","pn1743","pn1760","pn1781","pn1791","pn1796","pn1799","pn1806","pn1820","pn1837","pn1838","pn1844","pn1850","pn1878","pn1891","pn1893","pn1898","pn1903","pn1909","pn1933","pn1950","pn1964","pn1965","pn2002","pn2006","pn2040","pn2045","pn2053","pn2079","pn2098","pn2103","pn2108","pn2111","pn2129","pn2147","pn2156","pn2158","pn2159","pn2164","pn2178","pn2181","pn2182","pn2183","pn2187","pn2188","pn2191","pn2202","pn2205","pn2207","pn2209","pn2217","pn2226","pn2230","pn2231","pn2239","pn2243","pn2244","pn2248","pn2250","pn2266","pn2279","pn2280","pn2294","pn2295","pn2296","pn2305","pn2313","pn2318","pn2321","pn2341","pn2358","pn2360","pn2367","pn2390","pn2398","pn2415","pn2416","pn2418","pn2421","pn2422","pn2444","pn2459","pn2461","pn2470","pn2471","pn2478","pn2479","pn2480","pn2496","pn2508","pn2513","pn2515","pn2525","pn2552","pn1834","pn1710"],"creationTime":0,"user":"cscw","creator":"system"},"tutorials":{"creationTime":1386532091097,"itemsUsedBy":[],"creator":"dvogel@uwaterloo.ca","user":"dvogel@uwaterloo.ca","label":"tutorials"},"Marketing / Market Research":{"label":"Marketing / Market Research","itemsUsedBy":["pn394","pn553","pn911","pn1078","pn1078","pn1079","pn1079","pn1166","pn1204","pn1515","pn2155","pn2186","pn2280","pn2302","pn2331","pn2408","pn2410"],"creationTime":0,"user":"cscw","creator":"system"},"Database access / Information Retrieval":{"label":"Database access / Information Retrieval","itemsUsedBy":["pn115","pn116","pn361","pn393","pn431","pn472","pn581","pn626","pn650","pn701","pn733","pn783","pn837","pn856","pn880","pn1010","pn1047","pn1071","pn1072","pn1159","pn1161","pn1191","pn1196","pn1311","pn1378","pn1460","pn1486","pn1536","pn1568","pn1687","pn1734","pn1910","pn2034","pn2128","pn2267","pn2392","pn2542"],"creationTime":0,"user":"cscw","creator":"system"},"Probes":{"creationTime":1386536545870,"itemsUsedBy":["pn2487"],"creator":"Mark.blythe@northumbria","user":"Mark.blythe@northumbria","label":"Probes"},"dialogue":{"creationTime":1386523231109,"itemsUsedBy":["pn118"],"creator":"mulderi@acm.org","user":"mulderi@acm.org","label":"dialogue"},"diversity":{"creationTime":1386522992287,"itemsUsedBy":["pn1517"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"diversity"},"Virtual Agents":{"creationTime":1386523699662,"itemsUsedBy":["pn1745"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"Virtual Agents"},"Multi-channel Applications":{"label":"Multi-channel Applications","itemsUsedBy":["pn205","pn339","pn414","pn826","pn927","pn1067","pn1387","pn1662","pn1691","pn2495"],"creationTime":0,"user":"cscw","creator":"system"},"Computer Supported Collaborative Boredom":{"creationTime":1386525767679,"itemsUsedBy":["pn1351"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Computer Supported Collaborative Boredom"},"viral contagion":{"creationTime":1386523299678,"itemsUsedBy":["pn1763"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"viral contagion"},"smart city":{"creationTime":1386523079466,"itemsUsedBy":["pn1675","pn558","pn1333","pn286"],"creator":"Marilyn.McGee-Lennon@glasgow.ac.uk","user":"Marilyn.McGee-Lennon@glasgow.ac.uk","label":"smart city"},"Post-humanist Design":{"creationTime":1386523061309,"itemsUsedBy":["pn2368"],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"Post-humanist Design"},"Dynamic Visualization":{"creationTime":1386525614845,"itemsUsedBy":["pn337"],"creator":"aquigley@st-andrews.ac.uk","user":"aquigley@st-andrews.ac.uk","label":"Dynamic Visualization"},"Academia":{"creationTime":1386522737983,"itemsUsedBy":["pn1642","pn2225"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Academia"},"Play":{"creationTime":1386523303683,"itemsUsedBy":["pn2268","pn1354","pn883","pn443"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"Play"},"Dysfunctional Communities":{"creationTime":1386522110980,"itemsUsedBy":["pn1296"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"Dysfunctional Communities"},"Intimacy":{"creationTime":1386523077623,"itemsUsedBy":["pn941"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Intimacy"},"gameplay experience":{"creationTime":1386527516185,"itemsUsedBy":["pn683"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"gameplay experience"},"Navigation":{"creationTime":1386522905333,"itemsUsedBy":["pn2420","pn1796","pn250","pn1447"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Navigation"},"general awesome":{"creationTime":1386526166010,"itemsUsedBy":["pn389"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"general awesome"},"Mobile Spatial Input":{"creationTime":1386531918221,"itemsUsedBy":["pn425"],"creator":"rsodhi2@illinois.edu","user":"rsodhi2@illinois.edu","label":"Mobile Spatial Input"},"self-esteem":{"creationTime":1386524637792,"itemsUsedBy":["pn1238"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"self-esteem"},"play":{"creationTime":1386536695054,"itemsUsedBy":["pn791"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"play"},"Persuasive Design":{"creationTime":1386523656517,"itemsUsedBy":["pn761","pn121"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Persuasive Design"},"Gesture Recognition":{"creationTime":1386531629905,"itemsUsedBy":["pn428","pn2157"],"creator":"otmar.hilliges@inf.ethz.ch","user":"otmar.hilliges@inf.ethz.ch","label":"Gesture Recognition"},"User Experience":{"creationTime":1386527018873,"itemsUsedBy":[],"creator":"e.karapanos@gmail.com","user":"e.karapanos@gmail.com","label":"User Experience"},"activity recognition":{"creationTime":1386525138773,"itemsUsedBy":[],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"activity recognition"},"Computational Journalism":{"creationTime":1386523491669,"itemsUsedBy":["pn576"],"creator":"joonhwan@snu.ac.kr","user":"joonhwan@snu.ac.kr","label":"Computational Journalism"},"Semantic Web":{"creationTime":1386524892501,"itemsUsedBy":[],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"Semantic Web"},"Elderly":{"creationTime":1386526266908,"itemsUsedBy":[],"creator":"takagih@jp.ibm.com","user":"takagih@jp.ibm.com","label":"Elderly"},"Physical Fitness":{"creationTime":1386522977259,"itemsUsedBy":["pn2274","pn1290","pn1845","pn1684"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Physical Fitness"},"Feet":{"creationTime":1386540235541,"itemsUsedBy":["pn1936"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Feet"},"reviews":{"creationTime":1386524267872,"itemsUsedBy":["pn691"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"reviews"},"Gaze":{"creationTime":1386525265226,"itemsUsedBy":["pn235","pn734","pn495","pn718"],"creator":"dan@microsoft.com","user":"dan@microsoft.com","label":"Gaze"},"online content":{"creationTime":1386526001156,"itemsUsedBy":["pn255"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"online content"},"individual differences":{"creationTime":1386530080403,"itemsUsedBy":["pn1015"],"creator":"judy.kay@gmail.com","user":"judy.kay@gmail.com","label":"individual differences"},"Digital Arts":{"creationTime":1386528176367,"itemsUsedBy":["pn1099"],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Digital Arts"},"Biometrics":{"creationTime":1386522238345,"itemsUsedBy":["pn521","pn490","pn420","pn2090"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"Biometrics"},"Wearable":{"creationTime":1386522061350,"itemsUsedBy":[],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"Wearable"},"HCI in Economic Life":{"creationTime":1386523081752,"itemsUsedBy":["pn2193","pn602"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"HCI in Economic Life"},"low income":{"creationTime":1386524594016,"itemsUsedBy":["pn905","pn119"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"low income"},"Stereoscopic":{"creationTime":1386522962889,"itemsUsedBy":["pn1262"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Stereoscopic"},"slow design":{"creationTime":1386522828949,"itemsUsedBy":["pn1241"],"creator":"mulderi@acm.org","user":"mulderi@acm.org","label":"slow design"},"Footsie":{"creationTime":1386525698886,"itemsUsedBy":["pn371"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"Footsie"},"Pen and Tactile Input":{"label":"Pen and Tactile Input","itemsUsedBy":["pn108","pn134","pn264","pn442","pn462","pn463","pn464","pn465","pn583","pn619","pn644","pn974","pn988","pn1129","pn1162","pn1222","pn1329","pn1370","pn1385","pn1513","pn1526","pn1530","pn1578","pn1635","pn1657","pn1749","pn1756","pn1992","pn2022","pn2101","pn2166","pn2187","pn2217","pn2363","pn2387","pn2392","pn2451","pn2497","pn2544","pn228"],"creationTime":0,"user":"cscw","creator":"system"},"Engagement":{"creationTime":1386522156955,"itemsUsedBy":["pn2417"],"creator":"fatchanceyouregettingmyemail@gmail.com","user":"fatchanceyouregettingmyemail@gmail.com","label":"Engagement"},"mobile instant messaging":{"creationTime":1386522402782,"itemsUsedBy":["pn180"],"creator":"gabriela.avram@gmail.com","user":"gabriela.avram@gmail.com","label":"mobile instant messaging"},"Menus":{"creationTime":1386522588462,"itemsUsedBy":[],"creator":"giulio.jacucci@hiit.fi","user":"giulio.jacucci@hiit.fi","label":"Menus"},"bias":{"creationTime":1386524212686,"itemsUsedBy":[],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"bias"},"sensory ethnography":{"creationTime":1386526282469,"itemsUsedBy":["to136"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"sensory ethnography"},"New Prototyping Methods":{"creationTime":1386523664307,"itemsUsedBy":["pn1262"],"creator":"scott.davidoff@jpl.nasa.gov","user":"scott.davidoff@jpl.nasa.gov","label":"New Prototyping Methods"},"Time Management":{"creationTime":1386527454832,"itemsUsedBy":["pn1773"],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Time Management"},"social media addiction":{"creationTime":1386525348439,"itemsUsedBy":["pn219"],"creator":"dgergle@northwestern.edu","user":"dgergle@northwestern.edu","label":"social media addiction"},"Touch input":{"creationTime":1386531829685,"itemsUsedBy":[],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Touch input"},"Tactile and Haptic UIs":{"label":"Tactile and Haptic UIs","itemsUsedBy":["pn128","pn130","pn196","pn233","pn360","pn426","pn438","pn495","pn564","pn634","pn730","pn775","pn835","pn849","pn901","pn962","pn995","pn1117","pn1135","pn1186","pn1263","pn1373","pn1404","pn1430","pn1433","pn1479","pn1526","pn1585","pn1604","pn1635","pn1657","pn1752","pn1866","pn1882","pn1943","pn2037","pn2054","pn2081","pn2101","pn2149","pn2170","pn2187","pn2217","pn2218","pn2392","pn2420","pn2497","pn2508","pn2517","pn2544","pn2548","pn1199","pn2277"],"creationTime":0,"user":"cscw","creator":"system"},"productivity":{"creationTime":1386524276928,"itemsUsedBy":["pn1351"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"productivity"},"Performance Metrics":{"label":"Performance Metrics","itemsUsedBy":["pn101","pn243","pn264","pn270","pn347","pn360","pn392","pn420","pn619","pn644","pn648","pn718","pn962","pn980","pn1024","pn1227","pn1289","pn1310","pn1357","pn1419","pn1494","pn1512","pn1531","pn1537","pn1568","pn1674","pn2000","pn2104","pn2118","pn2155","pn2185","pn2187","pn2217","pn2330","pn2339","pn2491","pn2493","pn2494","pn2548"],"creationTime":0,"user":"cscw","creator":"system"},"Elders":{"creationTime":1386522833289,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Elders"},"make":{"creationTime":1386522297454,"itemsUsedBy":["pn1904","pn2011","pn1428","pn1682"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"make"},"Child Labor":{"creationTime":1386523134443,"itemsUsedBy":["pn1448"],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"Child Labor"},"Life changes":{"creationTime":1386523123908,"itemsUsedBy":["pn590"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"Life changes"},"Multi-touch":{"creationTime":1386532251679,"itemsUsedBy":["pn1222","pn113","pn1046"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"Multi-touch"},"food":{"creationTime":1386521963024,"itemsUsedBy":[],"creator":"elainemayhuang@gmail.com","user":"elainemayhuang@gmail.com","label":"food"},"authentication":{"creationTime":1386528753001,"itemsUsedBy":["pn1097"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"authentication"},"Augmented Reality and Projection":{"label":"Augmented Reality and Projection","itemsUsedBy":["pn153","pn162","pn172","pn185","pn311","pn334","pn452","pn571","pn606","pn616","pn621","pn670","pn672","pn728","pn849","pn888","pn895","pn916","pn1016","pn1372","pn1403","pn1438","pn1620","pn1730","pn1784","pn1792","pn1796","pn1812","pn1846","pn1912","pn1950","pn1966","pn2152","pn2168","pn2260","pn2336","pn2412","pn2542","pn1958"],"creationTime":0,"user":"cscw","creator":"system"},"digital fabrication":{"creationTime":1386522277371,"itemsUsedBy":["pn1904","pn736","pn297"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"digital fabrication"},"health care":{"creationTime":1386526531757,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"health care"},"Behavior Modification":{"creationTime":1386525093276,"itemsUsedBy":["pn219"],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"Behavior Modification"},"events":{"creationTime":1386521758076,"itemsUsedBy":["pn653"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"events"},"Computer vision":{"creationTime":1386532404126,"itemsUsedBy":["pn2441"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Computer vision"},"Software architecture and engineering":{"label":"Software architecture and engineering","itemsUsedBy":["pn115","pn231","pn239","pn454","pn457","pn663","pn694","pn767","pn774","pn788","pn808","pn885","pn983","pn1162","pn1179","pn1187","pn1211","pn1308","pn1321","pn1368","pn1449","pn1489","pn1496","pn1637","pn1735","pn1816","pn1824","pn1833","pn1905","pn1906","pn2075","pn2184","pn2299","pn2416","pn2433","pn2450","pn2504","pn313"],"creationTime":0,"user":"cscw","creator":"system"},"document managment":{"creationTime":1386523110857,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"document managment"},"touch input":{"creationTime":1386523957403,"itemsUsedBy":[],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"touch input"},"Kinecting People":{"creationTime":1386523837336,"itemsUsedBy":["pn601","pn139","pn420"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Kinecting People"},"Tasks and Plans":{"creationTime":1386536981939,"itemsUsedBy":["to137","pn2105"],"creator":"dabbish@cmu.edu","user":"dabbish@cmu.edu","label":"Tasks and Plans"},"Mobile UI":{"creationTime":1386523807659,"itemsUsedBy":["pn1057"],"creator":"jws@microsoft.com","user":"jws@microsoft.com","label":"Mobile UI"},"life logging":{"creationTime":1386524571611,"itemsUsedBy":["pn493"],"creator":"asellen@microsoft.com","user":"asellen@microsoft.com","label":"life logging"},"full body interaction":{"creationTime":1386531703890,"itemsUsedBy":["pn1936","pn142"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"full body interaction"},"activity tracking":{"creationTime":1386524546220,"itemsUsedBy":["pn493","pn876"],"creator":"asellen@microsoft.com","user":"asellen@microsoft.com","label":"activity tracking"},"Creativity Support Tools":{"label":"Creativity Support Tools","itemsUsedBy":["pn132","pn133","pn228","pn297","pn342","pn363","pn388","pn411","pn482","pn487","pn541","pn547","pn563","pn614","pn662","pn669","pn713","pn747","pn774","pn801","pn810","pn811","pn854","pn872","pn894","pn949","pn955","pn971","pn992","pn1000","pn1021","pn1139","pn1168","pn1178","pn1185","pn1215","pn1357","pn1363","pn1385","pn1393","pn1403","pn1421","pn1428","pn1443","pn1452","pn1481","pn1510","pn1520","pn1523","pn1536","pn1542","pn1543","pn1602","pn1639","pn1673","pn1685","pn1687","pn1706","pn1710","pn1723","pn1755","pn1827","pn1879","pn1913","pn1935","pn1992","pn2004","pn2014","pn2097","pn2208","pn2268","pn2303","pn2323","pn2341","pn2343","pn2451","pn1709","pn2235","pn1264"],"creationTime":0,"user":"cscw","creator":"system"},"Process Improvement":{"label":"Process Improvement","itemsUsedBy":["pn243","pn392","pn471","pn550","pn663","pn963","pn1018","pn1191","pn1243","pn1260","pn1573","pn1824","pn1907","pn1913","pn2116","pn2206","pn2241","pn2292","pn2353","pn2435","pn2450","pn2459","pn2499","pn2544"],"creationTime":0,"user":"cscw","creator":"system"},"fNIRS":{"creationTime":1386525487153,"itemsUsedBy":["pn183"],"creator":"erin@cs.drexel.edu","user":"erin@cs.drexel.edu","label":"fNIRS"},"fabrication":{"creationTime":1386525023847,"itemsUsedBy":["pn1911","pn1081","pn2029"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"fabrication"},"diabetes":{"creationTime":1386522726910,"itemsUsedBy":["pn2074","pn2368"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"diabetes"},"Located accountabilities in design":{"creationTime":1386523112422,"itemsUsedBy":["pn2220"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Located accountabilities in design"},"inquiry learning":{"creationTime":1386523398086,"itemsUsedBy":["pn1817","pn1182"],"creator":"aeo@andrew.cmu.edu","user":"aeo@andrew.cmu.edu","label":"inquiry learning"},"Inference":{"creationTime":1386531952570,"itemsUsedBy":["pn583"],"creator":"yangli@acm.org","user":"yangli@acm.org","label":"Inference"},"Design requirements":{"creationTime":1386522853728,"itemsUsedBy":["pn887"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Design requirements"},"Software Engineering":{"creationTime":1386521703752,"itemsUsedBy":["pn2103","pn2096"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Software Engineering"},"banking":{"creationTime":1386525059226,"itemsUsedBy":["pn119"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"banking"},"Branding":{"label":"Branding","itemsUsedBy":["pn1364","pn1450","pn2408"],"creationTime":0,"user":"cscw","creator":"system"},"eye tracking":{"creationTime":1386522597533,"itemsUsedBy":["pn2560","pn431","pn951","pn950","pn750","pn405","pn626"],"creator":"D.StantonFraser@bath.ac.uk","user":"D.StantonFraser@bath.ac.uk","label":"eye tracking"},"persuasive":{"creationTime":1386522941016,"itemsUsedBy":["pn761"],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"persuasive"},"Back of Device Interaction":{"creationTime":1386521663268,"itemsUsedBy":[],"creator":"alexander.de.luca@ifi.lmu.de","user":"alexander.de.luca@ifi.lmu.de","label":"Back of Device Interaction"},"Emergency Response":{"creationTime":1386521720206,"itemsUsedBy":["pn286","pn1014","pn1454","pn1281"],"creator":"emailaddress","user":"emailaddress","label":"Emergency Response"},"new directions for hci":{"creationTime":1386525646731,"itemsUsedBy":["pn838"],"creator":"asellen@microsoft.com","user":"asellen@microsoft.com","label":"new directions for hci"},"user experience":{"label":"user experience","itemsUsedBy":["to102","to105","to106","to107","to108","to120","to128","to131","to136","pn320","pn683","pn319"],"creationTime":0,"user":"cscw","creator":"system"},"End-user Programming":{"label":"End-user Programming","itemsUsedBy":["pn207","pn392","pn455","pn637","pn662","pn663","pn727","pn762","pn808","pn949","pn1211","pn1287","pn1552","pn1566","pn1839","pn1917","pn2058","pn2082","pn2087","pn2091","pn2170","pn2323","pn2379","pn2504","pn2522","pn2441"],"creationTime":0,"user":"cscw","creator":"system"},"information visualization":{"creationTime":1386524444027,"itemsUsedBy":["to126"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"information visualization"},"cci":{"label":"cci","itemsUsedBy":[],"creationTime":0,"user":"cscw","creator":"system"},"organization":{"creationTime":1386524122827,"itemsUsedBy":["pn405"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"organization"},"research thorugh design":{"creationTime":1386522939140,"itemsUsedBy":[],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"research thorugh design"},"user modelling":{"creationTime":1386522188783,"itemsUsedBy":["pn2119","pn1293"],"creator":"david.kirk@ncl.ac.uk","user":"david.kirk@ncl.ac.uk","label":"user modelling"},"Visualization":{"label":"Visualization","itemsUsedBy":["pn115","pn132","pn133","pn135","pn206","pn220","pn221","pn269","pn287","pn330","pn342","pn346","pn369","pn377","pn382","pn392","pn398","pn430","pn435","pn437","pn469","pn474","pn489","pn500","pn528","pn543","pn548","pn551","pn561","pn606","pn613","pn640","pn646","pn655","pn667","pn696","pn701","pn797","pn798","pn801","pn843","pn845","pn853","pn857","pn861","pn863","pn865","pn909","pn926","pn987","pn991","pn1000","pn1015","pn1021","pn1024","pn1033","pn1052","pn1082","pn1086","pn1093","pn1100","pn1118","pn1119","pn1150","pn1154","pn1197","pn1233","pn1316","pn1322","pn1335","pn1342","pn1361","pn1369","pn1403","pn1404","pn1409","pn1418","pn1423","pn1435","pn1446","pn1447","pn1456","pn1460","pn1464","pn1484","pn1494","pn1503","pn1516","pn1558","pn1561","pn1574","pn1723","pn1778","pn1783","pn1784","pn1813","pn1820","pn1825","pn1848","pn1853","pn1875","pn1879","pn1884","pn1892","pn1906","pn1937","pn1942","pn1945","pn1973","pn1986","pn2000","pn2019","pn2027","pn2047","pn2052","pn2061","pn2075","pn2089","pn2134","pn2177","pn2197","pn2242","pn2264","pn2310","pn2340","pn2345","pn2389","pn2392","pn2416","pn2447","pn2457","pn2276","to117","pn1360"],"creationTime":0,"user":"cscw","creator":"system"},"Surveys":{"creationTime":1386522918235,"itemsUsedBy":["pn2489"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"Surveys"},"city point of view":{"creationTime":1386521917694,"itemsUsedBy":["pn2401"],"creator":"jacovi@il.ibm.com","user":"jacovi@il.ibm.com","label":"city point of view"},"money":{"creationTime":1386522411383,"itemsUsedBy":["pn119","pn186"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"money"},"entreprise communities":{"creationTime":1386522944850,"itemsUsedBy":["pn1341"],"creator":"myriam.lewkowicz@utt.fr","user":"myriam.lewkowicz@utt.fr","label":"entreprise communities"},"reflection provocation":{"creationTime":1386523231277,"itemsUsedBy":["pn1949"],"creator":"sharrison@vt.edu","user":"sharrison@vt.edu","label":"reflection provocation"},"Designing With People":{"creationTime":1386523317099,"itemsUsedBy":["pn2220"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Designing With People"},"Risk management":{"creationTime":1386521873850,"itemsUsedBy":["pn191"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"Risk management"},"bimanual input":{"creationTime":1386525725202,"itemsUsedBy":["pn1635","pn730"],"creator":"forlines@alumni.cmu.edu","user":"forlines@alumni.cmu.edu","label":"bimanual input"},"Mobile Accessibility":{"creationTime":1386526666911,"itemsUsedBy":[],"creator":"tjvg@di.fc.ul.pt","user":"tjvg@di.fc.ul.pt","label":"Mobile Accessibility"},"self studies":{"creationTime":1386523754925,"itemsUsedBy":["pn1242"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"self studies"},"Exergame":{"creationTime":1386521715934,"itemsUsedBy":[],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Exergame"},"wearable":{"creationTime":1386532068928,"itemsUsedBy":[],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"wearable"},"BCI":{"creationTime":1386532112981,"itemsUsedBy":["pn1471","pn2031"],"creator":"j.d.hook@ncl.ac.uk","user":"j.d.hook@ncl.ac.uk","label":"BCI"},"visualization":{"creationTime":1386524267499,"itemsUsedBy":["to126"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"visualization"},"PIM":{"creationTime":1386523656024,"itemsUsedBy":["pn400"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"PIM"},"Getting Personal":{"creationTime":1386526428153,"itemsUsedBy":["pn493","pn785","pn400"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Getting Personal"},"visual perception":{"creationTime":1386524447288,"itemsUsedBy":["to126"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"visual perception"},"Universal (or Disability)  Access":{"label":"Universal (or Disability)  Access","itemsUsedBy":["pn128","pn129","pn145","pn373","pn564","pn600","pn631","pn634","pn685","pn807","pn817","pn908","pn1040","pn1076","pn1085","pn1116","pn1138","pn1142","pn1147","pn1233","pn1305","pn1373","pn1401","pn1505","pn1506","pn1547","pn1563","pn1671","pn1680","pn1708","pn1714","pn1777","pn1856","pn1905","pn1999","pn2007","pn2028","pn2070","pn2113","pn2133","pn2170","pn2178","pn2185","pn2295","pn2302","pn2304","pn2310","pn2338","pn2344","pn2385","pn2462","pn2481","pn2508","pn2511"],"creationTime":0,"user":"cscw","creator":"system"},"Robots":{"label":"Robots","itemsUsedBy":["pn313","pn532","pn563","pn586","pn595","pn610","pn710","pn870","pn875","pn1119","pn1167","pn1175","pn1227","pn1252","pn1261","pn1400","pn1420","pn1593","pn1619","pn1664","pn1722","pn1808","pn1858","pn1861","pn2016","pn2091","pn2178","pn2207","pn2280","pn2331","pn2357","pn2358","pn2384","pn2538"],"creationTime":0,"user":"cscw","creator":"system"},"google glass":{"creationTime":1386526887188,"itemsUsedBy":[],"creator":"maria.wolters@ed.ac.uk","user":"maria.wolters@ed.ac.uk","label":"google glass"},"I'm bored/board":{"creationTime":1386525739406,"itemsUsedBy":["pn1351"],"creator":"paul.marshall@ucl.ac.uk","user":"paul.marshall@ucl.ac.uk","label":"I'm bored/board"},"Gestural Interaction":{"creationTime":1386525534609,"itemsUsedBy":["pn1936","pn343","pn428","pn2022","pn2157"],"creator":"elm@purdue.edu","user":"elm@purdue.edu","label":"Gestural Interaction"},"input":{"creationTime":1386525153526,"itemsUsedBy":["to135","pn198","pn2449","pn2372","pn755","pn1783"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"input"},"Ethics":{"creationTime":1386522300928,"itemsUsedBy":[],"creator":"jantin@gmail.com","user":"jantin@gmail.com","label":"Ethics"},"Annotation":{"creationTime":1386522182872,"itemsUsedBy":["pn1375","pn340","pn1865"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Annotation"},"community structures":{"creationTime":1386523041637,"itemsUsedBy":["pn1296","pn602"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"community structures"},"MOOCs":{"creationTime":1386523269443,"itemsUsedBy":["pn1362"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"MOOCs"},"Multitouchy Feely":{"creationTime":1386526770298,"itemsUsedBy":["pn1092","pn426","pn386","pn420"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Multitouchy Feely"},"Qualitative":{"creationTime":1386525390024,"itemsUsedBy":["to107"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Qualitative"},"making practices":{"creationTime":1386522731091,"itemsUsedBy":["pn2011","pn1904","pn967","pn1428","pn1682"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"making practices"},"Awareness Support":{"creationTime":1386527460810,"itemsUsedBy":["pn1773"],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Awareness Support"},"gestures":{"creationTime":1386522788784,"itemsUsedBy":["pn2216","pn1651","pn1425","pn601","pn1722","pn138","pn898","pn847"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"gestures"},"(passive) Brain-Computer Interfaces":{"creationTime":1386525120337,"itemsUsedBy":["pn673","pn183","pn366","pn648","pn1471"],"creator":"dan@microsoft.com","user":"dan@microsoft.com","label":"(passive) Brain-Computer Interfaces"},"game":{"creationTime":1386522796792,"itemsUsedBy":["pn1183","pn941","pn2020","pn241","pn1758"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"game"},"telepresence":{"creationTime":1386523096388,"itemsUsedBy":["pn532","pn1199"],"creator":"com@psychology.nottingham.ac.uk","user":"com@psychology.nottingham.ac.uk","label":"telepresence"},"Head-Worn Displays":{"creationTime":1386536868501,"itemsUsedBy":["pn222"],"creator":"feiner@cs.columbia.edu","user":"feiner@cs.columbia.edu","label":"Head-Worn Displays"},"Social Computing and Social Navigation":{"label":"Social Computing and Social Navigation","itemsUsedBy":["pn101","pn131","pn141","pn181","pn195","pn211","pn218","pn273","pn275","pn356","pn357","pn394","pn429","pn447","pn454","pn458","pn473","pn518","pn566","pn572","pn611","pn612","pn631","pn633","pn656","pn663","pn674","pn679","pn693","pn695","pn701","pn707","pn713","pn716","pn722","pn725","pn731","pn749","pn766","pn767","pn774","pn784","pn789","pn791","pn810","pn837","pn842","pn858","pn860","pn871","pn907","pn910","pn923","pn932","pn941","pn975","pn979","pn1039","pn1043","pn1047","pn1049","pn1052","pn1122","pn1126","pn1151","pn1152","pn1161","pn1202","pn1204","pn1221","pn1240","pn1249","pn1254","pn1259","pn1284","pn1288","pn1310","pn1327","pn1346","pn1349","pn1356","pn1359","pn1374","pn1392","pn1394","pn1406","pn1409","pn1413","pn1416","pn1424","pn1440","pn1474","pn1478","pn1479","pn1481","pn1498","pn1499","pn1528","pn1557","pn1599","pn1630","pn1631","pn1686","pn1721","pn1751","pn1762","pn1782","pn1807","pn1815","pn1845","pn1849","pn1897","pn1922","pn1986","pn2002","pn2013","pn2032","pn2034","pn2064","pn2110","pn2125","pn2131","pn2164","pn2174","pn2219","pn2253","pn2276","pn2298","pn2305","pn2329","pn2332","pn2362","pn2367","pn2380","pn2390","pn2410","pn2417","pn2421","pn2427","pn2444","pn2460","pn2463","pn2465","pn2483","pn2504","pn2515","pn2516","pn2525","pn2540","pn1525","pn1675","pn245","pn1800"],"creationTime":0,"user":"cscw","creator":"system"},"Computer Support Collaborative Romance":{"creationTime":1386523303663,"itemsUsedBy":[],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Computer Support Collaborative Romance"},"E-Governmentt":{"creationTime":1386522507517,"itemsUsedBy":[],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"E-Governmentt"},"performativity":{"creationTime":1386523465399,"itemsUsedBy":["pn1949"],"creator":"sharrison@vt.edu","user":"sharrison@vt.edu","label":"performativity"},"Pervasive Health":{"creationTime":1386523251265,"itemsUsedBy":["pn2487"],"creator":"wilcox@cc.gatech.edu","user":"wilcox@cc.gatech.edu","label":"Pervasive Health"},"user performance":{"creationTime":1386524357843,"itemsUsedBy":["pn2119"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"user performance"},"Art":{"creationTime":1386523197866,"itemsUsedBy":[],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Art"},"(passive) BCI":{"creationTime":1386525334333,"itemsUsedBy":["pn366","pn648"],"creator":"erin@cs.drexel.edu","user":"erin@cs.drexel.edu","label":"(passive) BCI"},"Human Computation":{"creationTime":1386524104411,"itemsUsedBy":["pn1237","pn1161"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Human Computation"},"avatars":{"creationTime":1386523100974,"itemsUsedBy":["pn1727"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"avatars"},"interactive storytelling":{"creationTime":1386523066685,"itemsUsedBy":["pn1820","to102"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"interactive storytelling"},"claa":{"creationTime":1386523703063,"itemsUsedBy":[],"creator":"moher@uic.edu","user":"moher@uic.edu","label":"claa"},"Interactive Machine Learning":{"creationTime":1386523750156,"itemsUsedBy":["pn1485","pn650","pn1586"],"creator":"mzhou@us.ibm.com","user":"mzhou@us.ibm.com","label":"Interactive Machine Learning"},"Music":{"creationTime":1386523051840,"itemsUsedBy":["pn1183","pn1586","pn1569","pn541","to114","pn547","pn1452","pn1834"],"creator":"mulderi@acm.org","user":"mulderi@acm.org","label":"Music"},"HCI and personal finance":{"creationTime":1386524625663,"itemsUsedBy":["pn119"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"HCI and personal finance"},"Machine Aesthetics":{"creationTime":1386523063584,"itemsUsedBy":[],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Machine Aesthetics"},"micro work tasks":{"creationTime":1386522302151,"itemsUsedBy":["pn263"],"creator":"gabriela.avram@gmail.com","user":"gabriela.avram@gmail.com","label":"micro work tasks"},"exertion interfaces":{"creationTime":1386521776382,"itemsUsedBy":["pn2277","pn1709","pn1521"],"creator":"gutwin@cs.usask.ca","user":"gutwin@cs.usask.ca","label":"exertion interfaces"},"social impact":{"creationTime":1386521356335,"itemsUsedBy":["pn1330","pn763","pn1264"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"social impact"},"crowd":{"creationTime":1386522597869,"itemsUsedBy":["pn810"],"creator":"wendyju@stanford.edu","user":"wendyju@stanford.edu","label":"crowd"},"Entertainment":{"label":"Entertainment","itemsUsedBy":["pn101","pn120","pn121","pn122","pn129","pn130","pn131","pn139","pn241","pn293","pn334","pn347","pn412","pn429","pn485","pn513","pn534","pn536","pn547","pn556","pn582","pn633","pn662","pn663","pn683","pn696","pn703","pn716","pn737","pn774","pn778","pn791","pn804","pn809","pn819","pn832","pn878","pn907","pn969","pn978","pn981","pn1016","pn1033","pn1034","pn1047","pn1069","pn1083","pn1099","pn1120","pn1167","pn1183","pn1218","pn1263","pn1275","pn1352","pn1386","pn1389","pn1393","pn1403","pn1445","pn1457","pn1458","pn1476","pn1487","pn1504","pn1518","pn1519","pn1523","pn1534","pn1536","pn1537","pn1568","pn1570","pn1575","pn1603","pn1620","pn1623","pn1632","pn1640","pn1675","pn1685","pn1713","pn1730","pn1741","pn1758","pn1765","pn1774","pn1787","pn1792","pn1815","pn1819","pn1838","pn1894","pn1901","pn1912","pn1934","pn1935","pn1938","pn1940","pn1987","pn1993","pn2014","pn2075","pn2084","pn2100","pn2108","pn2125","pn2151","pn2185","pn2194","pn2195","pn2199","pn2202","pn2223","pn2224","pn2264","pn2277","pn2297","pn2305","pn2328","pn2337","pn2408","pn2435","pn2504","pn2508"],"creationTime":0,"user":"cscw","creator":"system"},"Industrial Design":{"label":"Industrial Design","itemsUsedBy":["pn103","pn184","pn342","pn632","pn682","pn849","pn971","pn986","pn1442","pn2178","pn2180","pn2187","pn2292","pn2497","pn2016"],"creationTime":0,"user":"cscw","creator":"system"},"twitter":{"creationTime":1386523195301,"itemsUsedBy":[],"creator":"mona@cs.umd.edu","user":"mona@cs.umd.edu","label":"twitter"},"peer support":{"creationTime":1386521260154,"itemsUsedBy":["pn802","pn2074"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"peer support"},"Emergency response":{"creationTime":1386521880638,"itemsUsedBy":[],"creator":"emailaddress","user":"emailaddress","label":"Emergency response"},"Accessibility":{"creationTime":1386523686234,"itemsUsedBy":[],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Accessibility"},"Dogs":{"creationTime":1386522920411,"itemsUsedBy":["pn2368"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Dogs"},"Datasets":{"creationTime":1386527208141,"itemsUsedBy":["pn2027"],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Datasets"},"community displays":{"creationTime":1386523926057,"itemsUsedBy":["pn166"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"community displays"},"Health sensing":{"creationTime":1386524129820,"itemsUsedBy":["pn1426"],"creator":"jws@microsoft.com","user":"jws@microsoft.com","label":"Health sensing"},"Smell":{"creationTime":1386522927252,"itemsUsedBy":["pn320","pn728"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Smell"},"bulletin boards":{"creationTime":1386523913178,"itemsUsedBy":["pn166"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"bulletin boards"},"interaction science":{"creationTime":1386524217521,"itemsUsedBy":["pn750","pn626","pn1071"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"interaction science"},"Remote Interaction":{"creationTime":1386522348070,"itemsUsedBy":["pn1199","pn279"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Remote Interaction"},"Research on Pinterest":{"creationTime":1386522647544,"itemsUsedBy":["pn1710"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Research on Pinterest"},"Human-robot interaction":{"creationTime":1386522782968,"itemsUsedBy":["pn1252","pn1722"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Human-robot interaction"},"Multilingual Interfaces":{"creationTime":1386524000297,"itemsUsedBy":["pn1203"],"creator":"eadar@mit.edu","user":"eadar@mit.edu","label":"Multilingual Interfaces"},"warnings":{"creationTime":1386526016890,"itemsUsedBy":["pn191","pn1811"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"warnings"},"Auditory I/O and Sound in the UI":{"label":"Auditory I/O and Sound in the UI","itemsUsedBy":["pn187","pn206","pn233","pn237","pn248","pn276","pn362","pn395","pn423","pn529","pn538","pn651","pn673","pn850","pn998","pn1075","pn1121","pn1193","pn1263","pn1360","pn1457","pn1475","pn1536","pn1586","pn1604","pn1856","pn1994","pn2155","pn2295","pn2495","pn2499","pn896"],"creationTime":0,"user":"cscw","creator":"system"},"is sustainability human centered?":{"creationTime":1386523068324,"itemsUsedBy":["pn1850"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"is sustainability human centered?"},"Telepresence":{"creationTime":1386522319884,"itemsUsedBy":["pn1958"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Telepresence"},"Facebook":{"creationTime":1386522711690,"itemsUsedBy":["pn751","pn2159","pn763","pn2463","pn590","pn2483"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"Facebook"},"innovation":{"creationTime":1386523481903,"itemsUsedBy":["pn2208"],"creator":"antonella.deangeli@disi.unitn.it","user":"antonella.deangeli@disi.unitn.it","label":"innovation"},"hyperlocal":{"creationTime":1386522121659,"itemsUsedBy":["pn1954"],"creator":"gabriela.avram@gmail.com","user":"gabriela.avram@gmail.com","label":"hyperlocal"},"Multimedia UIs":{"label":"Multimedia UIs","itemsUsedBy":["pn147","pn224","pn305","pn334","pn421","pn457","pn595","pn695","pn796","pn797","pn798","pn888","pn894","pn958","pn998","pn1072","pn1138","pn1157","pn1176","pn1191","pn1194","pn1201","pn1263","pn1334","pn1339","pn1352","pn1558","pn1568","pn1574","pn1685","pn1691","pn1743","pn1787","pn1797","pn1810","pn1872","pn1905","pn1927","pn1958","pn1990","pn2155","pn2175","pn2194","pn2199","pn2223","pn2291","pn2341","pn2383","pn2460","pn2508","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"participation":{"creationTime":1386522573418,"itemsUsedBy":["pn1918"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"participation"},"geo tagging analytics":{"creationTime":1386521900965,"itemsUsedBy":["pn2401"],"creator":"jacovi@il.ibm.com","user":"jacovi@il.ibm.com","label":"geo tagging analytics"},"Health Information Management":{"creationTime":1386523746598,"itemsUsedBy":["pn1298","pn2214"],"creator":"mentis@umbc.edu","user":"mentis@umbc.edu","label":"Health Information Management"},"Fitts's Law":{"creationTime":1386521986563,"itemsUsedBy":["pn737","pn272","pn1916","pn750"],"creator":"rcm@mit.edu","user":"rcm@mit.edu","label":"Fitts's Law"},"Touchy":{"creationTime":1386525383193,"itemsUsedBy":["pn1092","pn386"],"creator":"dgergle@northwestern.edu","user":"dgergle@northwestern.edu","label":"Touchy"},"Personalization":{"creationTime":1386524029956,"itemsUsedBy":["pn785","pn255","pn400","pn1398","pn1776"],"creator":"sameer.patil@hiit.fi","user":"sameer.patil@hiit.fi","label":"Personalization"},"User-Centered Design / Human-Centered Design":{"label":"User-Centered Design / Human-Centered Design","itemsUsedBy":["pn105","pn110","pn131","pn151","pn157","pn168","pn178","pn184","pn196","pn202","pn213","pn229","pn231","pn234","pn269","pn278","pn342","pn348","pn357","pn376","pn392","pn413","pn421","pn427","pn430","pn441","pn448","pn457","pn482","pn511","pn513","pn522","pn538","pn546","pn550","pn569","pn574","pn575","pn576","pn600","pn602","pn609","pn617","pn624","pn632","pn634","pn642","pn645","pn647","pn652","pn657","pn661","pn669","pn687","pn695","pn704","pn735","pn741","pn774","pn799","pn801","pn807","pn811","pn813","pn815","pn816","pn820","pn826","pn846","pn852","pn853","pn866","pn875","pn886","pn887","pn888","pn889","pn891","pn895","pn901","pn903","pn911","pn912","pn913","pn926","pn927","pn929","pn935","pn942","pn960","pn991","pn996","pn997","pn998","pn1001","pn1037","pn1040","pn1044","pn1063","pn1082","pn1088","pn1092","pn1094","pn1097","pn1104","pn1108","pn1112","pn1116","pn1125","pn1128","pn1130","pn1134","pn1143","pn1145","pn1180","pn1184","pn1191","pn1195","pn1197","pn1208","pn1224","pn1240","pn1248","pn1265","pn1268","pn1274","pn1291","pn1309","pn1314","pn1322","pn1323","pn1324","pn1325","pn1328","pn1342","pn1380","pn1381","pn1383","pn1387","pn1401","pn1415","pn1417","pn1420","pn1442","pn1445","pn1450","pn1463","pn1475","pn1479","pn1488","pn1494","pn1504","pn1507","pn1511","pn1542","pn1546","pn1551","pn1556","pn1563","pn1568","pn1601","pn1606","pn1618","pn1628","pn1629","pn1633","pn1637","pn1641","pn1646","pn1652","pn1657","pn1673","pn1676","pn1691","pn1695","pn1700","pn1701","pn1706","pn1716","pn1720","pn1740","pn1755","pn1757","pn1758","pn1787","pn1790","pn1794","pn1808","pn1824","pn1827","pn1831","pn1842","pn1846","pn1859","pn1873","pn1874","pn1880","pn1896","pn1897","pn1919","pn1940","pn1960","pn1965","pn1967","pn1972","pn1977","pn1987","pn1995","pn2002","pn2003","pn2004","pn2014","pn2016","pn2017","pn2019","pn2026","pn2028","pn2031","pn2040","pn2044","pn2047","pn2059","pn2074","pn2075","pn2080","pn2082","pn2089","pn2106","pn2133","pn2138","pn2141","pn2143","pn2146","pn2159","pn2160","pn2165","pn2176","pn2178","pn2182","pn2185","pn2186","pn2192","pn2196","pn2204","pn2217","pn2234","pn2238","pn2240","pn2247","pn2257","pn2270","pn2291","pn2292","pn2296","pn2299","pn2308","pn2311","pn2316","pn2320","pn2331","pn2335","pn2348","pn2354","pn2368","pn2376","pn2381","pn2383","pn2384","pn2386","pn2416","pn2420","pn2426","pn2450","pn2453","pn2455","pn2468","pn2471","pn2476","pn2497","pn2500","pn2508","pn2515","pn2516","pn2519","pn2528","pn2538","pn2542"],"creationTime":0,"user":"cscw","creator":"system"},"Camera-based UIs":{"label":"Camera-based UIs","itemsUsedBy":["pn144","pn209","pn235","pn347","pn436","pn441","pn495","pn510","pn521","pn535","pn564","pn571","pn587","pn649","pn705","pn745","pn830","pn849","pn927","pn951","pn974","pn995","pn1050","pn1109","pn1179","pn1206","pn1212","pn1279","pn1345","pn1372","pn1387","pn1403","pn1494","pn1595","pn1616","pn1618","pn1691","pn1698","pn1744","pn1772","pn1873","pn1919","pn1932","pn2022","pn2126","pn2195","pn2282","pn2369","pn2516","pn2544"],"creationTime":0,"user":"cscw","creator":"system"},"Collective action":{"creationTime":1386521899244,"itemsUsedBy":["pn763"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Collective action"},"place-based identity":{"creationTime":1386524604918,"itemsUsedBy":["to122"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"place-based identity"},"ICTD":{"creationTime":1386521831347,"itemsUsedBy":["pn2226","pn1475","pn248","pn2134","pn905","pn1978","pn1732"],"creator":"jonfroehlich@gmail.com","user":"jonfroehlich@gmail.com","label":"ICTD"},"gesture elicitation":{"creationTime":1386524171596,"itemsUsedBy":["pn799"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"gesture elicitation"},"interactive surfaces":{"creationTime":1386523244235,"itemsUsedBy":["pn2216","pn1092","pn426"],"creator":"fernaeus@kth.se","user":"fernaeus@kth.se","label":"interactive surfaces"},"Pain":{"creationTime":1386523567983,"itemsUsedBy":["pn1446","pn1684"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Pain"},"Food Messaging":{"creationTime":1386523152124,"itemsUsedBy":[],"creator":"emailaddress","user":"emailaddress","label":"Food Messaging"},"Gesture":{"creationTime":1386525240148,"itemsUsedBy":[],"creator":"dan@microsoft.com","user":"dan@microsoft.com","label":"Gesture"},"sensor fusion":{"creationTime":1386525922742,"itemsUsedBy":["pn730"],"creator":"benko@microsoft.com","user":"benko@microsoft.com","label":"sensor fusion"},"constructivist":{"creationTime":1386527057403,"itemsUsedBy":["to114"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"constructivist"},"Reputation":{"creationTime":1386523502776,"itemsUsedBy":["pn924"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Reputation"},"Multi-Device User Interfaces":{"creationTime":1386524525541,"itemsUsedBy":["pn205","pn1776","pn1200","pn1336","pn142"],"creator":"fabio.paterno@isti.cnr.it","user":"fabio.paterno@isti.cnr.it","label":"Multi-Device User Interfaces"},"HCI and Journalism":{"creationTime":1386523673148,"itemsUsedBy":["pn1460"],"creator":"mzhou@us.ibm.com","user":"mzhou@us.ibm.com","label":"HCI and Journalism"},"Business Strategy":{"label":"Business Strategy","itemsUsedBy":["pn184","pn234","pn394","pn663","pn2186","pn2427","pn2266"],"creationTime":0,"user":"cscw","creator":"system"},"Museum experience":{"creationTime":1386526241003,"itemsUsedBy":["pn1704","pn1632"],"creator":"kgajos@eecs.harvard.edu","user":"kgajos@eecs.harvard.edu","label":"Museum experience"},"Information Visualization":{"creationTime":1386525221780,"itemsUsedBy":["pn2442","pn337","pn1911","pn1337","pn1472","pn966","pn845","pn796","pn164","pn2242"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Information Visualization"},"gatekeeping":{"creationTime":1386523386664,"itemsUsedBy":["pn1918","pn1014"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"gatekeeping"},"Musical intefaces":{"creationTime":1386523975023,"itemsUsedBy":[],"creator":"roudauta@gmail.com","user":"roudauta@gmail.com","label":"Musical intefaces"},"tools for learning":{"creationTime":1386523293523,"itemsUsedBy":["pn223","pn1623"],"creator":"aeo@andrew.cmu.edu","user":"aeo@andrew.cmu.edu","label":"tools for learning"},"tongue":{"creationTime":1386525333653,"itemsUsedBy":["pn208"],"creator":"forlines@alumni.cmu.edu","user":"forlines@alumni.cmu.edu","label":"tongue"},"repair":{"creationTime":1386522690922,"itemsUsedBy":["pn2011","pn643"],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"repair"},"History of CHI":{"creationTime":1386526190796,"itemsUsedBy":["pn164"],"creator":"kash@diku.dk","user":"kash@diku.dk","label":"History of CHI"},"communication":{"creationTime":1386523887183,"itemsUsedBy":["pn1727"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"communication"},"ephemera":{"creationTime":1386523512632,"itemsUsedBy":["pn419","pn590"],"creator":"dtatar@cs.vt.edu","user":"dtatar@cs.vt.edu","label":"ephemera"},"Design Theory":{"creationTime":1386522122658,"itemsUsedBy":[],"creator":"bilge@cs.wisc.edu","user":"bilge@cs.wisc.edu","label":"Design Theory"},"Art Installation":{"creationTime":1386523195882,"itemsUsedBy":[],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Art Installation"},"cause and effect":{"creationTime":1386525385203,"itemsUsedBy":["pn1417"],"creator":"paul.marshall@ucl.ac.uk","user":"paul.marshall@ucl.ac.uk","label":"cause and effect"},"in the wild":{"creationTime":1386527394253,"itemsUsedBy":["pn2150"],"creator":"dominicfurniss@gmail.com","user":"dominicfurniss@gmail.com","label":"in the wild"},"Crazy ideas":{"creationTime":1386523918032,"itemsUsedBy":["pn1179"],"creator":"jws@microsoft.com","user":"jws@microsoft.com","label":"Crazy ideas"},"mobile phone":{"creationTime":1386523094646,"itemsUsedBy":["pn1904","pn2525"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"mobile phone"},"CAPTCHAs":{"creationTime":1386521652050,"itemsUsedBy":["pn1976"],"creator":"egelman@cs.berkeley.edu","user":"egelman@cs.berkeley.edu","label":"CAPTCHAs"},"Media Space":{"creationTime":1386522767090,"itemsUsedBy":["pn279"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Media Space"},"Nutrition":{"creationTime":1386522014613,"itemsUsedBy":["pn2276"],"creator":"me@patrickgage.com","user":"me@patrickgage.com","label":"Nutrition"},"graphical passwords":{"creationTime":1386527924809,"itemsUsedBy":[],"creator":"wmoncur@dundee.ac.uk","user":"wmoncur@dundee.ac.uk","label":"graphical passwords"},"young children":{"creationTime":1386523060820,"itemsUsedBy":["pn1354"],"creator":"mona@cs.umd.edu","user":"mona@cs.umd.edu","label":"young children"},"design tools":{"creationTime":1386522385537,"itemsUsedBy":["pn1709","pn313"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"design tools"},"Presentation tool":{"creationTime":1386524359149,"itemsUsedBy":["pn1179","pn1587"],"creator":"xiangcao@acm.org","user":"xiangcao@acm.org","label":"Presentation tool"},"Concept Design":{"label":"Concept Design","itemsUsedBy":["pn110","pn141","pn178","pn229","pn230","pn260","pn394","pn589","pn663","pn695","pn758","pn880","pn900","pn917","pn971","pn992","pn994","pn1064","pn1176","pn1261","pn1274","pn1324","pn1479","pn1483","pn1568","pn1740","pn1746","pn1837","pn1949","pn1989","pn2056","pn2204","pn2206","pn2296","pn2412","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"information needs":{"creationTime":1386525131876,"itemsUsedBy":["pn1295","to129"],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"information needs"},"war and peace":{"creationTime":1386523870101,"itemsUsedBy":["pn1325"],"creator":"eva@ehornecker.de","user":"eva@ehornecker.de","label":"war and peace"},"gaze":{"creationTime":1386525571268,"itemsUsedBy":[],"creator":"bickmore@ccs.neu.edu","user":"bickmore@ccs.neu.edu","label":"gaze"},"Therapy":{"creationTime":1386523854192,"itemsUsedBy":["pn787"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Therapy"},"Underserved Communities":{"creationTime":1386523119457,"itemsUsedBy":["pn547"],"creator":"scott.davidoff@jpl.nasa.gov","user":"scott.davidoff@jpl.nasa.gov","label":"Underserved Communities"},"heritage":{"creationTime":1386522243019,"itemsUsedBy":["pn1978","pn1632","pn1704"],"creator":"daverandall2008@gmail.com","user":"daverandall2008@gmail.com","label":"heritage"},"Understanding Design":{"creationTime":1386523217090,"itemsUsedBy":["pn2129","pn2358","pn687"],"creator":"scott.davidoff@jpl.nasa.gov","user":"scott.davidoff@jpl.nasa.gov","label":"Understanding Design"},"movement interaction":{"creationTime":1386522645088,"itemsUsedBy":["pn1034","pn1579","pn1183"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"movement interaction"},"optimized keyboard layout":{"creationTime":1386525560161,"itemsUsedBy":["to118"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"optimized keyboard layout"},"Economics & HCI":{"creationTime":1386522222350,"itemsUsedBy":["pn2193","pn2266","pn602"],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Economics & HCI"},"Animals":{"creationTime":1386523051939,"itemsUsedBy":["pn2368"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Animals"},"Video Content / Communications":{"label":"Video Content / Communications","itemsUsedBy":["pn147","pn224","pn260","pn305","pn333","pn334","pn352","pn353","pn354","pn468","pn501","pn531","pn696","pn709","pn782","pn858","pn883","pn889","pn968","pn1060","pn1076","pn1139","pn1194","pn1350","pn1381","pn1558","pn1587","pn1623","pn1829","pn1958","pn1978","pn2124","pn2200","pn2268","pn2282","pn2283","pn2395","pn2472","pn1333","pn1032","pn796"],"creationTime":0,"user":"cscw","creator":"system"},"Keyboards":{"creationTime":1386531678450,"itemsUsedBy":["pn428","pn2157","pn2464","pn2454"],"creator":"otmar.hilliges@inf.ethz.ch","user":"otmar.hilliges@inf.ethz.ch","label":"Keyboards"},"Affective Communication":{"creationTime":1386522368392,"itemsUsedBy":["pn2054","pn2417"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"Affective Communication"},"body-based identification":{"creationTime":1386521878662,"itemsUsedBy":["pn521"],"creator":"rob.comber@ncl.ac.uk","user":"rob.comber@ncl.ac.uk","label":"body-based identification"},"Crowd-sourcing actions":{"creationTime":1386523769399,"itemsUsedBy":["pn1237","pn1421"],"creator":"mzhou@us.ibm.com","user":"mzhou@us.ibm.com","label":"Crowd-sourcing actions"},"implicit structure and organization":{"creationTime":1386522803265,"itemsUsedBy":["pn1642","pn1470","pn1123"],"creator":"dtatar@cs.vt.edu","user":"dtatar@cs.vt.edu","label":"implicit structure and organization"},"reputation management":{"creationTime":1386521901229,"itemsUsedBy":["pn924"],"creator":"myriam.lewkowicz@utt.fr","user":"myriam.lewkowicz@utt.fr","label":"reputation management"},"goals":{"creationTime":1386521396223,"itemsUsedBy":["pn1341","pn2560"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"goals"},"Audio AR":{"creationTime":1386525229523,"itemsUsedBy":["pn1193"],"creator":"dan@microsoft.com","user":"dan@microsoft.com","label":"Audio AR"},"Get Up! Technology for Physical Fitness":{"creationTime":1386523248109,"itemsUsedBy":[],"creator":"a.parker@neu.edu","user":"a.parker@neu.edu","label":"Get Up! Technology for Physical Fitness"},"social movement":{"creationTime":1386522968635,"itemsUsedBy":["pn763"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"social movement"},"Social Media and Habits":{"creationTime":1386525475471,"itemsUsedBy":["pn1036","pn219"],"creator":"dgergle@northwestern.edu","user":"dgergle@northwestern.edu","label":"Social Media and Habits"},"Human error":{"creationTime":1386528310446,"itemsUsedBy":["pn639","pn2560"],"creator":"david.geerts@soc.kuleuven.be","user":"david.geerts@soc.kuleuven.be","label":"Human error"},"Technology and Close Relationships":{"creationTime":1386523955834,"itemsUsedBy":["pn1238"],"creator":"dgergle@northwestern.edu","user":"dgergle@northwestern.edu","label":"Technology and Close Relationships"},"behavioural economics":{"creationTime":1386524245645,"itemsUsedBy":["pn2489"],"creator":"mc+frenzy@ecs.soton.ac.uk","user":"mc+frenzy@ecs.soton.ac.uk","label":"behavioural economics"},"Context-Aware Computing":{"label":"Context-Aware Computing","itemsUsedBy":["pn109","pn207","pn246","pn250","pn312","pn352","pn355","pn402","pn408","pn454","pn543","pn629","pn635","pn663","pn826","pn1050","pn1151","pn1152","pn1187","pn1214","pn1245","pn1317","pn1355","pn1426","pn1441","pn1479","pn1553","pn1603","pn1606","pn1638","pn1691","pn1740","pn1743","pn1747","pn1748","pn1830","pn1831","pn1887","pn1888","pn1899","pn1975","pn1980","pn2076","pn2080","pn2116","pn2164","pn2177","pn2182","pn2273","pn2288","pn2322","pn2396","pn2411","pn2458","pn2502","pn2503","pn2516","pn2525"],"creationTime":0,"user":"cscw","creator":"system"},"Agents and Intelligent Systems":{"label":"Agents and Intelligent Systems","itemsUsedBy":["pn207","pn340","pn398","pn480","pn569","pn595","pn650","pn695","pn762","pn806","pn840","pn870","pn909","pn985","pn1026","pn1159","pn1161","pn1162","pn1192","pn1232","pn1252","pn1342","pn1400","pn1408","pn1420","pn1467","pn1485","pn1514","pn1568","pn1593","pn1664","pn1696","pn1711","pn2012","pn2040","pn2046","pn2058","pn2063","pn2090","pn2174","pn2188","pn2199","pn2206","pn2267","pn2273","pn2299","pn2338","pn2339","pn2341","pn2423","pn2453","pn2507","pn1354"],"creationTime":0,"user":"cscw","creator":"system"},"Haptics":{"creationTime":1386522918513,"itemsUsedBy":["pn2420","pn1046","pn1583"],"creator":"carmster@gmail.com","user":"carmster@gmail.com","label":"Haptics"},"geocaching":{"creationTime":1386522905026,"itemsUsedBy":["pn1333"],"creator":"yardi@umich.edu","user":"yardi@umich.edu","label":"geocaching"},"procedural content":{"creationTime":1386523056650,"itemsUsedBy":["pn2046"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"procedural content"},"Twitter":{"creationTime":1386522430338,"itemsUsedBy":["pn1236","pn1255","pn1330","pn1347","pn1009","pn653","pn2284"],"creator":"jacovi@il.ibm.com","user":"jacovi@il.ibm.com","label":"Twitter"},"I'm board":{"creationTime":1386525432334,"itemsUsedBy":["pn166"],"creator":"paul.marshall@ucl.ac.uk","user":"paul.marshall@ucl.ac.uk","label":"I'm board"},"ontologies":{"creationTime":1386522590303,"itemsUsedBy":["pn2225"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"ontologies"},"Target Acquisition":{"creationTime":1386532142653,"itemsUsedBy":["pn264","pn756","pn2449","pn1901","pn755","pn2432"],"creator":"yangli@acm.org","user":"yangli@acm.org","label":"Target Acquisition"},"research through design":{"creationTime":1386522058813,"itemsUsedBy":["pn758","pn2048","pn999","pn2129","pn1442"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"research through design"},"Engineering":{"creationTime":1386523928400,"itemsUsedBy":["pn1222"],"creator":"jbigham@cmu.edu","user":"jbigham@cmu.edu","label":"Engineering"},"data management":{"creationTime":1386522967503,"itemsUsedBy":["pn590"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"data management"},"Social Network Sites":{"creationTime":1386521484254,"itemsUsedBy":["pn751","pn763","pn1009","pn245"],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Social Network Sites"},"Visual System Design / Visual Design":{"label":"Visual System Design / Visual Design","itemsUsedBy":["pn115","pn131","pn135","pn220","pn309","pn430","pn613","pn641","pn646","pn695","pn747","pn774","pn801","pn805","pn851","pn861","pn888","pn945","pn1000","pn1024","pn1038","pn1077","pn1082","pn1086","pn1195","pn1211","pn1314","pn1403","pn1446","pn1450","pn1494","pn1574","pn1625","pn1744","pn1778","pn1813","pn1846","pn1875","pn1879","pn2019","pn2062","pn2082","pn2089","pn2165","pn2187","pn2340","pn2350","pn2442"],"creationTime":0,"user":"cscw","creator":"system"},"Printed Electronics":{"creationTime":1386525982716,"itemsUsedBy":["pn1225","pn1081"],"creator":"steimle@media.mit.edu","user":"steimle@media.mit.edu","label":"Printed Electronics"},"Big data":{"creationTime":1386522715634,"itemsUsedBy":[],"creator":"nithyas@gmail.com","user":"nithyas@gmail.com","label":"Big data"},"Personal Informatics":{"creationTime":1386523633230,"itemsUsedBy":["pn2214","pn345","pn1351","pn493"],"creator":"corina@comp.lancs.ac.uk","user":"corina@comp.lancs.ac.uk","label":"Personal Informatics"},"Community Management":{"creationTime":1386522388290,"itemsUsedBy":["pn1642"],"creator":"emailaddress","user":"emailaddress","label":"Community Management"},"Design Fiction":{"creationTime":1386523228409,"itemsUsedBy":[],"creator":"ledantec@gatech.edu","user":"ledantec@gatech.edu","label":"Design Fiction"},"theories for HCI":{"creationTime":1386523952701,"itemsUsedBy":["pn838"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"theories for HCI"},"accessibility":{"creationTime":1386522807468,"itemsUsedBy":[],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"accessibility"},"email overload":{"creationTime":1386524652965,"itemsUsedBy":["pn345","pn1257"],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"email overload"},"engineering":{"label":"engineering","itemsUsedBy":["to131","to134","pn672"],"creationTime":0,"user":"cscw","creator":"system"},"Smartphones":{"creationTime":1386523539197,"itemsUsedBy":["pn286","pn641","pn263","pn1675","pn2399","pn2525"],"creator":"jacovi@il.ibm.com","user":"jacovi@il.ibm.com","label":"Smartphones"},"tabletop":{"creationTime":1386523224271,"itemsUsedBy":["pn2216","pn426","pn386","pn1092","to114"],"creator":"fernaeus@kth.se","user":"fernaeus@kth.se","label":"tabletop"},"Design Cards":{"creationTime":1386522419003,"itemsUsedBy":[],"creator":"ztoups@nmsu.edu","user":"ztoups@nmsu.edu","label":"Design Cards"},"visual analytics":{"creationTime":1386527990676,"itemsUsedBy":["pn2027"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"visual analytics"},"Information Spaces":{"creationTime":1386525094282,"itemsUsedBy":["pn2424"],"creator":"petra.isenberg@inria.fr","user":"petra.isenberg@inria.fr","label":"Information Spaces"},"multisensory interaction":{"creationTime":1386525799337,"itemsUsedBy":["pn728"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"multisensory interaction"},"information foraging":{"creationTime":1386523987273,"itemsUsedBy":["pn626"],"creator":"Brumby@cs.ucl.ac.uk","user":"Brumby@cs.ucl.ac.uk","label":"information foraging"},"Internationalization / Localization":{"label":"Internationalization / Localization","itemsUsedBy":["pn184","pn210","pn212","pn216","pn232","pn248","pn329","pn675","pn807","pn1028","pn1126","pn1140","pn1195","pn1347","pn1352","pn1512","pn2077","pn2125","pn2229","pn2344","pn2466","pn2528"],"creationTime":0,"user":"cscw","creator":"system"},"cycling":{"creationTime":1386525915012,"itemsUsedBy":["pn1796"],"creator":"davidmcgookin@gmail.com","user":"davidmcgookin@gmail.com","label":"cycling"},"reflective ethnography":{"creationTime":1386523040826,"itemsUsedBy":[],"creator":"silvia.lindtner@gmail.com","user":"silvia.lindtner@gmail.com","label":"reflective ethnography"},"College students":{"creationTime":1386522591660,"itemsUsedBy":["pn2153","pn2175"],"creator":"mmassimi@microsoft.com","user":"mmassimi@microsoft.com","label":"College students"},"tailoring":{"creationTime":1386525955700,"itemsUsedBy":["pn255"],"creator":"garyhsieh@gmail.com","user":"garyhsieh@gmail.com","label":"tailoring"},"Flavours":{"creationTime":1386527894734,"itemsUsedBy":["pn319"],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Flavours"},"Physical Therapy":{"creationTime":1386523244336,"itemsUsedBy":["pn2487","pn1684"],"creator":"wilcox@cc.gatech.edu","user":"wilcox@cc.gatech.edu","label":"Physical Therapy"},"Running":{"creationTime":1386523784971,"itemsUsedBy":["pn1845"],"creator":"jkientz@uw.edu","user":"jkientz@uw.edu","label":"Running"},"Augmented Reality":{"creationTime":1386525749769,"itemsUsedBy":["pn916","pn654"],"creator":"j.alexander@lancaster.ac.uk","user":"j.alexander@lancaster.ac.uk","label":"Augmented Reality"},"Tangible UIs":{"label":"Tangible UIs","itemsUsedBy":["pn310","pn313","pn371","pn397","pn423","pn451","pn478","pn529","pn616","pn617","pn634","pn742","pn794","pn851","pn901","pn943","pn973","pn1065","pn1077","pn1091","pn1108","pn1113","pn1176","pn1212","pn1225","pn1307","pn1385","pn1448","pn1493","pn1511","pn1522","pn1528","pn1531","pn1568","pn1630","pn1712","pn1752","pn1756","pn1866","pn1892","pn1905","pn1934","pn2022","pn2029","pn2041","pn2043","pn2087","pn2116","pn2165","pn2206","pn2216","pn2372","pn2466","pn2477","pn2493","pn2497","pn2517","pn2544","pn1186","pn1911","pn241","to114","pn1241"],"creationTime":0,"user":"cscw","creator":"system"},"On-Body Interfaces":{"creationTime":1386525339606,"itemsUsedBy":["pn1488","pn222","pn1471"],"creator":"steimle@media.mit.edu","user":"steimle@media.mit.edu","label":"On-Body Interfaces"},"notifications":{"creationTime":1386523486509,"itemsUsedBy":["pn641","pn1282"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"notifications"},"Literacy":{"creationTime":1386523208128,"itemsUsedBy":["pn443","pn1354","pn1820"],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"Literacy"},"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)":{"label":"Design Methods (Design Rationale, Claims Analysis, Scenarios, Storyboards)","itemsUsedBy":["pn118","pn168","pn230","pn232","pn239","pn269","pn392","pn421","pn430","pn457","pn513","pn543","pn558","pn586","pn634","pn663","pn676","pn687","pn747","pn758","pn805","pn842","pn853","pn886","pn888","pn917","pn926","pn978","pn992","pn999","pn1000","pn1028","pn1041","pn1064","pn1133","pn1138","pn1202","pn1207","pn1231","pn1265","pn1274","pn1291","pn1309","pn1315","pn1320","pn1328","pn1350","pn1379","pn1438","pn1440","pn1442","pn1463","pn1507","pn1517","pn1534","pn1556","pn1572","pn1576","pn1577","pn1605","pn1657","pn1673","pn1677","pn1701","pn1740","pn1746","pn1813","pn1816","pn1820","pn1824","pn1837","pn1841","pn1854","pn1866","pn1873","pn1904","pn1915","pn1926","pn1965","pn1994","pn2002","pn2004","pn2019","pn2028","pn2035","pn2040","pn2048","pn2050","pn2056","pn2070","pn2075","pn2082","pn2085","pn2100","pn2122","pn2165","pn2178","pn2180","pn2182","pn2186","pn2220","pn2229","pn2247","pn2289","pn2342","pn2348","pn2354","pn2359","pn2466","pn2473","pn2476","pn2486","pn887","pn1034","pn787"],"creationTime":0,"user":"cscw","creator":"system"},"Social Computing":{"creationTime":1386523573773,"itemsUsedBy":[],"creator":"lana@research.att.com","user":"lana@research.att.com","label":"Social Computing"},"natural language interface":{"creationTime":1386524084622,"itemsUsedBy":["to101"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"natural language interface"},"Boring":{"creationTime":1386527694343,"itemsUsedBy":["pn1103"],"creator":"john.vines@ncl.ac.uk","user":"john.vines@ncl.ac.uk","label":"Boring"},"heck frickin' yeah":{"creationTime":1386525385180,"itemsUsedBy":["pn728","pn1983","pn389","pn438","pn1675"],"creator":"forlines@alumni.cmu.edu","user":"forlines@alumni.cmu.edu","label":"heck frickin' yeah"},"emotion and user performance":{"creationTime":1386527688292,"itemsUsedBy":["pn639"],"creator":"elaw@mcs.le.ac.uk","user":"elaw@mcs.le.ac.uk","label":"emotion and user performance"},"Usability Research":{"label":"Usability Research","itemsUsedBy":["pn145","pn172","pn184","pn207","pn210","pn247","pn268","pn270","pn292","pn293","pn309","pn322","pn350","pn357","pn374","pn392","pn406","pn409","pn415","pn452","pn481","pn500","pn567","pn587","pn629","pn636","pn659","pn681","pn685","pn687","pn689","pn741","pn774","pn807","pn854","pn879","pn918","pn934","pn1025","pn1044","pn1053","pn1068","pn1079","pn1104","pn1145","pn1191","pn1195","pn1227","pn1300","pn1309","pn1310","pn1323","pn1339","pn1408","pn1431","pn1437","pn1450","pn1494","pn1511","pn1514","pn1538","pn1559","pn1568","pn1599","pn1634","pn1656","pn1668","pn1676","pn1691","pn1695","pn1732","pn1739","pn1743","pn1787","pn1797","pn1828","pn1831","pn1833","pn1846","pn1878","pn1886","pn1892","pn1908","pn1946","pn1965","pn1995","pn2012","pn2027","pn2053","pn2068","pn2089","pn2098","pn2120","pn2151","pn2155","pn2161","pn2169","pn2176","pn2196","pn2204","pn2217","pn2231","pn2234","pn2238","pn2247","pn2267","pn2275","pn2286","pn2316","pn2320","pn2329","pn2353","pn2360","pn2372","pn2376","pn2394","pn2400","pn2405","pn2416","pn2422","pn2444","pn2453","pn2456","pn2467","pn2481","pn2484","pn2493","pn2505","pn2525","pn806"],"creationTime":0,"user":"cscw","creator":"system"},"Foot Interaction":{"creationTime":1386525424446,"itemsUsedBy":["pn371"],"creator":"j.alexander@lancaster.ac.uk","user":"j.alexander@lancaster.ac.uk","label":"Foot Interaction"},"Socioeconomic status":{"creationTime":1386522862570,"itemsUsedBy":["pn704"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"Socioeconomic status"},"Evaluation methods":{"creationTime":1386522535040,"itemsUsedBy":["pn2330"],"creator":"aantle@sfu.ca","user":"aantle@sfu.ca","label":"Evaluation methods"},"Rehabilitation":{"creationTime":1386526298326,"itemsUsedBy":["pn2115","pn1171"],"creator":"tjvg@di.fc.ul.pt","user":"tjvg@di.fc.ul.pt","label":"Rehabilitation"},"sensemaking":{"creationTime":1386523363425,"itemsUsedBy":["pn1470"],"creator":"emilee@gmail.com","user":"emilee@gmail.com","label":"sensemaking"},"ICT":{"creationTime":1386524607771,"itemsUsedBy":[],"creator":"lorrie@acm.org","user":"lorrie@acm.org","label":"ICT"},"Whimsical":{"creationTime":1386521410780,"itemsUsedBy":[],"creator":"smunson@uw.edu","user":"smunson@uw.edu","label":"Whimsical"},"Graph Visualization":{"creationTime":1386526191699,"itemsUsedBy":["pn845"],"creator":"mtory@cs.uvic.ca","user":"mtory@cs.uvic.ca","label":"Graph Visualization"},"Wearables":{"creationTime":1386526491196,"itemsUsedBy":["pn714","pn739","pn1482","pn2112","pn1448","pn222","pn142","pn372"],"creator":"tjvg@di.fc.ul.pt","user":"tjvg@di.fc.ul.pt","label":"Wearables"},"design research evaluation":{"creationTime":1386522651776,"itemsUsedBy":["pn999"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"design research evaluation"},"display technology":{"creationTime":1386523961461,"itemsUsedBy":["pn1727"],"creator":"depaula@acm.org","user":"depaula@acm.org","label":"display technology"},"Workshops":{"creationTime":1386523318994,"itemsUsedBy":["pn2327"],"creator":"e.v.d.hoven@tue.nl","user":"e.v.d.hoven@tue.nl","label":"Workshops"},"design fiction":{"creationTime":1386522104615,"itemsUsedBy":["pn758","pn118"],"creator":"johnz@cs.cmu.edu","user":"johnz@cs.cmu.edu","label":"design fiction"},"public displays":{"creationTime":1386523992748,"itemsUsedBy":["pn1776","pn166","pn389","to105","pn1269"],"creator":"krueger@dfki.de","user":"krueger@dfki.de","label":"public displays"},"texting keeps up apart":{"creationTime":1386525515598,"itemsUsedBy":[],"creator":"beverly_harrison@yahoo.com","user":"beverly_harrison@yahoo.com","label":"texting keeps up apart"},"Location based technologies":{"creationTime":1386521451501,"itemsUsedBy":["pn1675"],"creator":"emailaddress","user":"emailaddress","label":"Location based technologies"},"Virtual Worlds":{"creationTime":1386526586323,"itemsUsedBy":["pn444"],"creator":"karyn.moffatt@mcgill.ca","user":"karyn.moffatt@mcgill.ca","label":"Virtual Worlds"},"Postcolonial Designing":{"creationTime":1386523352083,"itemsUsedBy":["pn2220"],"creator":"lirani@ucsd.edu","user":"lirani@ucsd.edu","label":"Postcolonial Designing"},"activism":{"creationTime":1386522869653,"itemsUsedBy":["pn763"],"creator":"teevan@gmail.com","user":"teevan@gmail.com","label":"activism"},"neurological disorders":{"creationTime":1386522975035,"itemsUsedBy":["pn1517"],"creator":"lennart.nacke@uoit.ca","user":"lennart.nacke@uoit.ca","label":"neurological disorders"},"SC_Beyond Individual":{"label":"SC_Beyond Individual","itemsUsedBy":["pn1375","pn2277","pn2343","pn677","pn2095","pn1675","pn763","pn1763","pn924","pn180","pn1123","pn558","pn1347","pn526","pn1558","pn2208","pn1343","pn1881","pn653","pn2235","pn1918","pn671","pn514","pn340","pn1330","pn2225","pn802","pn1333","pn2488","pn286","pn419","pn1642","pn1032","pn1470","pn1255","pn150","pn263","pn1954","pn1009","pn1867","pn590","pn1236","pn1727","pn2401","pn490","pn1296","pn751","pn641","pn2074","pn1341","pn1014","pn1896"],"user":"rcm","creator":"rcm","creationTime":1387315556618},"SC_Cap & Mod":{"label":"SC_Cap & Mod","itemsUsedBy":["pn734","pn966","pn241","pn183","pn1635","pn288","pn673","pn1225","pn796","pn138","pn916","pn1081","pn1983","pn111","pn395","pn1193","pn366","pn438","pn1992","pn728","pn648","pn371","pn1911","pn2424","pn235","pn2442","pn233","pn495","pn718","pn389","pn208","pn730","pn337","pn621","pn1628","pn549","pn1337","pn385","pn791","pn1587","pn1865","pn876","pn1586","pn1796","pn775","pn1472","pn2096","pn1186","pn1488"],"user":"rcm","creator":"rcm","creationTime":1387315644708},"SC_Design-R":{"label":"SC_Design-R","itemsUsedBy":["pn2129","pn586","pn1183","pn2016","pn2020","pn866","pn687","pn2327","pn2358","pn967","pn547","pn941","pn534","pn1517","pn2420","pn2303","pn1949","pn1518","pn701","pn2368","pn279","pn1252","pn1241","pn2216","pn1859","pn2046","pn118","pn576","pn1758","pn1448","pn1262","pn320"],"user":"rcm","creator":"rcm","creationTime":1387315711722},"SC_Design-B":{"label":"SC_Design-B","itemsUsedBy":["pn581","pn614","pn887","pn2048","pn1442","pn1095","pn1667","pn1452","pn810","pn1710","pn1268","pn2220","pn2193","pn1034","pn189","pn2330","pn1750","pn704","pn1190","pn1904","pn216","pn1820","pn1626","pn1942","pn758","pn555","pn999","pn2140","pn1682","pn1199","pn1709","pn1579","pn2406","pn2011","pn1428"],"user":"rcm","creator":"rcm","creationTime":1387315755893},"SC_Interaction Techniques":{"label":"SC_Interaction Techniques","itemsUsedBy":["pn654","pn2022","pn1473","pn222","pn1007","pn1883","pn794","pn2031","pn428","pn425","pn589","pn755","pn2041","pn977","pn343","pn1360","pn2451","pn2266","pn464","pn525","pn198","pn372","pn264","pn2454","pn1513","pn330","pn1222","pn2464","pn1336","pn1783","pn2090","pn1046","pn583","pn1936","pn142","pn529","pn2432","pn2029","pn2157","pn896","pn1872","pn1316","pn1200","pn2449","pn1583","pn147","pn756","pn228","pn113","pn2010","pn988","pn2372","pn1471","pn2441"],"user":"rcm","creator":"rcm","creationTime":1387315840543},"SC_People-V":{"label":"SC_People-V","itemsUsedBy":["pn1238","pn951","pn601","pn345","pn905","pn455","pn1227","pn1092","pn1295","pn1351","pn426","pn897","pn1425","pn361","pn119","pn750","pn1110","pn493","pn1242","pn1325","pn405","pn139","pn219","pn1417","pn1398","pn292","pn166","pn838","pn190","pn1203","pn1414","pn255","pn1071","pn400","pn420","pn785","pn386","pn657","pn1036","pn691","pn862","pn626","pn272","pn799"],"user":"rcm","creator":"rcm","creationTime":1387315946625},"SC_People-D":{"label":"SC_People-D","itemsUsedBy":["pn2159","pn2203","pn1932","pn1646","pn2128","pn1916","pn1982","pn1410","pn2175","pn1490","pn2463","pn2160","pn2317","pn2153","pn1901","pn1850","pn2328","pn2202","pn1806","pn2119","pn532","pn1742","pn2560","pn186","pn2417","pn1834","pn2294","pn2489","pn2117","pn1732","pn1978","pn2525","pn2105","pn1549","pn1760","pn2380","pn2394","pn1987","pn1756","pn1293"],"user":"rcm","creator":"rcm","creationTime":1387316032684},"SC_Systems & Tools":{"label":"SC_Systems & Tools","itemsUsedBy":["pn736","pn239","pn1460","pn672","pn1776","pn1503","pn2168","pn983","pn1485","pn224","pn1237","pn104","pn505","pn1161","pn1372","pn1179","pn2447","pn1969","pn1421","pn171","pn1426","pn271","pn2483","pn297","pn276","pn205","pn1958","pn313","pn1651","pn1057","pn650"],"user":"rcm","creator":"rcm","creationTime":1387316081819},"SC_Usability":{"label":"SC_Usability","itemsUsedBy":["pn116","pn435","pn2084","pn847","pn1269","pn2150","pn1257","pn2472","pn319","pn692","pn1020","pn965","pn643","pn1015","pn1722","pn2490","pn250","pn1188","pn1275","pn1521","pn1103","pn2027","pn602","pn639","pn898","pn1282","pn683","pn1818","pn1447","pn1099","pn1097","pn806","pn2003","pn2094","pn1670"],"user":"rcm","creator":"rcm","creationTime":1387316165002},"SC_TOCHI":{"creationTime":1386527699566,"itemsUsedBy":["to111","to104","to118","to106","to114","to128","to123","to107","to133","to120","to126","to102","to112","to113","to129","to105","to103","to122","to127","to117","to101","to134","to132","to131","to110","to136","to137","to108","to135"],"creator":"jeff@jeffreynichols.com","user":"jeff@jeffreynichols.com","label":"SC_TOCHI"},"SC_Applications-B":{"label":"SC_Applications-B","itemsUsedBy":["pn169","pn2227","pn155","pn737","pn1192","pn1617","pn248","pn1475","pn1976","pn1724","pn1811","pn2134","pn2399","pn1707","pn2054","pn2226","pn399","pn2103","pn2005","pn2244","pn2522","pn1399","pn757","pn2276","pn191","pn1525","pn1915","pn1454","pn2112","pn521","pn664"],"user":"rcm","creator":"rcm","creationTime":1387315446250},"SC_Applications-V":{"label":"SC_Applications-V","itemsUsedBy":["pn541","pn1632","pn1800","pn245","pn164","pn1704","pn739","pn1423","pn845","pn1264","pn1700","pn1482","pn121","pn714","pn1171","pn975","pn1923","pn444","pn1569","pn1773","pn2115","pn1055","pn2001","pn2242","pn906","pn1281","pn122","pn404"],"user":"rcm","creator":"rcm","creationTime":1387315486589},"SC_Applications-W":{"label":"SC_Applications-W","itemsUsedBy":["pn2293","pn1413","pn1623","pn2284","pn1120","pn1182","pn1684","pn884","pn761","pn1821","pn1736","pn1377","pn1354","pn950","pn1446","pn1514","pn2214","pn787","pn2268","pn686","pn1290","pn1298","pn2274","pn1745","pn883","pn1362","pn431","pn1845","pn2487","pn223","pn1817","pn1814","pn2200","pn443"],"user":"rcm","creator":"rcm","creationTime":1387315188154},"Models":{"label":"Models","itemsUsedBy":["pn1742"],"user":"Tovi.Grossman@autodesk.com","creator":"Tovi.Grossman@autodesk.com","creationTime":1388783382686},"was touch:grip before":{"label":"was touch:grip before","itemsUsedBy":["pn1916","pn1057","pn583","pn2394","pn426","pn730"],"user":"albrecht.schmidt@vis.uni-stuttgart.de","creator":"albrecht.schmidt@vis.uni-stuttgart.de","creationTime":1389105496485},"was Viz Vis Aesthetics":{"label":"was Viz Vis Aesthetics","itemsUsedBy":["pn1667"],"user":"albrecht.schmidt@vis.uni-stuttgart.de","creator":"albrecht.schmidt@vis.uni-stuttgart.de","creationTime":1389107287830},"was Vis Vis Sys design":{"label":"was Vis Vis Sys design","itemsUsedBy":["pn1503"],"user":"albrecht.schmidt@vis.uni-stuttgart.de","creator":"albrecht.schmidt@vis.uni-stuttgart.de","creationTime":1389107397371}},"categoryCompletion":{"completedItemIds":["pn1623","pn1626","pn1628","pn2150","pn2153","pn2029","pn1710","pn626","pn2159","pn444","pn2157","pn464","pn601","pn602","pn1099","pn1092","pn1097","pn264","pn263","pn116","pn111","pn113","pn119","pn118","pn965","pn286","pn967","pn288","pn761","pn1161","pn1362","pn1360","pn847","pn845","pn1942","pn1949","pn2447","pn2442","pn2441","pn2449","pn2140","pn1896","pn2020","pn2022","pn2031","pn2027","pn1763","pn1760","pn1421","pn1423","pn1425","pn1426","pn1428","pn1399","pn1398","pn614","pn1081","pn279","pn271","pn272","pn276","pn104","pn297","pn292","pn1171","pn1179","pn1375","pn1377","pn1372","pn621","pn2522","pn2525","pn1954","pn1958","pn2454","pn2451","pn1883","pn1881","pn2041","pn2046","pn1773","pn1776","pn1414","pn1417","pn1410","pn1413","pn2193","pn590","pn1569","pn443","pn139","pn138","pn916","pn1188","pn1186","pn1182","pn1183","pn1341","pn1343","pn1347","pn1969","pn2463","pn2464","pn2293","pn2294","pn589","pn583","pn581","pn586","pn1579","pn455","pn121","pn122","pn906","pn905","pn1199","pn1190","pn1193","pn1192","pn639","pn1354","pn1351","pn838","pn2128","pn1978","pn1009","pn1976","pn169","pn2472","pn532","pn1750","pn1756","pn1758","pn1992","pn2266","pn1503","pn2084","pn337","pn330","pn150","pn155","pn1745","pn1325","pn1742","pn806","pn802","pn1036","pn1034","pn1032","pn1987","pn1982","pn1983","pn1667","pn2401","pn2406","pn2317","pn2074","pn2274","pn2277","pn2276","pn1513","pn1514","pn1517","pn1518","pn2095","pn2094","pn2096","pn2090","pn495","pn490","pn320","pn1200","pn1203","pn924","pn142","pn147","pn1330","pn1333","pn1337","pn1336","pn810","pn1020","pn796","pn2417","pn1682","pn1684","pn2303","pn2242","pn2244","pn1549","to108","to105","to104","to107","to106","to101","to103","to102","pn1525","pn1521","pn319","pn313","pn1238","pn799","pn1236","pn1237","pn558","pn730","pn555","pn951","pn950","pn734","pn736","pn1014","pn1015","pn2424","pn2420","pn1646","pn1834","pn2330","pn426","pn1586","pn1642","pn1587","to122","to127","pn1783","to118","pn1651","to117","to114","to112","to113","to110","pn1227","pn1225","pn1222","pn785","pn787","pn549","pn547","pn541","pn941","pn763","pn1316","pn164","pn1007","pn2432","pn1821","pn1820","pn2328","pn2327","pn1796","pn2220","pn2226","pn2227","pn2225","to129","to123","pn2134","to120","pn1558","pn1635","pn1252","pn1257","pn1255","pn1490","pn576","pn751","pn750","pn208","pn205","pn687","pn686","pn371","pn372","pn757","pn756","pn755","pn977","pn198","pn975","pn999","pn1103","pn1818","pn1811","pn1814","pn1817","pn2358","pn2235","to134","to135","to136","to137","to131","to132","to133","pn1704","pn1670","pn1675","pn1709","pn1241","pn1242","pn1482","pn1485","pn1488","pn219","pn216","pn692","pn691","pn361","pn366","pn189","pn186","pn180","pn983","pn988","pn1110","pn1071","pn191","pn1806","pn1800","pn1904","pn2343","pn1901","pn2208","pn2200","pn2202","pn2203","pn2119","pn2112","pn2115","pn2117","pn1275","pn514","pn1475","pn1472","pn1473","pn1470","pn1471","pn739","pn228","pn223","pn222","pn737","pn224","pn428","pn425","pn794","pn641","pn643","pn648","pn791","pn1055","pn1057","pn1296","pn1295","pn1293","pn1290","pn1298","pn2268","pn1120","pn1123","pn775","pn1872","pn896","pn2372","pn897","to126","pn2216","pn2214","pn2105","pn2103","pn183","pn1617","pn1727","pn1724","pn1722","pn1269","pn1268","pn1262","pn1264","pn505","pn1460","pn1583","pn728","pn438","pn345","pn657","pn654","pn653","pn650","pn1046","pn235","pn233","pn239","pn1865","pn1867","pn2368","pn966","pn2560","pn171","pn1918","pn1915","pn1916","pn1911","to111","pn2175","pn2054","pn1736","pn1732","pn2005","pn2003","pn2001","pn1452","pn534","pn1454","pn400","pn405","pn404","pn664","pn887","pn884","pn883","pn395","pn399","pn241","pn714","pn245","pn248","pn718","pn435","pn2483","pn2487","pn2488","pn2489","pn866","pn2284","pn1859","pn1850","pn340","pn2399","pn2129","pn2394","pn343","pn431","pn1923","pn2160","pn1632","pn2168","pn1700","pn1707","pn2016","pn2011","pn2010","pn1447","pn1446","pn1442","pn1448","pn529","pn521","pn525","pn526","pn493","pn419","pn1281","pn898","pn677","pn671","pn672","pn673","pn389","pn385","pn386","pn701","pn250","pn704","pn255","pn2490","pn876","pn758","pn420","pn1845","pn2380","pn1936","pn1932","pn1282"],"incompletedItemIds":["pn1095","pn2048","pn166","to128","pn683","pn190","pn862"]},"acceptedPapers":["to101","to102","to103","to104","to105","to106","to107","to108","to110","to111","to112","to113","to114","to117","to118","to120","to122","to123","to126","to127","to128","to129","to131","to132","to133","to134","to135","to136","to137","pn150","pn180","pn263","pn286","pn340","pn419","pn490","pn514","pn526","pn558","pn590","pn641","pn653","pn671","pn677","pn751","pn763","pn802","pn924","pn1009","pn1014","pn1032","pn1123","pn1236","pn1255","pn1296","pn1330","pn1333","pn1341","pn1343","pn1347","pn1375","pn1470","pn1558","pn1642","pn1675","pn1727","pn1763","pn1867","pn1881","pn1896","pn1918","pn1954","pn2074","pn2095","pn2208","pn2225","pn2235","pn2277","pn2343","pn2401","pn2488","pn155","pn169","pn191","pn248","pn399","pn521","pn664","pn737","pn757","pn1192","pn1399","pn1454","pn1475","pn1525","pn1617","pn1707","pn1724","pn1811","pn1915","pn1976","pn2005","pn2054","pn2103","pn2112","pn2134","pn2226","pn2227","pn2244","pn2276","pn2399","pn2522","pn189","pn216","pn555","pn581","pn614","pn704","pn758","pn810","pn887","pn999","pn1034","pn1095","pn1190","pn1199","pn1268","pn1428","pn1442","pn1452","pn1579","pn1626","pn1667","pn1682","pn1709","pn1710","pn1750","pn1820","pn1904","pn1942","pn2011","pn2048","pn2140","pn2193","pn2220","pn2330","pn2406","pn118","pn279","pn320","pn534","pn547","pn576","pn586","pn687","pn701","pn866","pn941","pn967","pn1183","pn1241","pn1252","pn1262","pn1448","pn1517","pn1518","pn1758","pn1859","pn1949","pn2016","pn2020","pn2046","pn2129","pn2216","pn2303","pn2327","pn2358","pn2368","pn2420","pn104","pn171","pn205","pn224","pn239","pn271","pn276","pn297","pn313","pn505","pn650","pn672","pn736","pn983","pn1057","pn1161","pn1179","pn1237","pn1372","pn1421","pn1426","pn1460","pn1485","pn1503","pn1651","pn1776","pn1958","pn1969","pn2168","pn2447","pn2483","pn119","pn139","pn166","pn190","pn219","pn255","pn272","pn292","pn345","pn361","pn386","pn400","pn405","pn420","pn426","pn455","pn493","pn601","pn626","pn657","pn691","pn750","pn785","pn799","pn838","pn862","pn897","pn905","pn951","pn1036","pn1071","pn1092","pn1110","pn1203","pn1227","pn1238","pn1242","pn1295","pn1325","pn1351","pn1398","pn1414","pn1417","pn1425","pn1120","pn1182","pn1290","pn1298","pn1354","pn1362","pn1377","pn1413","pn1446","pn1514","pn1623","pn1684","pn1736","pn1745","pn1814","pn1817","pn1821","pn1845","pn2200","pn2214","pn223","pn2268","pn2274","pn2284","pn2293","pn2487","pn431","pn443","pn686","pn761","pn787","pn883","pn884","pn950","pn121","pn122","pn164","pn245","pn404","pn444","pn541","pn714","pn739","pn845","pn906","pn975","pn1055","pn1171","pn1264","pn1281","pn1423","pn1482","pn1569","pn1632","pn1700","pn1704","pn1773","pn1800","pn1923","pn2001","pn2115","pn2242","pn116","pn250","pn319","pn435","pn602","pn639","pn643","pn683","pn692","pn806","pn847","pn898","pn965","pn1015","pn1020","pn1097","pn1099","pn1103","pn1188","pn1257","pn1269","pn1275","pn1282","pn1447","pn1521","pn1670","pn1722","pn1818","pn2003","pn2027","pn2084","pn2094","pn2150","pn2472","pn2490","pn111","pn138","pn183","pn208","pn233","pn235","pn241","pn288","pn337","pn366","pn371","pn385","pn389","pn395","pn438","pn495","pn549","pn621","pn648","pn673","pn718","pn728","pn730","pn734","pn775","pn791","pn796","pn876","pn916","pn966","pn1081","pn1186","pn1193","pn1225","pn1337","pn1472","pn1488","pn1586","pn1587","pn1628","pn1635","pn1796","pn1865","pn1911","pn1983","pn1992","pn2096","pn2424","pn2442","pn186","pn532","pn1293","pn1410","pn1490","pn1549","pn1646","pn1732","pn1742","pn1756","pn1760","pn1806","pn1834","pn1850","pn1901","pn1916","pn1932","pn1978","pn1982","pn1987","pn2105","pn2117","pn2119","pn2128","pn2153","pn2159","pn2160","pn2175","pn2202","pn2203","pn2294","pn2317","pn2328","pn2380","pn2394","pn2417","pn2463","pn2489","pn2525","pn2560","pn113","pn142","pn147","pn198","pn222","pn228","pn264","pn330","pn343","pn372","pn425","pn428","pn464","pn525","pn529","pn583","pn589","pn654","pn755","pn756","pn794","pn896","pn977","pn988","pn1007","pn1046","pn1200","pn1222","pn1316","pn1336","pn1360","pn1471","pn1473","pn1513","pn1583","pn1783","pn1872","pn1883","pn1936","pn2010","pn2022","pn2029","pn2031","pn2041","pn2090","pn2157","pn2266","pn2372","pn2432","pn2441","pn2449","pn2451","pn2454","pn2464"],"completionLastUpdated":1390664589476,"categories":{},"history":{"locations":[],"events":[]}}